{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b6329b-d65c-484b-8a3f-2df7b26c717b",
   "metadata": {},
   "source": [
    "## Evaluate Llama output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "0b1a421e-6ff6-43cd-805a-ff17af2f3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bert_score import plot_example\n",
    "from bert_score import score\n",
    "import utils_llama as ulla\n",
    "from smatch import amr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sacrebleu\n",
    "import evaluate\n",
    "import random\n",
    "import pickle\n",
    "import smatch\n",
    "import nltk\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e8c46f15-85c3-4aa1-8ea2-dd953c4e0ebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smatch in c:\\users\\sanne\\anaconda3\\lib\\site-packages (1.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install smatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "16e6734b-21e8-4f5e-9c42-ead527450597",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_llama = 'last_results_llama.pkl'\n",
    "results = pickle.load(open(results_llama, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43c5b0ff-66e1-43ab-8187-e05a92fe1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/all_merged_data.pkl\", \"rb\") as f:\n",
    "    all_merged_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8e9f5aeb-2e65-4ef8-9bd8-81da45ed2b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"sentence\": \"Look at the location in front of you.\", \"speech AMR\": \"(d/deixis-GA :ARG0 (s/signaler) :ARG1 (f/front) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate that the right arm is moving forward, pointing to a location. Then, it moves down and the hand forms a claw shape, before moving up again and pointing forward once more. This sequence of movements suggests that the speaker is directing attention to a specific location in front of them. The gesture AMR confirms this interpretation, with the location being the ARG1.\"}]\n",
      "so put put a block on the back block good\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Put the block in the location, then put another block there.\", \"speech AMR\": \"(s/put-01 :ARG0 (b/block) :location (l/location)) (a/and :op1 (s/put-02 :ARG0 (b2/block) :location (l2/location)))\", \"explanation\": \"The gesture label indicates that the arms move down into a gap on the left, and the hands are in a claw position. This suggests two separate actions: putting a block in a location, and then putting another block there. The gesture AMR reflects this structure with two gesture units, each representing one of these actions.\"}]\n",
      "put two blocks\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Put the block down.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block :mod (d/down)) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate that the arms are rotating and the hands are in a claw position, pointing downwards. This suggests an action of putting something down. The gesture AMR shows two gesture units combined with 'and', which indicates a sequential action. The first unit is an icon representing the action of putting (p/put-01), and the second unit is a deixis indicating the location where the block should be put.\"}]\n",
      "um\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Point to the location.\", \"speech AMR\": \"(d/deixis-01 :mode declarative :ARG0 (y/you) :ARG1 (l/location))\", \"explanation\": \"The gesture label indicates that the speaker is moving their hand up and pointing forward, which corresponds to a deixis gesture. The speech AMR reflects this by indicating that the speaker is performing a deixis action, with the location as the target of the action.\"}]\n",
      "and then put one on the top\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"I'm grabbing two blocks.\", \"speech AMR\": \"(i/icon-GA :ARG0 (s/signaler) :ARG1 (g/grab-01 :ARG1 (b/block :quant 2)) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate a downward movement of the arms and hands into a claw shape, suggesting a grasping action. The second set of gestures shows an upward movement of the arms with hands still in a claw shape, which could imply a closing or holding action. The speech AMR reflects this by including 'grab-01' as the icon, indicating a specific type of grasp, and specifying that two blocks are being grabbed.\"}]\n",
      "no that doesn't look like it’s going to work\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Look up there.\", \"speech AMR\": \"(d/deixis-GA :ARG0 (s/signaler) :ARG1 (u/up) :ARG2 (t/there))\", \"explanation\": \"The gesture label indicates that the body is still, and the RA moves up. This suggests a pointing or indicating action, which corresponds to the deictic gesture in the Gesture AMR. The RH clawing down is not directly related to the speech AMR, but it could be interpreted as an emphasis on the direction of the gaze.\"}]\n",
      "yes\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Point to the block, then count them.\", \"speech AMR\": \"(c/count-01 :mode imperative :ARG0 (s/signaler) :ARG1 (a/actor)) (d/deixis-GA :ARG0 s :ARG1 b/block :ARG2 a)\", \"explanation\": \"The gesture labels indicate that the right arm moves to point to something in front, and then the hand shakes down. This is followed by the hand moving into a pointing position again, but this time in a forward direction. The unknown label suggests a pause or break between gestures. In the gesture AMR, there are three units: (1) an icon representing a jiggle gesture, indicating expressive mode; (2) a deixis gesture pointing to two blocks, and (3) another deixis gesture pointing to one block. Based on this, we can infer that the speaker is pointing to multiple blocks and then counting them.\"}]\n",
      "so jiggle the go\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"You're okay.\", \"speech AMR\": \"(e/emblem-GA :ARG0 (s/signaler) :ARG1 (o/ok) :ARG2 (a/actor))\", \"explanation\": \"The gesture label indicates that the arms move up and hands open in front, which is a common emblem for 'okay'. The speech AMR reflects this interpretation.\"}]\n",
      "good enough\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Point to the block.\", \"speech AMR\": \"(p/point-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block))\", \"explanation\": \"The gesture labels indicate that the hands are shaking closed and then pointing down, which suggests a pointing action. The arms moving down further emphasizes this action. In the gesture AMR, the mode is expressive, indicating that the action is being performed for emphasis or to convey information. The ARG1 of the point-01 action is set to (b/block), which corresponds to the block referred to in the gesture labels.\"}]\n",
      "and then jiggle the two in front of them\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Point to the location in front of you, then put it down.\", \"speech AMR\": \"(p/put-01 :op1 (d/deixis-GA :ARG0 s :ARG1 l :ARG2 a) :op2 (i/icon-GA :ARG0 s :ARG1 p :ARG2 a))\", \"explanation\": \"The gesture label indicates that the speaker is pointing to a location in front of them and then putting something down. The gesture AMR reflects this, with the first operation being a deixis (pointing) to a location, and the second operation being an icon (putting) of the spread action.\"}]\n",
      "take another block put it next to it\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Point to the location in front of you.\", \"speech AMR\": \"(d/deixis-GA :ARG0 (y/you) :ARG1 (l/location) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate that the right arm is moving into a pointing position, and the left arm is moving towards the front. The gesture AMR shows a deixis gesture, which indicates pointing to a location, so we can infer that the speaker wants the listener to point to a location in front of them.\"}]\n",
      "okay\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Put it over there.\", \"speech AMR\": \"(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (i/it) :ARG2 (o/over-there))\", \"explanation\": \"The gesture labels indicate that the speaker is pointing to a location with their arm and hand, which corresponds to the 'deixis-GA' component in the Gesture AMR. The subsequent gestures of rotating arms and hands into point, followed by moving down, suggest the action of placing or putting something. The final gestures of RA moving up and RH into point left indicate the direction of the location where the object should be placed.\"}]\n",
      "one block on top of each of those two\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"It's okay.\", \"speech AMR\": \"(e/emblem-GA :ARG0 (s/signaler) :ARG1 (o/ok) :ARG2 (a/actor))\", \"explanation\": \"The gesture label is unknown, but the gesture AMR indicates an emblem gesture with ARG1 being 'o/ok', which corresponds to a positive or affirmative meaning. Therefore, the generated sentence and speech AMR reflect this interpretation.\"}]\n",
      "perfect grab\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"I'm going to slide this forward, touch it, and then hold still.\", \"speech AMR\": \"(i/icon-GA :ARG0 (s/signaler) :ARG1 (s2/slide-01 :direction (f/forward))) (i/icon-GA :ARG0 (s/signaler) :ARG1 (t/touch-01)) (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate a series of movements and actions: sliding something forward, touching it, and then holding still. The first two gestures match the icon-GA AMR, indicating an action performed by the signaler on the slide or touch. The third gesture matches the deixis-GA AMR, indicating a location or actor involved in the action.\"}]\n",
      "and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"I don't understand.\", \"speech AMR\": \"(g/dont-know :mode declarative :ARG0 (i/i) :mod (n/no))\", \"explanation\": \"The gesture labels indicate a lack of understanding or confusion, with arms apart and hands inching down. The LA moving right and LH/RH closing down suggests a sense of uncertainty or puzzlement. In the speech AMR, 'I don't understand' is used to convey this sentiment in a declarative mode.\"}]\n",
      "only two of them\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Point to the left, then down.\", \"speech AMR\": \"(i/implicit-predicate-00 :mode imperative :ARG0 (y/you) :ARG1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) :manner (p/point)) (i/implicit-predicate-00 :mode imperative :ARG0 (y/you) :ARG1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) :manner (d/down))\", \"explanation\": \"The gesture AMR indicates two separate actions: pointing to the left and then down. The speech AMR is generated accordingly, with each action represented as an implicit predicate in imperative mode.\"}]\n",
      "place it on the two that are diagonal and\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Move them this way, like you had it before.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (t/them) :direction (d/direction :mod (t2/this)) :ARG1-of (l/like-04 :ARG2 (h/have-04 :ARG0 y :ARG1 (i/it) :time (b/before)))\", \"explanation\": \"The gesture labels indicate a movement of the left arm forward, with the right hand closed and the right arm moving backward. The hands then move down to the back in a fist shape. This corresponds to flipping something, which is indicated by the icon-GA 'f/flip-01'. The emblem-GA 'n/no' suggests negation or opposition, implying that the speaker wants to do it differently. Therefore, the sentence should be about moving something in a certain way, like before.\"}]\n",
      "flip those two\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"They're going to be all connected.\", \"speech AMR\": \"(c/connect-01 :ARG1 (t/they))\", \"explanation\": \"The gesture label 'arms: move, down back' and 'hands: facing, into fist' implies a connection or union of something. The gesture AMR indicates rotation, which can be interpreted as bringing things together to form a connection. Therefore, the sentence generated is in the present tense, indicating an action that will happen.\"}]\n",
      "keep going a little bit more\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Move back and then move forward into the gap on the left.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/back) :time (t/then)) (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (i/into-04 :ARG2 (g/gap :mod (l/left))))\", \"explanation\": \"The gesture label indicates that the arms move down back, then front into a gap on the left. The hands also perform different actions during these movements. The speech AMR reflects this sequence of movement and direction.\"}]\n",
      "just like that but closer together\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Look at that.\", \"speech AMR\": \"(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate a forward movement and pointing downwards with the left hand, which is typically associated with directing attention to a location. The gesture AMR confirms this interpretation by indicating deixis (pointing or showing) towards a location.\"}]\n",
      "doesn't matter\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Put the object together in front of you.\", \"speech AMR\": \"(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (o/object) :ARG2 (t/together :location (f/front :poss y)))\", \"explanation\": \"The gesture label(s) indicate that the speaker is pointing to an object and moving their arms together, suggesting a command to put the object in front of the listener. The speech AMR reflects this interpretation, with 'put' as the main verb and 'together' as a location for the object.\"}]\n",
      "move those together a little bit closer and then put that on top yay\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Push together\", \"speech AMR\": \"(i/icon-GA :op1 (p/push-01 :mode imperative :ARG0 (y/you) :ARG1 (t/together) :ARG2 (a/actor)))\", \"explanation\": \"The gesture label indicates that the arms are moving together to the left, which corresponds to the ARG1 'together' in the gesture AMR. The body being still suggests an imperative mode, and the actor is implied to be the speaker themselves.\"}]\n",
      "put them together\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"The block is over there, and it's two.\", \"speech AMR\": \"(s/is-01 :ARG1 (b/block) :mod (d/deixis-GA :ARG0 (t/there) :ARG1 (a/actor)) :op2 (i/icon-GA :mode expressive :ARG0 s :ARG1 2 :ARG2 a))\", \"explanation\": \"The gesture label indicates that the speaker is pointing to something behind them with their right hand, and then moving their left arm back while facing forward. The speech AMR represents this as 'the block' being in a location indicated by deixis (pointing), and also specifying that there are two of them.\"}]\n",
      "two more blocks up\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"I agree.\", \"speech AMR\": \"(e/emblem-GA :ARG0 (s/signaler) :ARG1 (y/yes) :ARG2 (a/actor))\", \"explanation\": \"The gesture label 'head: nod' is associated with the emblem-GA relation, which typically indicates agreement or confirmation. The speech AMR reflects this by using the 'yes' slot to indicate agreement.\"}]\n",
      "yep\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"That's correct.\", \"speech AMR\": \"(y/yes :ARG0 (s/signaler) :ARG1 (t/correct-01 :ARG0 (a/actor)))\", \"explanation\": \"The gesture labels indicate a nod, which typically indicates agreement or confirmation. The arms being together and hands facing also suggest a sense of unity or confirmation. The presence of an emblem-GA in the gesture AMR further supports this interpretation, as it represents a symbol or sign that conveys a specific meaning.\"}]\n",
      "go near yeah\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Come here.\", \"speech AMR\": \"(c/come-01 :mode imperative :ARG0 (y/you) :location (h/here))\", \"explanation\": \"The gesture labels indicate a series of movements that convey the meaning 'come here'. The arms moving up front and hands into facing, closed position suggest pointing or indicating direction. The beckon gesture further emphasizes the invitation to come closer. Finally, the arms moving down and hands returning to facing, closed position implies a sense of completion or finality, as if saying 'you're welcome' or 'it's done'. The speech AMR reflects this interpretation by using the verb 'come' in an imperative mode with the location specified as 'here', indicating that the speaker is inviting someone to move towards them.\"}]\n",
      "and uh one block uh ahead of it\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Pick up the block.\", \"speech AMR\": \"(p/put :mode imperative :ARG0 (y/you) :ARG1 (b/block) :location (g/gap :mod (l/left)))\", \"explanation\": \"The gesture label indicates that the arms are moving upwards in front, into a gap on the left. This suggests picking up an object from a location. The hands are initially facing and closed, which implies grasping or picking up. Then, the arms move downwards with the hands in a claw-like position, indicating holding or carrying something.\"}]\n",
      "put one block wherever you want\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Put it to the right.\", \"speech AMR\": \"(p/put-01 :ARG0 (s/signaler) :ARG1 (t/to-the-right) :ARG2 (a/actor))\", \"explanation\": \"The gesture AMR indicates that the signaler is performing a put action on an object, and then sliding it to the right. The speech AMR reflects this by specifying the direction of the slide as 'to the right'. The sentence generated from this information is 'Put it to the right.'\"}]\n",
      "the first block you put it the one nearest and the right side of it\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Put the block in space.\", \"speech AMR\": \"(p/put-01 :mode imperative :polarity + :ARG0 (y/you) :ARG1 (b/block) :ARG2 (s/space))\", \"explanation\": \"The gesture label indicates that the arms are moving apart, and the hands are facing inwards. This suggests a 'put' action. The second icon-GA indicates that the block is being put into space.\"}]\n",
      "we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"No, go back to the top.\", \"speech AMR\": \"(e/enough-01 :ARG2 (n/no)) (d/deixis-GA :mode expressive :ARG0 (s/signaler) :ARG1 (b/backward) :ARG2 (a/actor)) (i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (t/top) :ARG2 (a/actor))\", \"explanation\": \"The gesture AMR indicates that the speaker is expressing a negative sentiment ('n/no') and pointing backwards. The 'top' icon suggests moving to the top, which is likely in response to the initial 'no'. Therefore, the sentence generated is 'No, go back to the top.'\" }]\n",
      "but that should be on top on top of the of the other blocks yeah\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"I'm separating myself from you.\", \"speech AMR\": \"(i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (a/apart) :ARG2 (a2/actor))\", \"explanation\": \"The gesture labels indicate that the arms are shaking and then moving apart, which suggests a separation or distinction between two entities. The gesture AMR confirms this interpretation by indicating that the mode is expressive and the action is 'apart', which means separating oneself from something or someone.\"}]\n",
      "can you just open it open it a little bit uh\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"He is standing in front of the block.\", \"speech AMR\": \"(s/infront-01 :ARG0 (h/he) :location (i2/in :op1 (l/left :mod (f/front))) :ARG2 (b/block))\", \"explanation\": \"The gesture label indicates that the arms are apart and to the left, which suggests a wide stance or position. The hands are into facing, left, closed, which implies that he is standing in front of something. The gesture AMR supports this interpretation by indicating that the ARG1 (block) is located at the location specified by the op1 (left) modifier.\"}]\n",
      "(unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Move the block up.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block :mod (t/top))\", \"explanation\": \"The gesture label indicates that the arms are moving up, and the hands are facing into a gap. The LA is also moving down, which suggests an action of moving something upwards. The RH is moving to face, which implies a direction or orientation. The RA is moving down, but this seems contradictory to the initial movement of the arms up. However, considering the overall gesture unit, it's likely that the block is being moved from a lower position to a higher one, hence the speech AMR reflects an action of moving the top of the block upwards.\"}]\n",
      "then the next row is just three on top of that in the middle of those gaps\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Stand apart and then bring your hands together in a fist.\", \"speech AMR\": \"(a/and :op1 (s/stand-apart-01 :mode imperative :ARG0 (y/you) :ARG1 (s/splayed) :time (t3/then)) :op2 (h/have-03 :ARG0 (i/implicit-role :quant 2) :ARG1 (f/fist)))\", \"explanation\": \"The gesture label indicates that the arms are apart and then into a gap, which suggests standing apart. The hands are then into a fist, indicating a specific hand movement. The speech AMR reflects this by using the 'stand-apart-01' predicate to indicate the initial position of the arms, and the 'have-03' predicate with the implicit role quantifier 2 to indicate that the hands are brought together in a fist.\"}]\n",
      "kind of splayed yeah\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Move down.\", \"speech AMR\": \"(i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (m/move-01 :ARG2 (c/close-10)) :ARG2 (a/actor))\", \"explanation\": \"The gesture label indicates that the right arm (RA) is moving down, which corresponds to the 'move' action in the gesture AMR. The speech AMR is generated directly from the gesture AMR, as it already represents the intended meaning of the gesture in a standardized format.\"}]\n",
      "come evenly there\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Look up and down.\", \"speech AMR\": \"(h/have-91 :ARG0 (a/actor) :ARG1 (l/look))\", \"explanation\": \"The gesture labels indicate that the arms are moving up and then down, suggesting a movement of looking up and down. The speech AMR is generated based on this interpretation, with 'have' as the main verb, 'actor' as the subject performing the action, and 'look' as the object of the action.\"}]\n",
      "like an angle\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Make a curve with your hand, then move it apart and bring it back down.\", \"speech AMR\": \"(m/make-01 :mode imperative :ARG0 (y/you) :ARG1 (c/curve) :direction (r/right) :ARG2 (a/actor)) (s/spread-03 :mode imperative :ARG0 (y/you) :ARG1 (t/them) :direction (a/apart) :quant (b/bit :mod (l/little))) (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (c/curve) :direction (d/down))\", \"explanation\": \"The gesture label indicates that the speaker is making a curve with their hand, then moving it apart and bringing it back down. The speech AMR reflects this by first describing the action of making a curve, then spreading something apart, and finally moving something downwards.\"}]\n",
      "and it's going to be like a fan or sound wave going out\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"The speaker is holding up four fingers in front of them.\", \"speech AMR\": \"(i/icon-GA :ARG0 (s/signaler) :ARG1 4 :ARG2 (a/actor))\", \"explanation\": \"The gesture label indicates that the right arm (RA) is moving upwards, and the right hand (RH) is forming a 'four' shape in front of the body. The speech AMR reflects this by specifying that the signaler (speaker) is using an icon (holding up fingers) to indicate the number 4.\"}]\n",
      "i need four base again\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Move it up to four and then down to three.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 4 :cause-of (i/increase-01 :ARG1 3) :cause-of (d/decrease-01 :ARG1 3))\", \"explanation\": \"The gesture labels indicate that the right arm moves up to four and then down to three. The speech AMR reflects this sequence of actions, with 'move' as the main action, and 'increase' and 'decrease' as secondary actions to specify the direction of movement.\"}]\n",
      "the next one is three on top of those\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Look over there.\", \"speech AMR\": \"(l/look :op1 (o/over-there :op1 (t/that)))\", \"explanation\": \"The gesture labels indicate a pointing action, which is typically associated with the meaning of looking or indicating something. The LA moving to the right and LH rotating closed down suggest a pointing action towards the right. The gesture AMR has two instances of deixis-GA, which indicates a pointing action. Therefore, the sentence 'Look over there' and speech AMR '(l/look :op1 (o/over-there :op1 (t/that)))' are generated.\"}]\n",
      "then you're going to put one right next to it and one right next to that\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Look over there.\", \"speech AMR\": \"(d/deixis-GA :ARG0 (y/you) :ARG1 (t/there) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate the speaker pointing upwards with their left arm and then keeping still, suggesting a deictic gesture. The speech AMR reflects this by indicating the speaker as the actor, the location as 'there', and the actor as the person being pointed at.\"}]\n",
      "you're gonna have one block\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Move the block to the left and then shake it.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block) :ARG2 (l/left)) (s/shake-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block))\", \"explanation\": \"The gesture labels indicate that the right arm moves up and left, then shakes, and finally moves down to the right while rotating. This suggests a sequence of actions involving moving an object to a location on the left, followed by shaking it.\"}]\n",
      "there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Look at the location below.\", \"speech AMR\": \"(d/deixis-GA :ARG0 (y/you) :ARG1 (l/location) :ARG2 (b/below))\", \"explanation\": \"The gesture label RA: move, up; RH: into open, down indicates a pointing action towards a location below. The gesture AMR d/deixis-GA represents a deictic gesture, which is used to point or indicate a location. In this case, the ARG0 (y/you) indicates that the speaker is directing the attention of the listener (ARG2 (a/actor)) to the location (ARG1 (l/location)) below.\"}]\n",
      "yeah right\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Put the top on.\", \"speech AMR\": \"(p/put-01 :ARG1 (t/top) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate that the speaker is moving their body up, and then the right arm moves up to shake something down. This suggests putting a top on an object. The final still gesture indicates completion of the action.\"}]\n",
      "the final one is just pretty much exactly on top of it\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Put it on the left.\", \"speech AMR\": \"(g/grab-01 :mode imperative :ARG0 (y/you) :ARG1 (p/place-01 :location (l/left)) :mod (i/icon-GA :ARG0 (s/signaler) :ARG1 (p/put-01) :ARG2 (a/actor)))\", \"explanation\": \"The gesture AMR indicates that the signaler is performing an action of putting something, and the actor is involved. The arms moving up into a gap on the left suggests placing or positioning something on the left side. The hands then move down to an open position, indicating completion of the action. The speech AMR reflects this by using the verb 'put' in imperative mode, with the location specified as 'left'. The icon-GA slot is used to indicate that the signaler is performing a putting action.\"}]\n",
      "pushed off like the same direction\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"You are indicating something in the location.\", \"speech AMR\": \"(i/implicit-predicate-00 :mode declarative :ARG0 (s/signaler) :ARG1 (l/location))\", \"explanation\": \"The gesture labels indicate a still body, moving arms to the left, rotating head and then moving arms back. This suggests that the speaker is indicating something in a specific location, which corresponds to the first gesture unit in the Gesture AMR. The second gesture unit indicates an icon of a block at a location, but this seems out of place given the initial gesture. The third gesture unit is an emblem of 'yes', which doesn't seem relevant to the initial gestures. Therefore, we focus on the first gesture unit and interpret it as indicating something in the location.\"}]\n",
      "a block space and on a third block\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Move your head down, then move it to the left.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (h/head) :direction (d/direction :mod (d/down))) (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (h/head) :direction (d/direction :mod (l/left)))\", \"explanation\": \"The gesture labels indicate that the head is moving down and then to the left. The first speech AMR corresponds to the head moving down, with the direction specified as 'down'. The second speech AMR corresponds to the head moving to the left, with the direction specified as 'left'.\"}]\n",
      "then on like the same line you're going to have a space\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"That's correct.\", \"speech AMR\": \"(y/yes-01 :mode declarative :ARG0 (s/signaler) :ARG1 (l/location))\", \"explanation\": \"The gesture label indicates a nod of the head, which is often used to indicate agreement or confirmation. The gesture AMR for 'emblem-GA' with 'y/yes' as the argument matches this interpretation. Therefore, the generated sentence and speech AMR reflect an affirmative response.\"}]\n",
      "over the space in between the blocks so it’ll be on\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Move the block in front of you, then move it to the left.\", \"speech AMR\": \"(a/and :op2 (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block) :quant (f/front)) :op3 (m/move-02 :mode imperative :ARG0 (y/you) :ARG1 (b/block) :quant (l/left)))\", \"explanation\": \"The gesture label indicates that the speaker is moving their arm in front and then to the left, which corresponds to the speech AMR indicating movement of the block in front and then to the left. The head shake gesture may indicate a change or emphasis on the direction of movement.\"}]\n",
      "what one less than\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"You're moving your arms diagonally.\", \"speech AMR\": \"(d/diagonal :mode expressive :ARG0 (y/you) :ARG1 (s/signaler) :ARG2 (a/actor))\", \"explanation\": \"The gesture label indicates that the speaker is moving their arms in a diagonal direction, which corresponds to the ARG1 'diagonal' in the gesture AMR. The mode is expressive, indicating that the speaker is conveying information or emotion through their gesture.\"}]\n",
      "the other direction it's the same except for there are five\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Point to the block in front of you and then move it down.\", \"speech AMR\": \"(i/icon-GA :ARG0 s :ARG1 (p/point-01 :mode imperative) :ARG2 (b/block) :ARG3 (l/location)) (m/move-01 :direction (f/front)) (d/deixis-GA :ARG0 s :ARG1 (l/location) :ARG2 a) (i/icon-GA :ARG0 s :ARG1 (m/move-01 :direction (d1/down)))\", \"explanation\": \"The gesture AMR indicates that the speaker is pointing to a block and then moving it down. The speech AMR reflects this by including an icon for pointing, followed by icons for moving in front of you and then down.\"}]\n",
      "then down down one\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Move your hand up and touch it to the right.\", \"speech AMR\": \"(i/icon-GA :op1 (m/move-01 :direction (u/up) :ARG0 (h/hand) :ARG2 (s/signaler)) :op2 (t/touch-01 :mode contact :location (r/right)))\", \"explanation\": \"The gesture labels indicate that the left hand is moving up and into an open position, then the right arm is moving down to the right. This suggests a diagonal movement with the hands in contact on the right side. The speech AMR reflects this by first describing the movement of the hand up, then the touch action on the right location.\"}]\n",
      "put them coming diagonal\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"They are closing in on each other.\", \"speech AMR\": \"(s/close-10 :ARG1 (t/they) :mod (i/in))\", \"explanation\": \"The gesture label indicates that the arms are moving together to the left, forming a closed position. This suggests a sense of convergence or coming together. The body remaining still implies a lack of movement or change in the actor's position. In the speech AMR, 't/they' represents the subject, and 'i/in' is a modifier indicating that the action is directed towards each other.\"}]\n",
      "no closest\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"They are standing still, pointing forward and holding hands.\", \"speech AMR\": \"(e/emblem-GA :ARG0 (s/signaler) :ARG1 2 :ARG2 (a/actor)) (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\", \"explanation\": \"The gesture label indicates that the speaker is standing still, pointing forward with their right hand, and holding hands with someone. The first AMR represents an emblematic gesture indicating a quantity of two, which in this context means 'they' are standing together. The second AMR represents a deictic gesture pointing to a location, which in this context means the speaker is pointing forward.\"}]\n",
      "and the one on the very end\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"I want you to take two blocks.\", \"speech AMR\": \"(w/want-01 :ARG0 (i/I) :ARG1 (t/take-01 :ARG0 (y/you) :ARG1 (b/block :quant 2)))\", \"explanation\": \"The gesture labels indicate a sequence of actions: the right arm moves to the front and closes, then opens to two fingers. This corresponds to wanting someone to take two blocks.\"}]\n",
      "and then on the other side the two closest to the middle get stacked\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Look at the front of it.\", \"speech AMR\": \"(l/look-01 :op1 (i/icon-GA :ARG0 (s/signaler) :ARG1 (f/front) :ARG2 (a/actor)))\", \"explanation\": \"The gesture labels indicate that the speaker is moving their arms forward and then backward, which suggests looking at something. The RH is moving into an open position, up, which further supports this interpretation. The speech AMR represents this action as 'look' with the direction specified as 'front'.\"}]\n",
      "two in front of you and two at the back\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Stop the row.\", \"speech AMR\": \"(s/stoppable-action :mode imperative :ARG0 (y/you) :ARG1 (r/row))\", \"explanation\": \"The gesture label 'arms: shake, left' suggests a warning or stopping action. The gesture AMR indicates that the signaler is referring to a row, which implies a need to stop or halt it.\"}]\n",
      "okay\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"I'm holding you on top of me.\", \"speech AMR\": \"(h/hold-01 :ARG0 (s/signaler) :ARG1 (a/actor) :ARG2 (o/on-top-of))\", \"explanation\": \"The gesture label indicates that the speaker is moving their body up, arms and hands are also moving up and into closed position. The head is shaking and then arms move up to hold something. This suggests a physical interaction between the speaker and another entity (a/actor). The speech AMR reflects this by indicating a holding action with the speaker as the agent and the actor as the patient, with the on-top-of relation.\"}]\n",
      "i don’t think can be touching\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Put the row in and put it down.\", \"speech AMR\": \"(p/put-01 :ARG0 (a2/actor) :ARG1 (r/row) :ARG2 (i/in-01 :ARG0 (s/signaler))) (p2/put-01 :mode imperative :ARG0 s :ARG1 r :ARG2 a2)\", \"explanation\": \"The gesture AMR indicates that the speaker is expressing an idea using two icon-GA units. The first unit represents putting something in, and the second unit represents putting it down. The arms moving back and hands facing into point suggest the action of placing or inserting something. The shaking of the left arm may indicate a change or addition to the previous action. The hands changing to a claw shape and then moving down suggests the action of putting something down.\"}]\n",
      "there is three blocks for the bottom of the smile\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Put it in the gap on the left.\", \"speech AMR\": \"(e/envelope-01 :mode imperative :ARG0 (y/you) :ARG1 (i2/implicit-role) :direction (l/left) :destination (a/at :op1 (g/gap)))\", \"explanation\": \"The gesture labels indicate that the arms move into a gap on the left and then move back, with the hands facing into a point. This suggests an action of putting something in a location. The speech AMR reflects this by using the verb 'put' and specifying the direction and destination.\"}]\n",
      "there is two blocks for the eyes\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Look at the row below.\", \"speech AMR\": \"(i/icon-GA :ARG0 s :ARG1 r :ARG2 a) (d/deixis-GA :ARG0 s :ARG1 l :ARG2 a)\", \"explanation\": \"The gesture label(s) indicate that the speaker is pointing to something, and the gesture AMR shows that the speaker is referring to a row or location. The sentence generated is a natural way to express this action.\"}]\n",
      "and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"The actor moves down, then pushes forward, and finally moves back up with their hands in a claw shape.\", \"speech AMR\": \"(s/move-01 :ARG0 (a/actor) :location (l/location)) (p/push-02 :ARG1 (f/forward) :ARG2 (d/down)) (s/move-03 :ARG0 (a/actor) :direction (b/back))\", \"explanation\": \"The gesture label indicates that the actor moves down, then pushes forward with their arms in front of them. The gesture AMR shows two gesture units: one for moving and another for pushing. The speech AMR is generated by combining these two gesture units into a single sentence.\"}]\n",
      "push them up a little bit\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Come down here and shake hands, then go back up.\", \n",
      "\"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (l/location)) (a/and :op1 (i/icon-GA :ARG0 s :ARG1 (h/handshake :mod (f/far)) :ARG2 a2)) (g/gesture-unit :op1 (d/deixis-GA :ARG0 s :ARG1 l :ARG2 a2) :op2 (m/move-01 :mode imperative :ARG0 s :ARG1 (u/up)))\",\n",
      "\"explanation\": \"The gesture labels indicate that the speaker is moving down, then shaking hands with someone in front of them, and finally going back up. The speech AMR reflects this sequence of actions, with the first part describing the movement down, the second part describing the handshake, and the third part describing the movement back up.\"}]\n",
      "and in on the one far on three divots farthest from you\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Put your hand on the left side.\", \"speech AMR\": \"(p/put-01 :mode imperative :ARG0 y :ARG1 (h/hand :mod (l/left)) :ARG2 (s/side :mod (l/location)))\", \"explanation\": \"The gesture labels indicate that the hands are moving into a facing position on the left side, which suggests putting one's hand on the left side. The gesture AMR uses deixis-GA to represent the pointing action, but since it's an imperative sentence, we use put-01 instead. The ARG2 is set to (s/side :mod (l/location)) to indicate that the location is on the left side.\"}]\n",
      "and then you got two towers like that on the sides\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"Point to the left.\", \"speech AMR\": \"(i/icon-GA :ARG0 s :ARG1 (p/point :mod (l/left)) :ARG2 a)\", \"explanation\": \"The gesture labels indicate that both hands are rotating into point, which is a direction. The body is still, indicating that there is no movement or change in the environment. Therefore, the speech AMR represents an iconographic representation of pointing to the left.\"}]\n",
      "and then you do that same process all the way up\n",
      "----------------------------------------------\n",
      "[{\"sentence\": \"look at the tower\", \"speech AMR\": \"(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) (i/icon-GA :ARG0 s :ARG1 (t/tower) :ARG2 a2)\", \"explanation\": \"The gesture label RH: rotate, into open, back indicates a pointing action towards the tower. The corresponding speech AMR represents this action as a deixis gesture (d/deixis-GA), indicating the location of the tower, and an icon gesture (i/icon-GA) representing the tower itself.\"}]\n",
      "no on top yeah\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## You can go through the results, e.g. look up specific sentences\n",
    "for item in results:\n",
    "    # print(item['scenario'])\n",
    "    if item['scenario'] == \"gesture\":\n",
    "    # print(item['prompt'])\n",
    "        print(item['llama_1'])\n",
    "        print(item['sentence'])\n",
    "        print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267ca56-8bfc-45a4-be96-07d8731231a3",
   "metadata": {},
   "source": [
    "## BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "9f2f0493-106c-4b15-b915-d1a42630e659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reference': 'just like that but closer together', 'scenario': 'speech', 'llama_run': 'llama_1', 'translation': 'you should just resemble that, having them close together more.'}\n",
      "{'reference': 'just like that but closer together', 'scenario': 'speech', 'llama_run': 'llama_2', 'translation': 'you just put that on, though you have to close it together more.'}\n",
      "{'reference': 'just like that but closer together', 'scenario': 'speech', 'llama_run': 'llama_3', 'translation': \"you should just resemble that, but you're having it close together more.\"}\n",
      "{'reference': 'just like that but closer together', 'scenario': 'gesture', 'llama_run': 'llama_1', 'translation': 'move back and then move forward into the gap on the left.'}\n",
      "{'reference': 'just like that but closer together', 'scenario': 'gesture', 'llama_run': 'llama_2', 'translation': 'move back and then point forward.'}\n",
      "{'reference': 'just like that but closer together', 'scenario': 'gesture', 'llama_run': 'llama_3', 'translation': 'move your hands back into a fist, then move them to the left and make a gap in front of you.'}\n",
      "{'reference': 'just like that but closer together', 'scenario': 'speech_gesture', 'llama_run': 'llama_1', 'translation': 'put that just like this.'}\n",
      "{'reference': 'just like that but closer together', 'scenario': 'speech_gesture', 'llama_run': 'llama_2', 'translation': 'put that just like you have it closer together.'}\n",
      "{'reference': 'just like that but closer together', 'scenario': 'speech_gesture', 'llama_run': 'llama_3', 'translation': 'put that just like you have it closed together more.'}\n"
     ]
    }
   ],
   "source": [
    "## Extract all references and generated sentences \n",
    "\n",
    "ref_and_transl = []\n",
    "references = []\n",
    "candidates = []\n",
    "for item in results:\n",
    "    #print(item['sentence'], item['scenario'])\n",
    "    for key in [\"llama_1\", \"llama_2\", \"llama_3\"]:\n",
    "        #print(item[key])\n",
    "        try:\n",
    "            sentences = re.findall(r'\"sentence\"\\s*:\\s*\"([^\"]+)\"', item[key])\n",
    "            for sent in sentences:\n",
    "                ref_and_transl.append({\n",
    "                    \"reference\": item[\"sentence\"],\n",
    "                    \"scenario\": item['scenario'],\n",
    "                    \"llama_run\": key,\n",
    "                    \"translation\": sent.lower()\n",
    "                })\n",
    "                \n",
    "                # references.append([nltk.word_tokenize(item[\"sentence\"])])\n",
    "                # candidates.append(nltk.word_tokenize(match.lower()))\n",
    "                references.append(item['sentence'])\n",
    "                candidates.append(sent.lower())\n",
    "                \n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"Failed to parse {key} {item[key]}\\nbecause: {e}.\")\n",
    "\n",
    "# # print(references[0:3])\n",
    "# # print(candidates[0:3])\n",
    "\n",
    "for item in ref_and_transl:                       \n",
    "    if item['reference'] == \"just like that but closer together\":\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "88ca205d-7ca0-4680-8f7b-3fa5ce9ea819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594\n"
     ]
    }
   ],
   "source": [
    "print(len(ref_and_transl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "id": "92516b82-2f8a-424f-ba6f-054cc4b144ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay\n",
      "Speech AMR:\n",
      " (o/okay-04)\n",
      "\n",
      "Example 2:\n",
      "Sentence: space two out a little less than a block length\n",
      "Speech AMR:\n",
      " (s/space-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:quant 2)\n",
      "\t:ARG2 (q/distance-quantity\n",
      "\t\t:unit (b/block)\n",
      "\t\t:ARG1-of (h/have-quant-91\n",
      "\t\t\t:ARG2 1\n",
      "\t\t\t:ARG3 (l/less\n",
      "\t\t\t\t:mod (l2/little)))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1)\n",
      "\t:ARG2 (b2/block\n",
      "\t\t:mod (b3/back)))\n",
      "\n",
      "[{\"sentence\": \"Put the back block.\", \"explanation\": \"The speech AMR indicates an imperative mode, meaning it's a command. The ARG0 is 'you', indicating the subject of the sentence. The ARG1 is 'block' with a quantity of 1, suggesting a single block. The ARG2 is also 'block' but with a modifier 'back', which likely means the back side or face of the block.\"}]\n",
      "so put put a block on the back block good\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: four blocks in the front okay\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 4\n",
      "\t:location (i/in\n",
      "\t\t:op1 (f/front)))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: shake, left; hands: into claw, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/row)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: it cannot fall down from the ground right\n",
      "Speech AMR:\n",
      " (p/possible-01\n",
      "\t:polarity -\n",
      "\t:ARG1 (f/fall-01\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:ARG3 (g/ground))\n",
      "\t:ARG1-of (r/request-confirmation-91))\n",
      "\n",
      "Gesture label(s): \n",
      "head: shake; hands: rotate, open, up;\n",
      "Unknown\n",
      "LA: move, down; LH: into point, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, front; RH: point, front;\n",
      "RA: move, down; RH: into claw, down;\n",
      "RA: move, up; RH: into point, front;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Look at the location in front of you.\", \"speech AMR\": \"(d/deixis-GA :ARG0 (s/signaler) :ARG1 (f/front) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate that the right arm is moving forward, pointing to a location. Then, it moves down and the hand forms a claw shape, before moving up again and pointing forward once more. This sequence of movements suggests that the speaker is directing attention to a specific location in front of them. The gesture AMR confirms this interpretation, with the location being the ARG1.\"}]\n",
      "so put put a block on the back block good\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: five blocks to start\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 5\n",
      "\t:ARG1-of (s/start-01))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, left;\n",
      "body: still;\n",
      "LH: into open, up;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: now these are a little jiggled\n",
      "Speech AMR:\n",
      " (j/jiggle-01\n",
      "\t:ARG1 (t/these)\n",
      "\t:mod (l/little))\n",
      "\n",
      "Gesture label(s): \n",
      "head: nod; LA: move, back;\n",
      "RA: move, up; RH: shake, down, open;\n",
      "RA: move, front; RH: into point, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (j/jiggle-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:mode expressive\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (j/jiggle-01)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (a1/and\n",
      "\t\t:op1 (d1/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b1/block)\n",
      "\t\t\t:ARG2 a)\n",
      "\t\t:op2 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b2/block)\n",
      "\t\t\t:ARG2 a)))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, front; RH: point, front;\n",
      "RA: move, down; RH: into claw, down;\n",
      "RA: move, up; RH: into point, front;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1)\n",
      "\t:ARG2 (b2/block\n",
      "\t\t:mod (b3/back)))\n",
      "\n",
      "[{\"sentence\": \"Put the block in front of you.\", \"explanation\": \"The gesture AMR indicates a deixis, pointing to a location (l/location) and an actor (a/actor), suggesting that the speaker is directing attention to something. The speech AMR provides the verb 'put' with imperative mode, indicating a command. Combining these elements, we get a sentence where the speaker is instructing someone to put a block in front of them.\"}]\n",
      "so put put a block on the back block good\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: you're done\n",
      "Speech AMR:\n",
      " (d/done-08\n",
      "\t:ARG0 (y/you))\n",
      "\n",
      "Example 2:\n",
      "Sentence: put a bit a bit right uh\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG2 (r/right-04\n",
      "\t\t:degree (b/bit)))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2))\n",
      "\n",
      "[{\"sentence\": \"Put two blocks.\", \"explanation\": \"The speech AMR indicates that the action is 'put' in an imperative mode, directed at the speaker ('you'), and the object being put is a block with a quantity of 2.\"}]\n",
      "put two blocks\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: it starts in the top left\n",
      "Speech AMR:\n",
      " (s/start-01\n",
      "\t:ARG0 (i/it)\n",
      "\t:location (i2/in\n",
      "\t\t:op1 (l/left\n",
      "\t\t\t:mod (t/top))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "LH: into claw, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: same direction that that's pushed off yea alright\n",
      "Speech AMR:\n",
      " (s/same-01\n",
      "\t:ARG2 (p/push-01\n",
      "\t\t:ARG1 (t/that)\n",
      "\t\t:ARG2 (o/off))\n",
      "\t:ARG3 (d/direction))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, down; RH: into open, down;\n",
      "arms: move, up, into gap, left; hands: into facing, left, into claw, left;\n",
      "LA: move, left;\n",
      "arms: move, down; hands: into open, down;\n",
      "head: rotate;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/left)\n",
      "\t:ARG2 (a/actor))\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (s2/slide\n",
      "\t\t\t:direction (l/left))\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, down, gap, left; hands: claw, down;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g2/gesture-unit\n",
      "\t\t:op1 (i/icon-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (p/put-01\n",
      "\t\t\t\t:ARG1 (b/block))\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (d/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g/gesture-unit\n",
      "\t\t:op1 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p2/put-01\n",
      "\t\t\t\t:ARG1 (b2/block))\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l2/location)\n",
      "\t\t\t:ARG2 a2)))\n",
      "\n",
      "[{\"sentence\": \"Put the block in the location, then put another block there.\", \"speech AMR\": \"(s/put-01 :ARG0 (b/block) :location (l/location)) (a/and :op1 (s/put-02 :ARG0 (b2/block) :location (l2/location)))\", \"explanation\": \"The gesture label indicates that the arms move down into a gap on the left, and the hands are in a claw position. This suggests two separate actions: putting a block in a location, and then putting another block there. The gesture AMR reflects this structure with two gesture units, each representing one of these actions.\"}]\n",
      "put two blocks\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: it's gonna be a pyramid from three of the rows of two\n",
      "Speech AMR:\n",
      " (p/pyramid\n",
      "\t:consist-of (r/row\n",
      "\t\t:quant 3\n",
      "\t\t:consist-of (r2/row\n",
      "\t\t\t:quant 2))\n",
      "\t:domain (i/it))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, front; LA: move, down;\n",
      "body: move, front; arms: into gap, left; hands: facing, into open;\n",
      "arms: move, down;\n",
      "RA: move, left;\n",
      "RA: shake, right;\n",
      "RA: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/put-01)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g2/gesture-unit\n",
      "\t\t:op1 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l2/location)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p2/put-01)\n",
      "\t\t\t:ARG2 a2)))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (r/row)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: then they connect to the two wider blocks\n",
      "Speech AMR:\n",
      " (c/connect-01\n",
      "\t:time (t/then)\n",
      "\t:ARG1 (t2/they)\n",
      "\t:ARG2 (b/block\n",
      "\t\t:quant 2\n",
      "\t\t:mod (w/wide\n",
      "\t\t\t:degree (m/more))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, up; hands: to face;\n",
      "arms: move, front; hands: into point, front;\n",
      "Unknown\n",
      "arms: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(a/and\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (d2/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (b2/block)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, down, gap, left; hands: claw, down;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g2/gesture-unit\n",
      "\t\t:op1 (i/icon-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (p/put-01\n",
      "\t\t\t\t:ARG1 (b/block))\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (d/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g/gesture-unit\n",
      "\t\t:op1 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p2/put-01\n",
      "\t\t\t\t:ARG1 (b2/block))\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l2/location)\n",
      "\t\t\t:ARG2 a2)))\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2))\n",
      "\n",
      "[{\"sentence\": \"Put the two blocks down.\", \"explanation\": \"The gesture labels indicate that the arms move down and to the left, with hands in a claw position. This suggests that the speaker is indicating a downward motion for placing or putting something. The speech AMR specifies 'put-01' as the action, which matches this interpretation. Additionally, the speech AMR mentions two blocks, which aligns with the gesture AMR's mention of 'and' combining two separate gestures, each involving a block.\"}]\n",
      "put two blocks\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay\n",
      "Speech AMR:\n",
      " (o/okay-04)\n",
      "\n",
      "Example 2:\n",
      "Sentence: get another one stacked on top\n",
      "Speech AMR:\n",
      " (g/get-04\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (s/stack-01\n",
      "\t\t:ARG1 (o/one\n",
      "\t\t\t:mod (a/another))\n",
      "\t\t:ARG2 (o2/on\n",
      "\t\t\t:op1 (t/top))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (u/um\n",
      "\t:mode expressive)\n",
      "\n",
      "[{\"sentence\": \"Um\", \"explanation\": \"The speech AMR indicates a mode of 'expressive', which suggests that the speaker is making an utterance to express themselves, rather than conveying information or giving instructions. In this case, the word 'um' is often used as a filler or hesitation sound in spoken language.\"}]\n",
      "um\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: move that block uh\n",
      "Speech AMR:\n",
      " (m/move-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (t/that)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, right; LH: claw, right;\n",
      "LH: rotate, claw, front;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: they’re in other words are not perfectly clear\n",
      "Speech AMR:\n",
      " (c/clear-06\n",
      "\t:manner (w/words\n",
      "\t\t:mod (o/other))\n",
      "\t:ARG1 (t/they)\n",
      "\t:polarity -\n",
      "\t:ARG1-of (p/perfect-02))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "body: still;\n",
      "hands: enough;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (k/know-01\n",
      "\t\t:polarity -)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (e2/enough)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: rotate, gap, left; hands: claw, down;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g2/gesture-unit\n",
      "\t\t:op1 (i/icon-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (p/put-01\n",
      "\t\t\t\t:ARG1 (b/block))\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (d/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g/gesture-unit\n",
      "\t\t:op1 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p2/put-01\n",
      "\t\t\t\t:ARG1 (b2/block))\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l2/location)\n",
      "\t\t\t:ARG2 a2)))\n",
      "\n",
      "[{\"sentence\": \"Put the block down.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block :mod (d/down)) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate that the arms are rotating and the hands are in a claw position, pointing downwards. This suggests an action of putting something down. The gesture AMR shows two gesture units combined with 'and', which indicates a sequential action. The first unit is an icon representing the action of putting (p/put-01), and the second unit is a deixis indicating the location where the block should be put.\"}]\n",
      "um\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: them towards you\n",
      "Speech AMR:\n",
      " (o/orient-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them\n",
      "\t\t:location (t2/towards\n",
      "\t\t\t:op1 y)))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: claw, down; LA: move, back; RA: move, front;\n",
      "hands: claw, down; LA: move, front; RA: move, back;\n",
      "hands: claw, down; LA: move, back; RA: move, front;\n",
      "hands: into closed, back; RA: move, back;\n",
      "arms: move, front, into gap, left; hands: facing, into closed;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (r/rotate-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: then you going to have a fourth block\n",
      "Speech AMR:\n",
      " (h/have-03\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:ord 4))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, right; RA: move, up; RH: to face;\n",
      "body: move, left; RA: move, down;\n",
      "LA: move, up; LH: into point, front;\n",
      "LA: move, down; LH: into open, right;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: rotate, gap, left; hands: claw, down;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g2/gesture-unit\n",
      "\t\t:op1 (i/icon-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (p/put-01\n",
      "\t\t\t\t:ARG1 (b/block))\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (d/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g/gesture-unit\n",
      "\t\t:op1 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p2/put-01\n",
      "\t\t\t\t:ARG1 (b2/block))\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l2/location)\n",
      "\t\t\t:ARG2 a2)))\n",
      "Speech AMR:\n",
      " (u/um\n",
      "\t:mode expressive)\n",
      "\n",
      "[{\"sentence\": \"You put the block in this location, and then you put the other block in that location.\", \"explanation\": \"The gesture label(s) indicate two separate actions of putting blocks into locations. The first action is represented by the gesture unit with icon-GA (i/icon-GA), where the signaler puts a block into a location. The second action is also represented by a gesture unit, but this time with icon-GA (i2/icon-GA) and put-01 (p/put-01), indicating that the signaler puts another block into a different location. The speech AMR indicates an expressive mode, suggesting that the speaker is emphasizing or drawing attention to these actions.\"}]\n",
      "um\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: just one\n",
      "Speech AMR:\n",
      " (i/implicit-role\n",
      "\t:quant 1)\n",
      "\n",
      "Example 2:\n",
      "Sentence: and go\n",
      "Speech AMR:\n",
      " (a/and)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:time (t/then)\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (o/one)\n",
      "\t\t:ARG2 (o2/on\n",
      "\t\t\t:op1 (t2/top))))\n",
      "\n",
      "[{\"sentence\": \"You put one on top then.\", \"explanation\": \"The speech AMR represents a sentence with the subject 'you' in an imperative mode, indicating a command. The verb is 'put-01', which means to place something somewhere. The ARG0 (argument 0) is 'you', the person performing the action. The ARG1 is 'one', the object being placed. The ARG2 is 'on top', specifying where the one will be placed, and 'then' indicates the time at which this should happen.\"}]\n",
      "and then put one on the top\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: the base is going to have four second one’s going to have three then two on top of that and then one\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (h/have-03\n",
      "\t\t:ARG0 (b/base)\n",
      "\t\t:ARG1 (i/implicit-role\n",
      "\t\t\t:quant 4))\n",
      "\t:op2 (h2/have-03\n",
      "\t\t:ARG0 (i2/implicit-role\n",
      "\t\t\t:ord (o/ordinal-entity\n",
      "\t\t\t\t:value 2))\n",
      "\t\t:ARG1 (i3/implicit-role\n",
      "\t\t\t:quant 3))\n",
      "\t:op3 (i4/implicit-predicate-00\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (i5/implicit-role\n",
      "\t\t\t:quant 2)\n",
      "\t\t:destination (o2/on-top-of\n",
      "\t\t\t:op1 (t/that)))\n",
      "\t:op4 (i6/implicit-predicate-00\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 (i7/implicit-role\n",
      "\t\t\t:quant 1)))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into four, front;\n",
      "RH: into three;\n",
      "RA: move, up; RH: into two;\n",
      "RH: into one;\n",
      "RA: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 4\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 3\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 2\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: start off with just a block and then put a block on top of\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (s/start-off-2\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:mod (j/just)))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 (b2/block)\n",
      "\t\t:ARG2 (o/on\n",
      "\t\t\t:op1 (t/top\n",
      "\t\t\t\t:op1 (t2/that)))\n",
      "\t\t:time (t3/then)))\n",
      "\n",
      "Gesture label(s): \n",
      "    arms: move, up, into gap, left; hands: into facing, left, into claw, left;\n",
      "    head: move, down;\n",
      "head: move, up; arms: move, down; hands: into open, down;\n",
      "body: move, up; RH: tap;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/top)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up; RH: into point, front;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Point to the location.\", \"speech AMR\": \"(d/deixis-01 :mode declarative :ARG0 (y/you) :ARG1 (l/location))\", \"explanation\": \"The gesture label indicates that the speaker is moving their hand up and pointing forward, which corresponds to a deixis gesture. The speech AMR reflects this by indicating that the speaker is performing a deixis action, with the location as the target of the action.\"}]\n",
      "and then put one on the top\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: stack stack it up no\n",
      "Speech AMR:\n",
      " (s/stack-up-03\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "LA: move, up; LH: into open, right;\n",
      "arms: together, left; hands: into contact, left, into closed, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/close-10)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: stack three blocks on one side yup\n",
      "Speech AMR:\n",
      " (s/stack-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 3)\n",
      "\t:ARG2 (o/on\n",
      "\t\t:op1 (s2/side\n",
      "\t\t\t:quant 1)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "RA: move, right; RH: into point, down;\n",
      "RH: tap, point;\n",
      "RA: move, up; RH: into claw, front;\n",
      "RA: move, down;\n",
      "LA: move, to hip;\n",
      "body: still;\n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/stack-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up; RH: into point, front;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:time (t/then)\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (o/one)\n",
      "\t\t:ARG2 (o2/on\n",
      "\t\t\t:op1 (t2/top))))\n",
      "\n",
      "[{\"sentence\": \"Put one on top.\", \"explanation\": \"The gesture label indicates the right arm moving up and the right hand entering a pointing position in front. This suggests that the speaker is indicating a location or object to be pointed at, which corresponds to the second deixis-GA in the Gesture AMR. The speech AMR includes an imperative mode for the action of putting one object on top, which aligns with the gesture's indication of a specific action. Therefore, the generated sentence 'Put one on top' reflects both the gesture and speech AMRs.\"}]\n",
      "and then put one on the top\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: like about a third of a block a part so more close in than that\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG2 (q/distance-quantity\n",
      "\t\t:mod (a/about)\n",
      "\t\t:unit (b/block\n",
      "\t\t\t:ARG1-of (h/have-quant-91\n",
      "\t\t\t\t:ARG2 (t/third)))\n",
      "\t\t:mod (a2/apart))\n",
      "\t:ARG2-of (i/infer-01\n",
      "\t\t:ARG1 (h2/have-degree-91\n",
      "\t\t\t:ARG2 (c/close-10)\n",
      "\t\t\t:ARG3 (m/more)\n",
      "\t\t\t:ARG4 (t2/that))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: four blocks\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quantity 4)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (m/multi-sentence\n",
      "\t:snt1 (n/no)\n",
      "\t:snt2 (l/look-02\n",
      "\t\t:ARG0 (t/that)\n",
      "\t\t:ARG1 (w/work-09)\n",
      "\t\t:polarity -))\n",
      "\n",
      "[{\"sentence\": \"No, that looks like work.\", \"explanation\": \"The speech AMR indicates a multi-sentence structure with two sentences. The first sentence is 'n/no', which corresponds to the word 'no'. The second sentence has a subject-verb-object (SVO) structure: 'that' is the subject, 'work' is the verb, and there's no explicit object. The polarity is negative (-), indicating that the sentence is negated. Therefore, the generated sentence is a combination of these elements.\"}]\n",
      "no that doesn't look like it’s going to work\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: great yep\n",
      "Speech AMR:\n",
      " (g/great)\n",
      "\n",
      "Gesture label(s): \n",
      "hands: thumb, up;\n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (g/good)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: seven blocks in a row\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 7)\n",
      "\t:manner (r/row))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, up; LH: into two, front; RH: into five, front;\n",
      "LA: move, down; RA: move, right; RH: closed, down;\n",
      "RA: move, back;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 7\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (r/row)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/place-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, down; hands: into claw, down;\n",
      "body: still;\n",
      "arms: move, up; hands: into claw, down;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (g/grab-01\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 2))\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/close-06)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"I'm grabbing two blocks.\", \"speech AMR\": \"(i/icon-GA :ARG0 (s/signaler) :ARG1 (g/grab-01 :ARG1 (b/block :quant 2)) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate a downward movement of the arms and hands into a claw shape, suggesting a grasping action. The second set of gestures shows an upward movement of the arms with hands still in a claw shape, which could imply a closing or holding action. The speech AMR reflects this by including 'grab-01' as the icon, indicating a specific type of grasp, and specifying that two blocks are being grabbed.\"}]\n",
      "no that doesn't look like it’s going to work\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and then three more coming off from the other direction touching the corner okay\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (i/implicit-role\n",
      "\t\t:quant 3\n",
      "\t\t:mod (m/more)\n",
      "\t\t:ARG1-of (c/come-33\n",
      "\t\t\t:ARG3 (f/from\n",
      "\t\t\t\t:op1 (d/direction\n",
      "\t\t\t\t\t:mod (o/other)))\n",
      "\t\t\t:mod (o2/off))\n",
      "\t\t:ARG0-of (t/touch-01\n",
      "\t\t\t:ARG1 (c2/corner))\n",
      "\t\t:time (t2/then)))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "LA: move, left; LH: into closed, front;\n",
      "body: still;\n",
      "head: nod; LA: move, right; LH: into closed, right;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/direction)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and then the second block goes on top of that\n",
      "Speech AMR:\n",
      " (g/go-01\n",
      "\t:ARG1 (b/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value 2);ARG4(o2/on\n",
      "\t\t\t:op1 (t/top\n",
      "\t\t\t\t:location (t2/that)))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up;\n",
      "RA: move, down; RH: into open, left;\n",
      "RA: rotate\n",
      "body: still;\n",
      "hands: rotate;\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/put-01)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (r/rotate-01)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g2/gesture-unit\n",
      "\t\t:op1 (i3/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (t/tower)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i4/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (r2/rotate-01)\n",
      "\t\t\t:ARG2 a2)))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, down; hands: into claw, down;\n",
      "body: still;\n",
      "arms: move, up; hands: into claw, down;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (g/grab-01\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 2))\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/close-06)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (m/multi-sentence\n",
      "\t:snt1 (n/no)\n",
      "\t:snt2 (l/look-02\n",
      "\t\t:ARG0 (t/that)\n",
      "\t\t:ARG1 (w/work-09)\n",
      "\t\t:polarity -))\n",
      "\n",
      "[{\"sentence\": \"No, look at that work.\", \"explanation\": \"The gesture labels indicate a sequence of actions. The first set of gestures suggests grabbing something with the hands in a claw position, which is represented by the 'grab' action in the Gesture AMR. Then, the arms move up and the hands are still in the same claw position, but this time it's represented by the 'close' action in the Gesture AMR. The Speech AMR provides additional context with two sentences: one indicating a negative response ('no') and another describing an action of looking at something ('that work'). The sentence generated combines these elements to form a coherent statement.\"}]\n",
      "no that doesn't look like it’s going to work\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: starting at row three column three\n",
      "Speech AMR:\n",
      " (s/start-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/be-located-at-91\n",
      "\t\t:ARG1 (a/and\n",
      "\t\t\t:op1 (r/row\n",
      "\t\t\t\t:ord (t/third))\n",
      "\t\t\t:op2 (c/column\n",
      "\t\t\t\t:ord 3))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: yeah great\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (y/yes)\n",
      "\n",
      "[{\"sentence\": \"Yes\", \"explanation\": \"The speech AMR indicates a single node labeled 'y' with the value 'yes'. This directly corresponds to the word 'yes' in natural spoken English, as there are no additional arguments or relationships specified.\"}]\n",
      "yes\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: closest to the middle yeah\n",
      "Speech AMR:\n",
      " (h/have-degree-91\n",
      "\t:ARG2 (c/close-10\n",
      "\t\t:ARG2 (m/middle))\n",
      "\t:ARG3 (m2/most))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/close-10)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: gonna have another block right next to that block so it’d be over the space of those two bottom blocks\n",
      "Speech AMR:\n",
      " (h/have-02\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (a/another))\n",
      "\t:location (n/next-to\n",
      "\t\t:ARG1 (t/that)\n",
      "\t\t:mod (r/right))\n",
      "\t:purpose (b2/be-located-at-91\n",
      "\t\t:ARG1 b\n",
      "\t\t:ARG2 (o/over\n",
      "\t\t\t:op1 (s/space\n",
      "\t\t\t\t:poss (b3/block\n",
      "\t\t\t\t\t:mod (t/that)\n",
      "\t\t\t\t\t:location (b4/bottom))))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into open, left;\n",
      "RA: move, right;\n",
      "LA: move, front; RA: move, down; hands: into open, back;\n",
      "head: move, right;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (s2/space)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: still;\n",
      "RA: move, up; RH: claw, down;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Look up there.\", \"speech AMR\": \"(d/deixis-GA :ARG0 (s/signaler) :ARG1 (u/up) :ARG2 (t/there))\", \"explanation\": \"The gesture label indicates that the body is still, and the RA moves up. This suggests a pointing or indicating action, which corresponds to the deictic gesture in the Gesture AMR. The RH clawing down is not directly related to the speech AMR, but it could be interpreted as an emphasis on the direction of the gaze.\"}]\n",
      "yes\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and one block on the right side of the first block and move back a bit\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (b/block\n",
      "\t\t:quant 1\n",
      "\t\t:location (o/on\n",
      "\t\t\t:op1 (s/side\n",
      "\t\t\t\t:ARG1-of (r/right-04)\n",
      "\t\t\t\t:poss (b2/block\n",
      "\t\t\t\t\t:ord (o2/ordinal-entity\n",
      "\t\t\t\t\t\t:value 1)))))\n",
      "\t:op3 (m/move-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:direction (b3/back\n",
      "\t\t\t:degree (b4/bit))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "Rh: into fist, back;\n",
      "body: still;\n",
      "Unknown\n",
      "hands: into facing, left;\n",
      "arms: beckon;\n",
      "body: still;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (b/backward))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: take one block put it on top of those two in the middle\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (t/take-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:ARG2 (o/on-top-of\n",
      "\t\t\t:op1 (b2/block\n",
      "\t\t\t\t:mod (t2/that)\n",
      "\t\t\t\t:quant 2\n",
      "\t\t\t\t:location (m/middle)))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into one, front;\n",
      "RA: move, front; RH: into L, down;\n",
      "RA: move, up; RH: L, down;\n",
      "RA: move, back;\n",
      "body: still;\n",
      "RA: move, down; RH: into point, down;\n",
      "LA: move, left; LH: into L, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: still;\n",
      "RA: move, up; RH: claw, down;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (y/yes)\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"sentence\": \"Point to the location.\",\n",
      "    \"explanation\": \"The gesture label indicates that the body is still, while the RA moves up and the RH claws down. The gesture AMR represents a deixis-GA, which typically involves pointing to a location. Therefore, the sentence generated is 'Point to the location'.\"\n",
      "  }\n",
      "]\n",
      "yes\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: the block you have in your left hand or in your hands goes in between that diagonal shape yep\n",
      "Speech AMR:\n",
      " (g/go-35\n",
      "\t:ARG1 (b/block\n",
      "\t\t:ARG1-of (h/have-03\n",
      "\t\t\t:ARG0 (y/you)\n",
      "\t\t\t:location (i/in\n",
      "\t\t\t\t:op1 (h2/hand\n",
      "\t\t\t\t\t:poss y))))\n",
      "\t:ARG2 (i2/in\n",
      "\t\t:op1 (b2/between\n",
      "\t\t\t:op1 (s/shape\n",
      "\t\t\t\t:mod (t/that)\n",
      "\t\t\t\t:mod (d/diagonal)))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and uh two blocks\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (b/block\n",
      "\t\t:quant 2))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (j/jiggle-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you))\n",
      "\n",
      "Here is the generated sentence and its explanation:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"sentence\": \"Jiggle!\",\n",
      "  \"explanation\": \"The speech AMR indicates that the verb 'jiggle' is in the imperative mode, which means it's a command or instruction. Therefore, the corresponding sentence should be an imperative sentence telling someone to jiggle.\"\n",
      "}\n",
      "```\n",
      "so jiggle the go\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: more great\n",
      "Speech AMR:\n",
      " (m/more)\n",
      "\n",
      "Gesture label(s): \n",
      "hands: shake, left;\n",
      "Unknown\n",
      "hands: into fist, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: spread them apart a little bit but not as wide as a full block\n",
      "Speech AMR:\n",
      " (s/spread-03\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:direction (a/apart\n",
      "\t\t:quant (b/bit\n",
      "\t\t\t:mod (l/little))\n",
      "\t\t:quant (l2/less-than\n",
      "\t\t\t:op1 (q/distance-quantity\n",
      "\t\t\t\t:unit (b2/block)\n",
      "\t\t\t\t:quant 1))))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, into gap, left; hands: facing, closed;\n",
      "body: still;\n",
      "arms: move, back;\n",
      "RA: move, up; RH: into one, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/spread-03\n",
      "\t\t:direction (a/apart))\n",
      "\t:ARG2 (a2/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, front; RH: into point, down;\n",
      "RH: shake, down;\n",
      "RH: into point, front;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:mode expressive\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (j/jiggle-01)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (a1/and\n",
      "\t\t:op1 (d1/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b1/block)\n",
      "\t\t\t:ARG2 a)\n",
      "\t\t:op2 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b2/block)\n",
      "\t\t\t:ARG2 a)))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (c/count-01\n",
      "\t\t\t:ARG2 (a/actor))\n",
      "\t\t:op2 (d/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b/block)\n",
      "\t\t\t:ARG2 a)))\n",
      "\n",
      "[{\"sentence\": \"Point to the block, then count them.\", \"speech AMR\": \"(c/count-01 :mode imperative :ARG0 (s/signaler) :ARG1 (a/actor)) (d/deixis-GA :ARG0 s :ARG1 b/block :ARG2 a)\", \"explanation\": \"The gesture labels indicate that the right arm moves to point to something in front, and then the hand shakes down. This is followed by the hand moving into a pointing position again, but this time in a forward direction. The unknown label suggests a pause or break between gestures. In the gesture AMR, there are three units: (1) an icon representing a jiggle gesture, indicating expressive mode; (2) a deixis gesture pointing to two blocks, and (3) another deixis gesture pointing to one block. Based on this, we can infer that the speaker is pointing to multiple blocks and then counting them.\"}]\n",
      "so jiggle the go\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: all right put a block down\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1\n",
      "\t\t:direction (d/down))\n",
      "\t:mod (a/all-right))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, front left; RH: into claw, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: ever so slightly alright\n",
      "Speech AMR:\n",
      " (s/slight\n",
      "\t:degree (s2/so\n",
      "\t\t:mod (e/ever)))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "hands: into open, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, front; RH: into point, down;\n",
      "RH: shake, down;\n",
      "RH: into point, front;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:mode expressive\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (j/jiggle-01)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (a1/and\n",
      "\t\t:op1 (d1/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b1/block)\n",
      "\t\t\t:ARG2 a)\n",
      "\t\t:op2 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b2/block)\n",
      "\t\t\t:ARG2 a)))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (c/count-01\n",
      "\t\t\t:ARG2 (a/actor))\n",
      "\t\t:op2 (d/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b/block)\n",
      "\t\t\t:ARG2 a)))\n",
      "Speech AMR:\n",
      " (j/jiggle-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you))\n",
      "\n",
      "[{\"sentence\": \"You jiggle the block in front of you, then count how many blocks are to your left and right.\", \"explanation\": \"The gesture labels indicate that the speaker is moving their hand in a 'move' motion towards the front, followed by 'into point' motions down and up. The RH shake motion suggests uncertainty or questioning. The speech AMR indicates an imperative mode for the action of jiggling, which matches the expressive mode in the gesture AMR. The gesture AMR also includes deixis-GA operations that indicate pointing to blocks on either side, which are likely being counted by the speaker. The final gesture unit corresponds to a counting operation, with the speaker counting the number of blocks.\"}]\n",
      "so jiggle the go\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: then a last block on the crack of those two blocks\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (l/last))\n",
      "\t:location (o/on\n",
      "\t\t:op1 (c/crack\n",
      "\t\t\t:poss (b2/block\n",
      "\t\t\t\t:quant 2\n",
      "\t\t\t\t:mod (t/that)))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and then take the two on top\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (t/take-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (i/implicit-role\n",
      "\t\t\t:quant 2\n",
      "\t\t\t:location (o/on\n",
      "\t\t\t\t:op1 (t2/top))))\n",
      "\t:mod (t3/then))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (e/enough-01\n",
      "\t:ARG2 (g/good))\n",
      "\n",
      "[{\"sentence\": \"It is good enough.\", \"explanation\": \"The speech AMR indicates that the predicate is 'enough' and it has an argument 'good'. This suggests a comparison or evaluation, where something is deemed sufficient or satisfactory. The sentence generated is a common idiomatic expression in English to convey this meaning.\"}]\n",
      "good enough\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: this one looks like a (oh sorry) this one looks like a smiley face\n",
      "Speech AMR:\n",
      " (l/look-02\n",
      "\t:ARG0 (o/one\n",
      "\t\t:mod (t/this))\n",
      "\t:ARG1 (l2/like-04\n",
      "\t\t:ARG2 (f/face\n",
      "\t\t\t:mod (s/smiley))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "body: move, front;\n",
      "body: move, back; hands: rotate;\n",
      "arms: move, up; hands: to face;\n",
      "arms: into gap, left; hands: into claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p2/put-01)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and there's one touching that block's bottom corner\n",
      "Speech AMR:\n",
      " (t/touch-01\n",
      "\t:ARG0 (i/implicit-role\n",
      "\t\t:quant 1)\n",
      "\t:ARG1 (c/corner\n",
      "\t\t:mod (b/bottom)\n",
      "\t\t:poss (b2/block\n",
      "\t\t\t:mod (t2/that))))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "hands: into point, down;\n",
      "arms: together, left; hands: into claw, down;\n",
      "RA: move, right; RH: into claw, down;\n",
      "RH: into open, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (m/move-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, up; hands: into open, front;\n",
      "body: move, back; arms: move, down;\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"You're okay.\", \"speech AMR\": \"(e/emblem-GA :ARG0 (s/signaler) :ARG1 (o/ok) :ARG2 (a/actor))\", \"explanation\": \"The gesture label indicates that the arms move up and hands open in front, which is a common emblem for 'okay'. The speech AMR reflects this interpretation.\"}]\n",
      "good enough\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: then the gap should be a little less of between him\n",
      "Speech AMR:\n",
      " (b/be-03\n",
      "\t:ARG0 (g/gap)\n",
      "\t:degree (l/less\n",
      "\t\t:mod (l2/little))\n",
      "\t:mod (b2/between\n",
      "\t\t:ARG1 (t/them)))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up; hands: facing, into gap, left;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/less)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/squeeze\n",
      "\t\t:direction (t/together))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: almost like that\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG1 (t/that)\n",
      "\t:mod (a/almost))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/rotate-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, up; hands: into open, front;\n",
      "body: move, back; arms: move, down;\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (e/enough-01\n",
      "\t:ARG2 (g/good))\n",
      "\n",
      "[{\"sentence\": \"That's okay.\", \"explanation\": \"The gesture labels and AMRs indicate that the speaker is signaling approval or agreement. The arms moving up and hands entering an open position in front suggest a positive or affirmative gesture, while the body moving back and arms moving down may indicate a sense of completion or satisfaction. The speech AMR confirms this interpretation with the 'enough' relation and the good argument indicating that everything is satisfactory.\"}]\n",
      "good enough\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: i want you to tilt all of them so that the one corner is touching\n",
      "Speech AMR:\n",
      " (w/want-01\n",
      "\t:ARG0 (i/I)\n",
      "\t:ARG1 (t/tilt-01\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (t2/them\n",
      "\t\t\t:mod (a/all))\n",
      "\t\t:purpose (t3/touch-01\n",
      "\t\t\t:ARG0 (c/corner\n",
      "\t\t\t\t:quant 1))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: it kind of goes down diagonally or so in yours\n",
      "Speech AMR:\n",
      " (g/go-06\n",
      "\t:ARG0 (i/it)\n",
      "\t:ARG2 (d/down)\n",
      "\t:manner (a/about\n",
      "\t\t:op1 (d2/diagonal))\n",
      "\t:location (i2/in\n",
      "\t\t:op1 (i3/implicit-role\n",
      "\t\t\t:poss (y/you)))\n",
      "\t:degree (k/kind-of))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (j/jiggle-01\n",
      "\t\t:time (t/then)\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (i/implicit-role\n",
      "\t\t\t:quant 2\n",
      "\t\t\t:location (f/front\n",
      "\t\t\t\t:poss (t2/them)))))\n",
      "\n",
      "[{\"sentence\": \"You should jiggle them in the front then.\", \"explanation\": \"The speech AMR indicates that 'jiggle' is a verb in imperative mode, meaning it's a command. The subject of the sentence is 'you', and the object is 'them'. The location of the action is specified as 'front' with possession by 'them', implying the objects being jigged are located at the front of something else.\"}]\n",
      "and then jiggle the two in front of them\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and it's turned at an angle\n",
      "Speech AMR:\n",
      " (t/turn-01\n",
      "\t:ARG1 (i/it)\n",
      "\t:destination (a2/angle))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: rotate;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/put-01)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (r/rotate-01)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g2/gesture-unit\n",
      "\t\t:op1 (i3/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (t/tower)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i4/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (r2/rotate-01)\n",
      "\t\t\t:ARG2 a2)))\n",
      "\n",
      "Example 2:\n",
      "Sentence: place it such that they are like interleaving\n",
      "Speech AMR:\n",
      " (p/place-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:cause-of (i2/interleave-01\n",
      "\t\t:ARG1 (t/they)))\n",
      "\n",
      "Gesture label(s): \n",
      "LH: rotate; RH: shake, left;\n",
      "hands: shake;\n",
      "arms: apart, left, into gap, left; hands: into claw, left, into facing, left; RA: move, right;\n",
      "arms: together, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (i2/interleave-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "hands: shake, closed;\n",
      "hands: shake, front, into point, down;\n",
      "arms: move, down;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (j/jiggle-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (s2/slide-01\n",
      "\t\t\t:direction (f/forward))\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (a1/and\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b1/block)\n",
      "\t\t\t:ARG2 a)\n",
      "\t\t:op2 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b/block)\n",
      "\t\t\t:ARG2 a)))\n",
      "\n",
      "[{\"sentence\": \"Point to the block.\", \"speech AMR\": \"(p/point-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block))\", \"explanation\": \"The gesture labels indicate that the hands are shaking closed and then pointing down, which suggests a pointing action. The arms moving down further emphasizes this action. In the gesture AMR, the mode is expressive, indicating that the action is being performed for emphasis or to convey information. The ARG1 of the point-01 action is set to (b/block), which corresponds to the block referred to in the gesture labels.\"}]\n",
      "and then jiggle the two in front of them\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: ah now uh move it so it's on the front front one and the one you just put it on\n",
      "Speech AMR:\n",
      " (m/multi-sentence\n",
      "\t:snt1 (n/no)\n",
      "\t:snt2 (m2/move-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:purpose (b/be-located-at-91\n",
      "\t\t\t:ARG1 i\n",
      "\t\t\t:ARG2 (a/and\n",
      "\t\t\t\t:op1 (o/one\n",
      "\t\t\t\t\t:mod (f/front))\n",
      "\t\t\t\t:op2 (o2/one\n",
      "\t\t\t\t\t:ARG2-of (p/put-01\n",
      "\t\t\t\t\t\t:ARG0 y\n",
      "\t\t\t\t\t\t:time (j/just)))))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up right; RH: into closed, left;\n",
      "RA: move, left; RH: closed, left;\n",
      "RA: move, front; RH: into point, front;\n",
      "RA: move, down back; RH: point, down;\n",
      "RA: move, front right; RH: point, down;\n",
      "body: still;\n",
      "RA: move, up; RH: into claw, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (m/move-01\n",
      "\t\t\t:direction (f/front))\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/turn\n",
      "\t\t:ARG1 (b/block))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: like they're all stacked right on top of each other\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG1 (t/they)\n",
      "\t:ARG2 (s/stack-01\n",
      "\t\t:quant (a/all)\n",
      "\t\t:destination (r/right\n",
      "\t\t\t:op1 (t2/top\n",
      "\t\t\t\t:quant (e/each-other)))))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, down, into gap, left; hands: into facing, left, into closed, left;\n",
      "arms: move, up; hands: into closed, back;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/stack-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "hands: shake, closed;\n",
      "hands: shake, front, into point, down;\n",
      "arms: move, down;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (j/jiggle-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (s2/slide-01\n",
      "\t\t\t:direction (f/forward))\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (a1/and\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b1/block)\n",
      "\t\t\t:ARG2 a)\n",
      "\t\t:op2 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b/block)\n",
      "\t\t\t:ARG2 a)))\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (j/jiggle-01\n",
      "\t\t:time (t/then)\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (i/implicit-role\n",
      "\t\t\t:quant 2\n",
      "\t\t\t:location (f/front\n",
      "\t\t\t\t:poss (t2/them)))))\n",
      "\n",
      "[{\"sentence\": \"You shake them, then you move down.\", \"explanation\": \"The gesture AMR indicates that the speaker is expressing a jiggle action with their hands, and then moving their arms down. The speech AMR suggests that this action should be done first (imperative mode), and then followed by another action (mode imperative). The 'you' in the speech AMR corresponds to the 'ARG0' of the gesture AMR, indicating that the speaker is directing the action at themselves or someone else. The 'them' in the speech AMR refers back to the 'implicit-role' in the gesture AMR, which indicates that the speaker is referring to something or someone in front of them.\"}]\n",
      "and then jiggle the two in front of them\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yep and then get the last block or another block and put it on top of the one\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (g/get-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (o/or\n",
      "\t\t\t:op1 (b/block\n",
      "\t\t\t\t:mod (l/last)\n",
      "\t\t\t\t:op2 (b2/block\n",
      "\t\t\t\t\t:mod (a/another))))\n",
      "\t\t:op2 (p/put-01\n",
      "\t\t\t:mode imperative\n",
      "\t\t\t:ARG0 y\n",
      "\t\t\t:ARG1 (i/it)\n",
      "\t\t\t:ARG2 (o2/on\n",
      "\t\t\t\t:op1 (t/top\n",
      "\t\t\t\t\t:poss (o3/one))))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: the right were were about correct\n",
      "Speech AMR:\n",
      " (c/correct-01\n",
      "\t:ARG0 (t/those\n",
      "\t\t:quant 2\n",
      "\t\t:location (r/right)))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (t/take-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:mod (a2/another)))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:ARG2 (n/next-to\n",
      "\t\t\t:op1 (i/it))))\n",
      "\n",
      "[{\"sentence\": \"Take another block and put it next to the one.\", \"explanation\": \"The speech AMR indicates that there are two operations, 'take' and 'put'. The 'take' operation has an imperative mode, indicating a command or instruction. It specifies the subject as 'you', and the object is 'another block' (modifying the noun with 'a2/another'). The 'put' operation also has an imperative mode and specifies the subject as 'you', the object as 'the block' (which is the same as the object in the 'take' operation), and the location as 'next to it'. This suggests that after taking another block, you should put it next to the one already present.\"}]\n",
      "take another block put it next to it\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: you have two blocks on top of these\n",
      "Speech AMR:\n",
      " (h/have-04\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/be-located-at-91\n",
      "\t\t:ARG1 (b2/block\n",
      "\t\t\t:quant 2)\n",
      "\t\t:ARG2 (o/on-top-of\n",
      "\t\t\t:op1 (t/this))))\n",
      "\n",
      "Gesture label(s): \n",
      "head: rotate; hands: into claw, down;\n",
      "head: rotate;\n",
      "head: rotate;\n",
      "arms: move, up; hands: to face;\n",
      "body: still;\n",
      "head: shake, left; arms: move, down; hands: into claws, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 2\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (o/on-top-of)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: on that exactly on that axis so\n",
      "Speech AMR:\n",
      " (o/on\n",
      "\t:op1 (a/axis\n",
      "\t\t:mod (t/that)))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, front; RH: into point, down;\n",
      "body: still;\n",
      "RA: move, back;\n",
      "arms: move, into gap, left; hands: facing, closed;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/spread-03\n",
      "\t\t:direction (a/apart))\n",
      "\t:ARG2 (a2/actor))\n",
      "\n",
      "[{\"sentence\": \"Point to the location in front of you, then put it down.\", \"speech AMR\": \"(p/put-01 :op1 (d/deixis-GA :ARG0 s :ARG1 l :ARG2 a) :op2 (i/icon-GA :ARG0 s :ARG1 p :ARG2 a))\", \"explanation\": \"The gesture label indicates that the speaker is pointing to a location in front of them and then putting something down. The gesture AMR reflects this, with the first operation being a deixis (pointing) to a location, and the second operation being an icon (putting) of the spread action.\"}]\n",
      "take another block put it next to it\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yeah\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "Gesture label(s): \n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: move that about one that tower about one block over\n",
      "Speech AMR:\n",
      " (m/move-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/tower\n",
      "\t\t:mod (t2/that))\n",
      "\t:ARG2 (a/about\n",
      "\t\t:op1 (q/distance-quantity\n",
      "\t\t\t:unit (b/block)\n",
      "\t\t\t:quant 1))\n",
      "\t:direction (o/over))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, front; LH: into claw, front;\n",
      "LA: shake, up; LH: claw, front;\n",
      "LA: move, left; LH: front, claw;\n",
      "body: still;\n",
      "arms: move, up; hands: into open, up;\n",
      "body: move, back; arms: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/tower)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/tower)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:ARG1 (t/tower)\n",
      "\t\t:direction (l/left))\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, front; RH: into point, down;\n",
      "body: still;\n",
      "RA: move, back;\n",
      "arms: move, into gap, left; hands: facing, closed;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/spread-03\n",
      "\t\t:direction (a/apart))\n",
      "\t:ARG2 (a2/actor))\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (t/take-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:mod (a2/another)))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:ARG2 (n/next-to\n",
      "\t\t\t:op1 (i/it))))\n",
      "\n",
      "[{\"sentence\": \"Take another block and put it next to it.\", \"explanation\": \"The gesture AMR indicates a deixis towards a location (l/location), which is followed by an icon of putting something (p/put-01). The speech AMR provides the imperative mode for taking another block (b/block) and putting it next to it (n/next-to).\"}]\n",
      "take another block put it next to it\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: that's it\n",
      "Speech AMR:\n",
      " (b/be-it-07\n",
      "\t:ARG1 (t/that))\n",
      "\n",
      "Example 2:\n",
      "Sentence: think of like a wifi signal where it’s a u shape\n",
      "Speech AMR:\n",
      " (t/think-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (s/signal\n",
      "\t\t:mod (w/wifi)\n",
      "\t\t:ARG1-of (m/mean-01\n",
      "\t\t\t:ARG2 (s2/shape\n",
      "\t\t\t\t:mod (u/u)))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (o/okay)\n",
      "\n",
      "[{\"sentence\": \"Okay\", \"explanation\": \"The speech AMR indicates that the word 'okay' is being used as a standalone expression, likely to acknowledge or agree with something. The structure of the AMR is minimal, suggesting that no additional context or arguments are required for this particular instance of 'okay'. Therefore, the generated sentence is simply the word 'Okay', conveying a straightforward and informal acknowledgement.\"}]\n",
      "okay\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: just like that and then you’re gonna do that one more time in the same direction so it’s kind of like a slanting height three yeah\n",
      "Speech AMR:\n",
      " (d/do-02\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:quant 2\n",
      "\t:ARG6 (h/height\n",
      "\t\t:quant 3)\n",
      "\t:mod (s/slanting))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "head: rotate;\n",
      "RA: move, up; RH: into open, down;\n",
      "RA: shake, down;\n",
      "RH: rotate, into claw, left;\n",
      "RA: move, left;\n",
      "RA: move, down right; RH: into open, down;\n",
      "Unknown\n",
      "RA: move, down left; RH: into open, down;\n",
      "RA: move, up right;\n",
      "RA: move, down;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: not not too much\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:manner (m/much\n",
      "\t\t:polarity -\n",
      "\t\t:degree (t/too)))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: rotate;\n",
      "head: rotate;\n",
      "arms: shake;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (a/apart)\n",
      "\t:ARG2 (a2/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, front; RH: into point, down;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "[{\"sentence\": \"Point to the location in front of you.\", \"speech AMR\": \"(d/deixis-GA :ARG0 (y/you) :ARG1 (l/location) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate that the right arm is moving into a pointing position, and the left arm is moving towards the front. The gesture AMR shows a deixis gesture, which indicates pointing to a location, so we can infer that the speaker wants the listener to point to a location in front of them.\"}]\n",
      "okay\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay perfect\n",
      "Speech AMR:\n",
      " (o/okay)\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and two blocks like making it smile\n",
      "Speech AMR:\n",
      " (m/make-02\n",
      "\t:ARG0 (b/block\n",
      "\t\t:quant 2)\n",
      "\t:ARG1 (s/smile\n",
      "\t\t:ARG0 (i/it)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, up; hands: facing, into point;\n",
      "hands: rotate;\n",
      "hands: rotate;\n",
      "arms: move, down; hands: into claw, up;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/smile)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, front; RH: into point, down;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "Speech AMR:\n",
      " (o/okay)\n",
      "\n",
      "[{\"sentence\": \"I'm putting it over there.\", \"explanation\": \"The gesture label indicates the right arm moving forward and the right hand pointing downwards, suggesting a deictic movement towards a location. The speech AMR is 'o/okay', which implies acceptance or confirmation of something. Combining these elements, the sentence generated is 'I'm putting it over there.' as it conveys the action of placing something at a specific location while acknowledging or confirming the action.\"}]\n",
      "okay\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: scoot it over so there's the blocks are flush on one side\n",
      "Speech AMR:\n",
      " (s/scoot-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:ARG2 (o/over)\n",
      "\t:purpose (f/flush\n",
      "\t\t:domain (b/block)\n",
      "\t\t:location (o2/on\n",
      "\t\t\t:op1 (s2/side\n",
      "\t\t\t\t:quant 1))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: so like fanned out away from you\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG1 (f/fan-01\n",
      "\t\t:mod (o/out)\n",
      "\t\t:direction (a/away\n",
      "\t\t\t:op1 (y/you))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 1\n",
      "\t:location (o/on-top-of\n",
      "\t\t:op1 (b2/block\n",
      "\t\t\t:mod (t/that)\n",
      "\t\t\t:quant (e/each)\n",
      "\t\t\t:quant 2))))\n",
      "\n",
      "[{\"sentence\": \"There is one block on top of each other two blocks.\", \"explanation\": \"The speech AMR represents a sentence with the following structure: there is one block (quantified by '1') located in a specific location, which is 'on-top-of'. The location further specifies that it's 'each' of another two blocks (quantified by '2'), denoted as 'b2', and modified by 'that'. Therefore, the sentence describes one block being on top of each of two other blocks.\"}]\n",
      "one block on top of each of those two\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: just turn it turn it vertical okay\n",
      "Speech AMR:\n",
      " (t/turn-01\n",
      "\t:mode imperative\n",
      "\t:mod (j/just)\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:direction (v/vertical))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, down;\n",
      "hands: rotate;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (r/rotate-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: on the side with three the one closest to the middle put another block on top\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (a/another))\n",
      "\t:ARG2 (o/on-top\n",
      "\t\t:op1 (o2/one\n",
      "\t\t\t:ARG1-of (h/have-degree-91\n",
      "\t\t\t\t:ARG2 (c/close-10\n",
      "\t\t\t\t\t:ARG1 o2\n",
      "\t\t\t\t\t:ARG2 (m/middle))\n",
      "\t\t\t\t:ARG3 (m2/most))\n",
      "\t\t\t:location (o3/on\n",
      "\t\t\t\t:op1 (s/side\n",
      "\t\t\t\t\t:ARG0-of (h2/have\n",
      "\t\t\t\t\t\t:ARG1 (i2/implicit-role\n",
      "\t\t\t\t\t\t\t:quant 3)))))))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "LA: move, left; LH: into open, front;\n",
      "body: still;\n",
      "LH: into point, front;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/side)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: rotate; hands: into point, down;\n",
      "arms: move, down;\n",
      "body: still;\n",
      "Unknown\n",
      "body: still;\n",
      "RA: move, up; RH: into point, left;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "[{\"sentence\": \"Put it over there.\", \"speech AMR\": \"(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (i/it) :ARG2 (o/over-there))\", \"explanation\": \"The gesture labels indicate that the speaker is pointing to a location with their arm and hand, which corresponds to the 'deixis-GA' component in the Gesture AMR. The subsequent gestures of rotating arms and hands into point, followed by moving down, suggest the action of placing or putting something. The final gestures of RA moving up and RH into point left indicate the direction of the location where the object should be placed.\"}]\n",
      "one block on top of each of those two\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: in the middle\n",
      "Speech AMR:\n",
      " (i/in\n",
      "\t:op1 (m/middle))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "RA: move, down; RH: into claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and turn it so it's parallel\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (t/turn-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:purpose (p/parallel\n",
      "\t\t\t:domain i)))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into claw, front;\n",
      "RH: rotate, claw, front;\n",
      "RA: move, down; RH: claw, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/turn\n",
      "\t\t:ARG1 (b/block))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: rotate; hands: into point, down;\n",
      "arms: move, down;\n",
      "body: still;\n",
      "Unknown\n",
      "body: still;\n",
      "RA: move, up; RH: into point, left;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 1\n",
      "\t:location (o/on-top-of\n",
      "\t\t:op1 (b2/block\n",
      "\t\t\t:mod (t/that)\n",
      "\t\t\t:quant (e/each)\n",
      "\t\t\t:quant 2))))\n",
      "\n",
      "[{\"sentence\": \"Put that block on top of each other.\", \"explanation\": \"The gesture AMR indicates a 'gesture-unit' with two operations. The first operation is a deixis-GA, which represents pointing or indicating a location. In this case, the ARG1 (l/location) is likely referring to the location where the actor (ARG2) will be placed. The second operation is an icon-GA, which represents an action. Here, the action is 'put-01', and the ARG2 (a/actor) is likely referring to the block that will be put on top of something else. In the speech AMR, we see a block with a quantity of 1, located on-top-of another block (b2/block), which has a modifier (t/that) indicating it's the one being referred to by 'that'. The quantity of this block is also 2, suggesting that there are two blocks being referred to. Therefore, the sentence should be 'Put that block on top of each other.'\"}]\n",
      "one block on top of each of those two\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yup\n",
      "Speech AMR:\n",
      " (y/yup)\n",
      "\n",
      "Example 2:\n",
      "Sentence: then that’s it for your base uh your height you’re every\n",
      "Speech AMR:\n",
      " (b/be-01\n",
      "\t:ARG2 (o/or\n",
      "\t\t:op1 (b2/base\n",
      "\t\t\t:ord (z/zero)\n",
      "\t\t\t:poss (y/your))\n",
      "\t\t:op2 (h/height\n",
      "\t\t\t:ord z\n",
      "\t\t\t:poss y)))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (p/perfect)\n",
      "\n",
      "Here is the output:\n",
      "\n",
      "```\n",
      "[\n",
      "  {\n",
      "    \"sentence\": \"It's perfect.\",\n",
      "    \"explanation\": \"The speech AMR indicates that the word 'perfect' is being used as an adjective to describe something, which is a common usage of this word. The sentence should be in the present tense and have a neutral tone.\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "perfect grab\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and then there must be one a hard that i'm having time seeing behind\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (l/likely-01\n",
      "\t\t:ARG1 (b/be-02\n",
      "\t\t\t:ARG1 (o/one\n",
      "\t\t\t\t:location (b2/behind)\n",
      "\t\t\t\t:ARG1-of (s/see-01\n",
      "\t\t\t\t\t:ARG0 (i/i)\n",
      "\t\t\t\t\t:ARG1-of (h/hard-02))))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into point, front;\n",
      "RA: move, up; RH: point, front;\n",
      "Unknown\n",
      "RA: move, front; RH: point, front;\n",
      "RA: move, front; RH: point, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: place it so it's um sitting in between the two like that\n",
      "Speech AMR:\n",
      " (p/place-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:purpose (s/sit-01\n",
      "\t\t:ARG1 i\n",
      "\t\t:ARG2 (i2/in-between\n",
      "\t\t\t:op1 (i3/implicit-role\n",
      "\t\t\t\t:quant 2))\n",
      "\t\t:ARG1-of (l/like-04\n",
      "\t\t\t:ARG2 (t/that))))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: into facing, closed;\n",
      "arms: together, left, into contact, left; hands: closed, up;\n",
      "body: still;\n",
      "arms: apart, left; hands: facing, into fist;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/rotate-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"It's okay.\", \"speech AMR\": \"(e/emblem-GA :ARG0 (s/signaler) :ARG1 (o/ok) :ARG2 (a/actor))\", \"explanation\": \"The gesture label is unknown, but the gesture AMR indicates an emblem gesture with ARG1 being 'o/ok', which corresponds to a positive or affirmative meaning. Therefore, the generated sentence and speech AMR reflect this interpretation.\"}]\n",
      "perfect grab\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay\n",
      "Speech AMR:\n",
      " (o/okay)\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into four, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 4\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: have two blocks right next to each other\n",
      "Speech AMR:\n",
      " (h/have-03\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2)\n",
      "\t:destination (n/next-to\n",
      "\t\t:op1 (o/other\n",
      "\t\t\t:mod (e/each))))\n",
      "\n",
      "Gesture label(s): \n",
      "head: move, down; LA: move, front; LH: into open, back; RA: move, down;\n",
      "head: move, up;\n",
      "    LA: move, back;\n",
      "head: rotate;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 2\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (p/perfect)\n",
      "\n",
      "[{\"sentence\": \"It is okay.\", \"explanation\": \"The gesture label 'Unknown' does not provide any information about the hand or head movements, so we cannot infer a specific action. However, the Gesture AMR indicates that the signaler (ARG0) has an ARG1 of 'o/ok', which corresponds to the speech AMR '(p/perfect)' indicating completion or correctness. Therefore, the sentence should convey a sense of approval or confirmation.\"}]\n",
      "perfect grab\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: three to one but they all gonna be rotated a\n",
      "Speech AMR:\n",
      " (r/rotate-02\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/they\n",
      "\t\t:quant 3)\n",
      "\t:ARG3 (t2/implicit-role\n",
      "\t\t:quant 1))\n",
      "\n",
      "Example 2:\n",
      "Sentence: put a block one block apart behind\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1)\n",
      "\t:location (a/apart\n",
      "\t\t:mod (b2/block\n",
      "\t\t\t:quant 1))\n",
      "\t:location (b3/behind))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (a2/and\n",
      "\t\t:op1 (t/take-hold-24\n",
      "\t\t\t:ARG0 (y/you)\n",
      "\t\t\t:ARG1 (i/implicit-role\n",
      "\t\t\t\t:quant 1))\n",
      "\t\t:op2 (p/push-01\n",
      "\t\t\t:ARG0 y\n",
      "\t\t\t:ARG1 (i2/it)\n",
      "\t\t\t:ARG2 (f/forward\n",
      "\t\t\t\t:mod (s/slight))\n",
      "\t\t\t:purpose (i3/it\n",
      "\t\t\t\t:location (o/on\n",
      "\t\t\t\t\t:op1 (d/diagonal))))\n",
      "\t\t:time (t2/then)))\n",
      "\n",
      "[{\"sentence\": \"You take hold of one thing and then push it forward slightly to put it on the diagonal.\", \"explanation\": \"The speech AMR represents a sequence of actions. The first action is 'take-hold-24' where you are the actor (ARG0) and there's an implicit role (i/implicit-role :quant 1), which means one thing. This is combined with another 'and' operation, which includes another action 'push-01'. In this action, you are again the actor (ARG0), and it (i2/it) is the thing being pushed. The purpose of pushing it is to put it on something else, specifically on the diagonal (o/on :op1 (d/diagonal)). The time relationship between these two actions is 'then' (t2/then). Therefore, the sentence generated is a sequence of these actions in the correct order.\"}]\n",
      "and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: right there uh\n",
      "Speech AMR:\n",
      " (t/there\n",
      "\t:mod (r/right))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into open, down;\n",
      "RA: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: like not stacked\n",
      "Speech AMR:\n",
      " (s/stack-01\n",
      "\t:polarity -)\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "RA: move, up, surround; RH: into point, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "LA: move, right; LH: into closed, down; RH: into closed, left;\n",
      "LA: move, up;\n",
      "LA: move, down; RA: move, front;\n",
      "LA: move, up; LH: into claw, right\n",
      "arms: together, left, into contact;\n",
      "arms: move, back; hands: facing, into fist;\n",
      "head: rotate, left;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (f/forward))\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/touch-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"I'm going to slide this forward, touch it, and then hold still.\", \"speech AMR\": \"(i/icon-GA :ARG0 (s/signaler) :ARG1 (s2/slide-01 :direction (f/forward))) (i/icon-GA :ARG0 (s/signaler) :ARG1 (t/touch-01)) (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate a series of movements and actions: sliding something forward, touching it, and then holding still. The first two gestures match the icon-GA AMR, indicating an action performed by the signaler on the slide or touch. The third gesture matches the deixis-GA AMR, indicating a location or actor involved in the action.\"}]\n",
      "and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: alright\n",
      "Speech AMR:\n",
      " (a/alright)\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, back; arms: apart, left; hands: facing, claw;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/okay)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: so starting from the top moving to your left down four diagonally a row with the corners\n",
      "Speech AMR:\n",
      " (s/start-01\n",
      "\t:source (t/top)\n",
      "\t:destination (l/left\n",
      "\t\t:poss (y/you)\n",
      "\t\t:direction (d/down))\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:quant 4\n",
      "\t\t:direction (d2/diagonal)\n",
      "\t\t:ARG0-of (h/have-03\n",
      "\t\t\t:ARG1 (c/corner\n",
      "\t\t\t\t:ARG0-of (t2/touch-01)))))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up; hands: into claw, down;\n",
      "arms: move, down;\n",
      "RA: move, front right;\n",
      "head: rotate;\n",
      "RA: move, back left;\n",
      "RA: move, front right;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/diagonal)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/diagonal)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "LA: move, right; LH: into closed, down; RH: into closed, left;\n",
      "LA: move, up;\n",
      "LA: move, down; RA: move, front;\n",
      "LA: move, up; LH: into claw, right\n",
      "arms: together, left, into contact;\n",
      "arms: move, back; hands: facing, into fist;\n",
      "head: rotate, left;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (f/forward))\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/touch-01)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (a2/and\n",
      "\t\t:op1 (t/take-hold-24\n",
      "\t\t\t:ARG0 (y/you)\n",
      "\t\t\t:ARG1 (i/implicit-role\n",
      "\t\t\t\t:quant 1))\n",
      "\t\t:op2 (p/push-01\n",
      "\t\t\t:ARG0 y\n",
      "\t\t\t:ARG1 (i2/it)\n",
      "\t\t\t:ARG2 (f/forward\n",
      "\t\t\t\t:mod (s/slight))\n",
      "\t\t\t:purpose (i3/it\n",
      "\t\t\t\t:location (o/on\n",
      "\t\t\t\t\t:op1 (d/diagonal))))\n",
      "\t\t:time (t2/then)))\n",
      "\n",
      "[{\"sentence\": \"You take hold of it and push it forward slightly on the diagonal.\", \"explanation\": \"The gesture AMR indicates a series of actions performed by the signaler, including sliding something forward (op1) and touching something (op2). The speech AMR provides more context for these actions, indicating that the speaker is taking hold of an object and pushing it forward slightly on the diagonal. The explanation matches this interpretation, providing a clear and concise sentence based on the given gesture labels and AMRs.\"}]\n",
      "and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: move forward a bit\n",
      "Speech AMR:\n",
      " (m/move-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:direction (f/forward\n",
      "\t\t:degree (b/bit)))\n",
      "\n",
      "Example 2:\n",
      "Sentence: both sides\n",
      "Speech AMR:\n",
      " (s/side\n",
      "\t:mod (b/both))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (i/implicit-role\n",
      "\t:quant 2\n",
      "\t:ARG1-of (i2/include-91\n",
      "\t\t:ARG2 (t/they))\n",
      "\t:mod (o/only))\n",
      "\n",
      "[{\"sentence\": \"They are the only ones.\", \"explanation\": \"The speech AMR indicates that there is an implicit role with a quantity of 2, which suggests 'both' or 'two'. The ARG1-of relation points to the verb 'include', and the ARG2 is 'they'. This implies that 'they' are included in some group. The mod relation is 'only', indicating that they are the only ones in this group.\"}]\n",
      "only two of them\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: alright grab three blocks\n",
      "Speech AMR:\n",
      " (g/grab-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 3)\n",
      "\t:mod (a/all-right))\n",
      "\n",
      "Gesture label(s): \n",
      "    body: still;\n",
      "arms: move, front, into contact, left; hands: into inch, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/space-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: yea yea and then it\n",
      "Speech AMR:\n",
      " (g/good\n",
      "\t:domain (t/that))\n",
      "\n",
      "Gesture label(s): \n",
      "head: move, up, nod; LA: move, up; LH: into thumbs, up;\n",
      "body: move, down; head: move, down; LA: move, down; LH: into open, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: apart, left; hands: inch, down;\n",
      "LA: move, right; LH: into closed, down; RH: into closed, left;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/space-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"I don't understand.\", \"speech AMR\": \"(g/dont-know :mode declarative :ARG0 (i/i) :mod (n/no))\", \"explanation\": \"The gesture labels indicate a lack of understanding or confusion, with arms apart and hands inching down. The LA moving right and LH/RH closing down suggests a sense of uncertainty or puzzlement. In the speech AMR, 'I don't understand' is used to convey this sentiment in a declarative mode.\"}]\n",
      "only two of them\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: take one block and put it on the table\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (t/take-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:ARG2 (o/on\n",
      "\t\t\t:op1 (t2/table))))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, front; LH: into point, down;\n",
      "LA: move, to hip;\n",
      "RA: move, front; RH: into point, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: alright move one of the blocks off to the side\n",
      "Speech AMR:\n",
      " (m/move-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1)\n",
      "\t:ARG2 (o/off\n",
      "\t\t:op1 (s/side))\n",
      "\t:mod (a/all-right))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: into open, down;\n",
      "RA: move, up right; RH: closed, back;\n",
      "RA: move, down left; RH: open, down;\n",
      "body: still;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: apart, left; hands: inch, down;\n",
      "LA: move, right; LH: into closed, down; RH: into closed, left;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/space-01)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (i/implicit-role\n",
      "\t:quant 2\n",
      "\t:ARG1-of (i2/include-91\n",
      "\t\t:ARG2 (t/they))\n",
      "\t:mod (o/only))\n",
      "\n",
      "[{\"sentence\": \"They are only two.\", \"explanation\": \"The gesture labels indicate that the speaker is emphasizing a distinction between two entities, as evidenced by the arms being apart and the hands moving down. The speech AMR supports this interpretation with the 'quant 2' role and the 'only' modifier.\"}]\n",
      "only two of them\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yea and touching corners\n",
      "Speech AMR:\n",
      " (t/touch-01\n",
      "\t:ARG0 (c/corners))\n",
      "\n",
      "Example 2:\n",
      "Sentence: yea on the side with four on the last one on the inside corner there is another block yeah\n",
      "Speech AMR:\n",
      " (b/be-located-at-91\n",
      "\t:ARG1 (b2/block\n",
      "\t\t:mod (a/another))\n",
      "\t:ARG2 (c/corner\n",
      "\t\t:mod (i/inside)\n",
      "\t\t:poss (i2/implicit-role\n",
      "\t\t\t:ord (o/ordinal-entity\n",
      "\t\t\t\t:value -1)\n",
      "\t\t\t:location (o2/on\n",
      "\t\t\t\t:op1 (s/side\n",
      "\t\t\t\t\t:ARG0-of (h/have-03\n",
      "\t\t\t\t\t\t:ARG1 (i3/implicit-role\n",
      "\t\t\t\t\t\t\t:quant 4)))))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (p/place-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:ARG2 (o/on\n",
      "\t\t:op1 (i2/implicit-role\n",
      "\t\t\t:quant 2\n",
      "\t\t\t:mod (d/diagonal))))\n",
      "\n",
      "[{\"sentence\": \"You place it on the diagonal.\", \"explanation\": \"The speech AMR indicates that the sentence is in imperative mode, meaning it's a command. The ARG0 is 'y/you', indicating the subject of the sentence is 'you'. The ARG1 is 'i/it', which is the object being placed. The ARG2 is 'o/on', with an implicit role indicating placement on the diagonal, and a quantity of 2.\"}]\n",
      "place it on the two that are diagonal and\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: one block on each side\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 1\n",
      "\t:location (o/on\n",
      "\t\t:op1 (s/side\n",
      "\t\t\t:quant (e/each)))))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, left; LH: into L, down;\n",
      "RA: move, right; RH: into L, down;\n",
      "body: still;\n",
      "arms: move, down;\n",
      "arms: rotate; hands: into point, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: five blocks in a row right in front of them\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 5)\n",
      "\t:manner (r/row)\n",
      "\t:location (f/front\n",
      "\t\t:poss (t/them)\n",
      "\t\t:mod (r2/right)))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into five, front;\n",
      "arms: move, front; hands: facing, into point, down;\n",
      "arms: move, back, to hip;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 5\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/row)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RH: rotate, into point, down left;\n",
      "RA: move, down; RH: point, down;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Point to the left, then down.\", \"speech AMR\": \"(i/implicit-predicate-00 :mode imperative :ARG0 (y/you) :ARG1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) :manner (p/point)) (i/implicit-predicate-00 :mode imperative :ARG0 (y/you) :ARG1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) :manner (d/down))\", \"explanation\": \"The gesture AMR indicates two separate actions: pointing to the left and then down. The speech AMR is generated accordingly, with each action represented as an implicit predicate in imperative mode.\"}]\n",
      "place it on the two that are diagonal and\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay and\n",
      "Speech AMR:\n",
      " (o/okay)\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "RA: move, right; RH: into closed, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/side)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: but it's still in berlin\n",
      "Speech AMR:\n",
      " (c/contrast-01\n",
      "\t:ARG2 (b/be-located-at-91\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:ARG2 (b2/Berlin)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 b2\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RH: rotate, into point, down left;\n",
      "RA: move, down; RH: point, down;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (p/place-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:ARG2 (o/on\n",
      "\t\t:op1 (i2/implicit-role\n",
      "\t\t\t:quant 2\n",
      "\t\t\t:mod (d/diagonal))))\n",
      "\n",
      "[{\"sentence\": \"Point it down there.\", \"explanation\": \"The gesture labels indicate that the right hand is rotating and pointing downwards, while the left hand is moving downwards. The speech AMR indicates an imperative mode, suggesting a command or instruction. The deixis-GA in the gesture AMR suggests a pointing action, which aligns with the 'point' action in the speech AMR. Therefore, the generated sentence is a command to point something down at a location.\"}]\n",
      "place it on the two that are diagonal and\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: please close a little bit the base the base\n",
      "Speech AMR:\n",
      " (c/close-01\n",
      "\t:mode imperative\n",
      "\t:polite +\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/base)\n",
      "\t:degree (b2/bit\n",
      "\t\t:mod (l/little)))\n",
      "\n",
      "Example 2:\n",
      "Sentence: so that’s our new you did not miss from in right blocks space\n",
      "Speech AMR:\n",
      " (u/unit\n",
      "\t:ARG1-of (n/new-01)\n",
      "\t:poss (w/we)\n",
      "\t:ARG2-of (m/measure-01)\n",
      "\t:domain (b/block_space))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (f/flip-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:quant 2\n",
      "\t\t:mod (t/that)))\n",
      "\n",
      "[{\"sentence\": \"You flip that.\", \"explanation\": \"The speech AMR indicates an imperative mode, meaning the sentence is a command. The ARG0 is 'y/you', indicating the subject of the sentence is the person being addressed. The ARG1 is 'i/implicit-role' with a quantifier of 2 and a modifier 't/that', suggesting that the object to be flipped is something that has been previously mentioned or implied, likely an object in the context.\"}]\n",
      "flip those two\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: move them this direction like you had it before so they’re touching corners\n",
      "Speech AMR:\n",
      " (m/move-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:direction (d/direction\n",
      "\t\t:mod (t2/this))\n",
      "\t:ARG1-of (l/like-04\n",
      "\t\t:ARG2 (h/have-04\n",
      "\t\t\t:ARG0 y\n",
      "\t\t\t:ARG1 (i/it)\n",
      "\t\t\t:time (b/before)))\n",
      "\t:purpose (t3/touch-01\n",
      "\t\t:ARG0 (t4/they)\n",
      "\t\t:ARG1 (c/corner)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, front; LH: closed, right; RA: move, back; RH: closed, left;\n",
      "body: still;\n",
      "arms: move, into contact;\n",
      "body: still;\n",
      "arms: move, into gap; hands: facing, closed;\n",
      "arms: move, down back; hands: into open, down;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/touch-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/rotate-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: on top of that you're going to between the overlapping the two you're going to have two blocks or the uh middle three\n",
      "Speech AMR:\n",
      " (h/have-01\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2)\n",
      "\t:ARG2 (o/on\n",
      "\t\t:location (m/middle\n",
      "\t\t\t:quant 3))\n",
      "\t:location (o2/or)\n",
      "\t:op1 (t/top\n",
      "\t\t:ARG1 (t2/that))\n",
      "\t:op2 (b2/between\n",
      "\t\t:ARG2 b\n",
      "\t\t:quant 2\n",
      "\t\t:mod (o3/overlapping)))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: together, left, into gap, left; hands: into claw, down;\n",
      "body: still;\n",
      "Unknown\n",
      "arms: move, up; hands: into facing, closed;\n",
      "body: still;\n",
      "hands: into inch, front;\n",
      "body: still;\n",
      "hands: into claw, down;\n",
      "arms: move, down;\n",
      "body: still;\n",
      "head: rotate;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/top)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/between)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 2)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/iconic-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 2)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "LA: move, front; LH: closed, right; RA: move, back; RH: closed, left;\n",
      "arms: move, down back; hands: into fist, back;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (f/flip-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (n/no)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Move them this way, like you had it before.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (t/them) :direction (d/direction :mod (t2/this)) :ARG1-of (l/like-04 :ARG2 (h/have-04 :ARG0 y :ARG1 (i/it) :time (b/before)))\", \"explanation\": \"The gesture labels indicate a movement of the left arm forward, with the right hand closed and the right arm moving backward. The hands then move down to the back in a fist shape. This corresponds to flipping something, which is indicated by the icon-GA 'f/flip-01'. The emblem-GA 'n/no' suggests negation or opposition, implying that the speaker wants to do it differently. Therefore, the sentence should be about moving something in a certain way, like before.\"}]\n",
      "flip those two\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: so you could squeeze them together a little bit there you go\n",
      "Speech AMR:\n",
      " (s/squeeze-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:direction (t2/together\n",
      "\t\t:mod (l/little)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: shake, left; hands: closed;\n",
      "arms: move, down; RH: into fist, down;\n",
      "LA: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/squeeze\n",
      "\t\t:direction (t/together))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: block the goes on top of the block you just placed but not totally centered\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (a/another)\n",
      "\t\t:ARG1-of (b2/be-located-at-91\n",
      "\t\t\t:ARG2 (c/contrast-01\n",
      "\t\t\t\t:ARG1 (o/on\n",
      "\t\t\t\t\t:op1 (t/top\n",
      "\t\t\t\t\t\t:poss b\n",
      "\t\t\t\t\t\t:ARG1-of (p/place-01\n",
      "\t\t\t\t\t\t\t:ARG0 b\n",
      "\t\t\t\t\t\t\t:time (j/just))))\n",
      "\t\t\t\t:ARG2 (c2/center-01\n",
      "\t\t\t\t\t:polarity -\n",
      "\t\t\t\t\t:mod (t2/total))))))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "LA: move, up; LH: into point, front;\n",
      "body: still;\n",
      "body: move, down; arms: move, down; hands: into open, back down;\n",
      "body: still;\n",
      "head: rotate;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "LA: move, front; LH: closed, right; RA: move, back; RH: closed, left;\n",
      "arms: move, down back; hands: into fist, back;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (f/flip-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (n/no)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (f/flip-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:quant 2\n",
      "\t\t:mod (t/that)))\n",
      "\n",
      "[{\"sentence\": \"Flip that over.\", \"explanation\": \"The gesture AMR indicates a flip action, which is an imperative mode in the speech AMR. The ARG0 of the icon-GA is the signaler, and the ARG1 is the flip action. The ARG2 is the actor, which corresponds to 'you' in the speech AMR. Therefore, the sentence should be in the imperative mood and indicate a flip action directed at the speaker.\"}]\n",
      "flip those two\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: this one is like three towers next to each other\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG0 (t/this\n",
      "\t\t:quant 1)\n",
      "\t:ARG1 (t2/tower\n",
      "\t\t:quant 3\n",
      "\t\t:mod (n/next-02\n",
      "\t\t\t:ARG1 (e/each))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: now the ones i just told you to put that were two that last two i told you to put\n",
      "Speech AMR:\n",
      " (k/know-02\n",
      "\t:polarity (a/amr-unknown)\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:quant 2\n",
      "\t\t:mod (l/last)\n",
      "\t\t:ARG1-of (p/put-01\n",
      "\t\t\t:ARG0 y\n",
      "\t\t\t:ARG1-of (t/tell-01\n",
      "\t\t\t\t:ARG0 (i2/I)))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (k/keep-02\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG2 (g/go-01\n",
      "\t\t:ARG2 (m/more\n",
      "\t\t\t:quant (b/bit\n",
      "\t\t\t\t:mod (l/little)))))\n",
      "\n",
      "[{\"sentence\": \"You keep going a little more.\", \"explanation\": \"The speech AMR indicates that the sentence is in imperative mode, meaning it's a command. The ARG0 is 'you', indicating the subject of the sentence. The ARG2 is 'g/go-01', which means to go or move. The ARG2 of this action is 'm/more', indicating an increase or addition. This is modified by 'l/little', which means small or a little bit, and quantified by 'b/bit', indicating a unit of measurement.\"}]\n",
      "keep going a little bit more\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: put them to the side of that little section so they line up\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:direction (t2/to\n",
      "\t\t:op1 (s/side\n",
      "\t\t\t:poss (s2/section\n",
      "\t\t\t\t:mod (t3/that)\n",
      "\t\t\t\t:mod (l/little))))\n",
      "\t:purpose (l2/line-up\n",
      "\t\t:ARG1 (t4/they)))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, left, into contact, left; hands: facing, closed;\n",
      "arms: move, left; LH: closed, right; RH: closed, back;\n",
      "Rh: into fist, back;\n",
      "LA: move, right; LH: closed, right;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (l/left))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: they gonna be all connecting\n",
      "Speech AMR:\n",
      " (c/connect-01\n",
      "\t:ARG1 (t/they))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, front;\n",
      "arms: move, back;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "arms: move, down back; hands: facing, into fist;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/rotate-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"They're going to be all connected.\", \"speech AMR\": \"(c/connect-01 :ARG1 (t/they))\", \"explanation\": \"The gesture label 'arms: move, down back' and 'hands: facing, into fist' implies a connection or union of something. The gesture AMR indicates rotation, which can be interpreted as bringing things together to form a connection. Therefore, the sentence generated is in the present tense, indicating an action that will happen.\"}]\n",
      "keep going a little bit more\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: it's just on the table\n",
      "Speech AMR:\n",
      " (b/be-located-at-91\n",
      "\t:ARG0 (i/it)\n",
      "\t:ARG1 (o/on\n",
      "\t\t:op1 (t/table))\n",
      "\t:mod (j/just))\n",
      "\n",
      "Gesture label(s): \n",
      "head: move, up;\n",
      "arms: move, front; hands: into point, down;\n",
      "head: shake; RA: move, back;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: you see how there are three divots\n",
      "Speech AMR:\n",
      " (s/see-01\n",
      "\t:polarity (a/amr-unknown)\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (d/divot\n",
      "\t\t:quant 3))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "arms: move, front; hands: into facing, left, into claw, left;\n",
      "arms: move, back; hands: into claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (d/divot)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d2/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "arms: move, down back; hands: facing, into fist;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/rotate-01)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (k/keep-02\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG2 (g/go-01\n",
      "\t\t:ARG2 (m/more\n",
      "\t\t\t:quant (b/bit\n",
      "\t\t\t\t:mod (l/little)))))\n",
      "\n",
      "[{\"sentence\": \"Go more slowly.\", \"explanation\": \"The gesture AMR indicates the action of rotating, which is associated with movement or change in direction. The speech AMR suggests an imperative mode and a command to go more, implying a need for gradual or slower movement.\"}]\n",
      "keep going a little bit more\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: three blocks\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 3)\n",
      "\n",
      "Example 2:\n",
      "Sentence: it will be diagonal like a diamond no no no\n",
      "Speech AMR:\n",
      " (d/diagonal\n",
      "\t:domain (i/it\n",
      "\t\t:ARG1-of (r/resemble-01\n",
      "\t\t\t:ARG2 (d2/diamond))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1-of (r/resemble-01\n",
      "\t\t:ARG2 (t1/that)\n",
      "\t\t:mod (j/just)\n",
      "\t\t:concession-of (h/have-degree-91\n",
      "\t\t\t:ARG2 (c/close\n",
      "\t\t\t\t:direction (t/together))\n",
      "\t\t\t:ARG3 (m/more))))\n",
      "\n",
      "[{\"sentence\": \"You should just resemble that, having them close together more.\", \"explanation\": \"The speech AMR indicates an imperative mode, meaning the sentence is a command or suggestion. The ARG0 is 'you', indicating the subject of the sentence. The :ARG1-of relation shows that the verb 'resemble' has two arguments: ARG2 (that) and mod (just). The concession-of relation indicates a concession or exception to the main action, which in this case is having them close together more.\"}]\n",
      "just like that but closer together\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: make a little bit of gap but in line with the back block okay\n",
      "Speech AMR:\n",
      " (m/make-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (c/contrast-01\n",
      "\t\t:ARG1 (g/gap\n",
      "\t\t\t:quant (b/bit\n",
      "\t\t\t\t:mod (l/little)))\n",
      "\t\t:ARG2 (i/in-line-04\n",
      "\t\t\t:ARG2 (b2/block\n",
      "\t\t\t\t:mod (b3/back)))))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "Unknown\n",
      "arms: apart, left; hands: claw, down;\n",
      "Unknown\n",
      "body: still;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/line)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and then grab another block\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (g/grab-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:mod (a2/another))\n",
      "\t\t:time (t/then)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "RH: into closed, left;\n",
      "hands: into facing, closed;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/rotate-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, down back; hands: into fist, back;\n",
      "arms: move, front, into gap, left; hands: facing, into closed;\n",
      "arms: move, down; hands: into claw, back;\n",
      "LA: move, up front; LH: into point, front;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (m/move-01\n",
      "\t\t:direction (t/together))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Move back and then move forward into the gap on the left.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/back) :time (t/then)) (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (i/into-04 :ARG2 (g/gap :mod (l/left))))\", \"explanation\": \"The gesture label indicates that the arms move down back, then front into a gap on the left. The hands also perform different actions during these movements. The speech AMR reflects this sequence of movement and direction.\"}]\n",
      "just like that but closer together\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: save on the fourth block on the other side\n",
      "Speech AMR:\n",
      " (s/same-01\n",
      "\t:ARG0 (b/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value 4)\n",
      "\t\t:location (s1/side\n",
      "\t\t\t:mod (o2/other))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, front; hands: into point, down;\n",
      "RA: shake, left;\n",
      "RA: move, back right; RH: into open, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: that one okay\n",
      "Speech AMR:\n",
      " (o/one\n",
      "\t:mod (t/that))\n",
      "\n",
      "Gesture label(s): \n",
      "head: nod;\n",
      "body: move, left;\n",
      "body: still;\n",
      "RA: move, right; RH: into closed, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/side)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, down back; hands: into fist, back;\n",
      "arms: move, front, into gap, left; hands: facing, into closed;\n",
      "arms: move, down; hands: into claw, back;\n",
      "LA: move, up front; LH: into point, front;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (m/move-01\n",
      "\t\t:direction (t/together))\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1-of (r/resemble-01\n",
      "\t\t:ARG2 (t1/that)\n",
      "\t\t:mod (j/just)\n",
      "\t\t:concession-of (h/have-degree-91\n",
      "\t\t\t:ARG2 (c/close\n",
      "\t\t\t\t:direction (t/together))\n",
      "\t\t\t:ARG3 (m/more))))\n",
      "\n",
      "[{\"sentence\": \"Put that just like this.\", \"explanation\": \"The gesture AMR indicates the use of an icon, which is a symbol or representation used to convey meaning. The speech AMR shows that the sentence should be in the imperative mode and 'you' is the subject performing the action. The hands are moving into closed fists and then back down, indicating a precise or exact movement. This suggests that the speaker wants the listener to put something in a specific way, just like they are demonstrating.\"}]\n",
      "just like that but closer together\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yep\n",
      "Speech AMR:\n",
      " (y/yep)\n",
      "\n",
      "Example 2:\n",
      "Sentence: looks like like a like jenga\n",
      "Speech AMR:\n",
      " (l/look-02\n",
      "\t:ARG1 (j/jenga))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (m/matter-01\n",
      "\t:ARG0 (i/it)\n",
      "\t:polarity -))\n",
      "\n",
      "[{\n",
      "  \"sentence\": \"It matters.\",\n",
      "  \"explanation\": \"The speech AMR indicates that 'matter' is the main concept, with 'it' as the subject (:ARG0) and a positive polarity (-)). This suggests that the sentence should convey a neutral or affirmative statement about something being important or significant.\"\n",
      "}]\n",
      "doesn't matter\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: maybe just pushed like slightly in the same\n",
      "Speech AMR:\n",
      " (p/push-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG2 (s/same)\n",
      "\t:degree (s2/slight\n",
      "\t\t:mod (j/just))\n",
      "\t:ARG1-of (p2/possible-01))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, up; RA: move, up left; RH: into open, left;\n",
      "RA: move, down; RH: into open, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/push-01\n",
      "\t\t:direction (l/left))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: the third block is it's on top of that block but it's pushed just slightly to the a off of it\n",
      "Speech AMR:\n",
      " (b/be-located-at-91\n",
      "\t:ARG1 (b2/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value 3))\n",
      "\t:ARG2 (o2/on\n",
      "\t\t:op1 (t/top\n",
      "\t\t\t:op1 (b3/block\n",
      "\t\t\t\t:mod (t2/that))))\n",
      "\t:concession (p/push-01\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:ARG2 (r/right\n",
      "\t\t\t:degree (s/slight\n",
      "\t\t\t\t:mod (j/just))\n",
      "\t\t\t:direction (o3/off\n",
      "\t\t\t\t:op1 (i2/it)))\n",
      "\t\t:time (t3/then)))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "RA: move, up, shake, down; RH: into claw, left;\n",
      "Unknown\n",
      "RA: move, right;\n",
      "arms: move, down; hands: into open, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a)\n",
      "\t:op3 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "LA: move, front; LH: into point, down;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Look at that.\", \"speech AMR\": \"(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate a forward movement and pointing downwards with the left hand, which is typically associated with directing attention to a location. The gesture AMR confirms this interpretation by indicating deixis (pointing or showing) towards a location.\"}]\n",
      "doesn't matter\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: one on the your le- yeah that one your left side its gonna be just one on top\n",
      "Speech AMR:\n",
      " (b/be-01\n",
      "\t:ARG0 (o/one\n",
      "\t\t:mod (o2/on\n",
      "\t\t\t:direction (l/left\n",
      "\t\t\t\t:poss (y/your))))\n",
      "\t:ARG6 o\n",
      "\t:mod o2\n",
      "\t:location (t/top))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up;\n",
      "body: still;\n",
      "RA: move, right;\n",
      "Unknown\n",
      "RA: move, up;\n",
      "RA: move, down;\n",
      "Unknown\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/left)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: keep them like turn them hor- vertically\n",
      "Speech AMR:\n",
      " (t/turn-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t2/them)\n",
      "\t:direction (h/horizontal))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up front, into gap, left; hands: facing, into claw;\n",
      "hands: rotate, claw, down;\n",
      "hands: claw, down; LA: move, back; RA: move, front;\n",
      "hands: claw, down; LA: move, front; RA: move, back;\n",
      "hands: claw, down; LA: move, back; RA: move, front;\n",
      "hands: claw, down; LA: move, front; RA: move, back;\n",
      "hands: claw, down; LA: move, back; RA: move, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (r/rotate-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "LA: move, front; LH: into point, down;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (m/matter-01\n",
      "\t:ARG0 (i/it)\n",
      "\t:polarity -))\n",
      "\n",
      "[{\"sentence\": \"Look down.\", \"explanation\": \"The gesture label LH: into point, down indicates a downward pointing action with the left hand. The gesture AMR d/deixis-GA suggests a deictic or pointing gesture, which is typically used to indicate a location or direction. In this case, the combination of these elements suggests that the speaker is indicating a downward direction, which corresponds to the sentence 'Look down'.\"}]\n",
      "doesn't matter\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: good\n",
      "Speech AMR:\n",
      " (g/good)\n",
      "\n",
      "Example 2:\n",
      "Sentence: two eyes first\n",
      "Speech AMR:\n",
      " (e/eye\n",
      "\t:quant 2\n",
      "\t:li 1)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (m/move\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (t/those)\n",
      "\t\t:direction (t2/together\n",
      "\t\t\t:ARG1-of (h/have-degree-91\n",
      "\t\t\t\t:ARG2 (c/close)\n",
      "\t\t\t\t:ARG3 (m2/more)\n",
      "\t\t\t\t:degree (b/bit\n",
      "\t\t\t\t\t:mod (l/little)))))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 (t3/that)\n",
      "\t\t:ARG2 (o/on\n",
      "\t\t\t:op1 (t4/top))))\n",
      "\n",
      "[{\"sentence\": \"You move those together to have them close a bit more, and put that on the top.\", \"explanation\": \"The speech AMR represents two imperative actions: moving 'those' together in a certain way, and putting 'that' on something (specifically, the top of something). The first action is described as 'together', with a specific degree of closeness ('a bit more'). The second action is simply to put 'that' on the top. The subject of both actions is 'you'. I combined these two actions into one sentence using 'and' because they are both imperative and seem to be related in meaning.\"}]\n",
      "move those together a little bit closer and then put that on top yay\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: um i think everything needs to be slightly closer together\n",
      "Speech AMR:\n",
      " (t/think-01\n",
      "\t:ARG0 (i/i)\n",
      "\t:ARG1 (h/have-degree-91\n",
      "\t\t:ARG1 (e/everything)\n",
      "\t\t:ARG2 (t2/together\n",
      "\t\t\t:mod (c/close-10))\n",
      "\t\t:ARG3 (m/more\n",
      "\t\t\t:mod (s/slightly))))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up; hands: into claw, down;\n",
      "arms: together, left, gap, left; hands: claw, down;\n",
      "body: still;\n",
      "arms: move, down; hands: into claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/close-06)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: stick them on the table in a line in front of you\n",
      "Speech AMR:\n",
      " (s/stick-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:ARG2 (t2/table)\n",
      "\t:manner (l/line\n",
      "\t\t:location (f/front\n",
      "\t\t\t:poss y)))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "head: move, down; arms: together, left; hands: into claw, down;\n",
      "arms: apart, left;\n",
      "head: move, up;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/line)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: shake, left; hands: facing, closed;\n",
      "arms: move, up; hands: into point, front;\n",
      "arms: move, down back; hands: point, down;\n",
      "LH: into fist, back;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (m/move-01\n",
      "\t\t\t:direction (t/together))\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "[{\"sentence\": \"Put the object together in front of you.\", \"speech AMR\": \"(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (o/object) :ARG2 (t/together :location (f/front :poss y)))\", \"explanation\": \"The gesture label(s) indicate that the speaker is pointing to an object and moving their arms together, suggesting a command to put the object in front of the listener. The speech AMR reflects this interpretation, with 'put' as the main verb and 'together' as a location for the object.\"}]\n",
      "move those together a little bit closer and then put that on top yay\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: get two blocks and put them on the\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (g/get-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 2))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:quant 2))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up; hands: into claw, down;\n",
      "Unknown\n",
      "arms: move, up; hands: into claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/put-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: no no\n",
      "Speech AMR:\n",
      " (n/no)\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (n/no)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: shake, left; hands: facing, closed;\n",
      "arms: move, up; hands: into point, front;\n",
      "arms: move, down back; hands: point, down;\n",
      "LH: into fist, back;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (m/move-01\n",
      "\t\t\t:direction (t/together))\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (m/move\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (t/those)\n",
      "\t\t:direction (t2/together\n",
      "\t\t\t:ARG1-of (h/have-degree-91\n",
      "\t\t\t\t:ARG2 (c/close)\n",
      "\t\t\t\t:ARG3 (m2/more)\n",
      "\t\t\t\t:degree (b/bit\n",
      "\t\t\t\t\t:mod (l/little)))))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 (t3/that)\n",
      "\t\t:ARG2 (o/on\n",
      "\t\t\t:op1 (t4/top))))\n",
      "\n",
      "[{\"sentence\": \"You move those together, close more a bit little and put that on top.\", \"explanation\": \"The gesture AMR indicates two units of gestures. The first unit is a deixis gesture pointing to a location, followed by an icon gesture representing the action 'move' with direction 'together'. The second unit is again a deixis gesture pointing to a location, followed by an icon gesture representing the action 'put' with arguments indicating that something should be put on top of another. From the speech AMR, we can see that the first action is in imperative mode and refers to the speaker (y/you) moving those things together, close more a bit little. The second action is also in imperative mode and refers to the speaker putting that thing on top. Combining these two actions with their corresponding gestures gives us the sentence 'You move those together, close more a bit little and put that on top.'.\"}]\n",
      "move those together a little bit closer and then put that on top yay\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: close a little bit more not\n",
      "Speech AMR:\n",
      " (c/close-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:degree (m/more\n",
      "\t\t:degree (b2/bit\n",
      "\t\t\t:mod (l/little))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: but bothe opposite way like\n",
      "Speech AMR:\n",
      " (c/contrast-01\n",
      "\t:ARG2 (i/implicit-predicate-00\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:direction (w/way\n",
      "\t\t\t:mod (o/opposite))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:ARG2 (t2/together))\n",
      "\n",
      "[{\"sentence\": \"Put them together.\", \"explanation\": \"The speech AMR indicates an imperative mode, meaning the sentence is a command. The ARG0 is 'y/you', indicating the subject of the sentence is the person being addressed. The ARG1 is 't/them', which are the objects to be put together. The ARG2 is 't2/together', specifying that they should be placed in close proximity or assembled.\"}]\n",
      "put them together\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yeah\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: now stick a block on the front one and the one to your left\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (s/stick-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1)\n",
      "\t\t:location (o/on\n",
      "\t\t\t:op1 (o2/one\n",
      "\t\t\t\t:mod (f/front)))\n",
      "\t\t:time (n/now))\n",
      "\t:op2 s\n",
      "\t\t:time n\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 (b2/block\n",
      "\t\t\t:quant 1)\n",
      "\t\t:location (o3/on\n",
      "\t\t\t:op1 (o4/one\n",
      "\t\t\t\t:ARG1-of (l/left-20\n",
      "\t\t\t\t\t:ARG2 y))))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, down; hands: into claw, down;\n",
      "RA: move, up; RH: into claw, down;\n",
      "RA: move, down left; RH: claw, down;\n",
      "RA: move, up right; RH: claw, down;\n",
      "LA: move, up right; LH: into closed, down; RA: move, up back; RH: claw, down;\n",
      "LA: move, down left; LH: into claw, down; RA: move, down front; RH: claw, down;\n",
      "RA: move, up right; RH: into closed, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01\n",
      "\t\t\t:ARG1 (b/block))\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(a/and\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/left-20\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:ARG2 a2))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (m/move-01\n",
      "\t\t\t:direction (f/front))\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: together, left;\n",
      "body: still;\n",
      "    Unknown\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/push-01\n",
      "\t\t:ARG2 (t/together))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Push together\", \"speech AMR\": \"(i/icon-GA :op1 (p/push-01 :mode imperative :ARG0 (y/you) :ARG1 (t/together) :ARG2 (a/actor)))\", \"explanation\": \"The gesture label indicates that the arms are moving together to the left, which corresponds to the ARG1 'together' in the gesture AMR. The body being still suggests an imperative mode, and the actor is implied to be the speaker themselves.\"}]\n",
      "put them together\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: every things on top of that\n",
      "Speech AMR:\n",
      " (b/be-01\n",
      "\t:ARG1 (e/everything)\n",
      "\t:location (t/top\n",
      "\t\t:ARG2 (t2/that)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: shake, left;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/base)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and then put the third one on the fourth one on top of these the middle one\n",
      "Speech AMR:\n",
      " (p/put\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: claw, down;\n",
      "RA: move, left; RH: into point, front;\n",
      "RA: move, right;\n",
      "RA: move, back;\n",
      "RA: move, front; RH: claw, down;\n",
      "RA: move, back; RH: into fist, back;\n",
      "RA: move, up; RH: into one, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: together, left;\n",
      "body: still;\n",
      "    Unknown\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/push-01\n",
      "\t\t:ARG2 (t/together))\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:ARG2 (t2/together))\n",
      "\n",
      "[{\"sentence\": \"Put them together.\", \"explanation\": \"The gesture label 'arms: together, left' indicates a movement of the arms towards each other, suggesting a collective or unified action. The speech AMR '(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (t/them) :ARG2 (t2/together))' also supports this interpretation by specifying 'together' as an argument of the verb 'put'. Therefore, a sentence that combines these elements is 'Put them together.'\"}]\n",
      "put them together\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: we’ll have another block just falling down as if it just for fell down from heaven\n",
      "Speech AMR:\n",
      " (h/have-03\n",
      "\t:ARG0 (w/we)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (a/another)\n",
      "\t\t:ARG1-of (f/fall-01\n",
      "\t\t\t:direction (d/down)\n",
      "\t\t\t:mod (j/just)\n",
      "\t\t\t:conj-as-if f\n",
      "\t\t\t:ARG1 (i/it)\n",
      "\t\t\t:ARG3 (f2/from\n",
      "\t\t\t\t:op1 (h2/heaven)))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and then there's two blocks um a little bit like out and then down or up for you\n",
      "Speech AMR:\n",
      " (b/be-located-at-91\n",
      "\t:time (t/then)\n",
      "\t:ARG1 (b2/block\n",
      "\t\t:quant 2)\n",
      "\t:ARG2 (a/and\n",
      "\t\t:op1 (o/out\n",
      "\t\t\t:degree (b3/bit\n",
      "\t\t\t\t:mod (l/little)))\n",
      "\t\t:op2 (o2/or\n",
      "\t\t\t:time (t2/then)\n",
      "\t\t\t:op1 (d/down)\n",
      "\t\t\t:op2 (u/up\n",
      "\t\t\t\t:poss (y/you)))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 2\n",
      "\t:mod (m/more))\n",
      "\n",
      "[{\"sentence\": \"There are two more blocks.\", \"explanation\": \"The speech AMR indicates that the subject is 'block' with a quantity of 2 and modified by 'more'. This suggests that there are two additional or extra blocks, which can be translated to 'two more blocks'.\"}]\n",
      "two more blocks up\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and they are just straight\n",
      "Speech AMR:\n",
      " (s/straight-04\n",
      "\t:ARG1 (t/they)\n",
      "\t:mod (j/just))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up, into gap, left;\n",
      "arms: shake, left; hands: closed, down;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/straight)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: the bottom layer starts with four blocks\n",
      "Speech AMR:\n",
      " (s/starts-01\n",
      "\t:ARG0 (l/layer\n",
      "\t\t:ARG0-of (b/bottom))\n",
      "\t:instrument (b2/blocks\n",
      "\t\t:quant 4))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, front; hands: into open, down;\n",
      "arms: apart, left;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/bottom)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 i\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/layer)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RH: into two, up;\n",
      "RA: move, back; RH: to face;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 2\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "[{\"sentence\": \"The block is over there, and it's two.\", \"speech AMR\": \"(s/is-01 :ARG1 (b/block) :mod (d/deixis-GA :ARG0 (t/there) :ARG1 (a/actor)) :op2 (i/icon-GA :mode expressive :ARG0 s :ARG1 2 :ARG2 a))\", \"explanation\": \"The gesture label indicates that the speaker is pointing to something behind them with their right hand, and then moving their left arm back while facing forward. The speech AMR represents this as 'the block' being in a location indicated by deixis (pointing), and also specifying that there are two of them.\"}]\n",
      "two more blocks up\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: all right then stick\n",
      "Speech AMR:\n",
      " (s/stick-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:time (t/then)\n",
      "\t:mod (a/all-right))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up, gap, left; hands: claw, down;\n",
      "arms: move, down; hands: into claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (g/grab-01\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 2))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and do the exact same thing there\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (d/do-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (t/thing\n",
      "\t\t\t:mod (s/same\n",
      "\t\t\t\t:mod (e/exact)))\n",
      "\t\t:location (t2/there)))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: claw, down;\n",
      "RA: move, down; RH: claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RH: into two, up;\n",
      "RA: move, back; RH: to face;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 2\n",
      "\t\t:ARG2 a))\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 2\n",
      "\t:mod (m/more))\n",
      "\n",
      "[{\"sentence\": \"You're pointing to two blocks over there.\", \"explanation\": \"The gesture label indicates that the speaker is using their right hand to point upwards, which corresponds to a deixis gesture in the Gesture AMR. The speech AMR shows that the speaker is referring to 'two' blocks, and the location is indicated as 'over there'. The explanation of the sentence generation process involves mapping the gesture labels to the corresponding Abstract Meaning Representation (AMR) elements and combining them with the speech AMR to form a coherent sentence in natural spoken English.\"}]\n",
      "two more blocks up\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: behind the two one and\n",
      "Speech AMR:\n",
      " (b/behind\n",
      "\t:op1 (o/one\n",
      "\t\t:mod (t/two)))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and you can you can place them close to each other\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (p/possible-01\n",
      "\t\t:ARG1 (p2/place-01\n",
      "\t\t\t:ARG0 (y/you)\n",
      "\t\t\t:ARG1 (t/them)\n",
      "\t\t\t:purpose (c/close-10\n",
      "\t\t\t\t:ARG1 t\n",
      "\t\t\t\t:ARG2 (o/other\n",
      "\t\t\t\t\t:mod (e/each))))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (y/yep)\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"sentence\": \"Yes.\",\n",
      "    \"explanation\": \"The speech AMR '(y/yep)' corresponds to a simple affirmative response, which is typically represented by the word 'yes' in natural spoken English.\"\n",
      "  }\n",
      "]\n",
      "yep\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: those too blocks right next each other\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2\n",
      "\t\t:mod (t/that)\n",
      "\t\t:location (n/next-to\n",
      "\t\t\t:mod (r/right)\n",
      "\t\t\t:op1 (o/other\n",
      "\t\t\t\t:mod (e/each)))))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, up; LH: into point, front;\n",
      "LA: move, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: okay and they’e just kind of jiggled around\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (j/jiggle-01\n",
      "\t\t:ARG1 (t/they)\n",
      "\t\t:degree (k/kind-of\n",
      "\t\t\t:mod (j2/just))\n",
      "\t\t:path (a1/around)))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: into open, down; LA: move, up;\n",
      "hands: shake;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (j/jiggle-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (k/know-01\n",
      "\t\t:polarity -)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "head: nod;\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"I agree.\", \"speech AMR\": \"(e/emblem-GA :ARG0 (s/signaler) :ARG1 (y/yes) :ARG2 (a/actor))\", \"explanation\": \"The gesture label 'head: nod' is associated with the emblem-GA relation, which typically indicates agreement or confirmation. The speech AMR reflects this by using the 'yes' slot to indicate agreement.\"}]\n",
      "yep\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and one block left of the first block first block and a bit in front of it\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (b/block\n",
      "\t\t:quant 1\n",
      "\t\t:ARG1-of (l/left-20\n",
      "\t\t\t:ARG2 (b2/block\n",
      "\t\t\t\t:ord (o/ordinal-entity\n",
      "\t\t\t\t\t:value 1)))\n",
      "\t\t:ARG1-of (f/front-01\n",
      "\t\t\t:ARG2 b2\n",
      "\t\t\t:degree (b3/bit))))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "arms: move, up; hands: facing, closed;\n",
      "Unknown\n",
      "body: still;\n",
      "Unknown\n",
      "hands: beckon;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (f/forward))\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (f/forward))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: the three blocks all touch and they’re straight\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (t/touch-01\n",
      "\t\t:ARG0 (b/block\n",
      "\t\t\t:quant 3))\n",
      "\t:op2 (s/straight-04\n",
      "\t\t:ARG1 (t2/they)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "hands: into claw, front;\n",
      "arms: move, back; hands: closed, back;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/together)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/straight)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "head: nod;\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (y/yep)\n",
      "\n",
      "[{\"sentence\": \"Yes.\", \"explanation\": \"The gesture label indicates a nod, which corresponds to the 'yes' icon in the Gesture AMR. The Speech AMR also confirms this interpretation with the word 'yep', which is an informal way of saying 'yes'. Therefore, the generated sentence is simply 'Yes.'\"}]\n",
      "yep\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: between the block you just placed and the third block on that side it's touching those two corners\n",
      "Speech AMR:\n",
      " (t/touch-01\n",
      "\t:ARG0 (i/it)\n",
      "\t:ARG1 (c/corner\n",
      "\t\t:mod (t2/that)\n",
      "\t\t:quant 2\n",
      "\t\t:location (b/between\n",
      "\t\t\t:op1 (b2/block\n",
      "\t\t\t\t:ARG1-of (p/place-01\n",
      "\t\t\t\t\t:ARG0 (y/you)\n",
      "\t\t\t\t\t:mod (j/just)))\n",
      "\t\t\t:op2 (b3/block\n",
      "\t\t\t\t:ord (o/ordinal-entity\n",
      "\t\t\t\t\t:value 3)\n",
      "\t\t\t\t:location (o2/on\n",
      "\t\t\t\t\t:op1 (s/side\n",
      "\t\t\t\t\t\t:mod (t3/that)))))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: close even more close but not touching yeah\n",
      "Speech AMR:\n",
      " (h/have-degree-91\n",
      "\t:ARG2 (c/close)\n",
      "\t:ARG3 (e/even\n",
      "\t\t:mod (m/more))\n",
      "\t:ARG1-of (c2/contrast-01\n",
      "\t\t:ARG2 (t/touch-01\n",
      "\t\t\t:polarity -)))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (g/go-01\n",
      "\t:manner (n/near-02))\n",
      "\n",
      "[{\"sentence\": \"Go near.\", \"explanation\": \"The speech AMR represents a verb 'go' with a manner modifier 'near'. This indicates that the action of going is performed in a near or close proximity to something, but it does not specify what that something is. Therefore, the generated sentence is 'Go near.'\"}]\n",
      "go near yeah\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: i want you take one block\n",
      "Speech AMR:\n",
      " (w/want-01\n",
      "\t:ARG0 (i/I)\n",
      "\t:ARG1 (t/take-01\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, up; LH: into point, front;\n",
      "LA: move, down; LH: into claw, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: yeah and\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "arms: apart, left; hands: facing, closed;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (m/move-01\n",
      "\t\t:ARG2 (n/near-02))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: together, left; hands: facing, closed;\n",
      "head: nod;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (m/move-01\n",
      "\t\t:ARG2 (n/near-02))\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"That's correct.\", \"speech AMR\": \"(y/yes :ARG0 (s/signaler) :ARG1 (t/correct-01 :ARG0 (a/actor)))\", \"explanation\": \"The gesture labels indicate a nod, which typically indicates agreement or confirmation. The arms being together and hands facing also suggest a sense of unity or confirmation. The presence of an emblem-GA in the gesture AMR further supports this interpretation, as it represents a symbol or sign that conveys a specific meaning.\"}]\n",
      "go near yeah\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: get two more blocks\n",
      "Speech AMR:\n",
      " (g/get-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2\n",
      "\t\t:mod (m/more)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, up front; LH: into point, front;\n",
      "LA: move, down back; LH: into claw, back;\n",
      "Unknown\n",
      "arms: move, up front, into gap, left; hands: facing, into claw;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: one right next to it touching\n",
      "Speech AMR:\n",
      " (n/next\n",
      "\t:ARG0 (o/one)\n",
      "\t:ARG1 (i/it)\n",
      "\t:mod (r/right)\n",
      "\t:mod (t/touching))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, left;\n",
      "body: still;\n",
      "RA: move, down right; RH: into closed, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 i\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (n/next)\n",
      "\t\t:ARG2 a)\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: together, left; hands: facing, closed;\n",
      "head: nod;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (m/move-01\n",
      "\t\t:ARG2 (n/near-02))\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (g/go-01\n",
      "\t:manner (n/near-02))\n",
      "\n",
      "[{\"sentence\": \"Let's go near it.\", \"explanation\": \"The gesture label indicates that the arms are together, which suggests a sense of unity or agreement. The hands facing and closed implies a confirmation or affirmation. The head nod further reinforces this interpretation. In the Gesture AMR, the icon-GA represents an expressive action, and the emblem-GA represents a confirmation. The speech AMR shows the verb 'go' with the manner specified as 'near-02', which is consistent with the gesture's meaning.\"}]\n",
      "go near yeah\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: get two blocks\n",
      "Speech AMR:\n",
      " (g/get-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2))\n",
      "\n",
      "Example 2:\n",
      "Sentence: the blocks are turned like half way on top of each block yeah\n",
      "Speech AMR:\n",
      " (t/turn-01\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (h/halfway)\n",
      "\t:location (o/on\n",
      "\t\t:op1 (t2/top\n",
      "\t\t\t:mod b\n",
      "\t\t\t:quant (e/each))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (b/block\n",
      "\t\t:quant 1\n",
      "\t\t:ARG1-of (a2/ahead-01\n",
      "\t\t\t:ARG2 (i/it))))\n",
      "\n",
      "[{\"sentence\": \"You have one block ahead of it.\", \"explanation\": \"The speech AMR indicates that the sentence is in imperative mode, and 'you' is the subject. The object is a single block, and there's an action 'ahead-01' performed by 'it', which implies something else is being referred to as 'it'. Therefore, the sentence should convey that you have one block ahead of it.\"}]\n",
      "and uh one block uh ahead of it\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and a little near you\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (n/near-02\n",
      "\t\t:ARG2 (y/you)\n",
      "\t\t:mod (l/little)))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: into claw, front;\n",
      "arms: move, back;\n",
      "hands: into claw, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (b2/block)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (g2/gesture-unit\n",
      "\t\t:op1 (i/icon-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (b/block)\n",
      "\t\t\t:ARG2 (a/actor))\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b2/block)\n",
      "\t\t\t:ARG2 a))\n",
      "\t:op2 (i3/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/pull-01\n",
      "\t\t\t:direction (b3/back))\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: center them on top of where the three blocks meet on it either side\n",
      "Speech AMR:\n",
      " (c/center-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:location (t2/top\n",
      "\t\t:poss (l/location\n",
      "\t\t\t:location-of (m/meet-03\n",
      "\t\t\t\t:ARG0 (b/block\n",
      "\t\t\t\t\t:quant 3)\n",
      "\t\t\t\t:location (s/side\n",
      "\t\t\t\t\t:mod (e/either))))))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up; hands: into claw, down;\n",
      "arms: move, front, into gap, left; hands: into point, front;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: still;\n",
      "arms: move, up front; hands: into facing, closed;\n",
      "hands: beckon;\n",
      "arms: move, down; hands: facing, closed;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (b/backward))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Come here.\", \"speech AMR\": \"(c/come-01 :mode imperative :ARG0 (y/you) :location (h/here))\", \"explanation\": \"The gesture labels indicate a series of movements that convey the meaning 'come here'. The arms moving up front and hands into facing, closed position suggest pointing or indicating direction. The beckon gesture further emphasizes the invitation to come closer. Finally, the arms moving down and hands returning to facing, closed position implies a sense of completion or finality, as if saying 'you're welcome' or 'it's done'. The speech AMR reflects this interpretation by using the verb 'come' in an imperative mode with the location specified as 'here', indicating that the speaker is inviting someone to move towards them.\"}]\n",
      "and uh one block uh ahead of it\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: they're more laid out in a flower pattern\n",
      "Speech AMR:\n",
      " (l/lay-out-01\n",
      "\t:ARG0 (t/they)\n",
      "\t:mod (m/more)\n",
      "\t:mod (p/pattern\n",
      "\t\t:mod (f/flower)))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: into contact, left; hands: into closed;\n",
      "arms: apart, left; hands: claw, down;\n",
      "arms: into contact, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/pattern\n",
      "\t\t:mod (f/flower))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: scoot the five over\n",
      "Speech AMR:\n",
      " (s/scoot-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:quant 5)\n",
      "\t:ARG2 (o/over))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, front; RH: closed, front;\n",
      "RA: move, left; RH: closed, left;\n",
      "LA: move, up; LH: closed, right;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (l/left))\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (f/flush)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: still;\n",
      "arms: move, up front; hands: into facing, closed;\n",
      "hands: beckon;\n",
      "arms: move, down; hands: facing, closed;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (b/backward))\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (b/block\n",
      "\t\t:quant 1\n",
      "\t\t:ARG1-of (a2/ahead-01\n",
      "\t\t\t:ARG2 (i/it))))\n",
      "\n",
      "[{\"sentence\": \"Come ahead.\", \"explanation\": \"The gesture AMR indicates a backward movement, which is not directly related to the speech AMR. However, considering the sequence of gestures and their meanings, it seems that the speaker is inviting or directing someone to come forward from behind. The 'beckon' gesture suggests an invitation or call to action, which aligns with the meaning of the speech AMR 'ahead'. Therefore, a suitable sentence would be 'Come ahead.'\"}]\n",
      "and uh one block uh ahead of it\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and don't rotate don't don't rotate yeah\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (r/rotate-01\n",
      "\t\t:polarity -\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)))\n",
      "\n",
      "Example 2:\n",
      "Sentence: the first block is like is like like the first tower yeah\n",
      "Speech AMR:\n",
      " (s/similar-01\n",
      "\t:ARG0 (b/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value 1))\n",
      "\t:ARG1 (t/tower\n",
      "\t\t:ord (o2/ordinal-entity\n",
      "\t\t\t:value 1)))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1)\n",
      "\t:ARG2 (w/wherever\n",
      "\t\t:ARG1-of (w2/want-01\n",
      "\t\t\t:ARG0 y)))\n",
      "\n",
      "[{\"sentence\": \"Put the block wherever you want.\", \"explanation\": \"The speech AMR indicates that the sentence is in imperative mode, meaning it's a command. The ARG0 is 'y/you', indicating the subject of the sentence is 'you'. The ARG1 is 'b/block' with a quantity of 1, implying a single block. The ARG2 is 'w/wherever', which is a location where something should be placed. The :ARG1-of relation indicates that this location is determined by the verb 'want-01', which is in the ARG0 position, also referring to 'you'. Therefore, the sentence is telling you to put the block wherever you want it to be.\"}]\n",
      "put one block wherever you want\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: put a block on like like on the crack of those two blocks\n",
      "Speech AMR:\n",
      " (p/put\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block)\n",
      "\t:location (c/crack\n",
      "\t\t:poss b\n",
      "\t\t:quant 2\n",
      "\t\t:mod (t/that)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, left;\n",
      "LA: move, down; LH: into open, right;\n",
      "LA: move, back;\n",
      "body: still;\n",
      "body: move, right; RA: move, up; RH: to face;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (c/crack)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: grab one more block place\n",
      "Speech AMR:\n",
      " (g/grab-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1\n",
      "\t\t:mod (m/more)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "body: still;\n",
      "RA: move, up; RH: into inch, front;\n",
      "RH: rotate, into point, down left;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, up front, into gap, left; hands: facing, closed;\n",
      "arms: move, down; hands: into claw, down;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/put-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Pick up the block.\", \"speech AMR\": \"(p/put :mode imperative :ARG0 (y/you) :ARG1 (b/block) :location (g/gap :mod (l/left)))\", \"explanation\": \"The gesture label indicates that the arms are moving upwards in front, into a gap on the left. This suggests picking up an object from a location. The hands are initially facing and closed, which implies grasping or picking up. Then, the arms move downwards with the hands in a claw-like position, indicating holding or carrying something.\"}]\n",
      "put one block wherever you want\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: that looks good\n",
      "Speech AMR:\n",
      " (l/look-02\n",
      "\t:ARG0 (t/that)\n",
      "\t:ARG1 (g/good))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, up; hands: into thumbs, up;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: stick it on the other side divot\n",
      "Speech AMR:\n",
      " (s/stick-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:ARG2 (d/divot\n",
      "\t\t:poss (s2/side\n",
      "\t\t\t:mod (o/other))))\n",
      "\n",
      "Gesture label(s): \n",
      "head: nod; hands: shake, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, up front, into gap, left; hands: facing, closed;\n",
      "arms: move, down; hands: into claw, down;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/put-01)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1)\n",
      "\t:ARG2 (w/wherever\n",
      "\t\t:ARG1-of (w2/want-01\n",
      "\t\t\t:ARG0 y)))\n",
      "\n",
      "[{\"sentence\": \"Put it wherever you want.\", \"explanation\": \"The speech AMR indicates an imperative mode, meaning the sentence is a command. The gesture AMR shows an icon representing 'put', which matches the verb in the speech AMR. The arms and hands gestures suggest a pointing or indicating action, but since the speech AMR already specifies the location as 'wherever you want', this gesture likely serves to emphasize the location rather than specify it. Therefore, the sentence generated is a direct translation of the speech AMR.\"}]\n",
      "put one block wherever you want\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yes\n",
      "Speech AMR:\n",
      " (y/yes)\n",
      "\n",
      "Example 2:\n",
      "Sentence: now do it on the other side\n",
      "Speech AMR:\n",
      " (d/do-02\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:location (o/on\n",
      "\t\t:op1 (s/side\n",
      "\t\t\t:mod (o2/other))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (b/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value 1)\n",
      "\t\t:ARG1-of (p/put-01\n",
      "\t\t\t:ARG0 (y/you))\n",
      "\t\t:ARG1-of (h/have-degree-91\n",
      "\t\t\t:ARG2 (n/near-02)\n",
      "\t\t\t:ARG3 (m/most)))\n",
      "\t:op2 (s/side\n",
      "\t\t:ARG1-of (r/right-04)\n",
      "\t\t:poss b))\n",
      "\n",
      "[{\"sentence\": \"You put the first block on the right side and it is most near you.\", \"explanation\": \"The speech AMR represents a sentence with two main clauses connected by 'and'. The first clause describes an action where the speaker puts something (the ARG1 of the 'put-01' relation) in a specific location (the ARG1-of the 'right-04' relation). The second part of the clause indicates that this thing is most near to the speaker. The second main clause, also connected by 'and', describes another action where the speaker puts something else (the ARG1 of the 'put-01' relation) in a specific location (the ordinal entity with value 1), and it is also most near to the speaker. The explanation of the sentence is based on the analysis of the AMR structure, identifying the main actions, their arguments, and the relationships between them.\"}]\n",
      "the first block you put it the one nearest and the right side of it\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: touching corners touching corners\n",
      "Speech AMR:\n",
      " (t/touch-01\n",
      "\t:ARG0 (c/corner)\n",
      "\t:ARG1 (c2/corner))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; hands: into contact, left;\n",
      "body: still;\n",
      "head: nod;\n",
      "body: still;\n",
      "head: nod;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/touch-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: yeah\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "head: nod;\n",
      "RA: move, up; RH: to face;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "body: still;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/put-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Put it to the right.\", \"speech AMR\": \"(p/put-01 :ARG0 (s/signaler) :ARG1 (t/to-the-right) :ARG2 (a/actor))\", \"explanation\": \"The gesture AMR indicates that the signaler is performing a put action on an object, and then sliding it to the right. The speech AMR reflects this by specifying the direction of the slide as 'to the right'. The sentence generated from this information is 'Put it to the right.'\"}]\n",
      "the first block you put it the one nearest and the right side of it\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: one block on top of the both\n",
      "Speech AMR:\n",
      " (b/be-located-at-91\n",
      "\t:ARG1 (b2/block\n",
      "\t\t:quant 1)\n",
      "\t:ARG2 (o/on-top-of\n",
      "\t\t:op1 (t/they\n",
      "\t\t\t:mod (b3/both))))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, up; hands: into point, front;\n",
      "LA: move, back; LH: to hip; RA: move, front; RH: into claw, down;\n",
      "RA: move, back; RH: into closed, back;\n",
      "body: still;\n",
      "arms: move, up; hands: into open, front;\n",
      "head: rotate; arms; move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/done)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: just like you’re building a tower\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG1 (b/build-01\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (t/tower))\n",
      "\t:mod (j/just))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up;\n",
      "arms: move, down;\n",
      "body: move, down;\n",
      "Unknown\n",
      "arms: move, up, into contact, left; hands: into claw, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/tower)\n",
      "\t:ARG2 (a/actor))\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/put-01)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g2/gesture-unit\n",
      "\t\t:op1 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l2/location)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p2/put-01)\n",
      "\t\t\t:ARG2 a2)))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "body: still;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/put-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (b/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value 1)\n",
      "\t\t:ARG1-of (p/put-01\n",
      "\t\t\t:ARG0 (y/you))\n",
      "\t\t:ARG1-of (h/have-degree-91\n",
      "\t\t\t:ARG2 (n/near-02)\n",
      "\t\t\t:ARG3 (m/most)))\n",
      "\t:op2 (s/side\n",
      "\t\t:ARG1-of (r/right-04)\n",
      "\t\t:poss b))\n",
      "\n",
      "[{\"sentence\": \"You have a block near you on the right side.\", \"explanation\": \"The gesture AMR indicates that the speaker is referring to an actor (you) and describing their relationship with a block. The speech AMR shows that the block is being described as something that has a degree of nearness, specifically 'near-02', which suggests proximity. Additionally, the block is associated with the ordinal entity '1' and is in the possession of the speaker. The gesture labels suggest stillness, but then two instances of sliding to the right, indicating movement towards the actor's right side. Therefore, the sentence generated is a description of the block's location relative to the actor.\"}]\n",
      "the first block you put it the one nearest and the right side of it\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: we’re building up a even column i guess so\n",
      "Speech AMR:\n",
      " (b/build-up-05\n",
      "\t:ARG0 (w/we)\n",
      "\t:ARG1 (c/column\n",
      "\t\t:mod (e/even))\n",
      "\t:ARG1-of (g/guess\n",
      "\t\t:ARG0 (i/i)))\n",
      "\n",
      "Example 2:\n",
      "Sentence: i'm not sure yeah\n",
      "Speech AMR:\n",
      " (s/sure-02\n",
      "\t:ARG0 (i/i)\n",
      "\t:polarity -)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (h/have-03\n",
      "\t:ARG0 (w/we)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2\n",
      "\t\t:mod (a/apart\n",
      "\t\t\t:op1 (o/other)\n",
      "\t\t\t:extent (b2/block\n",
      "\t\t\t\t:quant 1))))\n",
      "\n",
      "[{\"sentence\": \"We have two blocks apart from each other.\", \"explanation\": \"The speech AMR indicates that the verb is 'have' in the third person singular form, which corresponds to the sentence 'We have'. The ARG0 is 'we', indicating the subject. The ARG1 is 'block', with a quantity of 2 and modified by 'apart from other block', where the extent is another block (quant 1). This structure suggests that we are talking about two blocks being separate or distinct.\"}]\n",
      "we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay this one's somewhat similar to the last one except it's a four four layers\n",
      "Speech AMR:\n",
      " (s/similar-01\n",
      "\t:ARG0 (o/one\n",
      "\t\t:mod (t/this))\n",
      "\t:ARG1 o\n",
      "\t:mod (l/last)\n",
      "\t:ARG2 (l2/layers\n",
      "\t\t:quant 4))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, down; hands: into fist, back;\n",
      "body: move, down;\n",
      "    body: still;\n",
      "LA: move, up; LH: into open, down; RH: into open, up;\n",
      "LA: move, up;\n",
      "LA: move, down; hands: into fist, down;\n",
      "arms: move, front; hands: into open, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/layers)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: don’t do that exactly\n",
      "Speech AMR:\n",
      " (d/do-01\n",
      "\t:mode imperative\n",
      "\t:polarity -\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/that))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, back;\n",
      "arms: move, down; hands: shake, into point, front;\n",
      "arms: move, up; hands: into claw, up;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (e/emblem-GA\n",
      "\t\t:mode expressive\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (n/no)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:mode expressive\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "arms: move, down;\n",
      "body: still;\n",
      "Unknown\n",
      "arms: apart, left; hands: facing, into closed;\n",
      "arms: together, left;\n",
      "head: nod;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 b2\n",
      "\t\t:ARG2 a2))\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/sigaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 p\n",
      "\t\t:ARG2 a2))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/space)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Put the block in space.\", \"speech AMR\": \"(p/put-01 :mode imperative :polarity + :ARG0 (y/you) :ARG1 (b/block) :ARG2 (s/space))\", \"explanation\": \"The gesture label indicates that the arms are moving apart, and the hands are facing inwards. This suggests a 'put' action. The second icon-GA indicates that the block is being put into space.\"}]\n",
      "we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and um the middle tower\n",
      "Speech AMR:\n",
      " (t/tower)\n",
      ":mod m/middle))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "arms: together, left, gap, left;\n",
      "body: move, down; head: rotate;\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/put-01\n",
      "\t\t\t\t:quant 3)\n",
      "\t\t\t:ARG2 a2)))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/tower)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: count in with your left hand count to block three and four\n",
      "Speech AMR:\n",
      " (c/count-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:instrument (h/hand\n",
      "\t\t:part-of y\n",
      "\t\t:mod (l/left))\n",
      "\t:destination (b/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value (a/and\n",
      "\t\t\t\t:op1 3\n",
      "\t\t\t\t:op2 4))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (c/count-01\n",
      "\t\t\t:ARG2 (a/actor))\n",
      "\t\t:op2 (d/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b/block)\n",
      "\t\t\t:ARG2 a)))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/left)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "arms: move, down;\n",
      "body: still;\n",
      "Unknown\n",
      "arms: apart, left; hands: facing, into closed;\n",
      "arms: together, left;\n",
      "head: nod;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 b2\n",
      "\t\t:ARG2 a2))\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/sigaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 p\n",
      "\t\t:ARG2 a2))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/space)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (h/have-03\n",
      "\t:ARG0 (w/we)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2\n",
      "\t\t:mod (a/apart\n",
      "\t\t\t:op1 (o/other)\n",
      "\t\t\t:extent (b2/block\n",
      "\t\t\t\t:quant 1))))\n",
      "\n",
      "[{\"sentence\": \"We have two blocks apart, and I'm putting one in the space, and you put the other block.\", \"explanation\": \"The gesture AMR indicates that there are two icons: one for 'block' (b) and another for 'putting' (p). The speech AMR shows that we have two blocks. The gestures suggest that the speaker is moving their arms down, then keeping still, followed by moving their arms apart to the left with hands facing into closed fists, then bringing them together on the left side, and finally nodding their head. This suggests a sequence of actions: first, indicating the presence of two blocks (arms apart), then putting one block in the space (hands facing into closed fists), and finally, the other person puts the other block (head nod). The speech AMR supports this interpretation by showing that we have two blocks and that they are being put in a certain way.\"}]\n",
      "we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and one block pick up one block and it is in front of the block you just put it and rotate it forty five degrees\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (p/pick-up-04\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1))\n",
      "\t:op3 (f/front-02\n",
      "\t\t:ARG1 b\n",
      "\t\t:ARG2 (b2/block\n",
      "\t\t\t:ARG1-of (p2/put-01\n",
      "\t\t\t\t:ARG0 y\n",
      "\t\t\t\t:time (j/just))))\n",
      "\t:op4 (r/rotate-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:extent (a2/angle-quantity\n",
      "\t\t\t:quant 45\n",
      "\t\t\t:unit (d/degree))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: so then your next one is going to be up one and it's going to be shifted over half a block to\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (b/be-01\n",
      "\t\t:ARG0 (o/one\n",
      "\t\t\t:mod (n/next))\n",
      "\t\t:location (u/up\n",
      "\t\t\t:mod o))\n",
      "\t:op2 (s/shift-01\n",
      "\t\t:mod (b2/block\n",
      "\t\t\t:quant (h/half))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (c/contrast-01\n",
      "\t:ARG2 (r/recommend-01\n",
      "\t\t:ARG1 (b/be-located-at-91\n",
      "\t\t\t:ARG1 (t/that)\n",
      "\t\t\t:ARG2 (o/on\n",
      "\t\t\t\t:op1 (t2/top\n",
      "\t\t\t\t\t:poss (b2/block\n",
      "\t\t\t\t\t\t:mod (o2/other)))))))\n",
      "\n",
      "[{\"sentence\": \"That should be located on the top of another block.\", \"explanation\": \"The speech AMR indicates a contrast between two locations, and one of them is a recommendation to locate 'that' on the top of another block. The word 'that' is assumed to refer to an object or location that has not been previously mentioned in the conversation.\"}]\n",
      "but that should be on top on top of the of the other blocks yeah\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: good enough good enough\n",
      "Speech AMR:\n",
      " (e/enough-01\n",
      "\t:ARG2 (g/good))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: enough;\n",
      "hands: shake, closed;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (e2/enough)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: towards to me at the top layer block\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i2/implicit-role)\n",
      "\t:direction (t/toward\n",
      "\t\t:op1 (m/me))\n",
      "\t:destination (a/at\n",
      "\t\t:op1 (t2/top-layer)\n",
      "\t\t:op2 (b/block)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, down; RA: move, up; RH: into claw, up;\n",
      "body: move, front; RA: move, down;\n",
      "RA: move, front;\n",
      "RA: move, down;\n",
      "Unknown\n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (m/move-01\n",
      "\t\t:ARG2 (c/close-10))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, down; hands: shake;\n",
      "hands: shake, into point, front;\n",
      "RA: move, up; RH: into claw, left;\n",
      "RH: shake, front;\n",
      "RA: move, down;\n",
      "Unknown\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (n/no)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/top)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/backward)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"No, go back to the top.\", \"speech AMR\": \"(e/enough-01 :ARG2 (n/no)) (d/deixis-GA :mode expressive :ARG0 (s/signaler) :ARG1 (b/backward) :ARG2 (a/actor)) (i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (t/top) :ARG2 (a/actor))\", \"explanation\": \"The gesture AMR indicates that the speaker is expressing a negative sentiment ('n/no') and pointing backwards. The 'top' icon suggests moving to the top, which is likely in response to the initial 'no'. Therefore, the sentence generated is 'No, go back to the top.'\" }]\n",
      "but that should be on top on top of the of the other blocks yeah\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: it stacks like straight up\n",
      "Speech AMR:\n",
      " (s/stack_up-03\n",
      "\t:mod (s2/straight))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, down; head: rotate;\n",
      "body: move, up; arms: move, up;\n",
      "arms: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/tower)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: just four\n",
      "Speech AMR:\n",
      " (i/implicit-role\n",
      "\t:quant 4\n",
      "\t:mod (j/just))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into four, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 4\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, down; hands: shake;\n",
      "hands: shake, into point, front;\n",
      "RA: move, up; RH: into claw, left;\n",
      "RH: shake, front;\n",
      "RA: move, down;\n",
      "Unknown\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (n/no)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/top)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/backward)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (c/contrast-01\n",
      "\t:ARG2 (r/recommend-01\n",
      "\t\t:ARG1 (b/be-located-at-91\n",
      "\t\t\t:ARG1 (t/that)\n",
      "\t\t\t:ARG2 (o/on\n",
      "\t\t\t\t:op1 (t2/top\n",
      "\t\t\t\t\t:poss (b2/block\n",
      "\t\t\t\t\t\t:mod (o2/other)))))))\n",
      "\n",
      "[{\"sentence\": \"Don't recommend that on the top of the other block.\", \"explanation\": \"The gesture AMR indicates a contrast between two actions, one being to recommend something and the other being to locate it at a specific place. The speech AMR provides more context, showing that the recommendation is for 'that' (which is likely referring to an object or entity) to be located on top of another block. The gesture labels suggest a series of movements and actions, including shaking hands into a pointing position, moving arms up and down, and indicating a claw shape with one hand. However, these gestures seem to be more expressive and illustrative rather than directly contributing to the meaning of the sentence. Therefore, the generated sentence focuses on the core message conveyed by the speech AMR and gesture AMR.\"}]\n",
      "but that should be on top on top of the of the other blocks yeah\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay\n",
      "Speech AMR:\n",
      " (o/okay-04)\n",
      "\n",
      "Example 2:\n",
      "Sentence: space two out a little less than a block length\n",
      "Speech AMR:\n",
      " (s/space-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:quant 2)\n",
      "\t:ARG2 (q/distance-quantity\n",
      "\t\t:unit (b/block)\n",
      "\t\t:ARG1-of (h/have-quant-91\n",
      "\t\t\t:ARG2 1\n",
      "\t\t\t:ARG3 (l/less\n",
      "\t\t\t\t:mod (l2/little)))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (o/open-01\n",
      "\t:mode imperative\n",
      "\t:polite +\n",
      "\t:mod (j/just)\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:degree (b/bit\n",
      "\t\t:mod (l/little)))\n",
      "\n",
      "[{\"sentence\": \"Just open it a bit.\", \"explanation\": \"The speech AMR indicates that the sentence is imperative, meaning it's a command. The polite marker '+' suggests that the tone is polite or courteous. The 'just' modifier implies that the action should be done in a minimal way. ARG0 is 'you', indicating who is being addressed, and ARG1 is 'it', specifying what needs to be opened. The degree of opening is specified as 'a bit', which is broken down into 'bit' with a 'little' modifier.\"}]\n",
      "can you just open it open it a little bit uh\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: four blocks in the front okay\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 4\n",
      "\t:location (i/in\n",
      "\t\t:op1 (f/front)))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: shake, left; hands: into claw, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/row)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: it cannot fall down from the ground right\n",
      "Speech AMR:\n",
      " (p/possible-01\n",
      "\t:polarity -\n",
      "\t:ARG1 (f/fall-01\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:ARG3 (g/ground))\n",
      "\t:ARG1-of (r/request-confirmation-91))\n",
      "\n",
      "Gesture label(s): \n",
      "head: shake; hands: rotate, open, up;\n",
      "Unknown\n",
      "LA: move, down; LH: into point, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: shake;\n",
      "arms: apart, left;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (a/apart)\n",
      "\t:ARG2 (a2/actor))\n",
      "\n",
      "[{\"sentence\": \"I'm separating myself from you.\", \"speech AMR\": \"(i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (a/apart) :ARG2 (a2/actor))\", \"explanation\": \"The gesture labels indicate that the arms are shaking and then moving apart, which suggests a separation or distinction between two entities. The gesture AMR confirms this interpretation by indicating that the mode is expressive and the action is 'apart', which means separating oneself from something or someone.\"}]\n",
      "can you just open it open it a little bit uh\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: five blocks to start\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 5\n",
      "\t:ARG1-of (s/start-01))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, left;\n",
      "body: still;\n",
      "LH: into open, up;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: now these are a little jiggled\n",
      "Speech AMR:\n",
      " (j/jiggle-01\n",
      "\t:ARG1 (t/these)\n",
      "\t:mod (l/little))\n",
      "\n",
      "Gesture label(s): \n",
      "head: nod; LA: move, back;\n",
      "RA: move, up; RH: shake, down, open;\n",
      "RA: move, front; RH: into point, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (j/jiggle-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:mode expressive\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (j/jiggle-01)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (a1/and\n",
      "\t\t:op1 (d1/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b1/block)\n",
      "\t\t\t:ARG2 a)\n",
      "\t\t:op2 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b2/block)\n",
      "\t\t\t:ARG2 a)))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: shake;\n",
      "arms: apart, left;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (a/apart)\n",
      "\t:ARG2 (a2/actor))\n",
      "Speech AMR:\n",
      " (o/open-01\n",
      "\t:mode imperative\n",
      "\t:polite +\n",
      "\t:mod (j/just)\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:degree (b/bit\n",
      "\t\t:mod (l/little)))\n",
      "\n",
      "[{\"sentence\": \"Just open it a little.\", \"explanation\": \"The gesture AMR indicates an expressive mode, suggesting the speaker is emphasizing or drawing attention to something. The icon-GA represents a gesture of 'apart', which in this context likely means spreading arms wide, often used to indicate separation or distance. This is combined with a speech AMR that includes the verb 'open' in an imperative mode, indicating a command or instruction. The polite marker '+' suggests a polite tone, and the degree modifier 'a little' matches the gesture's emphasis on separation.\"}]\n",
      "can you just open it open it a little bit uh\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: you're done\n",
      "Speech AMR:\n",
      " (d/done-08\n",
      "\t:ARG0 (y/you))\n",
      "\n",
      "Example 2:\n",
      "Sentence: put a bit a bit right uh\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG2 (r/right-04\n",
      "\t\t:degree (b/bit)))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (c/contrast-01\n",
      "\t:ARG2 (r/recommend-01\n",
      "\t\t:polarity -\n",
      "\t\t:ARG1 (f/fall-01\n",
      "\t\t\t:ARG1 (i/it))))\n",
      "\n",
      "[{\"sentence\": \"It doesn't recommend the fall.\", \"explanation\": \"In this speech AMR, 'contrast' is used to indicate a contrast between two ideas. The ARG2 of 'contrast' is 'recommend', which means that there is a recommendation being made. However, the polarity of 'recommend' is '-', indicating negation, so it doesn't recommend something. The ARG1 of 'recommend' is 'fall-01', which refers to an event or action. Therefore, the sentence should be in the form of 'It doesn't recommend the fall.'\"}]\n",
      "(unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: it starts in the top left\n",
      "Speech AMR:\n",
      " (s/start-01\n",
      "\t:ARG0 (i/it)\n",
      "\t:location (i2/in\n",
      "\t\t:op1 (l/left\n",
      "\t\t\t:mod (t/top))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "LH: into claw, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: same direction that that's pushed off yea alright\n",
      "Speech AMR:\n",
      " (s/same-01\n",
      "\t:ARG2 (p/push-01\n",
      "\t\t:ARG1 (t/that)\n",
      "\t\t:ARG2 (o/off))\n",
      "\t:ARG3 (d/direction))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, down; RH: into open, down;\n",
      "arms: move, up, into gap, left; hands: into facing, left, into claw, left;\n",
      "LA: move, left;\n",
      "arms: move, down; hands: into open, down;\n",
      "head: rotate;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/left)\n",
      "\t:ARG2 (a/actor))\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (s2/slide\n",
      "\t\t\t:direction (l/left))\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "arms: apart, left; hands: into facing, left, closed;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"He is standing in front of the block.\", \"speech AMR\": \"(s/infront-01 :ARG0 (h/he) :location (i2/in :op1 (l/left :mod (f/front))) :ARG2 (b/block))\", \"explanation\": \"The gesture label indicates that the arms are apart and to the left, which suggests a wide stance or position. The hands are into facing, left, closed, which implies that he is standing in front of something. The gesture AMR supports this interpretation by indicating that the ARG1 (block) is located at the location specified by the op1 (left) modifier.\"}]\n",
      "(unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: it's gonna be a pyramid from three of the rows of two\n",
      "Speech AMR:\n",
      " (p/pyramid\n",
      "\t:consist-of (r/row\n",
      "\t\t:quant 3\n",
      "\t\t:consist-of (r2/row\n",
      "\t\t\t:quant 2))\n",
      "\t:domain (i/it))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, front; LA: move, down;\n",
      "body: move, front; arms: into gap, left; hands: facing, into open;\n",
      "arms: move, down;\n",
      "RA: move, left;\n",
      "RA: shake, right;\n",
      "RA: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/put-01)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g2/gesture-unit\n",
      "\t\t:op1 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l2/location)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p2/put-01)\n",
      "\t\t\t:ARG2 a2)))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (r/row)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: then they connect to the two wider blocks\n",
      "Speech AMR:\n",
      " (c/connect-01\n",
      "\t:time (t/then)\n",
      "\t:ARG1 (t2/they)\n",
      "\t:ARG2 (b/block\n",
      "\t\t:quant 2\n",
      "\t\t:mod (w/wide\n",
      "\t\t\t:degree (m/more))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, up; hands: to face;\n",
      "arms: move, front; hands: into point, front;\n",
      "Unknown\n",
      "arms: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(a/and\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (d2/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (b2/block)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "arms: apart, left; hands: into facing, left, closed;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (c/contrast-01\n",
      "\t:ARG2 (r/recommend-01\n",
      "\t\t:polarity -\n",
      "\t\t:ARG1 (f/fall-01\n",
      "\t\t\t:ARG1 (i/it))))\n",
      "\n",
      "[{\"sentence\": \"It's not recommended to fall.\", \"explanation\": \"The gesture AMR indicates a contrastive relationship between the speaker and the action of falling, with the speaker expressing disapproval or warning. The speech AMR supports this interpretation by indicating that it is not recommended to fall.\"}]\n",
      "(unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay\n",
      "Speech AMR:\n",
      " (o/okay-04)\n",
      "\n",
      "Example 2:\n",
      "Sentence: get another one stacked on top\n",
      "Speech AMR:\n",
      " (g/get-04\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (s/stack-01\n",
      "\t\t:ARG1 (o/one\n",
      "\t\t\t:mod (a/another))\n",
      "\t\t:ARG2 (o2/on\n",
      "\t\t\t:op1 (t/top))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (b/be-01\n",
      "\t:ARG0 (r/row\n",
      "\t\t:mod (n/next))\n",
      "\t:ARG1 (t/three\n",
      "\t\t:location (t2/top\n",
      "\t\t\t:location (g/gap)\n",
      "\t\t\t:mod (m/middle))))\n",
      "\n",
      "[{\"sentence\": \"The next row will be three at the middle of the top gap.\", \"explanation\": \"The speech AMR represents a sentence with 'be' as the main verb. The subject is 'the next row', which is modified by 'next'. The object of the sentence is 'three', which is located at the top gap, specifically in the middle.\"}]\n",
      "then the next row is just three on top of that in the middle of those gaps\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: move that block uh\n",
      "Speech AMR:\n",
      " (m/move-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (t/that)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, right; LH: claw, right;\n",
      "LH: rotate, claw, front;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: they’re in other words are not perfectly clear\n",
      "Speech AMR:\n",
      " (c/clear-06\n",
      "\t:manner (w/words\n",
      "\t\t:mod (o/other))\n",
      "\t:ARG1 (t/they)\n",
      "\t:polarity -\n",
      "\t:ARG1-of (p/perfect-02))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "body: still;\n",
      "hands: enough;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (k/know-01\n",
      "\t\t:polarity -)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (e2/enough)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "arms: move, up; hands: facing, into gap, open;\n",
      "LA: move, down; RA: move, up; RH: to face\n",
      "RA: move, down;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 i\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (t/top)\n",
      "\t\t:ARG2 a)\n",
      "\n",
      "[{\"sentence\": \"Move the block up.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block :mod (t/top))\", \"explanation\": \"The gesture label indicates that the arms are moving up, and the hands are facing into a gap. The LA is also moving down, which suggests an action of moving something upwards. The RH is moving to face, which implies a direction or orientation. The RA is moving down, but this seems contradictory to the initial movement of the arms up. However, considering the overall gesture unit, it's likely that the block is being moved from a lower position to a higher one, hence the speech AMR reflects an action of moving the top of the block upwards.\"}]\n",
      "then the next row is just three on top of that in the middle of those gaps\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: them towards you\n",
      "Speech AMR:\n",
      " (o/orient-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them\n",
      "\t\t:location (t2/towards\n",
      "\t\t\t:op1 y)))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: claw, down; LA: move, back; RA: move, front;\n",
      "hands: claw, down; LA: move, front; RA: move, back;\n",
      "hands: claw, down; LA: move, back; RA: move, front;\n",
      "hands: into closed, back; RA: move, back;\n",
      "arms: move, front, into gap, left; hands: facing, into closed;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (r/rotate-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: then you going to have a fourth block\n",
      "Speech AMR:\n",
      " (h/have-03\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:ord 4))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, right; RA: move, up; RH: to face;\n",
      "body: move, left; RA: move, down;\n",
      "LA: move, up; LH: into point, front;\n",
      "LA: move, down; LH: into open, right;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "arms: move, up; hands: facing, into gap, open;\n",
      "LA: move, down; RA: move, up; RH: to face\n",
      "RA: move, down;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 i\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (t/top)\n",
      "\t\t:ARG2 a)\n",
      "Speech AMR:\n",
      " (b/be-01\n",
      "\t:ARG0 (r/row\n",
      "\t\t:mod (n/next))\n",
      "\t:ARG1 (t/three\n",
      "\t\t:location (t2/top\n",
      "\t\t\t:location (g/gap)\n",
      "\t\t\t:mod (m/middle))))\n",
      "\n",
      "[{\"sentence\": \"The next row is at the top of the middle gap.\", \"explanation\": \"The gesture AMR indicates a gesture unit with two operations. The first operation involves the signaler, block, and actor, but this information is not relevant to the current sentence generation task. The second operation involves the signaler, top, and actor, which suggests that the focus is on the top location. The speech AMR provides more context by indicating that the next row is at the top of the middle gap.\"}]\n",
      "then the next row is just three on top of that in the middle of those gaps\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: just one\n",
      "Speech AMR:\n",
      " (i/implicit-role\n",
      "\t:quant 1)\n",
      "\n",
      "Example 2:\n",
      "Sentence: and go\n",
      "Speech AMR:\n",
      " (a/and)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (s/splay-01\n",
      "\t:ARG0 (t/they)\n",
      "\t:mod (k/kind-of))\n",
      "\n",
      "[{\n",
      "  \"sentence\": \"They are kind of scattered.\",\n",
      "  \"explanation\": \"The speech AMR indicates that the subject is 'they' and the verb is a splay-01, which means to scatter or spread out. The modifier 'kind of' is used to describe the scattering action.\"\n",
      "}]\n",
      "kind of splayed yeah\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: the base is going to have four second one’s going to have three then two on top of that and then one\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (h/have-03\n",
      "\t\t:ARG0 (b/base)\n",
      "\t\t:ARG1 (i/implicit-role\n",
      "\t\t\t:quant 4))\n",
      "\t:op2 (h2/have-03\n",
      "\t\t:ARG0 (i2/implicit-role\n",
      "\t\t\t:ord (o/ordinal-entity\n",
      "\t\t\t\t:value 2))\n",
      "\t\t:ARG1 (i3/implicit-role\n",
      "\t\t\t:quant 3))\n",
      "\t:op3 (i4/implicit-predicate-00\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (i5/implicit-role\n",
      "\t\t\t:quant 2)\n",
      "\t\t:destination (o2/on-top-of\n",
      "\t\t\t:op1 (t/that)))\n",
      "\t:op4 (i6/implicit-predicate-00\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 (i7/implicit-role\n",
      "\t\t\t:quant 1)))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into four, front;\n",
      "RH: into three;\n",
      "RA: move, up; RH: into two;\n",
      "RH: into one;\n",
      "RA: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 4\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 3\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 2\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: start off with just a block and then put a block on top of\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (s/start-off-2\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:mod (j/just)))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 (b2/block)\n",
      "\t\t:ARG2 (o/on\n",
      "\t\t\t:op1 (t/top\n",
      "\t\t\t\t:op1 (t2/that)))\n",
      "\t\t:time (t3/then)))\n",
      "\n",
      "Gesture label(s): \n",
      "    arms: move, up, into gap, left; hands: into facing, left, into claw, left;\n",
      "    head: move, down;\n",
      "head: move, up; arms: move, down; hands: into open, down;\n",
      "body: move, up; RH: tap;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/top)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: apart, left;\n",
      "hands: into fist;\n",
      "body: move, down;\n",
      "Unknown\n",
      "arms: into gap, left;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/splayed)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Stand apart and then bring your hands together in a fist.\", \"speech AMR\": \"(a/and :op1 (s/stand-apart-01 :mode imperative :ARG0 (y/you) :ARG1 (s/splayed) :time (t3/then)) :op2 (h/have-03 :ARG0 (i/implicit-role :quant 2) :ARG1 (f/fist)))\", \"explanation\": \"The gesture label indicates that the arms are apart and then into a gap, which suggests standing apart. The hands are then into a fist, indicating a specific hand movement. The speech AMR reflects this by using the 'stand-apart-01' predicate to indicate the initial position of the arms, and the 'have-03' predicate with the implicit role quantifier 2 to indicate that the hands are brought together in a fist.\"}]\n",
      "kind of splayed yeah\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: stack stack it up no\n",
      "Speech AMR:\n",
      " (s/stack-up-03\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "LA: move, up; LH: into open, right;\n",
      "arms: together, left; hands: into contact, left, into closed, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/close-10)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: stack three blocks on one side yup\n",
      "Speech AMR:\n",
      " (s/stack-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 3)\n",
      "\t:ARG2 (o/on\n",
      "\t\t:op1 (s2/side\n",
      "\t\t\t:quant 1)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "RA: move, right; RH: into point, down;\n",
      "RH: tap, point;\n",
      "RA: move, up; RH: into claw, front;\n",
      "RA: move, down;\n",
      "LA: move, to hip;\n",
      "body: still;\n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/stack-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: apart, left;\n",
      "hands: into fist;\n",
      "body: move, down;\n",
      "Unknown\n",
      "arms: into gap, left;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/splayed)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (s/splay-01\n",
      "\t:ARG0 (t/they)\n",
      "\t:mod (k/kind-of))\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"sentence\": \"They're kind of splayed.\",\n",
      "    \"explanation\": \n",
      "      The gesture labels indicate that the speaker is using a splayed posture, with arms apart and hands in fists. This corresponds to the icon-GA AMR, which represents an emblem or symbol (s2/splayed) being used by the speaker (s/signaler). The speech AMR indicates that \"they\" are performing this action, and the modifier \"kind-of\" suggests a degree of uncertainty or approximation.\n",
      "    }\n",
      "]\n",
      "kind of splayed yeah\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: like about a third of a block a part so more close in than that\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG2 (q/distance-quantity\n",
      "\t\t:mod (a/about)\n",
      "\t\t:unit (b/block\n",
      "\t\t\t:ARG1-of (h/have-quant-91\n",
      "\t\t\t\t:ARG2 (t/third)))\n",
      "\t\t:mod (a2/apart))\n",
      "\t:ARG2-of (i/infer-01\n",
      "\t\t:ARG1 (h2/have-degree-91\n",
      "\t\t\t:ARG2 (c/close-10)\n",
      "\t\t\t:ARG3 (m/more)\n",
      "\t\t\t:ARG4 (t2/that))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: four blocks\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quantity 4)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (c/cover-02\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/there)\n",
      "\t:ARG2 (i/implicit-role))\n",
      "\n",
      "[{\"sentence\": \"You cover there.\", \"explanation\": \"The speech AMR indicates that the subject of the sentence is 'you' (ARG0), and the action being performed is 'cover' (c/cover-02). The location where this action takes place is 'there' (ARG1). Since the role is implicit, we don't need to specify any additional details. Therefore, the generated sentence is a simple statement of the subject performing the action at the specified location.\"}]\n",
      "come evenly there\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: great yep\n",
      "Speech AMR:\n",
      " (g/great)\n",
      "\n",
      "Gesture label(s): \n",
      "hands: thumb, up;\n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (g/good)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: seven blocks in a row\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 7)\n",
      "\t:manner (r/row))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, up; LH: into two, front; RH: into five, front;\n",
      "LA: move, down; RA: move, right; RH: closed, down;\n",
      "RA: move, back;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 7\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (r/row)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/place-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, down;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (m/move-01\n",
      "\t\t:ARG2 (c/close-10))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Move down.\", \"speech AMR\": \"(i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (m/move-01 :ARG2 (c/close-10)) :ARG2 (a/actor))\", \"explanation\": \"The gesture label indicates that the right arm (RA) is moving down, which corresponds to the 'move' action in the gesture AMR. The speech AMR is generated directly from the gesture AMR, as it already represents the intended meaning of the gesture in a standardized format.\"}]\n",
      "come evenly there\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and then three more coming off from the other direction touching the corner okay\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (i/implicit-role\n",
      "\t\t:quant 3\n",
      "\t\t:mod (m/more)\n",
      "\t\t:ARG1-of (c/come-33\n",
      "\t\t\t:ARG3 (f/from\n",
      "\t\t\t\t:op1 (d/direction\n",
      "\t\t\t\t\t:mod (o/other)))\n",
      "\t\t\t:mod (o2/off))\n",
      "\t\t:ARG0-of (t/touch-01\n",
      "\t\t\t:ARG1 (c2/corner))\n",
      "\t\t:time (t2/then)))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "LA: move, left; LH: into closed, front;\n",
      "body: still;\n",
      "head: nod; LA: move, right; LH: into closed, right;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/direction)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and then the second block goes on top of that\n",
      "Speech AMR:\n",
      " (g/go-01\n",
      "\t:ARG1 (b/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value 2);ARG4(o2/on\n",
      "\t\t\t:op1 (t/top\n",
      "\t\t\t\t:location (t2/that)))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up;\n",
      "RA: move, down; RH: into open, left;\n",
      "RA: rotate\n",
      "body: still;\n",
      "hands: rotate;\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/put-01)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (r/rotate-01)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g2/gesture-unit\n",
      "\t\t:op1 (i3/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (t/tower)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i4/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (r2/rotate-01)\n",
      "\t\t\t:ARG2 a2)))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, down;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (m/move-01\n",
      "\t\t:ARG2 (c/close-10))\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (c/cover-02\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/there)\n",
      "\t:ARG2 (i/implicit-role))\n",
      "\n",
      "[{\"sentence\": \"You're moving down to cover there.\", \"explanation\": \"The gesture label indicates a downward movement, which is associated with the speech AMR's 'cover-02' action. The actor in the gesture AMR matches the implicit role in the speech AMR, and the location of the action is indicated by the speech AMR as 'there'. Therefore, the sentence generated is 'You're moving down to cover there.'\"}]\n",
      "come evenly there\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: starting at row three column three\n",
      "Speech AMR:\n",
      " (s/start-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/be-located-at-91\n",
      "\t\t:ARG1 (a/and\n",
      "\t\t\t:op1 (r/row\n",
      "\t\t\t\t:ord (t/third))\n",
      "\t\t\t:op2 (c/column\n",
      "\t\t\t\t:ord 3))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: yeah great\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (r/resemble-01\n",
      "\t:ARG1 (i/it)\n",
      "\t:ARG2 (a/angle))\n",
      "\n",
      "[{\"sentence\": \"It resembles an angle.\", \"explanation\": \"The speech AMR indicates that the word 'resemble' is being used as a verb, with 'it' as the subject and 'an angle' as the object. The word 'resemble' means to have a similar appearance or character, so the sentence generated is a grammatically correct representation of this meaning.\"}]\n",
      "like an angle\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: closest to the middle yeah\n",
      "Speech AMR:\n",
      " (h/have-degree-91\n",
      "\t:ARG2 (c/close-10\n",
      "\t\t:ARG2 (m/middle))\n",
      "\t:ARG3 (m2/most))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/close-10)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: gonna have another block right next to that block so it’d be over the space of those two bottom blocks\n",
      "Speech AMR:\n",
      " (h/have-02\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (a/another))\n",
      "\t:location (n/next-to\n",
      "\t\t:ARG1 (t/that)\n",
      "\t\t:mod (r/right))\n",
      "\t:purpose (b2/be-located-at-91\n",
      "\t\t:ARG1 b\n",
      "\t\t:ARG2 (o/over\n",
      "\t\t\t:op1 (s/space\n",
      "\t\t\t\t:poss (b3/block\n",
      "\t\t\t\t\t:mod (t/that)\n",
      "\t\t\t\t\t:location (b4/bottom))))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into open, left;\n",
      "RA: move, right;\n",
      "LA: move, front; RA: move, down; hands: into open, back;\n",
      "head: move, right;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (s2/space)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, up;\n",
      "arms: move, down;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (a3/angle-02\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 a3\n",
      "\t\t\t:ARG2 i2)))\n",
      "\n",
      "[{\"sentence\": \"Look up and down.\", \"speech AMR\": \"(h/have-91 :ARG0 (a/actor) :ARG1 (l/look))\", \"explanation\": \"The gesture labels indicate that the arms are moving up and then down, suggesting a movement of looking up and down. The speech AMR is generated based on this interpretation, with 'have' as the main verb, 'actor' as the subject performing the action, and 'look' as the object of the action.\"}]\n",
      "like an angle\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and one block on the right side of the first block and move back a bit\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (b/block\n",
      "\t\t:quant 1\n",
      "\t\t:location (o/on\n",
      "\t\t\t:op1 (s/side\n",
      "\t\t\t\t:ARG1-of (r/right-04)\n",
      "\t\t\t\t:poss (b2/block\n",
      "\t\t\t\t\t:ord (o2/ordinal-entity\n",
      "\t\t\t\t\t\t:value 1)))))\n",
      "\t:op3 (m/move-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:direction (b3/back\n",
      "\t\t\t:degree (b4/bit))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "Rh: into fist, back;\n",
      "body: still;\n",
      "Unknown\n",
      "hands: into facing, left;\n",
      "arms: beckon;\n",
      "body: still;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (b/backward))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: take one block put it on top of those two in the middle\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (t/take-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:ARG2 (o/on-top-of\n",
      "\t\t\t:op1 (b2/block\n",
      "\t\t\t\t:mod (t2/that)\n",
      "\t\t\t\t:quant 2\n",
      "\t\t\t\t:location (m/middle)))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into one, front;\n",
      "RA: move, front; RH: into L, down;\n",
      "RA: move, up; RH: L, down;\n",
      "RA: move, back;\n",
      "body: still;\n",
      "RA: move, down; RH: into point, down;\n",
      "LA: move, left; LH: into L, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, up;\n",
      "arms: move, down;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (a3/angle-02\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 a3\n",
      "\t\t\t:ARG2 i2)))\n",
      "Speech AMR:\n",
      " (r/resemble-01\n",
      "\t:ARG1 (i/it)\n",
      "\t:ARG2 (a/angle))\n",
      "\n",
      "[{\"sentence\": \"Move your arms up and down.\", \"explanation\": \"The gesture labels indicate that the arms are moving in an upward and downward motion, which corresponds to the speech AMR's resemblance relation between 'it' and 'angle'. The gesture AMR's icon-GA relation indicates a pointing or indicating action, which is consistent with the instruction to move one's arms up and down.\"}]\n",
      "like an angle\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: the block you have in your left hand or in your hands goes in between that diagonal shape yep\n",
      "Speech AMR:\n",
      " (g/go-35\n",
      "\t:ARG1 (b/block\n",
      "\t\t:ARG1-of (h/have-03\n",
      "\t\t\t:ARG0 (y/you)\n",
      "\t\t\t:location (i/in\n",
      "\t\t\t\t:op1 (h2/hand\n",
      "\t\t\t\t\t:poss y))))\n",
      "\t:ARG2 (i2/in\n",
      "\t\t:op1 (b2/between\n",
      "\t\t\t:op1 (s/shape\n",
      "\t\t\t\t:mod (t/that)\n",
      "\t\t\t\t:mod (d/diagonal)))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and uh two blocks\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (b/block\n",
      "\t\t:quant 2))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (l/like-04\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:ARG2 (o/or\n",
      "\t\t\t:op1 (f/fan)\n",
      "\t\t\t:op2 (w/wave\n",
      "\t\t\t\t:mod (s/sound)\n",
      "\t\t\t\t:ARG0-of (g/go-out-17)))))\n",
      "\n",
      "[{\"sentence\": \"It's like a fan or a wave of sound going out.\", \"explanation\": \"The speech AMR indicates that the sentence is describing something 'like' two options, which are 'a fan' and 'a wave of sound'. The word 'going out' is indicated by the predicate 'go-out-17', suggesting movement away from the speaker. This suggests a comparison between two different sounds or movements, with the second option being more dynamic.\"}]\n",
      "and it's going to be like a fan or sound wave going out\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: more great\n",
      "Speech AMR:\n",
      " (m/more)\n",
      "\n",
      "Gesture label(s): \n",
      "hands: shake, left;\n",
      "Unknown\n",
      "hands: into fist, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: spread them apart a little bit but not as wide as a full block\n",
      "Speech AMR:\n",
      " (s/spread-03\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:direction (a/apart\n",
      "\t\t:quant (b/bit\n",
      "\t\t\t:mod (l/little))\n",
      "\t\t:quant (l2/less-than\n",
      "\t\t\t:op1 (q/distance-quantity\n",
      "\t\t\t\t:unit (b2/block)\n",
      "\t\t\t\t:quant 1))))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, into gap, left; hands: facing, closed;\n",
      "body: still;\n",
      "arms: move, back;\n",
      "RA: move, up; RH: into one, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/spread-03\n",
      "\t\t:direction (a/apart))\n",
      "\t:ARG2 (a2/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: into contact, front; hands: into closed, back;\n",
      "Unknown\n",
      "arms: apart, left;\n",
      "arms: into contact, front;\n",
      "arms: apart, left;\n",
      "arms: move, down;\n",
      "Unknown\n",
      "arms: into contact, front; hands: into closed, back;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/curve)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/curve)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Make a curve with your hand, then move it apart and bring it back down.\", \"speech AMR\": \"(m/make-01 :mode imperative :ARG0 (y/you) :ARG1 (c/curve) :direction (r/right) :ARG2 (a/actor)) (s/spread-03 :mode imperative :ARG0 (y/you) :ARG1 (t/them) :direction (a/apart) :quant (b/bit :mod (l/little))) (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (c/curve) :direction (d/down))\", \"explanation\": \"The gesture label indicates that the speaker is making a curve with their hand, then moving it apart and bringing it back down. The speech AMR reflects this by first describing the action of making a curve, then spreading something apart, and finally moving something downwards.\"}]\n",
      "and it's going to be like a fan or sound wave going out\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: all right put a block down\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1\n",
      "\t\t:direction (d/down))\n",
      "\t:mod (a/all-right))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, front left; RH: into claw, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: ever so slightly alright\n",
      "Speech AMR:\n",
      " (s/slight\n",
      "\t:degree (s2/so\n",
      "\t\t:mod (e/ever)))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "hands: into open, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: into contact, front; hands: into closed, back;\n",
      "Unknown\n",
      "arms: apart, left;\n",
      "arms: into contact, front;\n",
      "arms: apart, left;\n",
      "arms: move, down;\n",
      "Unknown\n",
      "arms: into contact, front; hands: into closed, back;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/curve)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/curve)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (l/like-04\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:ARG2 (o/or\n",
      "\t\t\t:op1 (f/fan)\n",
      "\t\t\t:op2 (w/wave\n",
      "\t\t\t\t:mod (s/sound)\n",
      "\t\t\t\t:ARG0-of (g/go-out-17)))))\n",
      "\n",
      "[{\"sentence\": \"It goes out like a fan or a wave.\", \"explanation\": \"The speech AMR indicates that the sentence should be similar to 'it goes out like a fan or a wave'. The gesture labels show arms moving into contact, front and hands closing, back, which suggests a circular motion. This is consistent with the gesture AMR indicating a curve. The mode of the gesture AMR is expressive, suggesting that it's describing something rather than giving instructions. Therefore, the sentence should be in the form of a description, which matches the speech AMR.\"}]\n",
      "and it's going to be like a fan or sound wave going out\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: then a last block on the crack of those two blocks\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (l/last))\n",
      "\t:location (o/on\n",
      "\t\t:op1 (c/crack\n",
      "\t\t\t:poss (b2/block\n",
      "\t\t\t\t:quant 2\n",
      "\t\t\t\t:mod (t/that)))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and then take the two on top\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (t/take-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (i/implicit-role\n",
      "\t\t\t:quant 2\n",
      "\t\t\t:location (o/on\n",
      "\t\t\t\t:op1 (t2/top))))\n",
      "\t:mod (t3/then))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (n/need-01\n",
      "\t:ARG0 (i/i)\n",
      "\t:ARG1 (b/base\n",
      "\t\t:quant 4)\n",
      "\t:mod (a/again))\n",
      "\n",
      "[{\"sentence\": \"I need to base it again.\", \"explanation\": \"The speech AMR indicates that the subject of the sentence is 'I' (ARG0), and the verb is 'need-01', which means 'to require or demand'. The object of the verb is 'base' (ARG1), with a quantity of 4, indicating that four bases are required. The modifier 'again' (mod) suggests that this is not the first time I need to base it.\"}]\n",
      "i need four base again\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: this one looks like a (oh sorry) this one looks like a smiley face\n",
      "Speech AMR:\n",
      " (l/look-02\n",
      "\t:ARG0 (o/one\n",
      "\t\t:mod (t/this))\n",
      "\t:ARG1 (l2/like-04\n",
      "\t\t:ARG2 (f/face\n",
      "\t\t\t:mod (s/smiley))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "body: move, front;\n",
      "body: move, back; hands: rotate;\n",
      "arms: move, up; hands: to face;\n",
      "arms: into gap, left; hands: into claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p2/put-01)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and there's one touching that block's bottom corner\n",
      "Speech AMR:\n",
      " (t/touch-01\n",
      "\t:ARG0 (i/implicit-role\n",
      "\t\t:quant 1)\n",
      "\t:ARG1 (c/corner\n",
      "\t\t:mod (b/bottom)\n",
      "\t\t:poss (b2/block\n",
      "\t\t\t:mod (t2/that))))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "hands: into point, down;\n",
      "arms: together, left; hands: into claw, down;\n",
      "RA: move, right; RH: into claw, down;\n",
      "RH: into open, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (m/move-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up; RH: into four, front;\n",
      "RH: shake, fornt;\n",
      "body: still;\n",
      "arms: into contact, front; hands: into closed, back;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 4\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"The speaker is holding up four fingers in front of them.\", \"speech AMR\": \"(i/icon-GA :ARG0 (s/signaler) :ARG1 4 :ARG2 (a/actor))\", \"explanation\": \"The gesture label indicates that the right arm (RA) is moving upwards, and the right hand (RH) is forming a 'four' shape in front of the body. The speech AMR reflects this by specifying that the signaler (speaker) is using an icon (holding up fingers) to indicate the number 4.\"}]\n",
      "i need four base again\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: then the gap should be a little less of between him\n",
      "Speech AMR:\n",
      " (b/be-03\n",
      "\t:ARG0 (g/gap)\n",
      "\t:degree (l/less\n",
      "\t\t:mod (l2/little))\n",
      "\t:mod (b2/between\n",
      "\t\t:ARG1 (t/them)))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up; hands: facing, into gap, left;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/less)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/squeeze\n",
      "\t\t:direction (t/together))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: almost like that\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG1 (t/that)\n",
      "\t:mod (a/almost))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/rotate-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up; RH: into four, front;\n",
      "RH: shake, fornt;\n",
      "body: still;\n",
      "arms: into contact, front; hands: into closed, back;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 4\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (n/need-01\n",
      "\t:ARG0 (i/i)\n",
      "\t:ARG1 (b/base\n",
      "\t\t:quant 4)\n",
      "\t:mod (a/again))\n",
      "\n",
      "[{\"sentence\": \"I need four bases again.\", \"explanation\": \"The gesture labels indicate that the RA is moving up, which could be interpreted as a signal or indication. The RH is into 'four', suggesting a reference to a quantity or number. This is consistent with the speech AMR, which indicates that the speaker needs four bases again. The other gestures (RH shake and arms/hands in contact/closed) do not seem directly related to this interpretation.\"}]\n",
      "i need four base again\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: i want you to tilt all of them so that the one corner is touching\n",
      "Speech AMR:\n",
      " (w/want-01\n",
      "\t:ARG0 (i/I)\n",
      "\t:ARG1 (t/tilt-01\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (t2/them\n",
      "\t\t\t:mod (a/all))\n",
      "\t\t:purpose (t3/touch-01\n",
      "\t\t\t:ARG0 (c/corner\n",
      "\t\t\t\t:quant 1))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: it kind of goes down diagonally or so in yours\n",
      "Speech AMR:\n",
      " (g/go-06\n",
      "\t:ARG0 (i/it)\n",
      "\t:ARG2 (d/down)\n",
      "\t:manner (a/about\n",
      "\t\t:op1 (d2/diagonal))\n",
      "\t:location (i2/in\n",
      "\t\t:op1 (i3/implicit-role\n",
      "\t\t\t:poss (y/you)))\n",
      "\t:degree (k/kind-of))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (i/implicit-role\n",
      "\t:quant 3\n",
      "\t:location (o/on-top-of\n",
      "\t\t:op1 (t/that))\n",
      "\t:domain (o2/one\n",
      "\t\t:mod (n/next)))\n",
      "\n",
      "[{\"sentence\": \"There are three on top of that one next.\", \"explanation\": \"The speech AMR indicates an implicit role 'i' with a quantity of 3, which corresponds to the word 'there'. The location is specified as 'on top of', with the object being 'that' and the quantifier being 'one', modified by 'next'. This translates directly into the sentence.\"}]\n",
      "the next one is three on top of those\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and it's turned at an angle\n",
      "Speech AMR:\n",
      " (t/turn-01\n",
      "\t:ARG1 (i/it)\n",
      "\t:destination (a2/angle))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: rotate;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/put-01)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (r/rotate-01)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g2/gesture-unit\n",
      "\t\t:op1 (i3/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (t/tower)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i4/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (r2/rotate-01)\n",
      "\t\t\t:ARG2 a2)))\n",
      "\n",
      "Example 2:\n",
      "Sentence: place it such that they are like interleaving\n",
      "Speech AMR:\n",
      " (p/place-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:cause-of (i2/interleave-01\n",
      "\t\t:ARG1 (t/they)))\n",
      "\n",
      "Gesture label(s): \n",
      "LH: rotate; RH: shake, left;\n",
      "hands: shake;\n",
      "arms: apart, left, into gap, left; hands: into claw, left, into facing, left; RA: move, right;\n",
      "arms: together, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (i2/interleave-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up; RH: into four, front;\n",
      "RH: into three;\n",
      "RA: move, down;\n",
      "Unknown\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 3\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Move it up to four and then down to three.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 4 :cause-of (i/increase-01 :ARG1 3) :cause-of (d/decrease-01 :ARG1 3))\", \"explanation\": \"The gesture labels indicate that the right arm moves up to four and then down to three. The speech AMR reflects this sequence of actions, with 'move' as the main action, and 'increase' and 'decrease' as secondary actions to specify the direction of movement.\"}]\n",
      "the next one is three on top of those\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: ah now uh move it so it's on the front front one and the one you just put it on\n",
      "Speech AMR:\n",
      " (m/multi-sentence\n",
      "\t:snt1 (n/no)\n",
      "\t:snt2 (m2/move-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:purpose (b/be-located-at-91\n",
      "\t\t\t:ARG1 i\n",
      "\t\t\t:ARG2 (a/and\n",
      "\t\t\t\t:op1 (o/one\n",
      "\t\t\t\t\t:mod (f/front))\n",
      "\t\t\t\t:op2 (o2/one\n",
      "\t\t\t\t\t:ARG2-of (p/put-01\n",
      "\t\t\t\t\t\t:ARG0 y\n",
      "\t\t\t\t\t\t:time (j/just)))))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up right; RH: into closed, left;\n",
      "RA: move, left; RH: closed, left;\n",
      "RA: move, front; RH: into point, front;\n",
      "RA: move, down back; RH: point, down;\n",
      "RA: move, front right; RH: point, down;\n",
      "body: still;\n",
      "RA: move, up; RH: into claw, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (m/move-01\n",
      "\t\t\t:direction (f/front))\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/turn\n",
      "\t\t:ARG1 (b/block))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: like they're all stacked right on top of each other\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG1 (t/they)\n",
      "\t:ARG2 (s/stack-01\n",
      "\t\t:quant (a/all)\n",
      "\t\t:destination (r/right\n",
      "\t\t\t:op1 (t2/top\n",
      "\t\t\t\t:quant (e/each-other)))))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, down, into gap, left; hands: into facing, left, into closed, left;\n",
      "arms: move, up; hands: into closed, back;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/stack-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up; RH: into four, front;\n",
      "RH: into three;\n",
      "RA: move, down;\n",
      "Unknown\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 3\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (i/implicit-role\n",
      "\t:quant 3\n",
      "\t:location (o/on-top-of\n",
      "\t\t:op1 (t/that))\n",
      "\t:domain (o2/one\n",
      "\t\t:mod (n/next)))\n",
      "\n",
      "[{\"sentence\": \"You're pointing to the next one.\", \"explanation\": \"The gesture AMR indicates that the speaker is referring to a specific entity, represented by the number 3. The speech AMR suggests that this entity is located on top of another entity (that) and is the next one in a sequence. The gestures suggest that the speaker is pointing to this entity, which implies that they are indicating its location.\"}]\n",
      "the next one is three on top of those\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yep and then get the last block or another block and put it on top of the one\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (g/get-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (o/or\n",
      "\t\t\t:op1 (b/block\n",
      "\t\t\t\t:mod (l/last)\n",
      "\t\t\t\t:op2 (b2/block\n",
      "\t\t\t\t\t:mod (a/another))))\n",
      "\t\t:op2 (p/put-01\n",
      "\t\t\t:mode imperative\n",
      "\t\t\t:ARG0 y\n",
      "\t\t\t:ARG1 (i/it)\n",
      "\t\t\t:ARG2 (o2/on\n",
      "\t\t\t\t:op1 (t/top\n",
      "\t\t\t\t\t:poss (o3/one))))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: the right were were about correct\n",
      "Speech AMR:\n",
      " (c/correct-01\n",
      "\t:ARG0 (t/those\n",
      "\t\t:quant 2\n",
      "\t\t:location (r/right)))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1)\n",
      "\t\t:location (n/next\n",
      "\t\t\t:ARG1 (i/it)))\n",
      "\t:op2 (p2/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:quant 1))\n",
      "\n",
      "[{\"sentence\": \"Put the block next to it, and put one block.\", \"explanation\": \"The speech AMR represents two actions: putting a block next to 'it' (implied by the location of 'next' with 'it') and putting one block. The first action is represented by the 'put-01' relation with 'you' as the subject, 'block' as the direct object, and 'next' as the location. The second action is also a 'put-01' relation but with 'one block' as the direct object.\"}]\n",
      "then you're going to put one right next to it and one right next to that\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: you have two blocks on top of these\n",
      "Speech AMR:\n",
      " (h/have-04\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/be-located-at-91\n",
      "\t\t:ARG1 (b2/block\n",
      "\t\t\t:quant 2)\n",
      "\t\t:ARG2 (o/on-top-of\n",
      "\t\t\t:op1 (t/this))))\n",
      "\n",
      "Gesture label(s): \n",
      "head: rotate; hands: into claw, down;\n",
      "head: rotate;\n",
      "head: rotate;\n",
      "arms: move, up; hands: to face;\n",
      "body: still;\n",
      "head: shake, left; arms: move, down; hands: into claws, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 2\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (o/on-top-of)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: on that exactly on that axis so\n",
      "Speech AMR:\n",
      " (o/on\n",
      "\t:op1 (a/axis\n",
      "\t\t:mod (t/that)))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "LA: move, right;\n",
      "LA: move, right;\n",
      "head: rotate;\n",
      "LH: rotate, closed, down;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Look over there.\", \"speech AMR\": \"(l/look :op1 (o/over-there :op1 (t/that)))\", \"explanation\": \"The gesture labels indicate a pointing action, which is typically associated with the meaning of looking or indicating something. The LA moving to the right and LH rotating closed down suggest a pointing action towards the right. The gesture AMR has two instances of deixis-GA, which indicates a pointing action. Therefore, the sentence 'Look over there' and speech AMR '(l/look :op1 (o/over-there :op1 (t/that)))' are generated.\"}]\n",
      "then you're going to put one right next to it and one right next to that\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yeah\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "Gesture label(s): \n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: move that about one that tower about one block over\n",
      "Speech AMR:\n",
      " (m/move-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/tower\n",
      "\t\t:mod (t2/that))\n",
      "\t:ARG2 (a/about\n",
      "\t\t:op1 (q/distance-quantity\n",
      "\t\t\t:unit (b/block)\n",
      "\t\t\t:quant 1))\n",
      "\t:direction (o/over))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, front; LH: into claw, front;\n",
      "LA: shake, up; LH: claw, front;\n",
      "LA: move, left; LH: front, claw;\n",
      "body: still;\n",
      "arms: move, up; hands: into open, up;\n",
      "body: move, back; arms: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/tower)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/tower)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:ARG1 (t/tower)\n",
      "\t\t:direction (l/left))\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "LA: move, right;\n",
      "LA: move, right;\n",
      "head: rotate;\n",
      "LH: rotate, closed, down;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1)\n",
      "\t\t:location (n/next\n",
      "\t\t\t:ARG1 (i/it)))\n",
      "\t:op2 (p2/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:quant 1))\n",
      "\n",
      "[{\"sentence\": \"Put one block next to it, and put one block next to it.\", \"explanation\": \"The gesture AMR indicates two deixis gestures (d/deixis-GA) pointing to a location (l/location), which suggests the speaker is directing the listener's attention to a specific place. The speech AMR shows an imperative mode for putting blocks, with 'next' as the location and 'it' as the reference point. Therefore, the sentence should indicate two actions of placing blocks next to something.\"}]\n",
      "then you're going to put one right next to it and one right next to that\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: that's it\n",
      "Speech AMR:\n",
      " (b/be-it-07\n",
      "\t:ARG1 (t/that))\n",
      "\n",
      "Example 2:\n",
      "Sentence: think of like a wifi signal where it’s a u shape\n",
      "Speech AMR:\n",
      " (t/think-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (s/signal\n",
      "\t\t:mod (w/wifi)\n",
      "\t\t:ARG1-of (m/mean-01\n",
      "\t\t\t:ARG2 (s2/shape\n",
      "\t\t\t\t:mod (u/u)))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (h/have-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1))\n",
      "\n",
      "[{\"sentence\": \"Block one.\", \"explanation\": \"The speech AMR indicates an imperative mode, meaning the sentence is a command. The ARG0 is 'y/you', indicating the subject of the sentence is the listener. The ARG1 is 'b/block', which corresponds to the verb in the sentence. The quant 1 specifies that the block refers to one specific instance or unit.\"}]\n",
      "you're gonna have one block\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: just like that and then you’re gonna do that one more time in the same direction so it’s kind of like a slanting height three yeah\n",
      "Speech AMR:\n",
      " (d/do-02\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:quant 2\n",
      "\t:ARG6 (h/height\n",
      "\t\t:quant 3)\n",
      "\t:mod (s/slanting))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "head: rotate;\n",
      "RA: move, up; RH: into open, down;\n",
      "RA: shake, down;\n",
      "RH: rotate, into claw, left;\n",
      "RA: move, left;\n",
      "RA: move, down right; RH: into open, down;\n",
      "Unknown\n",
      "RA: move, down left; RH: into open, down;\n",
      "RA: move, up right;\n",
      "RA: move, down;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: not not too much\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:manner (m/much\n",
      "\t\t:polarity -\n",
      "\t\t:degree (t/too)))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: rotate;\n",
      "head: rotate;\n",
      "arms: shake;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (a/apart)\n",
      "\t:ARG2 (a2/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "LA: move, up; LH: into closed, right;\n",
      "LA: move, down;\n",
      "body: still;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Look over there.\", \"speech AMR\": \"(d/deixis-GA :ARG0 (y/you) :ARG1 (t/there) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate the speaker pointing upwards with their left arm and then keeping still, suggesting a deictic gesture. The speech AMR reflects this by indicating the speaker as the actor, the location as 'there', and the actor as the person being pointed at.\"}]\n",
      "you're gonna have one block\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay perfect\n",
      "Speech AMR:\n",
      " (o/okay)\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and two blocks like making it smile\n",
      "Speech AMR:\n",
      " (m/make-02\n",
      "\t:ARG0 (b/block\n",
      "\t\t:quant 2)\n",
      "\t:ARG1 (s/smile\n",
      "\t\t:ARG0 (i/it)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, up; hands: facing, into point;\n",
      "hands: rotate;\n",
      "hands: rotate;\n",
      "arms: move, down; hands: into claw, up;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/smile)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "LA: move, up; LH: into closed, right;\n",
      "LA: move, down;\n",
      "body: still;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (h/have-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1))\n",
      "\n",
      "[{\"sentence\": \"You have a block.\", \"explanation\": \"The gesture AMRs indicate that the speaker is pointing to a location, which in this case corresponds to a single block. The speech AMR shows that the sentence is imperative and the subject is 'you'. Therefore, the generated sentence is 'You have a block.'\"}]\n",
      "you're gonna have one block\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: scoot it over so there's the blocks are flush on one side\n",
      "Speech AMR:\n",
      " (s/scoot-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:ARG2 (o/over)\n",
      "\t:purpose (f/flush\n",
      "\t\t:domain (b/block)\n",
      "\t\t:location (o2/on\n",
      "\t\t\t:op1 (s2/side\n",
      "\t\t\t\t:quant 1))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: so like fanned out away from you\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG1 (f/fan-01\n",
      "\t\t:mod (o/out)\n",
      "\t\t:direction (a/away\n",
      "\t\t\t:op1 (y/you))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (b/be-01\n",
      "\t:ARG0 (t/there)\n",
      "\t:ARG1 (o/one\n",
      "\t\t:ord 3)\n",
      "\t:ARG1 (h/hang\n",
      "\t\t:location (e/edge\n",
      "\t\t\t:location (h2/height\n",
      "\t\t\t\t:ord 1))))\n",
      "\n",
      "[{\"sentence\": \"There is one hang on the edge at height one.\", \"explanation\": \"The speech AMR indicates that 'there' is the subject ('ARG0'), and it is being described in a state of having something. The 'one' refers to the third instance of 'hang', which is located on an edge, and this edge is at a height of one.\"}]\n",
      "there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: just turn it turn it vertical okay\n",
      "Speech AMR:\n",
      " (t/turn-01\n",
      "\t:mode imperative\n",
      "\t:mod (j/just)\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:direction (v/vertical))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, down;\n",
      "hands: rotate;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (r/rotate-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: on the side with three the one closest to the middle put another block on top\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (a/another))\n",
      "\t:ARG2 (o/on-top\n",
      "\t\t:op1 (o2/one\n",
      "\t\t\t:ARG1-of (h/have-degree-91\n",
      "\t\t\t\t:ARG2 (c/close-10\n",
      "\t\t\t\t\t:ARG1 o2\n",
      "\t\t\t\t\t:ARG2 (m/middle))\n",
      "\t\t\t\t:ARG3 (m2/most))\n",
      "\t\t\t:location (o3/on\n",
      "\t\t\t\t:op1 (s/side\n",
      "\t\t\t\t\t:ARG0-of (h2/have\n",
      "\t\t\t\t\t\t:ARG1 (i2/implicit-role\n",
      "\t\t\t\t\t\t\t:quant 3)))))))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "LA: move, left; LH: into open, front;\n",
      "body: still;\n",
      "LH: into point, front;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/side)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "RA: move, up left; RH: into closed, left;\n",
      "RA: shake;\n",
      "RA: move, down right; RH: rotate, closed, down;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Move the block to the left and then shake it.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block) :ARG2 (l/left)) (s/shake-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block))\", \"explanation\": \"The gesture labels indicate that the right arm moves up and left, then shakes, and finally moves down to the right while rotating. This suggests a sequence of actions involving moving an object to a location on the left, followed by shaking it.\"}]\n",
      "there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: in the middle\n",
      "Speech AMR:\n",
      " (i/in\n",
      "\t:op1 (m/middle))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "RA: move, down; RH: into claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and turn it so it's parallel\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (t/turn-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:purpose (p/parallel\n",
      "\t\t\t:domain i)))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into claw, front;\n",
      "RH: rotate, claw, front;\n",
      "RA: move, down; RH: claw, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/turn\n",
      "\t\t:ARG1 (b/block))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "Unknown\n",
      "RA: move, up left; RH: into closed, left;\n",
      "RA: shake;\n",
      "RA: move, down right; RH: rotate, closed, down;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (b/be-01\n",
      "\t:ARG0 (t/there)\n",
      "\t:ARG1 (o/one\n",
      "\t\t:ord 3)\n",
      "\t:ARG1 (h/hang\n",
      "\t\t:location (e/edge\n",
      "\t\t\t:location (h2/height\n",
      "\t\t\t\t:ord 1))))\n",
      "\n",
      "[{\"sentence\": \"Move the left object to the edge of the third one.\", \"explanation\": \"The gesture AMR indicates a deixis, which is a pointing or indicating action. The RA and RH gestures suggest moving an object up and down, and rotating it while in the closed position. This implies that the speaker is referring to an object on the left side (ARG2) being moved to a location (ARG1), specifically the edge of another object (the third one). The speech AMR confirms this interpretation by indicating 'one' as the third object, with the verb 'be' describing its position.\"}]\n",
      "there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yup\n",
      "Speech AMR:\n",
      " (y/yup)\n",
      "\n",
      "Example 2:\n",
      "Sentence: then that’s it for your base uh your height you’re every\n",
      "Speech AMR:\n",
      " (b/be-01\n",
      "\t:ARG2 (o/or\n",
      "\t\t:op1 (b2/base\n",
      "\t\t\t:ord (z/zero)\n",
      "\t\t\t:poss (y/your))\n",
      "\t\t:op2 (h/height\n",
      "\t\t\t:ord z\n",
      "\t\t\t:poss y)))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "Here is the output:\n",
      "\n",
      "```\n",
      "[\n",
      "  {\n",
      "    \"sentence\": \"Yeah\",\n",
      "    \"explanation\": \"The speech AMR indicates that the word 'yeah' is being used as an affirmative expression, which corresponds to a simple sentence in natural spoken English.\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "yeah right\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and then there must be one a hard that i'm having time seeing behind\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (l/likely-01\n",
      "\t\t:ARG1 (b/be-02\n",
      "\t\t\t:ARG1 (o/one\n",
      "\t\t\t\t:location (b2/behind)\n",
      "\t\t\t\t:ARG1-of (s/see-01\n",
      "\t\t\t\t\t:ARG0 (i/i)\n",
      "\t\t\t\t\t:ARG1-of (h/hard-02))))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into point, front;\n",
      "RA: move, up; RH: point, front;\n",
      "Unknown\n",
      "RA: move, front; RH: point, front;\n",
      "RA: move, front; RH: point, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: place it so it's um sitting in between the two like that\n",
      "Speech AMR:\n",
      " (p/place-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:purpose (s/sit-01\n",
      "\t\t:ARG1 i\n",
      "\t\t:ARG2 (i2/in-between\n",
      "\t\t\t:op1 (i3/implicit-role\n",
      "\t\t\t\t:quant 2))\n",
      "\t\t:ARG1-of (l/like-04\n",
      "\t\t\t:ARG2 (t/that))))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: into facing, closed;\n",
      "arms: together, left, into contact, left; hands: closed, up;\n",
      "body: still;\n",
      "arms: apart, left; hands: facing, into fist;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/rotate-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up; RH: into open, down;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Look at the location below.\", \"speech AMR\": \"(d/deixis-GA :ARG0 (y/you) :ARG1 (l/location) :ARG2 (b/below))\", \"explanation\": \"The gesture label RA: move, up; RH: into open, down indicates a pointing action towards a location below. The gesture AMR d/deixis-GA represents a deictic gesture, which is used to point or indicate a location. In this case, the ARG0 (y/you) indicates that the speaker is directing the attention of the listener (ARG2 (a/actor)) to the location (ARG1 (l/location)) below.\"}]\n",
      "yeah right\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay\n",
      "Speech AMR:\n",
      " (o/okay)\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into four, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 4\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: have two blocks right next to each other\n",
      "Speech AMR:\n",
      " (h/have-03\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2)\n",
      "\t:destination (n/next-to\n",
      "\t\t:op1 (o/other\n",
      "\t\t\t:mod (e/each))))\n",
      "\n",
      "Gesture label(s): \n",
      "head: move, down; LA: move, front; LH: into open, back; RA: move, down;\n",
      "head: move, up;\n",
      "    LA: move, back;\n",
      "head: rotate;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 2\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up; RH: into open, down;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "[{\"sentence\": \"Look at that.\", \"explanation\": \"The gesture labels indicate the right arm moving up and the right hand moving into an open position downwards, suggesting a pointing or gesturing action. The Deictic Gesture Abstract Meaning Representation (GA) indicates the presence of deixis, which is a reference to a location or object in space. This suggests that the speaker is indicating something in their surroundings. The speech AMR for 'yeah' implies agreement or confirmation, but given the context of the gesture, it's more likely that the speaker is pointing out or drawing attention to something.\"}]\n",
      "yeah right\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: three to one but they all gonna be rotated a\n",
      "Speech AMR:\n",
      " (r/rotate-02\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/they\n",
      "\t\t:quant 3)\n",
      "\t:ARG3 (t2/implicit-role\n",
      "\t\t:quant 1))\n",
      "\n",
      "Example 2:\n",
      "Sentence: put a block one block apart behind\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1)\n",
      "\t:location (a/apart\n",
      "\t\t:mod (b2/block\n",
      "\t\t\t:quant 1))\n",
      "\t:location (b3/behind))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (b/be-located-at-91\n",
      "\t:ARG1 (o/one\n",
      "\t\t:mod (o2/ordinal-entity\n",
      "\t\t\t:value -1))\n",
      "\t:ARG2 (o3/on\n",
      "\t\t:op1 (t/top\n",
      "\t\t\t:op1 (i/it))\n",
      "\t\t:mod (e/exactly\n",
      "\t\t\t:degree (p/pretty-much)))\n",
      "\t:mod (j/just)\n",
      "\t:time (t2/then))\n",
      "\n",
      "[{\"sentence\": \"It was just then that one, pretty much exactly on top of it, was located.\", \"explanation\": \"The speech AMR indicates a past tense event using the 'be-located-at' relation. The ARG1 is 'one', which has an ordinal modifier indicating it's referring to something in the past (value -1). The ARG2 is 'on', with a top-of modifier specifying that it's on top of 'it'. The exactly modifier indicates precision, and pretty-much degree specifies the level of precision. Finally, just modifies the entire event, and then specifies the time as 'then'.\"}]\n",
      "the final one is just pretty much exactly on top of it\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: right there uh\n",
      "Speech AMR:\n",
      " (t/there\n",
      "\t:mod (r/right))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into open, down;\n",
      "RA: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: like not stacked\n",
      "Speech AMR:\n",
      " (s/stack-01\n",
      "\t:polarity -)\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "RA: move, up, surround; RH: into point, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: move, up;\n",
      "RA: move, up, shake, down; RH: into open, down;\n",
      "body: move, down; RA: move, down; RH: into open, down;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (t/top)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "[{\"sentence\": \"Put the top on.\", \"speech AMR\": \"(p/put-01 :ARG1 (t/top) :ARG2 (a/actor))\", \"explanation\": \"The gesture labels indicate that the speaker is moving their body up, and then the right arm moves up to shake something down. This suggests putting a top on an object. The final still gesture indicates completion of the action.\"}]\n",
      "the final one is just pretty much exactly on top of it\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: alright\n",
      "Speech AMR:\n",
      " (a/alright)\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, back; arms: apart, left; hands: facing, claw;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/okay)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: so starting from the top moving to your left down four diagonally a row with the corners\n",
      "Speech AMR:\n",
      " (s/start-01\n",
      "\t:source (t/top)\n",
      "\t:destination (l/left\n",
      "\t\t:poss (y/you)\n",
      "\t\t:direction (d/down))\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:quant 4\n",
      "\t\t:direction (d2/diagonal)\n",
      "\t\t:ARG0-of (h/have-03\n",
      "\t\t\t:ARG1 (c/corner\n",
      "\t\t\t\t:ARG0-of (t2/touch-01)))))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up; hands: into claw, down;\n",
      "arms: move, down;\n",
      "RA: move, front right;\n",
      "head: rotate;\n",
      "RA: move, back left;\n",
      "RA: move, front right;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/diagonal)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/diagonal)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: move, up;\n",
      "RA: move, up, shake, down; RH: into open, down;\n",
      "body: move, down; RA: move, down; RH: into open, down;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (t/top)\n",
      "\t\t:ARG2 a))\n",
      "Speech AMR:\n",
      " (b/be-located-at-91\n",
      "\t:ARG1 (o/one\n",
      "\t\t:mod (o2/ordinal-entity\n",
      "\t\t\t:value -1))\n",
      "\t:ARG2 (o3/on\n",
      "\t\t:op1 (t/top\n",
      "\t\t\t:op1 (i/it))\n",
      "\t\t:mod (e/exactly\n",
      "\t\t\t:degree (p/pretty-much)))\n",
      "\t:mod (j/just)\n",
      "\t:time (t2/then))\n",
      "\n",
      "[{\"sentence\": \"Put it on top.\", \"explanation\": \"The gesture label indicates a series of movements, starting with the body moving up and the right arm shaking down. The hand then moves into an open position and down. This is followed by the body moving back down, the right arm moving down, and the hand again moving into an open position and down. Finally, the body remains still. The gesture AMR indicates that this series of movements corresponds to the icon 'put' (i/icon-GA :ARG1 (p/put-01)), which is directed at the actor. Therefore, the sentence should be 'Put it on top.'\"}]\n",
      "the final one is just pretty much exactly on top of it\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: move forward a bit\n",
      "Speech AMR:\n",
      " (m/move-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:direction (f/forward\n",
      "\t\t:degree (b/bit)))\n",
      "\n",
      "Example 2:\n",
      "Sentence: both sides\n",
      "Speech AMR:\n",
      " (s/side\n",
      "\t:mod (b/both))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (p/push-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:ARG2 (d/direction\n",
      "\t\t:mod (s/same))\n",
      "\t:direction (o/off))\n",
      "\n",
      "[{\"sentence\": \"Push it off in the same direction.\", \"explanation\": \"The speech AMR indicates an imperative mode, meaning a command or instruction. The ARG0 is 'y/you', indicating that the subject of the sentence is the person being addressed. The ARG1 is 'i/it', which is the object being pushed. The ARG2 is 'd/direction' with a modifier 's/same', indicating that the direction is the same as something else, likely referring to the direction in which it was previously moving or positioned. Finally, the direction itself is 'o/off'. Therefore, the sentence should instruct someone to push an object off in the same direction.\"}]\n",
      "pushed off like the same direction\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: alright grab three blocks\n",
      "Speech AMR:\n",
      " (g/grab-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 3)\n",
      "\t:mod (a/all-right))\n",
      "\n",
      "Gesture label(s): \n",
      "    body: still;\n",
      "arms: move, front, into contact, left; hands: into inch, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/space-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: yea yea and then it\n",
      "Speech AMR:\n",
      " (g/good\n",
      "\t:domain (t/that))\n",
      "\n",
      "Gesture label(s): \n",
      "head: move, up, nod; LA: move, up; LH: into thumbs, up;\n",
      "body: move, down; head: move, down; LA: move, down; LH: into open, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, up, into gap, left; hands: into facing, left, into claw, left;\n",
      "LA: move, left;\n",
      "arms: move, down; hands: into open, down;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/put-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide\n",
      "\t\t:direction (l/left))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Put it on the left.\", \"speech AMR\": \"(g/grab-01 :mode imperative :ARG0 (y/you) :ARG1 (p/place-01 :location (l/left)) :mod (i/icon-GA :ARG0 (s/signaler) :ARG1 (p/put-01) :ARG2 (a/actor)))\", \"explanation\": \"The gesture AMR indicates that the signaler is performing an action of putting something, and the actor is involved. The arms moving up into a gap on the left suggests placing or positioning something on the left side. The hands then move down to an open position, indicating completion of the action. The speech AMR reflects this by using the verb 'put' in imperative mode, with the location specified as 'left'. The icon-GA slot is used to indicate that the signaler is performing a putting action.\"}]\n",
      "pushed off like the same direction\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: take one block and put it on the table\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (t/take-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:ARG2 (o/on\n",
      "\t\t\t:op1 (t2/table))))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, front; LH: into point, down;\n",
      "LA: move, to hip;\n",
      "RA: move, front; RH: into point, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: alright move one of the blocks off to the side\n",
      "Speech AMR:\n",
      " (m/move-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1)\n",
      "\t:ARG2 (o/off\n",
      "\t\t:op1 (s/side))\n",
      "\t:mod (a/all-right))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: into open, down;\n",
      "RA: move, up right; RH: closed, back;\n",
      "RA: move, down left; RH: open, down;\n",
      "body: still;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, up, into gap, left; hands: into facing, left, into claw, left;\n",
      "LA: move, left;\n",
      "arms: move, down; hands: into open, down;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/put-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide\n",
      "\t\t:direction (l/left))\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (p/push-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:ARG2 (d/direction\n",
      "\t\t:mod (s/same))\n",
      "\t:direction (o/off))\n",
      "\n",
      "[{\"sentence\": \"Push it off to the left.\", \"explanation\": \"The gesture AMR indicates two actions: putting something and sliding something. The speech AMR is a push action with an imperative mode, indicating that the speaker wants the listener to perform the action. Combining these elements, we get the sentence 'Push it off to the left.'\"}]\n",
      "pushed off like the same direction\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yea and touching corners\n",
      "Speech AMR:\n",
      " (t/touch-01\n",
      "\t:ARG0 (c/corners))\n",
      "\n",
      "Example 2:\n",
      "Sentence: yea on the side with four on the last one on the inside corner there is another block yeah\n",
      "Speech AMR:\n",
      " (b/be-located-at-91\n",
      "\t:ARG1 (b2/block\n",
      "\t\t:mod (a/another))\n",
      "\t:ARG2 (c/corner\n",
      "\t\t:mod (i/inside)\n",
      "\t\t:poss (i2/implicit-role\n",
      "\t\t\t:ord (o/ordinal-entity\n",
      "\t\t\t\t:value -1)\n",
      "\t\t\t:location (o2/on\n",
      "\t\t\t\t:op1 (s/side\n",
      "\t\t\t\t\t:ARG0-of (h/have-03\n",
      "\t\t\t\t\t\t:ARG1 (i3/implicit-role\n",
      "\t\t\t\t\t\t\t:quant 4)))))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:ARG1 (a/and\n",
      "\t\t:op1 (r/resemble-01\n",
      "\t\t\t:ARG1 (s/space)\n",
      "\t\t\t:mod (b/block))\n",
      "\t\t:op2 (b2/block\n",
      "\t\t\t:ord (o/ordinal-entity\n",
      "\t\t\t\t:value 3))\n",
      "\t\t:time (t/then)))\n",
      "\n",
      "[{\"sentence\": \"Then there was a block that resembled space, and the third block.\", \"explanation\": \"The speech AMR indicates an implicit predicate with 'and' as its main argument. The first operand of 'and' is a resemblance relation between a block (b2/block) and space (s/space), which implies that the block resembles space. The second operand of 'and' is also a block, but this time it's specified to be the third one in an ordinal sequence (o/ordinal-entity with value 3). The temporal relationship indicated by 'then' suggests that this event occurred after some other event.\"}]\n",
      "a block space and on a third block\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: one block on each side\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 1\n",
      "\t:location (o/on\n",
      "\t\t:op1 (s/side\n",
      "\t\t\t:quant (e/each)))))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, left; LH: into L, down;\n",
      "RA: move, right; RH: into L, down;\n",
      "body: still;\n",
      "arms: move, down;\n",
      "arms: rotate; hands: into point, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: five blocks in a row right in front of them\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 5)\n",
      "\t:manner (r/row)\n",
      "\t:location (f/front\n",
      "\t\t:poss (t/them)\n",
      "\t\t:mod (r2/right)))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into five, front;\n",
      "arms: move, front; hands: facing, into point, down;\n",
      "arms: move, back, to hip;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 5\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/row)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: still;\n",
      "arms: move, left;\n",
      "head: rotate; arms: move, back;\n",
      "body: still;\n",
      "head: nod;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (s2/space)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l2/location)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"You are indicating something in the location.\", \"speech AMR\": \"(i/implicit-predicate-00 :mode declarative :ARG0 (s/signaler) :ARG1 (l/location))\", \"explanation\": \"The gesture labels indicate a still body, moving arms to the left, rotating head and then moving arms back. This suggests that the speaker is indicating something in a specific location, which corresponds to the first gesture unit in the Gesture AMR. The second gesture unit indicates an icon of a block at a location, but this seems out of place given the initial gesture. The third gesture unit is an emblem of 'yes', which doesn't seem relevant to the initial gestures. Therefore, we focus on the first gesture unit and interpret it as indicating something in the location.\"}]\n",
      "a block space and on a third block\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay and\n",
      "Speech AMR:\n",
      " (o/okay)\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "RA: move, right; RH: into closed, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/side)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: but it's still in berlin\n",
      "Speech AMR:\n",
      " (c/contrast-01\n",
      "\t:ARG2 (b/be-located-at-91\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:ARG2 (b2/Berlin)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 b2\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: still;\n",
      "arms: move, left;\n",
      "head: rotate; arms: move, back;\n",
      "body: still;\n",
      "head: nod;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (s2/space)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l2/location)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:ARG1 (a/and\n",
      "\t\t:op1 (r/resemble-01\n",
      "\t\t\t:ARG1 (s/space)\n",
      "\t\t\t:mod (b/block))\n",
      "\t\t:op2 (b2/block\n",
      "\t\t\t:ord (o/ordinal-entity\n",
      "\t\t\t\t:value 3))\n",
      "\t\t:time (t/then)))\n",
      "\n",
      "[{\"sentence\": \"And then, the space resembles a block at third position.\", \"explanation\": \"The gesture AMR indicates two gesture units. The first unit is an icon gesture that represents a signaler moving into a space with an actor. This corresponds to the speech AMR's implicit predicate-00, which has an and operator with two operands. The first operand is a resemble predicate that takes the space as its argument 1 and a block as its modifier. The second operand is a block entity with ordinal value 3. The time of this event is 'then'. Therefore, the sentence can be generated by combining these elements into a coherent English sentence.\"}]\n",
      "a block space and on a third block\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: please close a little bit the base the base\n",
      "Speech AMR:\n",
      " (c/close-01\n",
      "\t:mode imperative\n",
      "\t:polite +\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/base)\n",
      "\t:degree (b2/bit\n",
      "\t\t:mod (l/little)))\n",
      "\n",
      "Example 2:\n",
      "Sentence: so that’s our new you did not miss from in right blocks space\n",
      "Speech AMR:\n",
      " (u/unit\n",
      "\t:ARG1-of (n/new-01)\n",
      "\t:poss (w/we)\n",
      "\t:ARG2-of (m/measure-01)\n",
      "\t:domain (b/block_space))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (h/have-03\n",
      "\t:time (t/then)\n",
      "\t:location (l/line\n",
      "\t\t:mod (s/same))\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (s2/space))\n",
      "\n",
      "[{\"sentence\": \"You had space then.\", \"explanation\": \"The speech AMR indicates that the sentence is in the past tense ('h/have-03' with 'time (t/then)'), and the subject is 'you' ('ARG0 (y/you)'). The object of the verb is 'space' ('ARG1 (s2/space)'). Therefore, a corresponding sentence in natural spoken English would be 'You had space then.'\" }]\n",
      "then on like the same line you're going to have a space\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: move them this direction like you had it before so they’re touching corners\n",
      "Speech AMR:\n",
      " (m/move-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:direction (d/direction\n",
      "\t\t:mod (t2/this))\n",
      "\t:ARG1-of (l/like-04\n",
      "\t\t:ARG2 (h/have-04\n",
      "\t\t\t:ARG0 y\n",
      "\t\t\t:ARG1 (i/it)\n",
      "\t\t\t:time (b/before)))\n",
      "\t:purpose (t3/touch-01\n",
      "\t\t:ARG0 (t4/they)\n",
      "\t\t:ARG1 (c/corner)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, front; LH: closed, right; RA: move, back; RH: closed, left;\n",
      "body: still;\n",
      "arms: move, into contact;\n",
      "body: still;\n",
      "arms: move, into gap; hands: facing, closed;\n",
      "arms: move, down back; hands: into open, down;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/touch-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/rotate-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: on top of that you're going to between the overlapping the two you're going to have two blocks or the uh middle three\n",
      "Speech AMR:\n",
      " (h/have-01\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2)\n",
      "\t:ARG2 (o/on\n",
      "\t\t:location (m/middle\n",
      "\t\t\t:quant 3))\n",
      "\t:location (o2/or)\n",
      "\t:op1 (t/top\n",
      "\t\t:ARG1 (t2/that))\n",
      "\t:op2 (b2/between\n",
      "\t\t:ARG2 b\n",
      "\t\t:quant 2\n",
      "\t\t:mod (o3/overlapping)))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: together, left, into gap, left; hands: into claw, down;\n",
      "body: still;\n",
      "Unknown\n",
      "arms: move, up; hands: into facing, closed;\n",
      "body: still;\n",
      "hands: into inch, front;\n",
      "body: still;\n",
      "hands: into claw, down;\n",
      "arms: move, down;\n",
      "body: still;\n",
      "head: rotate;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/top)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/between)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 2)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/iconic-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 2)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: still;\n",
      "    head: move, down; RA: move, front; RH: into open, back;\n",
      "RA: move, left;\n",
      "arms: into gap, left; hands: into facing, left, into open, left;\n",
      "head: move, up;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/line)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l2/location)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (s2/space)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l2/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "[{\"sentence\": \"Move your head down, then move it to the left.\", \"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (h/head) :direction (d/direction :mod (d/down))) (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (h/head) :direction (d/direction :mod (l/left)))\", \"explanation\": \"The gesture labels indicate that the head is moving down and then to the left. The first speech AMR corresponds to the head moving down, with the direction specified as 'down'. The second speech AMR corresponds to the head moving to the left, with the direction specified as 'left'.\"}]\n",
      "then on like the same line you're going to have a space\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: so you could squeeze them together a little bit there you go\n",
      "Speech AMR:\n",
      " (s/squeeze-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:direction (t2/together\n",
      "\t\t:mod (l/little)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: shake, left; hands: closed;\n",
      "arms: move, down; RH: into fist, down;\n",
      "LA: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/squeeze\n",
      "\t\t:direction (t/together))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: block the goes on top of the block you just placed but not totally centered\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (a/another)\n",
      "\t\t:ARG1-of (b2/be-located-at-91\n",
      "\t\t\t:ARG2 (c/contrast-01\n",
      "\t\t\t\t:ARG1 (o/on\n",
      "\t\t\t\t\t:op1 (t/top\n",
      "\t\t\t\t\t\t:poss b\n",
      "\t\t\t\t\t\t:ARG1-of (p/place-01\n",
      "\t\t\t\t\t\t\t:ARG0 b\n",
      "\t\t\t\t\t\t\t:time (j/just))))\n",
      "\t\t\t\t:ARG2 (c2/center-01\n",
      "\t\t\t\t\t:polarity -\n",
      "\t\t\t\t\t:mod (t2/total))))))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "LA: move, up; LH: into point, front;\n",
      "body: still;\n",
      "body: move, down; arms: move, down; hands: into open, back down;\n",
      "body: still;\n",
      "head: rotate;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: still;\n",
      "    head: move, down; RA: move, front; RH: into open, back;\n",
      "RA: move, left;\n",
      "arms: into gap, left; hands: into facing, left, into open, left;\n",
      "head: move, up;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/line)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l2/location)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (s2/space)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l2/location)\n",
      "\t\t:ARG2 a))\n",
      "Speech AMR:\n",
      " (h/have-03\n",
      "\t:time (t/then)\n",
      "\t:location (l/line\n",
      "\t\t:mod (s/same))\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (s2/space))\n",
      "\n",
      "[{\"sentence\": \"You have this space over here.\", \"explanation\": \"The gesture AMR indicates two gesture units. The first unit is an icon gesture representing a line, and the second unit is a deixis gesture pointing to a location. This suggests that the speaker is drawing attention to a specific location or area. The speech AMR indicates that the speaker has this space (line) over here (location). The head movement down and arm movements suggest a pointing action, reinforcing the idea of drawing attention to a specific location.\"}]\n",
      "then on like the same line you're going to have a space\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: this one is like three towers next to each other\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG0 (t/this\n",
      "\t\t:quant 1)\n",
      "\t:ARG1 (t2/tower\n",
      "\t\t:quant 3\n",
      "\t\t:mod (n/next-02\n",
      "\t\t\t:ARG1 (e/each))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: now the ones i just told you to put that were two that last two i told you to put\n",
      "Speech AMR:\n",
      " (k/know-02\n",
      "\t:polarity (a/amr-unknown)\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:quant 2\n",
      "\t\t:mod (l/last)\n",
      "\t\t:ARG1-of (p/put-01\n",
      "\t\t\t:ARG0 y\n",
      "\t\t\t:ARG1-of (t/tell-01\n",
      "\t\t\t\t:ARG0 (i2/I)))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (r/resemble-01\n",
      "\t:ARG1 (o/over\n",
      "\t\t:op1 (s/space\n",
      "\t\t\t:location (b/between\n",
      "\t\t\t\t:op1 (b2/block))))\n",
      "\t:purpose (b3/be-located-at-91\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:ARG2 (o2/on)))\n",
      "\n",
      "[{\"sentence\": \"It resembles a block over space between blocks.\", \"explanation\": \"The speech AMR represents the sentence 'It resembles a block over space between blocks.' by using the following components:\n",
      "\n",
      "- The root concept is 'resemble' (r/resemble-01), which indicates that something has a similar appearance or quality.\n",
      "- The first argument of 'resemble' is 'over' (o/over), which is an action or state indicating a location in space. This is further broken down into:\n",
      "  - 'space' (s/space) as the location where the action takes place.\n",
      "  - 'between' (b/between) as the relationship between two entities, with 'block' (b2/block) being one of them.\n",
      "- The purpose of the resemblance is to be located at a particular position, which is represented by 'be-located-at-91' (b3/be-located-at-91). This concept has two arguments:\n",
      "  - 'it' (i/it), which is the entity that is being described.\n",
      "  - 'on' (o2/on), indicating the location where 'it' is situated.\n",
      "\n",
      "By combining these components, we get the sentence 'It resembles a block over space between blocks.'\"]}]\n",
      "over the space in between the blocks so it’ll be on\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: put them to the side of that little section so they line up\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:direction (t2/to\n",
      "\t\t:op1 (s/side\n",
      "\t\t\t:poss (s2/section\n",
      "\t\t\t\t:mod (t3/that)\n",
      "\t\t\t\t:mod (l/little))))\n",
      "\t:purpose (l2/line-up\n",
      "\t\t:ARG1 (t4/they)))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, left, into contact, left; hands: facing, closed;\n",
      "arms: move, left; LH: closed, right; RH: closed, back;\n",
      "Rh: into fist, back;\n",
      "LA: move, right; LH: closed, right;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (l/left))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: they gonna be all connecting\n",
      "Speech AMR:\n",
      " (c/connect-01\n",
      "\t:ARG1 (t/they))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, front;\n",
      "arms: move, back;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up; RH: into point, front;\n",
      "RA: move, down; hands: into point, down;\n",
      "body: still;\n",
      "head: nod;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"That's correct.\", \"speech AMR\": \"(y/yes-01 :mode declarative :ARG0 (s/signaler) :ARG1 (l/location))\", \"explanation\": \"The gesture label indicates a nod of the head, which is often used to indicate agreement or confirmation. The gesture AMR for 'emblem-GA' with 'y/yes' as the argument matches this interpretation. Therefore, the generated sentence and speech AMR reflect an affirmative response.\"}]\n",
      "over the space in between the blocks so it’ll be on\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: it's just on the table\n",
      "Speech AMR:\n",
      " (b/be-located-at-91\n",
      "\t:ARG0 (i/it)\n",
      "\t:ARG1 (o/on\n",
      "\t\t:op1 (t/table))\n",
      "\t:mod (j/just))\n",
      "\n",
      "Gesture label(s): \n",
      "head: move, up;\n",
      "arms: move, front; hands: into point, down;\n",
      "head: shake; RA: move, back;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: you see how there are three divots\n",
      "Speech AMR:\n",
      " (s/see-01\n",
      "\t:polarity (a/amr-unknown)\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (d/divot\n",
      "\t\t:quant 3))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "arms: move, front; hands: into facing, left, into claw, left;\n",
      "arms: move, back; hands: into claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (d/divot)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d2/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up; RH: into point, front;\n",
      "RA: move, down; hands: into point, down;\n",
      "body: still;\n",
      "head: nod;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (r/resemble-01\n",
      "\t:ARG1 (o/over\n",
      "\t\t:op1 (s/space\n",
      "\t\t\t:location (b/between\n",
      "\t\t\t\t:op1 (b2/block))))\n",
      "\t:purpose (b3/be-located-at-91\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:ARG2 (o2/on)))\n",
      "\n",
      "[{\"sentence\": \"It's between the blocks.\", \"explanation\": \"The gesture AMR indicates deixis, pointing to a location. The speech AMR shows that something is located on or between two things. The emblem-GA in the gesture AMR indicates agreement or confirmation with what was previously said, which suggests that the speaker is confirming where 'it' is located.\"}]\n",
      "over the space in between the blocks so it’ll be on\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: three blocks\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 3)\n",
      "\n",
      "Example 2:\n",
      "Sentence: it will be diagonal like a diamond no no no\n",
      "Speech AMR:\n",
      " (d/diagonal\n",
      "\t:domain (i/it\n",
      "\t\t:ARG1-of (r/resemble-01\n",
      "\t\t\t:ARG2 (d2/diamond))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (i/implicit-predicate\n",
      "\t:ARG0 (i2/implicit-role\n",
      "\t\t:quant 1)\n",
      "\t:ARG1 (l/less)\n",
      "\t:ARG2 (t/than)\n",
      "\t:ARG4 (t2/that))\n",
      "\n",
      "[{\"sentence\": \"There is one that is less than that.\", \"explanation\": \"The speech AMR indicates an implicit predicate with a single argument of type 'implicit-role' with quantifier 1, which means there is one. The arguments ARG1 and ARG2 are the words 'less' and 'than', indicating a comparison. The final argument ARG4 is 'that', likely referring to a previously mentioned or implied entity.\"}]\n",
      "what one less than\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: make a little bit of gap but in line with the back block okay\n",
      "Speech AMR:\n",
      " (m/make-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (c/contrast-01\n",
      "\t\t:ARG1 (g/gap\n",
      "\t\t\t:quant (b/bit\n",
      "\t\t\t\t:mod (l/little)))\n",
      "\t\t:ARG2 (i/in-line-04\n",
      "\t\t\t:ARG2 (b2/block\n",
      "\t\t\t\t:mod (b3/back)))))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "Unknown\n",
      "arms: apart, left; hands: claw, down;\n",
      "Unknown\n",
      "body: still;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/line)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and then grab another block\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (g/grab-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:mod (a2/another))\n",
      "\t\t:time (t/then)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "RH: into closed, left;\n",
      "hands: into facing, closed;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/rotate-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, front; RH: into point, front;\n",
      "RA: move, left; RH: into point, left;\n",
      "head: shake; RA: move, down right;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (m/move-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "[{\"sentence\": \"Move the block in front of you, then move it to the left.\", \"speech AMR\": \"(a/and :op2 (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block) :quant (f/front)) :op3 (m/move-02 :mode imperative :ARG0 (y/you) :ARG1 (b/block) :quant (l/left)))\", \"explanation\": \"The gesture label indicates that the speaker is moving their arm in front and then to the left, which corresponds to the speech AMR indicating movement of the block in front and then to the left. The head shake gesture may indicate a change or emphasis on the direction of movement.\"}]\n",
      "what one less than\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: save on the fourth block on the other side\n",
      "Speech AMR:\n",
      " (s/same-01\n",
      "\t:ARG0 (b/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value 4)\n",
      "\t\t:location (s1/side\n",
      "\t\t\t:mod (o2/other))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, front; hands: into point, down;\n",
      "RA: shake, left;\n",
      "RA: move, back right; RH: into open, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: that one okay\n",
      "Speech AMR:\n",
      " (o/one\n",
      "\t:mod (t/that))\n",
      "\n",
      "Gesture label(s): \n",
      "head: nod;\n",
      "body: move, left;\n",
      "body: still;\n",
      "RA: move, right; RH: into closed, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/side)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, front; RH: into point, front;\n",
      "RA: move, left; RH: into point, left;\n",
      "head: shake; RA: move, down right;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (m/move-01)\n",
      "\t\t:ARG2 a))\n",
      "Speech AMR:\n",
      " (i/implicit-predicate\n",
      "\t:ARG0 (i2/implicit-role\n",
      "\t\t:quant 1)\n",
      "\t:ARG1 (l/less)\n",
      "\t:ARG2 (t/than)\n",
      "\t:ARG4 (t2/that))\n",
      "\n",
      "[{\"sentence\": \"Point to the block that is less than that.\", \"explanation\": \"The gesture AMR indicates a deixis-GA (deictic gesture) pointing to a block, and an icon-GA (iconic gesture) representing movement. The speech AMR suggests a comparison between two quantities, with 'less' being one of the arguments. Combining these elements, we get a sentence that points to a block while indicating it is less than something else.\"}]\n",
      "what one less than\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yep\n",
      "Speech AMR:\n",
      " (y/yep)\n",
      "\n",
      "Example 2:\n",
      "Sentence: looks like like a like jenga\n",
      "Speech AMR:\n",
      " (l/look-02\n",
      "\t:ARG1 (j/jenga))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (s/same-01\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:direction (o/other))\n",
      "\t:concession (i2/include\n",
      "\t\t:ARG1 (i3/implicit-role\n",
      "\t\t\t:quant 5)))\n",
      "\n",
      "[{\"sentence\": \"It's the same, but it includes five others.\", \"explanation\": \"The speech AMR indicates that 'same' is being used to compare two things. The concession relation suggests a contrast or exception, which is resolved by including five other entities in the scope of comparison.\"}]\n",
      "the other direction it's the same except for there are five\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: maybe just pushed like slightly in the same\n",
      "Speech AMR:\n",
      " (p/push-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG2 (s/same)\n",
      "\t:degree (s2/slight\n",
      "\t\t:mod (j/just))\n",
      "\t:ARG1-of (p2/possible-01))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, up; RA: move, up left; RH: into open, left;\n",
      "RA: move, down; RH: into open, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/push-01\n",
      "\t\t:direction (l/left))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: the third block is it's on top of that block but it's pushed just slightly to the a off of it\n",
      "Speech AMR:\n",
      " (b/be-located-at-91\n",
      "\t:ARG1 (b2/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value 3))\n",
      "\t:ARG2 (o2/on\n",
      "\t\t:op1 (t/top\n",
      "\t\t\t:op1 (b3/block\n",
      "\t\t\t\t:mod (t2/that))))\n",
      "\t:concession (p/push-01\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:ARG2 (r/right\n",
      "\t\t\t:degree (s/slight\n",
      "\t\t\t\t:mod (j/just))\n",
      "\t\t\t:direction (o3/off\n",
      "\t\t\t\t:op1 (i2/it)))\n",
      "\t\t:time (t3/then)))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "RA: move, up, shake, down; RH: into claw, left;\n",
      "Unknown\n",
      "RA: move, right;\n",
      "arms: move, down; hands: into open, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a)\n",
      "\t:op3 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, up, into gap, left; hands: into facing, left, into open, left;\n",
      "arms: move, front left; hands: into facing, front, into open, front;\n",
      "Unknown\n",
      "head: rotate; arms: shake, front left;\n",
      "arms: move, down; hands: into open, down;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/diagonal)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"You're moving your arms diagonally.\", \"speech AMR\": \"(d/diagonal :mode expressive :ARG0 (y/you) :ARG1 (s/signaler) :ARG2 (a/actor))\", \"explanation\": \"The gesture label indicates that the speaker is moving their arms in a diagonal direction, which corresponds to the ARG1 'diagonal' in the gesture AMR. The mode is expressive, indicating that the speaker is conveying information or emotion through their gesture.\"}]\n",
      "the other direction it's the same except for there are five\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: one on the your le- yeah that one your left side its gonna be just one on top\n",
      "Speech AMR:\n",
      " (b/be-01\n",
      "\t:ARG0 (o/one\n",
      "\t\t:mod (o2/on\n",
      "\t\t\t:direction (l/left\n",
      "\t\t\t\t:poss (y/your))))\n",
      "\t:ARG6 o\n",
      "\t:mod o2\n",
      "\t:location (t/top))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up;\n",
      "body: still;\n",
      "RA: move, right;\n",
      "Unknown\n",
      "RA: move, up;\n",
      "RA: move, down;\n",
      "Unknown\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/left)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: keep them like turn them hor- vertically\n",
      "Speech AMR:\n",
      " (t/turn-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t2/them)\n",
      "\t:direction (h/horizontal))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up front, into gap, left; hands: facing, into claw;\n",
      "hands: rotate, claw, down;\n",
      "hands: claw, down; LA: move, back; RA: move, front;\n",
      "hands: claw, down; LA: move, front; RA: move, back;\n",
      "hands: claw, down; LA: move, back; RA: move, front;\n",
      "hands: claw, down; LA: move, front; RA: move, back;\n",
      "hands: claw, down; LA: move, back; RA: move, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (r/rotate-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, up, into gap, left; hands: into facing, left, into open, left;\n",
      "arms: move, front left; hands: into facing, front, into open, front;\n",
      "Unknown\n",
      "head: rotate; arms: shake, front left;\n",
      "arms: move, down; hands: into open, down;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/diagonal)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (s/same-01\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:direction (o/other))\n",
      "\t:concession (i2/include\n",
      "\t\t:ARG1 (i3/implicit-role\n",
      "\t\t\t:quant 5)))\n",
      "\n",
      "[{\"sentence\": \"Move the object to the left and then turn it diagonally.\", \"explanation\": \"The gesture AMR indicates that the speaker is expressing a direction or movement, which corresponds to the speech AMR's ARG1 being 'i/implicit-role' with direction (o/other). The gesture labels show arms moving up into the gap on the left, indicating a diagonal movement. The speech AMR also includes a concession that there are five implicit roles involved in this action, but since we're focusing on the main action described by the gestures, we can ignore this detail.\"}]\n",
      "the other direction it's the same except for there are five\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: good\n",
      "Speech AMR:\n",
      " (g/good)\n",
      "\n",
      "Example 2:\n",
      "Sentence: two eyes first\n",
      "Speech AMR:\n",
      " (e/eye\n",
      "\t:quant 2\n",
      "\t:li 1)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:direction (d/down\n",
      "\t\t:degree 1)\n",
      "\t:time (t/then))\n",
      "\n",
      "[{\"sentence\": \"You go down then.\", \"explanation\": \"The speech AMR indicates an implicit predicate with a mode of imperative, meaning it's a command or instruction. The ARG0 is 'you', indicating the subject of the sentence. The direction is specified as 'down' with a degree of 1, implying movement in that direction. Finally, the time is specified as 'then', which can be interpreted as an adverbial phrase indicating when the action should take place.\"}]\n",
      "then down down one\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: um i think everything needs to be slightly closer together\n",
      "Speech AMR:\n",
      " (t/think-01\n",
      "\t:ARG0 (i/i)\n",
      "\t:ARG1 (h/have-degree-91\n",
      "\t\t:ARG1 (e/everything)\n",
      "\t\t:ARG2 (t2/together\n",
      "\t\t\t:mod (c/close-10))\n",
      "\t\t:ARG3 (m/more\n",
      "\t\t\t:mod (s/slightly))))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up; hands: into claw, down;\n",
      "arms: together, left, gap, left; hands: claw, down;\n",
      "body: still;\n",
      "arms: move, down; hands: into claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/close-06)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: stick them on the table in a line in front of you\n",
      "Speech AMR:\n",
      " (s/stick-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:ARG2 (t2/table)\n",
      "\t:manner (l/line\n",
      "\t\t:location (f/front\n",
      "\t\t\t:poss y)))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "head: move, down; arms: together, left; hands: into claw, down;\n",
      "arms: apart, left;\n",
      "head: move, up;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/line)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up, surround; RH: into point, down;\n",
      "RA: move, front; RH: into point, front;\n",
      "RA: move, down; RH: into open, down;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (m/move-01\n",
      "\t\t\t:direction (d1/down))\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "[{\"sentence\": \"Point to the block in front of you and then move it down.\", \"speech AMR\": \"(i/icon-GA :ARG0 s :ARG1 (p/point-01 :mode imperative) :ARG2 (b/block) :ARG3 (l/location)) (m/move-01 :direction (f/front)) (d/deixis-GA :ARG0 s :ARG1 (l/location) :ARG2 a) (i/icon-GA :ARG0 s :ARG1 (m/move-01 :direction (d1/down)))\", \"explanation\": \"The gesture AMR indicates that the speaker is pointing to a block and then moving it down. The speech AMR reflects this by including an icon for pointing, followed by icons for moving in front of you and then down.\"}]\n",
      "then down down one\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: get two blocks and put them on the\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (g/get-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 2))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:quant 2))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up; hands: into claw, down;\n",
      "Unknown\n",
      "arms: move, up; hands: into claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/put-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: no no\n",
      "Speech AMR:\n",
      " (n/no)\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (n/no)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up, surround; RH: into point, down;\n",
      "RA: move, front; RH: into point, front;\n",
      "RA: move, down; RH: into open, down;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (m/move-01\n",
      "\t\t\t:direction (d1/down))\n",
      "\t\t:ARG2 a))\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:direction (d/down\n",
      "\t\t:degree 1)\n",
      "\t:time (t/then))\n",
      "\n",
      "[{\"sentence\": \"Move down, then move the block down.\", \"explanation\": \"The gesture labels indicate a series of movements with the right arm and hand. The first movement is 'move up' with the right arm, but this is likely an error in labeling, as the subsequent movements are all downward. The second movement is 'into point', which suggests a pointing action, possibly indicating a location or object. The third movement is also 'into point', again suggesting a pointing action. The fourth and final movement is 'into open' with the right hand, but this is likely another error in labeling, as it doesn't fit with the downward theme of the other movements. The gesture AMR indicates that the speaker is signaling to an actor (likely the listener) about a location (l/location). The speech AMR suggests an imperative mode and direction down, which matches the downward movement theme of the gestures.\"}]\n",
      "then down down one\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: close a little bit more not\n",
      "Speech AMR:\n",
      " (c/close-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:degree (m/more\n",
      "\t\t:degree (b2/bit\n",
      "\t\t\t:mod (l/little))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: but bothe opposite way like\n",
      "Speech AMR:\n",
      " (c/contrast-01\n",
      "\t:ARG2 (i/implicit-predicate-00\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:direction (w/way\n",
      "\t\t\t:mod (o/opposite))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:manner (c/come-33\n",
      "\t\t:ARG2 (d/diagonal)))\n",
      "\n",
      "[{\"sentence\": \"Come and put them in a diagonal manner.\", \"explanation\": \"The speech AMR indicates an imperative mode, meaning the sentence is a command. The ARG0 is 'y/you', indicating the subject of the sentence is the person being addressed. The ARG1 is 't/them', indicating the object of the action is 'them'. The manner is specified as 'c/come-33' with an ARG2 of 'd/diagonal', which means the action should be done in a diagonal direction. Therefore, the generated sentence is a command to come and put something in a diagonal manner.\"}]\n",
      "put them coming diagonal\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yeah\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: now stick a block on the front one and the one to your left\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (s/stick-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1)\n",
      "\t\t:location (o/on\n",
      "\t\t\t:op1 (o2/one\n",
      "\t\t\t\t:mod (f/front)))\n",
      "\t\t:time (n/now))\n",
      "\t:op2 s\n",
      "\t\t:time n\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 (b2/block\n",
      "\t\t\t:quant 1)\n",
      "\t\t:location (o3/on\n",
      "\t\t\t:op1 (o4/one\n",
      "\t\t\t\t:ARG1-of (l/left-20\n",
      "\t\t\t\t\t:ARG2 y))))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, down; hands: into claw, down;\n",
      "RA: move, up; RH: into claw, down;\n",
      "RA: move, down left; RH: claw, down;\n",
      "RA: move, up right; RH: claw, down;\n",
      "LA: move, up right; LH: into closed, down; RA: move, up back; RH: claw, down;\n",
      "LA: move, down left; LH: into claw, down; RA: move, down front; RH: claw, down;\n",
      "RA: move, up right; RH: into closed, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01\n",
      "\t\t\t:ARG1 (b/block))\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(a/and\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/left-20\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:ARG2 a2))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (m/move-01\n",
      "\t\t\t:direction (f/front))\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "LH: into open, up;\n",
      "LA: move, down right;\n",
      "RA: move, up; hands: into contact, left;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/diagonal)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/touch-01)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Move your hand up and touch it to the right.\", \"speech AMR\": \"(i/icon-GA :op1 (m/move-01 :direction (u/up) :ARG0 (h/hand) :ARG2 (s/signaler)) :op2 (t/touch-01 :mode contact :location (r/right)))\", \"explanation\": \"The gesture labels indicate that the left hand is moving up and into an open position, then the right arm is moving down to the right. This suggests a diagonal movement with the hands in contact on the right side. The speech AMR reflects this by first describing the movement of the hand up, then the touch action on the right location.\"}]\n",
      "put them coming diagonal\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: every things on top of that\n",
      "Speech AMR:\n",
      " (b/be-01\n",
      "\t:ARG1 (e/everything)\n",
      "\t:location (t/top\n",
      "\t\t:ARG2 (t2/that)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: shake, left;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/base)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and then put the third one on the fourth one on top of these the middle one\n",
      "Speech AMR:\n",
      " (p/put\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: claw, down;\n",
      "RA: move, left; RH: into point, front;\n",
      "RA: move, right;\n",
      "RA: move, back;\n",
      "RA: move, front; RH: claw, down;\n",
      "RA: move, back; RH: into fist, back;\n",
      "RA: move, up; RH: into one, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "LH: into open, up;\n",
      "LA: move, down right;\n",
      "RA: move, up; hands: into contact, left;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/diagonal)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/touch-01)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:manner (c/come-33\n",
      "\t\t:ARG2 (d/diagonal)))\n",
      "\n",
      "[{\"sentence\": \"You put them on top of each other.\", \"explanation\": \"The gesture label LH: into open, up indicates a vertical movement, suggesting a stacking or placing action. The LA: move, down right and RA: move, up; hands: into contact, left gestures suggest a diagonal motion, which is confirmed by the speech AMR's manner (c/come-33 :ARG2 (d/diagonal)). The icon-GA in the gesture AMR indicates a direct action, which aligns with the imperative mode in the speech AMR. Therefore, the sentence generated is 'You put them on top of each other.'\"}]\n",
      "put them coming diagonal\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: we’ll have another block just falling down as if it just for fell down from heaven\n",
      "Speech AMR:\n",
      " (h/have-03\n",
      "\t:ARG0 (w/we)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (a/another)\n",
      "\t\t:ARG1-of (f/fall-01\n",
      "\t\t\t:direction (d/down)\n",
      "\t\t\t:mod (j/just)\n",
      "\t\t\t:conj-as-if f\n",
      "\t\t\t:ARG1 (i/it)\n",
      "\t\t\t:ARG3 (f2/from\n",
      "\t\t\t\t:op1 (h2/heaven)))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and then there's two blocks um a little bit like out and then down or up for you\n",
      "Speech AMR:\n",
      " (b/be-located-at-91\n",
      "\t:time (t/then)\n",
      "\t:ARG1 (b2/block\n",
      "\t\t:quant 2)\n",
      "\t:ARG2 (a/and\n",
      "\t\t:op1 (o/out\n",
      "\t\t\t:degree (b3/bit\n",
      "\t\t\t\t:mod (l/little)))\n",
      "\t\t:op2 (o2/or\n",
      "\t\t\t:time (t2/then)\n",
      "\t\t\t:op1 (d/down)\n",
      "\t\t\t:op2 (u/up\n",
      "\t\t\t\t:poss (y/you)))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (n/no)\n",
      "\n",
      "[{\"sentence\": \"No\", \"explanation\": \"The speech AMR indicates that the word 'no' is being used as a negation, likely in response to a question or statement. The absence of any additional arguments or modifiers suggests that it's a simple denial or rejection.\"}]\n",
      "no closest\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and they are just straight\n",
      "Speech AMR:\n",
      " (s/straight-04\n",
      "\t:ARG1 (t/they)\n",
      "\t:mod (j/just))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up, into gap, left;\n",
      "arms: shake, left; hands: closed, down;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/straight)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: the bottom layer starts with four blocks\n",
      "Speech AMR:\n",
      " (s/starts-01\n",
      "\t:ARG0 (l/layer\n",
      "\t\t:ARG0-of (b/bottom))\n",
      "\t:instrument (b2/blocks\n",
      "\t\t:quant 4))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, front; hands: into open, down;\n",
      "arms: apart, left;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/bottom)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 i\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/layer)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: together, left; hands: into contact, left, into closed, left;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/close-10)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"They are closing in on each other.\", \"speech AMR\": \"(s/close-10 :ARG1 (t/they) :mod (i/in))\", \"explanation\": \"The gesture label indicates that the arms are moving together to the left, forming a closed position. This suggests a sense of convergence or coming together. The body remaining still implies a lack of movement or change in the actor's position. In the speech AMR, 't/they' represents the subject, and 'i/in' is a modifier indicating that the action is directed towards each other.\"}]\n",
      "no closest\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: all right then stick\n",
      "Speech AMR:\n",
      " (s/stick-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:time (t/then)\n",
      "\t:mod (a/all-right))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up, gap, left; hands: claw, down;\n",
      "arms: move, down; hands: into claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (g/grab-01\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 2))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and do the exact same thing there\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (d/do-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (t/thing\n",
      "\t\t\t:mod (s/same\n",
      "\t\t\t\t:mod (e/exact)))\n",
      "\t\t:location (t2/there)))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: claw, down;\n",
      "RA: move, down; RH: claw, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: together, left; hands: into contact, left, into closed, left;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/close-10)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (n/no)\n",
      "\n",
      "[{\"sentence\": \"No\", \"explanation\": \"The gesture label indicates that the arms are together and hands are in a closed position, which suggests a negative response or refusal. The speech AMR confirms this interpretation with the 'no' token.\"}]\n",
      "no closest\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: behind the two one and\n",
      "Speech AMR:\n",
      " (b/behind\n",
      "\t:op1 (o/one\n",
      "\t\t:mod (t/two)))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and you can you can place them close to each other\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (p/possible-01\n",
      "\t\t:ARG1 (p2/place-01\n",
      "\t\t\t:ARG0 (y/you)\n",
      "\t\t\t:ARG1 (t/them)\n",
      "\t\t\t:purpose (c/close-10\n",
      "\t\t\t\t:ARG1 t\n",
      "\t\t\t\t:ARG2 (o/other\n",
      "\t\t\t\t\t:mod (e/each))))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (o/one\n",
      "\t\t:location (o2/on\n",
      "\t\t\t:op1 (e/end\n",
      "\t\t\t\t:degree (v/very)))))\n",
      "\n",
      "[{\"sentence\": \"And one is on the very end.\", \"explanation\": \"The speech AMR indicates that 'and' is a conjunction, and it has an operation of type 'o/one'. The location of this 'one' is specified as being 'on' something. Within the 'on' operation, there's another operation of type 'e/end', which is modified by 'v/very', indicating a degree or extent. Therefore, the sentence generated is 'And one is on the very end.'\"}]\n",
      "and the one on the very end\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: those too blocks right next each other\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2\n",
      "\t\t:mod (t/that)\n",
      "\t\t:location (n/next-to\n",
      "\t\t\t:mod (r/right)\n",
      "\t\t\t:op1 (o/other\n",
      "\t\t\t\t:mod (e/each)))))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, up; LH: into point, front;\n",
      "LA: move, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: okay and they’e just kind of jiggled around\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (j/jiggle-01\n",
      "\t\t:ARG1 (t/they)\n",
      "\t\t:degree (k/kind-of\n",
      "\t\t\t:mod (j2/just))\n",
      "\t\t:path (a1/around)))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: into open, down; LA: move, up;\n",
      "hands: shake;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (j/jiggle-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (k/know-01\n",
      "\t\t:polarity -)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: still;\n",
      "RH: into point, front;\n",
      "RH: rotate;\n",
      "arms: together, left; hands: into hold;\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 2\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"They are standing still, pointing forward and holding hands.\", \"speech AMR\": \"(e/emblem-GA :ARG0 (s/signaler) :ARG1 2 :ARG2 (a/actor)) (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\", \"explanation\": \"The gesture label indicates that the speaker is standing still, pointing forward with their right hand, and holding hands with someone. The first AMR represents an emblematic gesture indicating a quantity of two, which in this context means 'they' are standing together. The second AMR represents a deictic gesture pointing to a location, which in this context means the speaker is pointing forward.\"}]\n",
      "and the one on the very end\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and one block left of the first block first block and a bit in front of it\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (b/block\n",
      "\t\t:quant 1\n",
      "\t\t:ARG1-of (l/left-20\n",
      "\t\t\t:ARG2 (b2/block\n",
      "\t\t\t\t:ord (o/ordinal-entity\n",
      "\t\t\t\t\t:value 1)))\n",
      "\t\t:ARG1-of (f/front-01\n",
      "\t\t\t:ARG2 b2\n",
      "\t\t\t:degree (b3/bit))))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "arms: move, up; hands: facing, closed;\n",
      "Unknown\n",
      "body: still;\n",
      "Unknown\n",
      "hands: beckon;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (f/forward))\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (f/forward))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: the three blocks all touch and they’re straight\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (t/touch-01\n",
      "\t\t:ARG0 (b/block\n",
      "\t\t\t:quant 3))\n",
      "\t:op2 (s/straight-04\n",
      "\t\t:ARG1 (t2/they)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "hands: into claw, front;\n",
      "arms: move, back; hands: closed, back;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/together)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/straight)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: still;\n",
      "RH: into point, front;\n",
      "RH: rotate;\n",
      "arms: together, left; hands: into hold;\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 2\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (o/one\n",
      "\t\t:location (o2/on\n",
      "\t\t\t:op1 (e/end\n",
      "\t\t\t\t:degree (v/very)))))\n",
      "\n",
      "[{\"sentence\": \"Point to the very end on one.\", \"explanation\": \"The gesture AMR indicates that the speaker is pointing to a location, which is represented by the 'deixis-GA' icon. The speech AMR shows that the speaker is indicating a location on something called 'one', and this location is at the 'very end'. The gesture labels suggest that the speaker's right hand is being used for pointing, as indicated by the 'into point' label.\"}]\n",
      "and the one on the very end\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: between the block you just placed and the third block on that side it's touching those two corners\n",
      "Speech AMR:\n",
      " (t/touch-01\n",
      "\t:ARG0 (i/it)\n",
      "\t:ARG1 (c/corner\n",
      "\t\t:mod (t2/that)\n",
      "\t\t:quant 2\n",
      "\t\t:location (b/between\n",
      "\t\t\t:op1 (b2/block\n",
      "\t\t\t\t:ARG1-of (p/place-01\n",
      "\t\t\t\t\t:ARG0 (y/you)\n",
      "\t\t\t\t\t:mod (j/just)))\n",
      "\t\t\t:op2 (b3/block\n",
      "\t\t\t\t:ord (o/ordinal-entity\n",
      "\t\t\t\t\t:value 3)\n",
      "\t\t\t\t:location (o2/on\n",
      "\t\t\t\t\t:op1 (s/side\n",
      "\t\t\t\t\t\t:mod (t3/that)))))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: close even more close but not touching yeah\n",
      "Speech AMR:\n",
      " (h/have-degree-91\n",
      "\t:ARG2 (c/close)\n",
      "\t:ARG3 (e/even\n",
      "\t\t:mod (m/more))\n",
      "\t:ARG1-of (c2/contrast-01\n",
      "\t\t:ARG2 (t/touch-01\n",
      "\t\t\t:polarity -)))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (g/get-04\n",
      "\t\t:ARG1 (s/stack-01\n",
      "\t\t\t:ARG2 (t/two\n",
      "\t\t\t\t:ARG1-of (h/have-degree-91\n",
      "\t\t\t\t\t:ARG2 (c/close-10\n",
      "\t\t\t\t\t\t:ARG2 (m/middle))\n",
      "\t\t\t\t\t:ARG3 (m2/most)))\n",
      "\t\t\t:location (o/on\n",
      "\t\t\t\t:op1 (s2/side\n",
      "\t\t\t\t\t:mod (o2/other))))\n",
      "\t\t:time (t2/then)))\n",
      "\n",
      "[{\"sentence\": \"You get two stacks, one on each side, and they're most close to the middle.\", \"explanation\": \"The speech AMR represents a sentence with multiple clauses. The main verb is 'get', which has an object 'stack-01' that contains another clause describing its location and properties. The stack is located on both sides, and it's described as being 'most close' to the middle. This structure is reflected in the generated sentence.\"}]\n",
      "and then on the other side the two closest to the middle get stacked\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: i want you take one block\n",
      "Speech AMR:\n",
      " (w/want-01\n",
      "\t:ARG0 (i/I)\n",
      "\t:ARG1 (t/take-01\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, up; LH: into point, front;\n",
      "LA: move, down; LH: into claw, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: yeah and\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "arms: apart, left; hands: facing, closed;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (m/move-01\n",
      "\t\t:ARG2 (n/near-02))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, right; RH: into closed, front;\n",
      "body: still;\n",
      "RH: into two, front;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/side)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 2\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"I want you to take two blocks.\", \"speech AMR\": \"(w/want-01 :ARG0 (i/I) :ARG1 (t/take-01 :ARG0 (y/you) :ARG1 (b/block :quant 2)))\", \"explanation\": \"The gesture labels indicate a sequence of actions: the right arm moves to the front and closes, then opens to two fingers. This corresponds to wanting someone to take two blocks.\"}]\n",
      "and then on the other side the two closest to the middle get stacked\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: get two more blocks\n",
      "Speech AMR:\n",
      " (g/get-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2\n",
      "\t\t:mod (m/more)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, up front; LH: into point, front;\n",
      "LA: move, down back; LH: into claw, back;\n",
      "Unknown\n",
      "arms: move, up front, into gap, left; hands: facing, into claw;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: one right next to it touching\n",
      "Speech AMR:\n",
      " (n/next\n",
      "\t:ARG0 (o/one)\n",
      "\t:ARG1 (i/it)\n",
      "\t:mod (r/right)\n",
      "\t:mod (t/touching))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, left;\n",
      "body: still;\n",
      "RA: move, down right; RH: into closed, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 i\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (n/next)\n",
      "\t\t:ARG2 a)\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, right; RH: into closed, front;\n",
      "body: still;\n",
      "RH: into two, front;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/side)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 2\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (g/get-04\n",
      "\t\t:ARG1 (s/stack-01\n",
      "\t\t\t:ARG2 (t/two\n",
      "\t\t\t\t:ARG1-of (h/have-degree-91\n",
      "\t\t\t\t\t:ARG2 (c/close-10\n",
      "\t\t\t\t\t\t:ARG2 (m/middle))\n",
      "\t\t\t\t\t:ARG3 (m2/most)))\n",
      "\t\t\t:location (o/on\n",
      "\t\t\t\t:op1 (s2/side\n",
      "\t\t\t\t\t:mod (o2/other))))\n",
      "\t\t:time (t2/then)))\n",
      "\n",
      "[{\"sentence\": \"get two on the other side, close most\", \"explanation\": \"The gesture AMR indicates that the signaler is performing an icon and an emblem gesture. The icon gesture represents a side or direction, which is then modified by the emblem gesture to indicate the quantity of 2. In the speech AMR, we see that the get action has two arguments: the stack (which is on the other side) and the quantity of 2. This matches with the gesture AMR's indication of getting two items from a location on the other side.\"}]\n",
      "and then on the other side the two closest to the middle get stacked\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: get two blocks\n",
      "Speech AMR:\n",
      " (g/get-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 2))\n",
      "\n",
      "Example 2:\n",
      "Sentence: the blocks are turned like half way on top of each block yeah\n",
      "Speech AMR:\n",
      " (t/turn-01\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (h/halfway)\n",
      "\t:location (o/on\n",
      "\t\t:op1 (t2/top\n",
      "\t\t\t:mod b\n",
      "\t\t\t:quant (e/each))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (i/implicit-role\n",
      "\t\t:quant 2\n",
      "\t\t:location (i2/in-front-of\n",
      "\t\t\t:op1 (y/you)))\n",
      "\t:op2 (i3/implicit-role\n",
      "\t\t:quant 2\n",
      "\t\t:location (a2/at\n",
      "\t\t\t:op1 (b/back))))\n",
      "\n",
      "[{\"sentence\": \"You are in front of you and at the back.\", \"explanation\": \"The speech AMR represents a sentence with two implicit roles, each with a quantity of 2. The first role is located 'in-front-of' the speaker ('you'), and the second role is located 'at' the back. This implies that the speaker is in front of themselves and at the same time, also at the back.\"}]\n",
      "two in front of you and two at the back\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and a little near you\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (n/near-02\n",
      "\t\t:ARG2 (y/you)\n",
      "\t\t:mod (l/little)))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: into claw, front;\n",
      "arms: move, back;\n",
      "hands: into claw, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (b2/block)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (g2/gesture-unit\n",
      "\t\t:op1 (i/icon-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (b/block)\n",
      "\t\t\t:ARG2 (a/actor))\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b2/block)\n",
      "\t\t\t:ARG2 a))\n",
      "\t:op2 (i3/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/pull-01\n",
      "\t\t\t:direction (b3/back))\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: center them on top of where the three blocks meet on it either side\n",
      "Speech AMR:\n",
      " (c/center-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:location (t2/top\n",
      "\t\t:poss (l/location\n",
      "\t\t\t:location-of (m/meet-03\n",
      "\t\t\t\t:ARG0 (b/block\n",
      "\t\t\t\t\t:quant 3)\n",
      "\t\t\t\t:location (s/side\n",
      "\t\t\t\t\t:mod (e/either))))))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up; hands: into claw, down;\n",
      "arms: move, front, into gap, left; hands: into point, front;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, front; RH: into open, up;\n",
      "arms: move, back, into contact, left; hands: into closed, back;\n",
      "body: still;\n",
      "head: rotate;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (f/front)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/back)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Look at the front of it.\", \"speech AMR\": \"(l/look-01 :op1 (i/icon-GA :ARG0 (s/signaler) :ARG1 (f/front) :ARG2 (a/actor)))\", \"explanation\": \"The gesture labels indicate that the speaker is moving their arms forward and then backward, which suggests looking at something. The RH is moving into an open position, up, which further supports this interpretation. The speech AMR represents this action as 'look' with the direction specified as 'front'.\"}]\n",
      "two in front of you and two at the back\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: they're more laid out in a flower pattern\n",
      "Speech AMR:\n",
      " (l/lay-out-01\n",
      "\t:ARG0 (t/they)\n",
      "\t:mod (m/more)\n",
      "\t:mod (p/pattern\n",
      "\t\t:mod (f/flower)))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: into contact, left; hands: into closed;\n",
      "arms: apart, left; hands: claw, down;\n",
      "arms: into contact, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (p/pattern\n",
      "\t\t:mod (f/flower))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: scoot the five over\n",
      "Speech AMR:\n",
      " (s/scoot-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:quant 5)\n",
      "\t:ARG2 (o/over))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, front; RH: closed, front;\n",
      "RA: move, left; RH: closed, left;\n",
      "LA: move, up; LH: closed, right;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (l/left))\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (f/flush)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, front; RH: into open, up;\n",
      "arms: move, back, into contact, left; hands: into closed, back;\n",
      "body: still;\n",
      "head: rotate;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (f/front)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/back)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (i/implicit-role\n",
      "\t\t:quant 2\n",
      "\t\t:location (i2/in-front-of\n",
      "\t\t\t:op1 (y/you)))\n",
      "\t:op2 (i3/implicit-role\n",
      "\t\t:quant 2\n",
      "\t\t:location (a2/at\n",
      "\t\t\t:op1 (b/back))))\n",
      "\n",
      "[{\"sentence\": \"You're facing the front and at the back.\", \"explanation\": \"The gesture labels indicate that the arms are moving forward, then backward into contact with the left hand closed. The head is rotating, but the body remains still. This suggests a description of spatial locations or directions. The speech AMR indicates two implicit roles, one in front of 'you' and another at 'back', which supports the interpretation of facing the front and being at the back.\"}]\n",
      "two in front of you and two at the back\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and don't rotate don't don't rotate yeah\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (r/rotate-01\n",
      "\t\t:polarity -\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)))\n",
      "\n",
      "Example 2:\n",
      "Sentence: the first block is like is like like the first tower yeah\n",
      "Speech AMR:\n",
      " (s/similar-01\n",
      "\t:ARG0 (b/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value 1))\n",
      "\t:ARG1 (t/tower\n",
      "\t\t:ord (o2/ordinal-entity\n",
      "\t\t\t:value 1)))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (o/okay)\n",
      "\n",
      "Here is the output:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"sentence\": \"Okay\",\n",
      "    \"explanation\": \"The speech AMR indicates that the word 'okay' is being spoken, so a simple sentence with this word as its subject and predicate is generated.\"\n",
      "  }\n",
      "]\n",
      "okay\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: put a block on like like on the crack of those two blocks\n",
      "Speech AMR:\n",
      " (p/put\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block)\n",
      "\t:location (c/crack\n",
      "\t\t:poss b\n",
      "\t\t:quant 2\n",
      "\t\t:mod (t/that)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, left;\n",
      "LA: move, down; LH: into open, right;\n",
      "LA: move, back;\n",
      "body: still;\n",
      "body: move, right; RA: move, up; RH: to face;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (c/crack)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: grab one more block place\n",
      "Speech AMR:\n",
      " (g/grab-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 1\n",
      "\t\t:mod (m/more)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "body: still;\n",
      "RA: move, up; RH: into inch, front;\n",
      "RH: rotate, into point, down left;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: shake, left; hands: into claw, down;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/row)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Stop the row.\", \"speech AMR\": \"(s/stoppable-action :mode imperative :ARG0 (y/you) :ARG1 (r/row))\", \"explanation\": \"The gesture label 'arms: shake, left' suggests a warning or stopping action. The gesture AMR indicates that the signaler is referring to a row, which implies a need to stop or halt it.\"}]\n",
      "okay\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: that looks good\n",
      "Speech AMR:\n",
      " (l/look-02\n",
      "\t:ARG0 (t/that)\n",
      "\t:ARG1 (g/good))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, up; hands: into thumbs, up;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: stick it on the other side divot\n",
      "Speech AMR:\n",
      " (s/stick-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:ARG2 (d/divot\n",
      "\t\t:poss (s2/side\n",
      "\t\t\t:mod (o/other))))\n",
      "\n",
      "Gesture label(s): \n",
      "head: nod; hands: shake, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: shake, left; hands: into claw, down;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/row)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (o/okay)\n",
      "\n",
      "[{\"sentence\": \"That's okay.\", \"explanation\": \"The gesture labels indicate a neutral or accepting attitude, with the arms shaking left and hands forming a claw shape. The body remains still, suggesting a calm demeanor. In the Gesture AMR, 'icon-GA' indicates an icon or symbol being used to convey meaning, which is likely related to agreement or acceptance. The Speech AMR '(o/okay)' directly supports this interpretation, as it is a common expression of agreement or confirmation.\"}]\n",
      "okay\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: yes\n",
      "Speech AMR:\n",
      " (y/yes)\n",
      "\n",
      "Example 2:\n",
      "Sentence: now do it on the other side\n",
      "Speech AMR:\n",
      " (d/do-02\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it)\n",
      "\t:location (o/on\n",
      "\t\t:op1 (s/side\n",
      "\t\t\t:mod (o2/other))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (t/think-01\n",
      "\t:ARG0 (i/i)\n",
      "\t:ARG1 (p/possible-01\n",
      "\t\t:ARG1 (t2/touch-01)\n",
      "\t\t:polarity -))\n",
      "\n",
      "[{\"sentence\": \"I think it is possible to touch.\", \"explanation\": \"The speech AMR indicates that the subject of the sentence is 'i' (I), and the verb is 'think'. The object of the verb is 'p/possible-01', which represents a possibility. Within this possibility, there is an action 't2/touch-01', indicating that touching is what makes it possible. The polarity '-' indicates negation, so the overall meaning is that I think it is not possible to touch.\"}]\n",
      "i don’t think can be touching\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: touching corners touching corners\n",
      "Speech AMR:\n",
      " (t/touch-01\n",
      "\t:ARG0 (c/corner)\n",
      "\t:ARG1 (c2/corner))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; hands: into contact, left;\n",
      "body: still;\n",
      "head: nod;\n",
      "body: still;\n",
      "head: nod;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/touch-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: yeah\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "head: nod;\n",
      "RA: move, up; RH: to face;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: move, up; arms; move, up; hands: into closed, up;\n",
      "head: shake; arms: move, up, into contact, left; hands: into hold;\n",
      "body: move, down; head: rotate;\n",
      "head: rotate; hands: into claw, down;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 2\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (o/on-top-of)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "[{\"sentence\": \"I'm holding you on top of me.\", \"speech AMR\": \"(h/hold-01 :ARG0 (s/signaler) :ARG1 (a/actor) :ARG2 (o/on-top-of))\", \"explanation\": \"The gesture label indicates that the speaker is moving their body up, arms and hands are also moving up and into closed position. The head is shaking and then arms move up to hold something. This suggests a physical interaction between the speaker and another entity (a/actor). The speech AMR reflects this by indicating a holding action with the speaker as the agent and the actor as the patient, with the on-top-of relation.\"}]\n",
      "i don’t think can be touching\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: one block on top of the both\n",
      "Speech AMR:\n",
      " (b/be-located-at-91\n",
      "\t:ARG1 (b2/block\n",
      "\t\t:quant 1)\n",
      "\t:ARG2 (o/on-top-of\n",
      "\t\t:op1 (t/they\n",
      "\t\t\t:mod (b3/both))))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, up; hands: into point, front;\n",
      "LA: move, back; LH: to hip; RA: move, front; RH: into claw, down;\n",
      "RA: move, back; RH: into closed, back;\n",
      "body: still;\n",
      "arms: move, up; hands: into open, front;\n",
      "head: rotate; arms; move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/done)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: just like you’re building a tower\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG1 (b/build-01\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (t/tower))\n",
      "\t:mod (j/just))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: move, up;\n",
      "arms: move, down;\n",
      "body: move, down;\n",
      "Unknown\n",
      "arms: move, up, into contact, left; hands: into claw, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/tower)\n",
      "\t:ARG2 (a/actor))\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/put-01)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g2/gesture-unit\n",
      "\t\t:op1 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l2/location)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p2/put-01)\n",
      "\t\t\t:ARG2 a2)))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: move, up; arms; move, up; hands: into closed, up;\n",
      "head: shake; arms: move, up, into contact, left; hands: into hold;\n",
      "body: move, down; head: rotate;\n",
      "head: rotate; hands: into claw, down;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 2\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (o/on-top-of)\n",
      "\t\t:ARG2 a))\n",
      "Speech AMR:\n",
      " (t/think-01\n",
      "\t:ARG0 (i/i)\n",
      "\t:ARG1 (p/possible-01\n",
      "\t\t:ARG1 (t2/touch-01)\n",
      "\t\t:polarity -))\n",
      "\n",
      "[{\"sentence\": \"I think it's possible to put two on top of the one.\", \"explanation\": \"The gesture AMR indicates that the speaker is signaling a gesture unit with an icon representing 'two' and another icon representing 'on top of', which suggests putting two objects on top of one. The speech AMR shows that the speaker is thinking about the possibility of touching something, but the polarity is negative, indicating that it's not certain or possible. However, considering the context from the gesture labels, it seems more likely that the speaker is suggesting a scenario where two objects are placed on top of one.\"}]\n",
      "i don’t think can be touching\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: we’re building up a even column i guess so\n",
      "Speech AMR:\n",
      " (b/build-up-05\n",
      "\t:ARG0 (w/we)\n",
      "\t:ARG1 (c/column\n",
      "\t\t:mod (e/even))\n",
      "\t:ARG1-of (g/guess\n",
      "\t\t:ARG0 (i/i)))\n",
      "\n",
      "Example 2:\n",
      "Sentence: i'm not sure yeah\n",
      "Speech AMR:\n",
      " (s/sure-02\n",
      "\t:ARG0 (i/i)\n",
      "\t:polarity -)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 3\n",
      "\t:purpose (b2/bottom\n",
      "\t\t:poss (s/smile)))\n",
      "\n",
      "[{\n",
      "  \"sentence\": \"You have three blocks for the bottom of your smile.\",\n",
      "  \"explanation\": \n",
      "    The speech AMR represents a sentence with the following components:\n",
      "    - :quant 3 indicates that there are three blocks.\n",
      "    - :purpose (b2/bottom) indicates that these blocks are for the bottom of something. In this case, it's likely referring to a smile, as indicated by :poss (s/smile).\n",
      "    Therefore, the generated sentence is \"You have three blocks for the bottom of your smile.\"\n",
      "there is three blocks for the bottom of the smile\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay this one's somewhat similar to the last one except it's a four four layers\n",
      "Speech AMR:\n",
      " (s/similar-01\n",
      "\t:ARG0 (o/one\n",
      "\t\t:mod (t/this))\n",
      "\t:ARG1 o\n",
      "\t:mod (l/last)\n",
      "\t:ARG2 (l2/layers\n",
      "\t\t:quant 4))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, down; hands: into fist, back;\n",
      "body: move, down;\n",
      "    body: still;\n",
      "LA: move, up; LH: into open, down; RH: into open, up;\n",
      "LA: move, up;\n",
      "LA: move, down; hands: into fist, down;\n",
      "arms: move, front; hands: into open, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/layers)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: don’t do that exactly\n",
      "Speech AMR:\n",
      " (d/do-01\n",
      "\t:mode imperative\n",
      "\t:polarity -\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/that))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, back;\n",
      "arms: move, down; hands: shake, into point, front;\n",
      "arms: move, up; hands: into claw, up;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (e/emblem-GA\n",
      "\t\t:mode expressive\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (n/no)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:mode expressive\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, back; hands: facing, into point;\n",
      "arms: shake, left;\n",
      "hands: into claw, down;\n",
      "arms: move, down;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/row)\n",
      "\t:ARG2 (a/actor))\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p2/put-01)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "[{\"sentence\": \"Put the row in and put it down.\", \"speech AMR\": \"(p/put-01 :ARG0 (a2/actor) :ARG1 (r/row) :ARG2 (i/in-01 :ARG0 (s/signaler))) (p2/put-01 :mode imperative :ARG0 s :ARG1 r :ARG2 a2)\", \"explanation\": \"The gesture AMR indicates that the speaker is expressing an idea using two icon-GA units. The first unit represents putting something in, and the second unit represents putting it down. The arms moving back and hands facing into point suggest the action of placing or inserting something. The shaking of the left arm may indicate a change or addition to the previous action. The hands changing to a claw shape and then moving down suggests the action of putting something down.\"}]\n",
      "there is three blocks for the bottom of the smile\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and um the middle tower\n",
      "Speech AMR:\n",
      " (t/tower)\n",
      ":mod m/middle))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "arms: together, left, gap, left;\n",
      "body: move, down; head: rotate;\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/put-01\n",
      "\t\t\t\t:quant 3)\n",
      "\t\t\t:ARG2 a2)))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/tower)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: count in with your left hand count to block three and four\n",
      "Speech AMR:\n",
      " (c/count-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:instrument (h/hand\n",
      "\t\t:part-of y\n",
      "\t\t:mod (l/left))\n",
      "\t:destination (b/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value (a/and\n",
      "\t\t\t\t:op1 3\n",
      "\t\t\t\t:op2 4))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (c/count-01\n",
      "\t\t\t:ARG2 (a/actor))\n",
      "\t\t:op2 (d/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b/block)\n",
      "\t\t\t:ARG2 a)))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/left)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, back; hands: facing, into point;\n",
      "arms: shake, left;\n",
      "hands: into claw, down;\n",
      "arms: move, down;\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/row)\n",
      "\t:ARG2 (a/actor))\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p2/put-01)\n",
      "\t\t:ARG2 a2))\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 3\n",
      "\t:purpose (b2/bottom\n",
      "\t\t:poss (s/smile)))\n",
      "\n",
      "[{\"sentence\": \"And you put three blocks at the bottom of your smile.\", \"explanation\": \"The gesture labels indicate a series of movements and actions, including moving arms back, shaking left arm, hands into claw position, and then moving down. The Gesture AMR shows an expressive mode with a row as the icon, indicating a sequence or collection of objects. The speech AMR indicates a block (b/block) with a quantity of 3 and a purpose to place at the bottom (b2/bottom) of something possessed by the speaker (s/smile). Combining these elements, the sentence can be generated as 'And you put three blocks at the bottom of your smile.'\"}]\n",
      "there is three blocks for the bottom of the smile\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and one block pick up one block and it is in front of the block you just put it and rotate it forty five degrees\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (p/pick-up-04\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1))\n",
      "\t:op3 (f/front-02\n",
      "\t\t:ARG1 b\n",
      "\t\t:ARG2 (b2/block\n",
      "\t\t\t:ARG1-of (p2/put-01\n",
      "\t\t\t\t:ARG0 y\n",
      "\t\t\t\t:time (j/just))))\n",
      "\t:op4 (r/rotate-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:extent (a2/angle-quantity\n",
      "\t\t\t:quant 45\n",
      "\t\t\t:unit (d/degree))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: so then your next one is going to be up one and it's going to be shifted over half a block to\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (b/be-01\n",
      "\t\t:ARG0 (o/one\n",
      "\t\t\t:mod (n/next))\n",
      "\t\t:location (u/up\n",
      "\t\t\t:mod o))\n",
      "\t:op2 (s/shift-01\n",
      "\t\t:mod (b2/block\n",
      "\t\t\t:quant (h/half))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 2\n",
      "\t:purpose (e/eye))\n",
      "\n",
      "Here is the generated sentence and its explanation:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"sentence\": \"The block is for your eye.\",\n",
      "  \"explanation\": \n",
      "    The speech AMR indicates that there are two blocks (quant 2) with a purpose of being for an eye. This suggests that the speaker is referring to something related to vision or sight, such as glasses or goggles.\n",
      "}\n",
      "```\n",
      "there is two blocks for the eyes\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: good enough good enough\n",
      "Speech AMR:\n",
      " (e/enough-01\n",
      "\t:ARG2 (g/good))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: enough;\n",
      "hands: shake, closed;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (e2/enough)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: towards to me at the top layer block\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i2/implicit-role)\n",
      "\t:direction (t/toward\n",
      "\t\t:op1 (m/me))\n",
      "\t:destination (a/at\n",
      "\t\t:op1 (t2/top-layer)\n",
      "\t\t:op2 (b/block)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, down; RA: move, up; RH: into claw, up;\n",
      "body: move, front; RA: move, down;\n",
      "RA: move, front;\n",
      "RA: move, down;\n",
      "Unknown\n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (m/move-01\n",
      "\t\t:ARG2 (c/close-10))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: into gap, left; hands: into claw, down;\n",
      "arms: move, down;\n",
      "Unknown\n",
      "arms: move, back; hands: facing, into point;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p2/put-01)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "[{\"sentence\": \"Put it in the gap on the left.\", \"speech AMR\": \"(e/envelope-01 :mode imperative :ARG0 (y/you) :ARG1 (i2/implicit-role) :direction (l/left) :destination (a/at :op1 (g/gap)))\", \"explanation\": \"The gesture labels indicate that the arms move into a gap on the left and then move back, with the hands facing into a point. This suggests an action of putting something in a location. The speech AMR reflects this by using the verb 'put' and specifying the direction and destination.\"}]\n",
      "there is two blocks for the eyes\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: it stacks like straight up\n",
      "Speech AMR:\n",
      " (s/stack_up-03\n",
      "\t:mod (s2/straight))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, down; head: rotate;\n",
      "body: move, up; arms: move, up;\n",
      "arms: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/tower)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: just four\n",
      "Speech AMR:\n",
      " (i/implicit-role\n",
      "\t:quant 4\n",
      "\t:mod (j/just))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into four, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 4\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: into gap, left; hands: into claw, down;\n",
      "arms: move, down;\n",
      "Unknown\n",
      "arms: move, back; hands: facing, into point;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p2/put-01)\n",
      "\t\t:ARG2 a2))\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 2\n",
      "\t:purpose (e/eye))\n",
      "\n",
      "[{\"sentence\": \"They put the claw into the gap, and then they point with their hands.\", \"explanation\": \"The gesture labels indicate that the arms move into a gap on the left side, and the hands move down into a claw shape. Then, the arms move down, but this is likely an error in the labeling as it doesn't contribute to the meaning of the sentence. The next action is for the arms to move back and the hands to face towards a point. This suggests that after putting something into the gap, they are now pointing with their hands. The speech AMR supports this interpretation by indicating two blocks (actions) with the purpose of eye contact or pointing.\"}]\n",
      "there is two blocks for the eyes\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay\n",
      "Speech AMR:\n",
      " (o/okay-04)\n",
      "\n",
      "Example 2:\n",
      "Sentence: space two out a little less than a block length\n",
      "Speech AMR:\n",
      " (s/space-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/implicit-role\n",
      "\t\t:quant 2)\n",
      "\t:ARG2 (q/distance-quantity\n",
      "\t\t:unit (b/block)\n",
      "\t\t:ARG1-of (h/have-quant-91\n",
      "\t\t\t:ARG2 1\n",
      "\t\t\t:ARG3 (l/less\n",
      "\t\t\t\t:mod (l2/little)))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (h/have-purpose-91\n",
      "\t:time (t/then)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 3)\n",
      "\t:ARG2 (m/make-01\n",
      "\t\t:ARG1 (s/smile\n",
      "\t\t\t:location (o/off\n",
      "\t\t\t\t:op1 (b2/block\n",
      "\t\t\t\t\t:quant 2\n",
      "\t\t\t\t\t:mod (w/wide\n",
      "\t\t\t\t\t\t:degree (m2/more)))))))\n",
      "\n",
      "[{\"sentence\": \"Then I have the purpose to make a smile off of block 3, which is wider than block 2.\", \"explanation\": \"The speech AMR represents a sentence in the imperative mode, where 'I' is the implicit subject. The main action is 'make', and its object is 'smile'. The location of this action is specified as 'off' of a certain block, which is described as having a quantity of 2 and being wider than another block with a quantity of 1. This structure is then embedded within the larger sentence 'Then I have the purpose to ...', indicating that the main action is part of a plan or intention.\"}]\n",
      "and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: four blocks in the front okay\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 4\n",
      "\t:location (i/in\n",
      "\t\t:op1 (f/front)))\n",
      "\n",
      "Gesture label(s): \n",
      "arms: shake, left; hands: into claw, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (r/row)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: it cannot fall down from the ground right\n",
      "Speech AMR:\n",
      " (p/possible-01\n",
      "\t:polarity -\n",
      "\t:ARG1 (f/fall-01\n",
      "\t\t:ARG1 (i/it)\n",
      "\t\t:ARG3 (g/ground))\n",
      "\t:ARG1-of (r/request-confirmation-91))\n",
      "\n",
      "Gesture label(s): \n",
      "head: shake; hands: rotate, open, up;\n",
      "Unknown\n",
      "LA: move, down; LH: into point, front;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up; RH: into point, down;\n",
      "RA: move, down;\n",
      "arms: into gap, left; hands: into point, down;\n",
      "arms: shake, left;\n",
      "Unknown\n",
      "arms: move, up; hands: into claw, down;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (r/row)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Look at the row below.\", \"speech AMR\": \"(i/icon-GA :ARG0 s :ARG1 r :ARG2 a) (d/deixis-GA :ARG0 s :ARG1 l :ARG2 a)\", \"explanation\": \"The gesture label(s) indicate that the speaker is pointing to something, and the gesture AMR shows that the speaker is referring to a row or location. The sentence generated is a natural way to express this action.\"}]\n",
      "and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: five blocks to start\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quant 5\n",
      "\t:ARG1-of (s/start-01))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, left;\n",
      "body: still;\n",
      "LH: into open, up;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: now these are a little jiggled\n",
      "Speech AMR:\n",
      " (j/jiggle-01\n",
      "\t:ARG1 (t/these)\n",
      "\t:mod (l/little))\n",
      "\n",
      "Gesture label(s): \n",
      "head: nod; LA: move, back;\n",
      "RA: move, up; RH: shake, down, open;\n",
      "RA: move, front; RH: into point, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (j/jiggle-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:mode expressive\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (j/jiggle-01)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (a1/and\n",
      "\t\t:op1 (d1/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b1/block)\n",
      "\t\t\t:ARG2 a)\n",
      "\t\t:op2 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (b2/block)\n",
      "\t\t\t:ARG2 a)))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RA: move, up; RH: into point, down;\n",
      "RA: move, down;\n",
      "arms: into gap, left; hands: into point, down;\n",
      "arms: shake, left;\n",
      "Unknown\n",
      "arms: move, up; hands: into claw, down;\n",
      "Unknown\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (r/row)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (h/have-purpose-91\n",
      "\t:time (t/then)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 3)\n",
      "\t:ARG2 (m/make-01\n",
      "\t\t:ARG1 (s/smile\n",
      "\t\t\t:location (o/off\n",
      "\t\t\t\t:op1 (b2/block\n",
      "\t\t\t\t\t:quant 2\n",
      "\t\t\t\t\t:mod (w/wide\n",
      "\t\t\t\t\t\t:degree (m2/more)))))))\n",
      "\n",
      "[{\"sentence\": \"Then we have three blocks to make a smile with two wide blocks more off.\", \"explanation\": \"The gesture AMR indicates that the speaker is pointing to a location (l/location) and then to a block (b/block). The speech AMR shows that the purpose of this action is to have three blocks (ARG1) to make a smile (m/make-01), which involves two wide blocks more off (s/smile:location (o/off)). The gesture labels suggest that the speaker is moving their arms up and down, pointing with their hands, and shaking their arms, which corresponds to the expressive mode of the gesture AMR. The unknown labels are ignored in this interpretation.\"}]\n",
      "and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: you're done\n",
      "Speech AMR:\n",
      " (d/done-08\n",
      "\t:ARG0 (y/you))\n",
      "\n",
      "Example 2:\n",
      "Sentence: put a bit a bit right uh\n",
      "Speech AMR:\n",
      " (p/put-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG2 (r/right-04\n",
      "\t\t:degree (b/bit)))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (p/push-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:ARG2 (u/up\n",
      "\t\t:degree (b/bit\n",
      "\t\t\t:mod (l/little))))\n",
      "\n",
      "[{\"sentence\": \"Push them up a little bit.\", \"explanation\": \"The speech AMR indicates that the sentence is imperative, meaning it's a command. The ARG0 is 'y/you', indicating that the subject of the sentence is the speaker or listener. The ARG1 is 't/them', indicating the object being pushed. The ARG2 is 'u/up', with a degree modifier 'b/bit' and a modification 'l/little'. This means that the action of pushing should be done to a small extent, which translates to 'a little bit'.\"}]\n",
      "push them up a little bit\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: it starts in the top left\n",
      "Speech AMR:\n",
      " (s/start-01\n",
      "\t:ARG0 (i/it)\n",
      "\t:location (i2/in\n",
      "\t\t:op1 (l/left\n",
      "\t\t\t:mod (t/top))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "LH: into claw, down;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: same direction that that's pushed off yea alright\n",
      "Speech AMR:\n",
      " (s/same-01\n",
      "\t:ARG2 (p/push-01\n",
      "\t\t:ARG1 (t/that)\n",
      "\t\t:ARG2 (o/off))\n",
      "\t:ARG3 (d/direction))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, down; RH: into open, down;\n",
      "arms: move, up, into gap, left; hands: into facing, left, into claw, left;\n",
      "LA: move, left;\n",
      "arms: move, down; hands: into open, down;\n",
      "head: rotate;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/left)\n",
      "\t:ARG2 (a/actor))\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (s2/slide\n",
      "\t\t\t:direction (l/left))\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: move, down; arms: move, front;\n",
      "body: move, up; arms: move, back; hands: into claw, down;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/push-01)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (g2/gesture-unit\n",
      "\t\t\t:op1 (d2/deixis-GA\n",
      "\t\t\t\t:ARG0 s\n",
      "\t\t\t\t:ARG1 l\n",
      "\t\t\t\t:ARG2 a2)\n",
      "\t\t\t:op2 (i2/icon-GA\n",
      "\t\t\t\t:ARG0 s\n",
      "\t\t\t\t:ARG1 p\n",
      "\t\t\t\t:ARG2 a2))))\n",
      "\n",
      "[{\"sentence\": \"The actor moves down, then pushes forward, and finally moves back up with their hands in a claw shape.\", \"speech AMR\": \"(s/move-01 :ARG0 (a/actor) :location (l/location)) (p/push-02 :ARG1 (f/forward) :ARG2 (d/down)) (s/move-03 :ARG0 (a/actor) :direction (b/back))\", \"explanation\": \"The gesture label indicates that the actor moves down, then pushes forward with their arms in front of them. The gesture AMR shows two gesture units: one for moving and another for pushing. The speech AMR is generated by combining these two gesture units into a single sentence.\"}]\n",
      "push them up a little bit\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: it's gonna be a pyramid from three of the rows of two\n",
      "Speech AMR:\n",
      " (p/pyramid\n",
      "\t:consist-of (r/row\n",
      "\t\t:quant 3\n",
      "\t\t:consist-of (r2/row\n",
      "\t\t\t:quant 2))\n",
      "\t:domain (i/it))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, front; LA: move, down;\n",
      "body: move, front; arms: into gap, left; hands: facing, into open;\n",
      "arms: move, down;\n",
      "RA: move, left;\n",
      "RA: shake, right;\n",
      "RA: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/put-01)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g2/gesture-unit\n",
      "\t\t:op1 (d2/deixis-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (l2/location)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p2/put-01)\n",
      "\t\t\t:ARG2 a2)))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (r/row)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: then they connect to the two wider blocks\n",
      "Speech AMR:\n",
      " (c/connect-01\n",
      "\t:time (t/then)\n",
      "\t:ARG1 (t2/they)\n",
      "\t:ARG2 (b/block\n",
      "\t\t:quant 2\n",
      "\t\t:mod (w/wide\n",
      "\t\t\t:degree (m/more))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, up; hands: to face;\n",
      "arms: move, front; hands: into point, front;\n",
      "Unknown\n",
      "arms: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(a/and\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (d2/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (b2/block)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "body: move, down; arms: move, front;\n",
      "body: move, up; arms: move, back; hands: into claw, down;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/push-01)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (g2/gesture-unit\n",
      "\t\t\t:op1 (d2/deixis-GA\n",
      "\t\t\t\t:ARG0 s\n",
      "\t\t\t\t:ARG1 l\n",
      "\t\t\t\t:ARG2 a2)\n",
      "\t\t\t:op2 (i2/icon-GA\n",
      "\t\t\t\t:ARG0 s\n",
      "\t\t\t\t:ARG1 p\n",
      "\t\t\t\t:ARG2 a2))))\n",
      "Speech AMR:\n",
      " (p/push-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them)\n",
      "\t:ARG2 (u/up\n",
      "\t\t:degree (b/bit\n",
      "\t\t\t:mod (l/little))))\n",
      "\n",
      "[{\"sentence\": \"Push them up a bit.\", \"explanation\": \"The gesture AMR indicates two units of action: the first unit involves pointing to a location and pushing an actor, while the second unit is another pointing action. The speech AMR specifies that the mode is imperative (command) and the subject is 'you', indicating a command to push something up. Combining these elements, we get the sentence 'Push them up a bit.'.\"}]\n",
      "push them up a little bit\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: okay\n",
      "Speech AMR:\n",
      " (o/okay-04)\n",
      "\n",
      "Example 2:\n",
      "Sentence: get another one stacked on top\n",
      "Speech AMR:\n",
      " (g/get-04\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (s/stack-01\n",
      "\t\t:ARG1 (o/one\n",
      "\t\t\t:mod (a/another))\n",
      "\t\t:ARG2 (o2/on\n",
      "\t\t\t:op1 (t/top))))\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:ARG1 (d/divot\n",
      "\t\t:quant 3\n",
      "\t\t:ARG1-of (h/have-degree-91\n",
      "\t\t\t:ARG2 (f/far\n",
      "\t\t\t\t:op1 (y/you))\n",
      "\t\t\t:ARG3 (m/most))))\n",
      "\n",
      "[{\"sentence\": \"You have the most far degrees.\", \"explanation\": \"The speech AMR indicates an implicit predicate with 'divot' as the main verb. The ARG1 is 'divot', which has a quantifier of 3, indicating multiple instances. The ARG2 is 'have-degree-91', which means to possess or have a certain degree. The ARG2's ARG2 is 'far', and its ARG3 is 'you'. This suggests that the speaker is describing their own possession of degrees, specifically far ones. Therefore, the sentence generated is in the passive voice and describes the speaker's possession.\"}]\n",
      "and in on the one far on three divots farthest from you\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: move that block uh\n",
      "Speech AMR:\n",
      " (m/move-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (t/that)))\n",
      "\n",
      "Gesture label(s): \n",
      "LA: move, right; LH: claw, right;\n",
      "LH: rotate, claw, front;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (r/right))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: they’re in other words are not perfectly clear\n",
      "Speech AMR:\n",
      " (c/clear-06\n",
      "\t:manner (w/words\n",
      "\t\t:mod (o/other))\n",
      "\t:ARG1 (t/they)\n",
      "\t:polarity -\n",
      "\t:ARG1-of (p/perfect-02))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "body: still;\n",
      "hands: enough;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (k/know-01\n",
      "\t\t:polarity -)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (e2/enough)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "hands: rotate, into closed, up;\n",
      "body: move, down; arms: move, front; hands: into closed, back;\n",
      "arms: shake, front;\n",
      "body: move, up; arms: move, back; hands: into claw, down;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (f/far)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (g2/gesture-unit\n",
      "\t\t\t:op1 (d2/deixis-GA\n",
      "\t\t\t\t:ARG0 s\n",
      "\t\t\t\t:ARG1 l\n",
      "\t\t\t\t:ARG2 a2)\n",
      "\t\t\t:op2 (i2/icon-GA\n",
      "\t\t\t\t:ARG0 s\n",
      "\t\t\t\t:ARG1 f\n",
      "\t\t\t\t:ARG2 a2))))\n",
      "\n",
      "[{\"sentence\": \"Come down here and shake hands, then go back up.\", \n",
      "\"speech AMR\": \"(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (l/location)) (a/and :op1 (i/icon-GA :ARG0 s :ARG1 (h/handshake :mod (f/far)) :ARG2 a2)) (g/gesture-unit :op1 (d/deixis-GA :ARG0 s :ARG1 l :ARG2 a2) :op2 (m/move-01 :mode imperative :ARG0 s :ARG1 (u/up)))\",\n",
      "\"explanation\": \"The gesture labels indicate that the speaker is moving down, then shaking hands with someone in front of them, and finally going back up. The speech AMR reflects this sequence of actions, with the first part describing the movement down, the second part describing the handshake, and the third part describing the movement back up.\"}]\n",
      "and in on the one far on three divots farthest from you\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: them towards you\n",
      "Speech AMR:\n",
      " (o/orient-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/them\n",
      "\t\t:location (t2/towards\n",
      "\t\t\t:op1 y)))\n",
      "\n",
      "Gesture label(s): \n",
      "hands: claw, down; LA: move, back; RA: move, front;\n",
      "hands: claw, down; LA: move, front; RA: move, back;\n",
      "hands: claw, down; LA: move, back; RA: move, front;\n",
      "hands: into closed, back; RA: move, back;\n",
      "arms: move, front, into gap, left; hands: facing, into closed;\n",
      "\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (b/block)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (r/rotate-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Example 2:\n",
      "Sentence: then you going to have a fourth block\n",
      "Speech AMR:\n",
      " (h/have-03\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:ord 4))\n",
      "\n",
      "Gesture label(s): \n",
      "body: move, right; RA: move, up; RH: to face;\n",
      "body: move, left; RA: move, down;\n",
      "LA: move, up; LH: into point, front;\n",
      "LA: move, down; LH: into open, right;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "hands: rotate, into closed, up;\n",
      "body: move, down; arms: move, front; hands: into closed, back;\n",
      "arms: shake, front;\n",
      "body: move, up; arms: move, back; hands: into claw, down;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (d/deixis-GA\n",
      "\t\t\t:ARG0 (s/signaler)\n",
      "\t\t\t:ARG1 (l/location)\n",
      "\t\t\t:ARG2 (a2/actor))\n",
      "\t\t:op2 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (f/far)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (g2/gesture-unit\n",
      "\t\t\t:op1 (d2/deixis-GA\n",
      "\t\t\t\t:ARG0 s\n",
      "\t\t\t\t:ARG1 l\n",
      "\t\t\t\t:ARG2 a2)\n",
      "\t\t\t:op2 (i2/icon-GA\n",
      "\t\t\t\t:ARG0 s\n",
      "\t\t\t\t:ARG1 f\n",
      "\t\t\t\t:ARG2 a2))))\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:ARG1 (d/divot\n",
      "\t\t:quant 3\n",
      "\t\t:ARG1-of (h/have-degree-91\n",
      "\t\t\t:ARG2 (f/far\n",
      "\t\t\t\t:op1 (y/you))\n",
      "\t\t\t:ARG3 (m/most))))\n",
      "\n",
      "[{\"sentence\": \"You have three divots that are far from you.\", \"explanation\": \"The gesture AMR indicates a combination of gestures, with the first part indicating a deixis towards a location and an icon representing something far. The second part is another deixis towards the same location and an icon representing something far again. This suggests that there are multiple instances of something (divots) that are far from the speaker or the actor. The speech AMR confirms this, with 'd/divot' being the main argument and its quantity being 3, indicating three divots. The phrase 'far from you' is also present in the speech AMR, which matches the icon representation in the gesture AMR.\"}]\n",
      "and in on the one far on three divots farthest from you\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: just one\n",
      "Speech AMR:\n",
      " (i/implicit-role\n",
      "\t:quant 1)\n",
      "\n",
      "Example 2:\n",
      "Sentence: and go\n",
      "Speech AMR:\n",
      " (a/and)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (g/get-01\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/tower\n",
      "\t\t:quantity 2\n",
      "\t\t:location (o/on\n",
      "\t\t\t:op1 (s/sides))))\n",
      "\n",
      "[{\"sentence\": \"You get two towers on the sides.\", \"explanation\": \"The speech AMR indicates that the subject is 'you' (ARG0), and the action is 'get' (g/get-01). The object of the action is 'two towers' (t/tower with quantity 2), which are located 'on the sides' (o/on with location on the sides).\"}]\n",
      "and then you got two towers like that on the sides\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: the base is going to have four second one’s going to have three then two on top of that and then one\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (h/have-03\n",
      "\t\t:ARG0 (b/base)\n",
      "\t\t:ARG1 (i/implicit-role\n",
      "\t\t\t:quant 4))\n",
      "\t:op2 (h2/have-03\n",
      "\t\t:ARG0 (i2/implicit-role\n",
      "\t\t\t:ord (o/ordinal-entity\n",
      "\t\t\t\t:value 2))\n",
      "\t\t:ARG1 (i3/implicit-role\n",
      "\t\t\t:quant 3))\n",
      "\t:op3 (i4/implicit-predicate-00\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (i5/implicit-role\n",
      "\t\t\t:quant 2)\n",
      "\t\t:destination (o2/on-top-of\n",
      "\t\t\t:op1 (t/that)))\n",
      "\t:op4 (i6/implicit-predicate-00\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 (i7/implicit-role\n",
      "\t\t\t:quant 1)))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into four, front;\n",
      "RH: into three;\n",
      "RA: move, up; RH: into two;\n",
      "RH: into one;\n",
      "RA: move, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 4\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 3\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 2\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: start off with just a block and then put a block on top of\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (s/start-off-2\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:mod (j/just)))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 (b2/block)\n",
      "\t\t:ARG2 (o/on\n",
      "\t\t\t:op1 (t/top\n",
      "\t\t\t\t:op1 (t2/that)))\n",
      "\t\t:time (t3/then)))\n",
      "\n",
      "Gesture label(s): \n",
      "    arms: move, up, into gap, left; hands: into facing, left, into claw, left;\n",
      "    head: move, down;\n",
      "head: move, up; arms: move, down; hands: into open, down;\n",
      "body: move, up; RH: tap;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (t/top)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, down, into gap, left; hands: into facing, left, into closed, left;\n",
      "arms: shake, left;\n",
      "arms: rotate; hands: into opposed, left, into open, left;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "[{\"sentence\": \"Put your hand on the left side.\", \"speech AMR\": \"(p/put-01 :mode imperative :ARG0 y :ARG1 (h/hand :mod (l/left)) :ARG2 (s/side :mod (l/location)))\", \"explanation\": \"The gesture labels indicate that the hands are moving into a facing position on the left side, which suggests putting one's hand on the left side. The gesture AMR uses deixis-GA to represent the pointing action, but since it's an imperative sentence, we use put-01 instead. The ARG2 is set to (s/side :mod (l/location)) to indicate that the location is on the left side.\"}]\n",
      "and then you got two towers like that on the sides\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: stack stack it up no\n",
      "Speech AMR:\n",
      " (s/stack-up-03\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (i/it))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "LA: move, up; LH: into open, right;\n",
      "arms: together, left; hands: into contact, left, into closed, left;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (b/block)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/close-10)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: stack three blocks on one side yup\n",
      "Speech AMR:\n",
      " (s/stack-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 3)\n",
      "\t:ARG2 (o/on\n",
      "\t\t:op1 (s2/side\n",
      "\t\t\t:quant 1)))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "RA: move, right; RH: into point, down;\n",
      "RH: tap, point;\n",
      "RA: move, up; RH: into claw, front;\n",
      "RA: move, down;\n",
      "LA: move, to hip;\n",
      "body: still;\n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/stack-01)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (o/ok)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "arms: move, down, into gap, left; hands: into facing, left, into closed, left;\n",
      "arms: shake, left;\n",
      "arms: rotate; hands: into opposed, left, into open, left;\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:mode expressive\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "Speech AMR:\n",
      " (g/get-01\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/tower\n",
      "\t\t:quantity 2\n",
      "\t\t:location (o/on\n",
      "\t\t\t:op1 (s/sides))))\n",
      "\n",
      "[{\"sentence\": \"Get the two towers on both sides.\", \"explanation\": \"The gesture AMR indicates a deictic gesture pointing to a location, which is then used as an argument for the speech AMR. The speech AMR specifies getting something, in this case, two towers, and placing them on both sides. The gesture labels support this interpretation by showing arms moving down into a gap, indicating a reference to a specific location, followed by shaking and rotating motions that suggest opposition or contrast, which aligns with the idea of placing objects on opposite sides.\"}]\n",
      "and then you got two towers like that on the sides\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: like about a third of a block a part so more close in than that\n",
      "Speech AMR:\n",
      " (l/like-04\n",
      "\t:ARG2 (q/distance-quantity\n",
      "\t\t:mod (a/about)\n",
      "\t\t:unit (b/block\n",
      "\t\t\t:ARG1-of (h/have-quant-91\n",
      "\t\t\t\t:ARG2 (t/third)))\n",
      "\t\t:mod (a2/apart))\n",
      "\t:ARG2-of (i/infer-01\n",
      "\t\t:ARG1 (h2/have-degree-91\n",
      "\t\t\t:ARG2 (c/close-10)\n",
      "\t\t\t:ARG3 (m/more)\n",
      "\t\t\t:ARG4 (t2/that))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: four blocks\n",
      "Speech AMR:\n",
      " (b/block\n",
      "\t:quantity 4)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (d/do-02\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (p/process\n",
      "\t\t:mod (s/same))\n",
      "\t:mod (a/all)\n",
      "\t:manner (u/up)))\n",
      "\n",
      "[{\"sentence\": \"You do everything the same way up.\", \"explanation\": \"The speech AMR indicates that 'do' is the main verb, with 'you' as the subject. The object of the action is a process described by 'same', indicating that you are doing something in the same manner. The adverbial modifier 'all' suggests that this applies to everything, and the manner 'up' modifies the entire process.\"}]\n",
      "and then you do that same process all the way up\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: great yep\n",
      "Speech AMR:\n",
      " (g/great)\n",
      "\n",
      "Gesture label(s): \n",
      "hands: thumb, up;\n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (g/good)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: seven blocks in a row\n",
      "Speech AMR:\n",
      " (i/implicit-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:quant 7)\n",
      "\t:manner (r/row))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "arms: move, up; LH: into two, front; RH: into five, front;\n",
      "LA: move, down; RA: move, right; RH: closed, down;\n",
      "RA: move, back;\n",
      "\n",
      "Gesture AMR:\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 7\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (r/row)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/place-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RH: rotate, into point, left;\n",
      "RA: rotate, into point, left;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (r/rotate-01\n",
      "\t\t\t:mod (u/up))\n",
      "\t\t:ARG2 a2)\n",
      "\t:op1 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (r2/rotate-01)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "[{\"sentence\": \"Point to the left.\", \"speech AMR\": \"(i/icon-GA :ARG0 s :ARG1 (p/point :mod (l/left)) :ARG2 a)\", \"explanation\": \"The gesture labels indicate that both hands are rotating into point, which is a direction. The body is still, indicating that there is no movement or change in the environment. Therefore, the speech AMR represents an iconographic representation of pointing to the left.\"}]\n",
      "and then you do that same process all the way up\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and then three more coming off from the other direction touching the corner okay\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (i/implicit-role\n",
      "\t\t:quant 3\n",
      "\t\t:mod (m/more)\n",
      "\t\t:ARG1-of (c/come-33\n",
      "\t\t\t:ARG3 (f/from\n",
      "\t\t\t\t:op1 (d/direction\n",
      "\t\t\t\t\t:mod (o/other)))\n",
      "\t\t\t:mod (o2/off))\n",
      "\t\t:ARG0-of (t/touch-01\n",
      "\t\t\t:ARG1 (c2/corner))\n",
      "\t\t:time (t2/then)))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "LA: move, left; LH: into closed, front;\n",
      "body: still;\n",
      "head: nod; LA: move, right; LH: into closed, right;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (d/direction)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: and then the second block goes on top of that\n",
      "Speech AMR:\n",
      " (g/go-01\n",
      "\t:ARG1 (b/block\n",
      "\t\t:ord (o/ordinal-entity\n",
      "\t\t\t:value 2);ARG4(o2/on\n",
      "\t\t\t:op1 (t/top\n",
      "\t\t\t\t:location (t2/that)))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up;\n",
      "RA: move, down; RH: into open, left;\n",
      "RA: rotate\n",
      "body: still;\n",
      "hands: rotate;\n",
      "\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (g/gesture-unit\n",
      "\t\t:op1 (i/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (p/put-01)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i2/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (r/rotate-01)\n",
      "\t\t\t:ARG2 a2))\n",
      "\t:op2 (g2/gesture-unit\n",
      "\t\t:op1 (i3/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (t/tower)\n",
      "\t\t\t:ARG2 a2)\n",
      "\t\t:op2 (i4/icon-GA\n",
      "\t\t\t:ARG0 s\n",
      "\t\t\t:ARG1 (r2/rotate-01)\n",
      "\t\t\t:ARG2 a2)))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RH: rotate, into point, left;\n",
      "RA: rotate, into point, left;\n",
      "body: still;\n",
      "Gesture AMR:\n",
      "(a/and\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (r/rotate-01\n",
      "\t\t\t:mod (u/up))\n",
      "\t\t:ARG2 a2)\n",
      "\t:op1 (i2/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (r2/rotate-01)\n",
      "\t\t:ARG2 a2))\n",
      "Speech AMR:\n",
      " (d/do-02\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (p/process\n",
      "\t\t:mod (s/same))\n",
      "\t:mod (a/all)\n",
      "\t:manner (u/up)))\n",
      "\n",
      "[{\"sentence\": \"You rotate something up and then do the same process all over again.\", \"explanation\": \"The gesture labels indicate that the person is rotating their right hand into a pointing position to the left, which corresponds to the speech AMR's 'rotate-01' action with an upward direction. The second part of the gesture AMR indicates another rotation action, which matches the second part of the speech AMR's process. Therefore, the sentence generated is based on the combination of these actions and their corresponding meanings in the speech AMR.\"}]\n",
      "and then you do that same process all the way up\n",
      "----------------------------------------------\n",
      "speech\n",
      "Given the following speech Abstract Meaning Representation (AMR), generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: starting at row three column three\n",
      "Speech AMR:\n",
      " (s/start-01\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/be-located-at-91\n",
      "\t\t:ARG1 (a/and\n",
      "\t\t\t:op1 (r/row\n",
      "\t\t\t\t:ord (t/third))\n",
      "\t\t\t:op2 (c/column\n",
      "\t\t\t\t:ord 3))))\n",
      "\n",
      "Example 2:\n",
      "Sentence: yeah great\n",
      "Speech AMR:\n",
      " (y/yeah)\n",
      "\n",
      "Now, generate a sentence from the following speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Speech AMR:\n",
      " (i/implicate-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/top\n",
      "\t\t:polarity -))\n",
      "\n",
      "[{\"sentence\": \"You must top.\", \"explanation\": \"The speech AMR indicates an imperative mode, meaning the sentence is a command or instruction. The ARG0 is 'y/you', indicating that the subject of the sentence is the speaker themselves. The ARG1 is 't/top' with a polarity of '-', which typically means negation in this context. Therefore, the sentence should be a negative imperative, instructing the speaker to do something (in this case, 'top') but expressing a sense that it's not possible or desirable.\"}]\n",
      "no on top yeah\n",
      "----------------------------------------------\n",
      "gesture\n",
      "Given the following gesture label(s) and gesture Abstract Meaning Representation (AMR), generate a corresponding sentence and speech AMR in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: closest to the middle yeah\n",
      "Speech AMR:\n",
      " (h/have-degree-91\n",
      "\t:ARG2 (c/close-10\n",
      "\t\t:ARG2 (m/middle))\n",
      "\t:ARG3 (m2/most))\n",
      "\n",
      "Gesture label(s): \n",
      "body: still;\n",
      "head: nod;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (c/close-10)\n",
      "\t:ARG2 (a/actor))\n",
      "(e/emblem-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (y/yes)\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: gonna have another block right next to that block so it’d be over the space of those two bottom blocks\n",
      "Speech AMR:\n",
      " (h/have-02\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (b/block\n",
      "\t\t:mod (a/another))\n",
      "\t:location (n/next-to\n",
      "\t\t:ARG1 (t/that)\n",
      "\t\t:mod (r/right))\n",
      "\t:purpose (b2/be-located-at-91\n",
      "\t\t:ARG1 b\n",
      "\t\t:ARG2 (o/over\n",
      "\t\t\t:op1 (s/space\n",
      "\t\t\t\t:poss (b3/block\n",
      "\t\t\t\t\t:mod (t/that)\n",
      "\t\t\t\t\t:location (b4/bottom))))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into open, left;\n",
      "RA: move, right;\n",
      "LA: move, front; RA: move, down; hands: into open, back;\n",
      "head: move, right;\n",
      "body: still;\n",
      "\n",
      "Gesture AMR:\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(d/deixis-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (l/location)\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (i/icon-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (s2/space)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (d/deixis-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence and the corresponding speech AMR from the following gesture label(s) and gesture AMR and explain your reasoning. Please provide the output only in json format. The speech AMR should be on one line:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"speech AMR:\" \"Your generated speech AMR here\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RH: rotate, into open, back;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (t/tower)\n",
      "\t\t:ARG2 a2))\n",
      "\n",
      "[{\"sentence\": \"look at the tower\", \"speech AMR\": \"(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) (i/icon-GA :ARG0 s :ARG1 (t/tower) :ARG2 a2)\", \"explanation\": \"The gesture label RH: rotate, into open, back indicates a pointing action towards the tower. The corresponding speech AMR represents this action as a deixis gesture (d/deixis-GA), indicating the location of the tower, and an icon gesture (i/icon-GA) representing the tower itself.\"}]\n",
      "no on top yeah\n",
      "----------------------------------------------\n",
      "speech_gesture\n",
      "Given the following gesture label(s), gesture Abstract Meaning Representation (AMR) and speech AMR, generate a corresponding sentence in natural spoken English. Provide a short explanation. First, read the examples to understand the Abstract Meaning Representation format:\n",
      "\n",
      "Example 1:\n",
      "Sentence: and one block on the right side of the first block and move back a bit\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op2 (b/block\n",
      "\t\t:quant 1\n",
      "\t\t:location (o/on\n",
      "\t\t\t:op1 (s/side\n",
      "\t\t\t\t:ARG1-of (r/right-04)\n",
      "\t\t\t\t:poss (b2/block\n",
      "\t\t\t\t\t:ord (o2/ordinal-entity\n",
      "\t\t\t\t\t\t:value 1)))))\n",
      "\t:op3 (m/move-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:direction (b3/back\n",
      "\t\t\t:degree (b4/bit))))\n",
      "\n",
      "Gesture label(s): \n",
      "Unknown\n",
      "Rh: into fist, back;\n",
      "body: still;\n",
      "Unknown\n",
      "hands: into facing, left;\n",
      "arms: beckon;\n",
      "body: still;\n",
      "Unknown\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 (s2/slide-01\n",
      "\t\t:direction (b/backward))\n",
      "\t:ARG2 (a/actor))\n",
      "\n",
      "Example 2:\n",
      "Sentence: take one block put it on top of those two in the middle\n",
      "Speech AMR:\n",
      " (a/and\n",
      "\t:op1 (t/take-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 (y/you)\n",
      "\t\t:ARG1 (b/block\n",
      "\t\t\t:quant 1))\n",
      "\t:op2 (p/put-01\n",
      "\t\t:mode imperative\n",
      "\t\t:ARG0 y\n",
      "\t\t:ARG1 b\n",
      "\t\t:ARG2 (o/on-top-of\n",
      "\t\t\t:op1 (b2/block\n",
      "\t\t\t\t:mod (t2/that)\n",
      "\t\t\t\t:quant 2\n",
      "\t\t\t\t:location (m/middle)))))\n",
      "\n",
      "Gesture label(s): \n",
      "RA: move, up; RH: into one, front;\n",
      "RA: move, front; RH: into L, down;\n",
      "RA: move, up; RH: L, down;\n",
      "RA: move, back;\n",
      "body: still;\n",
      "RA: move, down; RH: into point, down;\n",
      "LA: move, left; LH: into L, down;\n",
      "\n",
      "Gesture AMR:\n",
      "(i/icon-GA\n",
      "\t:ARG0 (s/signaler)\n",
      "\t:ARG1 1\n",
      "\t:ARG2 (a/actor))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (p/put-01)\n",
      "\t\t:ARG2 a))\n",
      "\n",
      "Now, generate a sentence from the following gesture label(s), gesture AMR and speech AMR and explain your reasoning. Please provide the output only in json format:\n",
      "[{\"sentence\": \"Your generated sentence here.\", \"explanation\": \"Your explanation here.\"}]\n",
      "Gesture label(s):\n",
      "RH: rotate, into open, back;\n",
      "Gesture AMR:\n",
      "(g/gesture-unit\n",
      "\t:op1 (d/deixis-GA\n",
      "\t\t:ARG0 (s/signaler)\n",
      "\t\t:ARG1 (l/location)\n",
      "\t\t:ARG2 (a2/actor))\n",
      "\t:op2 (i/icon-GA\n",
      "\t\t:ARG0 s\n",
      "\t\t:ARG1 (t/tower)\n",
      "\t\t:ARG2 a2))\n",
      "Speech AMR:\n",
      " (i/implicate-predicate-00\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (t/top\n",
      "\t\t:polarity -))\n",
      "\n",
      "[{\"sentence\": \"Turn the tower around.\", \"explanation\": \"The gesture labels indicate that the right hand is rotating into an open position, which suggests a circular motion. The speech AMR indicates that the action is imperative and directed at 'you', suggesting a command. The presence of 't/tower' in the gesture AMR and the imperative mode in the speech AMR supports this interpretation.\"}]\n",
      "no on top yeah\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for item in results:\n",
    "    print(item['scenario'])\n",
    "    print(item['prompt'])\n",
    "    print(item['llama_1'])\n",
    "    print(item['sentence'])\n",
    "    print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "1cad7ea7-d11a-4075-a302-111a9bbcab11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.958518646956533\n",
      "0.157\n",
      "----------------------------------------\n",
      "0.157\n",
      "----------------------------------------\n",
      "0.157\n",
      "----------------------------------------\n",
      "0.043\n",
      "----------------------------------------\n",
      "0.043\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.057\n",
      "----------------------------------------\n",
      "0.057\n",
      "----------------------------------------\n",
      "0.057\n",
      "----------------------------------------\n",
      "0.595\n",
      "----------------------------------------\n",
      "0.595\n",
      "----------------------------------------\n",
      "0.595\n",
      "----------------------------------------\n",
      "0.031\n",
      "----------------------------------------\n",
      "0.066\n",
      "----------------------------------------\n",
      "0.066\n",
      "----------------------------------------\n",
      "0.180\n",
      "----------------------------------------\n",
      "0.180\n",
      "----------------------------------------\n",
      "0.244\n",
      "----------------------------------------\n",
      "1.000\n",
      "----------------------------------------\n",
      "1.000\n",
      "----------------------------------------\n",
      "1.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.278\n",
      "----------------------------------------\n",
      "0.278\n",
      "----------------------------------------\n",
      "0.278\n",
      "----------------------------------------\n",
      "0.072\n",
      "----------------------------------------\n",
      "0.072\n",
      "----------------------------------------\n",
      "0.072\n",
      "----------------------------------------\n",
      "0.286\n",
      "----------------------------------------\n",
      "0.302\n",
      "----------------------------------------\n",
      "0.286\n",
      "----------------------------------------\n",
      "0.070\n",
      "----------------------------------------\n",
      "0.070\n",
      "----------------------------------------\n",
      "0.059\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.084\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.070\n",
      "----------------------------------------\n",
      "0.064\n",
      "----------------------------------------\n",
      "0.070\n",
      "----------------------------------------\n",
      "1.000\n",
      "----------------------------------------\n",
      "0.500\n",
      "----------------------------------------\n",
      "0.500\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.184\n",
      "----------------------------------------\n",
      "0.184\n",
      "----------------------------------------\n",
      "0.184\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.055\n",
      "----------------------------------------\n",
      "0.031\n",
      "----------------------------------------\n",
      "0.036\n",
      "----------------------------------------\n",
      "0.055\n",
      "----------------------------------------\n",
      "0.160\n",
      "----------------------------------------\n",
      "0.214\n",
      "----------------------------------------\n",
      "0.214\n",
      "----------------------------------------\n",
      "0.214\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.319\n",
      "----------------------------------------\n",
      "0.319\n",
      "----------------------------------------\n",
      "0.075\n",
      "----------------------------------------\n",
      "0.186\n",
      "----------------------------------------\n",
      "0.172\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.049\n",
      "----------------------------------------\n",
      "0.049\n",
      "----------------------------------------\n",
      "0.057\n",
      "----------------------------------------\n",
      "0.050\n",
      "----------------------------------------\n",
      "0.041\n",
      "----------------------------------------\n",
      "0.339\n",
      "----------------------------------------\n",
      "0.339\n",
      "----------------------------------------\n",
      "0.525\n",
      "----------------------------------------\n",
      "0.063\n",
      "----------------------------------------\n",
      "0.050\n",
      "----------------------------------------\n",
      "0.058\n",
      "----------------------------------------\n",
      "0.525\n",
      "----------------------------------------\n",
      "0.525\n",
      "----------------------------------------\n",
      "0.307\n",
      "----------------------------------------\n",
      "1.000\n",
      "----------------------------------------\n",
      "1.000\n",
      "----------------------------------------\n",
      "1.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.434\n",
      "----------------------------------------\n",
      "0.434\n",
      "----------------------------------------\n",
      "0.447\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.049\n",
      "----------------------------------------\n",
      "0.099\n",
      "----------------------------------------\n",
      "0.446\n",
      "----------------------------------------\n",
      "0.446\n",
      "----------------------------------------\n",
      "0.305\n",
      "----------------------------------------\n",
      "0.275\n",
      "----------------------------------------\n",
      "0.275\n",
      "----------------------------------------\n",
      "0.275\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.129\n",
      "----------------------------------------\n",
      "0.116\n",
      "----------------------------------------\n",
      "0.127\n",
      "----------------------------------------\n",
      "0.063\n",
      "----------------------------------------\n",
      "0.064\n",
      "----------------------------------------\n",
      "0.080\n",
      "----------------------------------------\n",
      "0.141\n",
      "----------------------------------------\n",
      "0.141\n",
      "----------------------------------------\n",
      "0.087\n",
      "----------------------------------------\n",
      "0.081\n",
      "----------------------------------------\n",
      "0.081\n",
      "----------------------------------------\n",
      "0.081\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.214\n",
      "----------------------------------------\n",
      "0.214\n",
      "----------------------------------------\n",
      "0.214\n",
      "----------------------------------------\n",
      "0.327\n",
      "----------------------------------------\n",
      "0.327\n",
      "----------------------------------------\n",
      "0.327\n",
      "----------------------------------------\n",
      "0.049\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.160\n",
      "----------------------------------------\n",
      "0.275\n",
      "----------------------------------------\n",
      "0.275\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.160\n",
      "----------------------------------------\n",
      "0.160\n",
      "----------------------------------------\n",
      "0.160\n",
      "----------------------------------------\n",
      "0.435\n",
      "----------------------------------------\n",
      "0.435\n",
      "----------------------------------------\n",
      "0.307\n",
      "----------------------------------------\n",
      "0.066\n",
      "----------------------------------------\n",
      "0.087\n",
      "----------------------------------------\n",
      "0.055\n",
      "----------------------------------------\n",
      "0.097\n",
      "----------------------------------------\n",
      "0.087\n",
      "----------------------------------------\n",
      "0.087\n",
      "----------------------------------------\n",
      "0.045\n",
      "----------------------------------------\n",
      "0.035\n",
      "----------------------------------------\n",
      "0.040\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.180\n",
      "----------------------------------------\n",
      "0.125\n",
      "----------------------------------------\n",
      "0.089\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.144\n",
      "----------------------------------------\n",
      "0.163\n",
      "----------------------------------------\n",
      "0.242\n",
      "----------------------------------------\n",
      "0.033\n",
      "----------------------------------------\n",
      "0.031\n",
      "----------------------------------------\n",
      "0.033\n",
      "----------------------------------------\n",
      "0.248\n",
      "----------------------------------------\n",
      "0.225\n",
      "----------------------------------------\n",
      "0.235\n",
      "----------------------------------------\n",
      "0.595\n",
      "----------------------------------------\n",
      "0.595\n",
      "----------------------------------------\n",
      "0.595\n",
      "----------------------------------------\n",
      "0.303\n",
      "----------------------------------------\n",
      "0.275\n",
      "----------------------------------------\n",
      "0.303\n",
      "----------------------------------------\n",
      "0.595\n",
      "----------------------------------------\n",
      "0.595\n",
      "----------------------------------------\n",
      "0.595\n",
      "----------------------------------------\n",
      "0.302\n",
      "----------------------------------------\n",
      "0.302\n",
      "----------------------------------------\n",
      "0.302\n",
      "----------------------------------------\n",
      "0.042\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.066\n",
      "----------------------------------------\n",
      "0.050\n",
      "----------------------------------------\n",
      "0.097\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.550\n",
      "----------------------------------------\n",
      "0.550\n",
      "----------------------------------------\n",
      "0.550\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.214\n",
      "----------------------------------------\n",
      "0.319\n",
      "----------------------------------------\n",
      "0.214\n",
      "----------------------------------------\n",
      "0.258\n",
      "----------------------------------------\n",
      "0.184\n",
      "----------------------------------------\n",
      "0.166\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.052\n",
      "----------------------------------------\n",
      "0.059\n",
      "----------------------------------------\n",
      "0.059\n",
      "----------------------------------------\n",
      "0.435\n",
      "----------------------------------------\n",
      "0.435\n",
      "----------------------------------------\n",
      "0.435\n",
      "----------------------------------------\n",
      "0.087\n",
      "----------------------------------------\n",
      "0.066\n",
      "----------------------------------------\n",
      "0.104\n",
      "----------------------------------------\n",
      "0.325\n",
      "----------------------------------------\n",
      "0.325\n",
      "----------------------------------------\n",
      "0.325\n",
      "----------------------------------------\n",
      "0.184\n",
      "----------------------------------------\n",
      "0.322\n",
      "----------------------------------------\n",
      "0.115\n",
      "----------------------------------------\n",
      "0.051\n",
      "----------------------------------------\n",
      "0.051\n",
      "----------------------------------------\n",
      "0.051\n",
      "----------------------------------------\n",
      "0.110\n",
      "----------------------------------------\n",
      "0.115\n",
      "----------------------------------------\n",
      "0.110\n",
      "----------------------------------------\n",
      "0.159\n",
      "----------------------------------------\n",
      "0.159\n",
      "----------------------------------------\n",
      "0.159\n",
      "----------------------------------------\n",
      "0.013\n",
      "----------------------------------------\n",
      "0.013\n",
      "----------------------------------------\n",
      "0.013\n",
      "----------------------------------------\n",
      "0.084\n",
      "----------------------------------------\n",
      "0.095\n",
      "----------------------------------------\n",
      "0.080\n",
      "----------------------------------------\n",
      "0.133\n",
      "----------------------------------------\n",
      "0.066\n",
      "----------------------------------------\n",
      "0.066\n",
      "----------------------------------------\n",
      "0.027\n",
      "----------------------------------------\n",
      "0.030\n",
      "----------------------------------------\n",
      "0.031\n",
      "----------------------------------------\n",
      "0.158\n",
      "----------------------------------------\n",
      "0.054\n",
      "----------------------------------------\n",
      "0.072\n",
      "----------------------------------------\n",
      "0.196\n",
      "----------------------------------------\n",
      "0.196\n",
      "----------------------------------------\n",
      "0.196\n",
      "----------------------------------------\n",
      "0.035\n",
      "----------------------------------------\n",
      "0.037\n",
      "----------------------------------------\n",
      "0.037\n",
      "----------------------------------------\n",
      "0.278\n",
      "----------------------------------------\n",
      "0.278\n",
      "----------------------------------------\n",
      "0.196\n",
      "----------------------------------------\n",
      "0.042\n",
      "----------------------------------------\n",
      "0.044\n",
      "----------------------------------------\n",
      "0.044\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.035\n",
      "----------------------------------------\n",
      "0.035\n",
      "----------------------------------------\n",
      "0.035\n",
      "----------------------------------------\n",
      "0.154\n",
      "----------------------------------------\n",
      "0.229\n",
      "----------------------------------------\n",
      "0.229\n",
      "----------------------------------------\n",
      "0.010\n",
      "----------------------------------------\n",
      "0.010\n",
      "----------------------------------------\n",
      "0.010\n",
      "----------------------------------------\n",
      "0.189\n",
      "----------------------------------------\n",
      "0.195\n",
      "----------------------------------------\n",
      "0.141\n",
      "----------------------------------------\n",
      "0.162\n",
      "----------------------------------------\n",
      "0.131\n",
      "----------------------------------------\n",
      "0.131\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.398\n",
      "----------------------------------------\n",
      "0.162\n",
      "----------------------------------------\n",
      "0.160\n",
      "----------------------------------------\n",
      "0.160\n",
      "----------------------------------------\n",
      "0.081\n",
      "----------------------------------------\n",
      "0.160\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.066\n",
      "----------------------------------------\n",
      "0.081\n",
      "----------------------------------------\n",
      "0.081\n",
      "----------------------------------------\n",
      "0.214\n",
      "----------------------------------------\n",
      "0.214\n",
      "----------------------------------------\n",
      "0.214\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.257\n",
      "----------------------------------------\n",
      "0.257\n",
      "----------------------------------------\n",
      "0.225\n",
      "----------------------------------------\n",
      "0.027\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.031\n",
      "----------------------------------------\n",
      "0.215\n",
      "----------------------------------------\n",
      "0.225\n",
      "----------------------------------------\n",
      "0.215\n",
      "----------------------------------------\n",
      "0.156\n",
      "----------------------------------------\n",
      "0.230\n",
      "----------------------------------------\n",
      "0.120\n",
      "----------------------------------------\n",
      "0.034\n",
      "----------------------------------------\n",
      "0.034\n",
      "----------------------------------------\n",
      "0.023\n",
      "----------------------------------------\n",
      "0.325\n",
      "----------------------------------------\n",
      "0.427\n",
      "----------------------------------------\n",
      "0.427\n",
      "----------------------------------------\n",
      "0.291\n",
      "----------------------------------------\n",
      "0.291\n",
      "----------------------------------------\n",
      "0.316\n",
      "----------------------------------------\n",
      "0.037\n",
      "----------------------------------------\n",
      "0.031\n",
      "----------------------------------------\n",
      "0.034\n",
      "----------------------------------------\n",
      "0.184\n",
      "----------------------------------------\n",
      "0.305\n",
      "----------------------------------------\n",
      "0.316\n",
      "----------------------------------------\n",
      "0.119\n",
      "----------------------------------------\n",
      "0.119\n",
      "----------------------------------------\n",
      "0.119\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.008\n",
      "----------------------------------------\n",
      "0.143\n",
      "----------------------------------------\n",
      "0.177\n",
      "----------------------------------------\n",
      "0.143\n",
      "----------------------------------------\n",
      "0.178\n",
      "----------------------------------------\n",
      "0.178\n",
      "----------------------------------------\n",
      "0.141\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.127\n",
      "----------------------------------------\n",
      "0.398\n",
      "----------------------------------------\n",
      "0.127\n",
      "----------------------------------------\n",
      "0.065\n",
      "----------------------------------------\n",
      "0.052\n",
      "----------------------------------------\n",
      "0.052\n",
      "----------------------------------------\n",
      "0.024\n",
      "----------------------------------------\n",
      "0.016\n",
      "----------------------------------------\n",
      "0.019\n",
      "----------------------------------------\n",
      "0.061\n",
      "----------------------------------------\n",
      "0.040\n",
      "----------------------------------------\n",
      "0.028\n",
      "----------------------------------------\n",
      "0.368\n",
      "----------------------------------------\n",
      "0.368\n",
      "----------------------------------------\n",
      "0.368\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.348\n",
      "----------------------------------------\n",
      "0.486\n",
      "----------------------------------------\n",
      "0.289\n",
      "----------------------------------------\n",
      "0.035\n",
      "----------------------------------------\n",
      "0.035\n",
      "----------------------------------------\n",
      "0.035\n",
      "----------------------------------------\n",
      "0.058\n",
      "----------------------------------------\n",
      "0.058\n",
      "----------------------------------------\n",
      "0.137\n",
      "----------------------------------------\n",
      "0.221\n",
      "----------------------------------------\n",
      "0.221\n",
      "----------------------------------------\n",
      "0.221\n",
      "----------------------------------------\n",
      "0.081\n",
      "----------------------------------------\n",
      "0.081\n",
      "----------------------------------------\n",
      "0.081\n",
      "----------------------------------------\n",
      "0.078\n",
      "----------------------------------------\n",
      "0.078\n",
      "----------------------------------------\n",
      "0.078\n",
      "----------------------------------------\n",
      "0.089\n",
      "----------------------------------------\n",
      "0.066\n",
      "----------------------------------------\n",
      "0.077\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.075\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.085\n",
      "----------------------------------------\n",
      "0.068\n",
      "----------------------------------------\n",
      "0.058\n",
      "----------------------------------------\n",
      "0.031\n",
      "----------------------------------------\n",
      "0.031\n",
      "----------------------------------------\n",
      "0.031\n",
      "----------------------------------------\n",
      "0.045\n",
      "----------------------------------------\n",
      "0.041\n",
      "----------------------------------------\n",
      "0.041\n",
      "----------------------------------------\n",
      "0.038\n",
      "----------------------------------------\n",
      "0.042\n",
      "----------------------------------------\n",
      "0.051\n",
      "----------------------------------------\n",
      "0.054\n",
      "----------------------------------------\n",
      "0.053\n",
      "----------------------------------------\n",
      "0.032\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.120\n",
      "----------------------------------------\n",
      "0.035\n",
      "----------------------------------------\n",
      "0.105\n",
      "----------------------------------------\n",
      "0.106\n",
      "----------------------------------------\n",
      "0.106\n",
      "----------------------------------------\n",
      "0.106\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.084\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.053\n",
      "----------------------------------------\n",
      "0.152\n",
      "----------------------------------------\n",
      "0.152\n",
      "----------------------------------------\n",
      "0.148\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.023\n",
      "----------------------------------------\n",
      "0.038\n",
      "----------------------------------------\n",
      "0.040\n",
      "----------------------------------------\n",
      "0.035\n",
      "----------------------------------------\n",
      "0.045\n",
      "----------------------------------------\n",
      "0.127\n",
      "----------------------------------------\n",
      "0.127\n",
      "----------------------------------------\n",
      "0.127\n",
      "----------------------------------------\n",
      "0.034\n",
      "----------------------------------------\n",
      "0.034\n",
      "----------------------------------------\n",
      "0.034\n",
      "----------------------------------------\n",
      "0.063\n",
      "----------------------------------------\n",
      "0.041\n",
      "----------------------------------------\n",
      "0.063\n",
      "----------------------------------------\n",
      "0.106\n",
      "----------------------------------------\n",
      "0.162\n",
      "----------------------------------------\n",
      "0.106\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.095\n",
      "----------------------------------------\n",
      "0.100\n",
      "----------------------------------------\n",
      "0.145\n",
      "----------------------------------------\n",
      "0.368\n",
      "----------------------------------------\n",
      "0.368\n",
      "----------------------------------------\n",
      "0.500\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.368\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.383\n",
      "----------------------------------------\n",
      "0.120\n",
      "----------------------------------------\n",
      "0.093\n",
      "----------------------------------------\n",
      "0.037\n",
      "----------------------------------------\n",
      "0.068\n",
      "----------------------------------------\n",
      "0.050\n",
      "----------------------------------------\n",
      "0.234\n",
      "----------------------------------------\n",
      "0.090\n",
      "----------------------------------------\n",
      "0.090\n",
      "----------------------------------------\n",
      "0.102\n",
      "----------------------------------------\n",
      "0.080\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.031\n",
      "----------------------------------------\n",
      "0.001\n",
      "----------------------------------------\n",
      "0.007\n",
      "----------------------------------------\n",
      "0.190\n",
      "----------------------------------------\n",
      "0.201\n",
      "----------------------------------------\n",
      "0.205\n",
      "----------------------------------------\n",
      "0.469\n",
      "----------------------------------------\n",
      "0.469\n",
      "----------------------------------------\n",
      "0.469\n",
      "----------------------------------------\n",
      "0.121\n",
      "----------------------------------------\n",
      "0.121\n",
      "----------------------------------------\n",
      "0.120\n",
      "----------------------------------------\n",
      "0.180\n",
      "----------------------------------------\n",
      "0.051\n",
      "----------------------------------------\n",
      "0.056\n",
      "----------------------------------------\n",
      "1.000\n",
      "----------------------------------------\n",
      "1.000\n",
      "----------------------------------------\n",
      "1.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.275\n",
      "----------------------------------------\n",
      "0.275\n",
      "----------------------------------------\n",
      "0.275\n",
      "----------------------------------------\n",
      "0.066\n",
      "----------------------------------------\n",
      "0.066\n",
      "----------------------------------------\n",
      "0.066\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.037\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.037\n",
      "----------------------------------------\n",
      "0.480\n",
      "----------------------------------------\n",
      "0.191\n",
      "----------------------------------------\n",
      "0.057\n",
      "----------------------------------------\n",
      "0.043\n",
      "----------------------------------------\n",
      "0.039\n",
      "----------------------------------------\n",
      "0.039\n",
      "----------------------------------------\n",
      "0.166\n",
      "----------------------------------------\n",
      "0.166\n",
      "----------------------------------------\n",
      "0.071\n",
      "----------------------------------------\n",
      "0.086\n",
      "----------------------------------------\n",
      "0.366\n",
      "----------------------------------------\n",
      "0.366\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.048\n",
      "----------------------------------------\n",
      "0.069\n",
      "----------------------------------------\n",
      "0.024\n",
      "----------------------------------------\n",
      "0.078\n",
      "----------------------------------------\n",
      "0.023\n",
      "----------------------------------------\n",
      "0.059\n",
      "----------------------------------------\n",
      "0.080\n",
      "----------------------------------------\n",
      "0.082\n",
      "----------------------------------------\n",
      "0.015\n",
      "----------------------------------------\n",
      "0.018\n",
      "----------------------------------------\n",
      "0.015\n",
      "----------------------------------------\n",
      "0.188\n",
      "----------------------------------------\n",
      "0.183\n",
      "----------------------------------------\n",
      "0.082\n",
      "----------------------------------------\n",
      "0.809\n",
      "----------------------------------------\n",
      "0.809\n",
      "----------------------------------------\n",
      "0.809\n",
      "----------------------------------------\n",
      "0.021\n",
      "----------------------------------------\n",
      "0.037\n",
      "----------------------------------------\n",
      "0.031\n",
      "----------------------------------------\n",
      "0.537\n",
      "----------------------------------------\n",
      "0.537\n",
      "----------------------------------------\n",
      "0.537\n",
      "----------------------------------------\n",
      "0.042\n",
      "----------------------------------------\n",
      "0.044\n",
      "----------------------------------------\n",
      "0.044\n",
      "----------------------------------------\n",
      "0.034\n",
      "----------------------------------------\n",
      "0.045\n",
      "----------------------------------------\n",
      "0.033\n",
      "----------------------------------------\n",
      "0.103\n",
      "----------------------------------------\n",
      "0.085\n",
      "----------------------------------------\n",
      "0.090\n",
      "----------------------------------------\n",
      "0.186\n",
      "----------------------------------------\n",
      "0.186\n",
      "----------------------------------------\n",
      "0.186\n",
      "----------------------------------------\n",
      "0.076\n",
      "----------------------------------------\n",
      "0.035\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.095\n",
      "----------------------------------------\n",
      "0.174\n",
      "----------------------------------------\n",
      "0.095\n",
      "----------------------------------------\n",
      "0.119\n",
      "----------------------------------------\n",
      "0.119\n",
      "----------------------------------------\n",
      "0.119\n",
      "----------------------------------------\n",
      "0.032\n",
      "----------------------------------------\n",
      "0.032\n",
      "----------------------------------------\n",
      "0.032\n",
      "----------------------------------------\n",
      "0.154\n",
      "----------------------------------------\n",
      "0.088\n",
      "----------------------------------------\n",
      "0.049\n",
      "----------------------------------------\n",
      "0.160\n",
      "----------------------------------------\n",
      "0.160\n",
      "----------------------------------------\n",
      "0.160\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n",
      "0.000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Corpus BLEU score\n",
    "bleu = sacrebleu.corpus_bleu(candidates, [references])\n",
    "print(bleu.score)\n",
    "\n",
    "## Calculate sentence_bleu to see score for individual sentences\n",
    "for item in ref_and_transl:\n",
    "    candidate = item['translation']\n",
    "    reference = item['reference']\n",
    "\n",
    "    print(f\"reference: {reference}\\nscenario: {item['scenario']}\\ncandidate: {candidate}\")\n",
    "    score = sacrebleu.sentence_bleu(candidate, [reference])\n",
    "    print(f\"{score.score/100:.3f}\")\n",
    "    print(40*\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "bc7e1e66-1c91-4395-8266-41ca6fbc8f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.177350373615706\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "## All candidates of speech scenario\n",
    "speech_references = []\n",
    "speech_candidates = []\n",
    "for item in ref_and_transl:\n",
    "    if item['scenario'] == \"speech\":\n",
    "        speech_references.append(item[\"reference\"])\n",
    "        speech_candidates.append(item['translation'])\n",
    "\n",
    "speech_score = sacrebleu.corpus_bleu(speech_candidates, [speech_references])\n",
    "print(speech_score.score)\n",
    "print(len(speech_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "46a9c068-4a95-4f37-ba0c-c49741eec3db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6974058412888725\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "## All candidates of gesture scenario\n",
    "gesture_references = []\n",
    "gesture_candidates = []\n",
    "for item in ref_and_transl:\n",
    "    if item['scenario'] == \"gesture\":\n",
    "        gesture_references.append(item[\"reference\"])\n",
    "        gesture_candidates.append(item['translation'])\n",
    "\n",
    "gesture_score = sacrebleu.corpus_bleu(gesture_candidates, [gesture_references])\n",
    "print(gesture_score.score)\n",
    "print(len(gesture_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f39c8021-0a01-4573-868b-9b9a82724b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.168389033086035\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "## All candidates of gesture+speech scenario\n",
    "speech_gesture_references = []\n",
    "speech_gesture_candidates = []\n",
    "for item in ref_and_transl:\n",
    "    if item['scenario'] == \"speech_gesture\":\n",
    "        speech_gesture_references.append(item[\"reference\"])\n",
    "        speech_gesture_candidates.append(item['translation'])\n",
    "\n",
    "speech_gesture_score = sacrebleu.corpus_bleu(speech_gesture_candidates, [speech_gesture_references])\n",
    "print(speech_gesture_score.score)\n",
    "print(len(speech_gesture_candidates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d042a-bd2f-4924-9821-1777e5f57cba",
   "metadata": {},
   "source": [
    "### Paired Bootstrap Resampling \n",
    "check whether the scores are significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "c6d9abe9-2e36-4901-9654-fde80abd62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_test_corpus_bleu(refs, sys1, sys2, num_samples=1000, seed=42):\n",
    "    \"\"\"\n",
    "    It tests how much better one system is than another (on average) and whether\n",
    "    that difference is significant\n",
    "    Args:\n",
    "        refs: list of references that you're checking against\n",
    "        sys1: list of tokenized candidates from first output\n",
    "        sys2: list of tokenized candidates from second output\n",
    "        num_samples: number of bootstrap resamples\n",
    "        seed: seed\n",
    "    Returns:\n",
    "        np.mean(diffs): average difference between system 1 and system 2 across all bootstrap samples\n",
    "        p_value: calculated p_value\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    diffs = []\n",
    "    refs = [[word_tokenize(r)] for r in refs]  \n",
    "    sys1 = [word_tokenize(s) for s in sys1]   \n",
    "    sys2 = [word_tokenize(s) for s in sys2]\n",
    "\n",
    "    n = len(sys1)\n",
    "    for _ in range(num_samples):\n",
    "        indices = [random.randint(0, n - 1) for _ in range(n)]  ## Generate n random indices 1000 times, with replacement\n",
    "        sample_refs = [refs[i] for i in indices]\n",
    "        sample_sys1 = [sys1[i] for i in indices]\n",
    "        sample_sys2 = [sys2[i] for i in indices]\n",
    "\n",
    "        bleu1 = corpus_bleu(sample_refs, sample_sys1)\n",
    "        bleu2 = corpus_bleu(sample_refs, sample_sys2)\n",
    "        diffs.append(bleu1 - bleu2)\n",
    "\n",
    "    diffs = np.array(diffs)                     ## If diff>0 sys1 performed better, if diff<0 sys2 performed better\n",
    "    p_value = np.mean(diffs <= 0)               ## Calculate the proportion of bootstrap samples where sys1 was not better than sys2\n",
    "    return np.mean(diffs), p_value              ## Average observed BLEU difference between the systems, estimated significance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64031ab-4090-4ee1-9eed-6a85d81f53dc",
   "metadata": {},
   "source": [
    "Check whether the BLEU scores for speech and gesture are statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "71381a3e-99c7-4d08-b9d6-a9bfbfa91eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanne\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Sanne\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech vs Gesture: ΔBLEU = 0.1856, p = 0.0000\n"
     ]
    }
   ],
   "source": [
    "## Speech compared to gesture\n",
    "speech_gesture_mean, speech_gesture_p = bootstrap_test_corpus_bleu(speech_references, speech_candidates, gesture_candidates)\n",
    "print(f\"Speech vs Gesture: ΔBLEU = {speech_gesture_mean:.4f}, p = {speech_gesture_p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53514893-3aaa-4d7f-af38-3f47025db895",
   "metadata": {},
   "source": [
    "ΔBLEU = 0.1856:\n",
    "The speech system's corpus BLEU score is on average 18.56% higher than the gesture system's across the sampled bootstrap runs\n",
    "\n",
    "p = 0.000 (i.e., p < 0.001):\n",
    "The probability that gesture otperforms or equals speech just by chance is essentially zero. This means the difference is statistically significant. You can confidently conclude: \n",
    "speech-based outputs are significantly better than gesture-based ones under BLEU evaluatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "4d34edb6-41de-424c-8d6f-3b61593f00e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech vs Speech+Gesture: ΔBLEU = 0.0765, p = 0.0000\n"
     ]
    }
   ],
   "source": [
    "## Speech compared to speech+gesture\n",
    "s_sg_mean, s_sg_p = bootstrap_test_corpus_bleu(speech_references, speech_candidates, speech_gesture_candidates)\n",
    "print(f\"Speech vs Speech+Gesture: ΔBLEU = {s_sg_mean:.4f}, p = {s_sg_p:.4f}\")\n",
    "\n",
    "# ΔBLEU = 0.0765:\n",
    "# The speech system’s corpus BLEU score is on average 7.65 percentage points higher than the \n",
    "# speech+gesture system’s across the sampled bootstrap runs. This is a substantial performance gap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9236e9b4-d233-4fe9-af21-37d261e0d64b",
   "metadata": {},
   "source": [
    "ΔBLEU = 0.0765:\n",
    "The speech system's corpus BLEU score is on average 7.65& higher than the speech+gesture system's across the samples bootstrap runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "4e5f4d9e-96d9-4df6-a8b0-8f68f6113833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanne\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Sanne\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesture vs Speech+Gesture: ΔBLEU = -0.1091, p = 1.0000\n"
     ]
    }
   ],
   "source": [
    "## Gesture compared to speech+gesture\n",
    "g_sg_mean, g_sg_p = bootstrap_test_corpus_bleu(gesture_references, gesture_candidates, speech_gesture_candidates)\n",
    "print(f\"Gesture vs Speech+Gesture: ΔBLEU = {g_sg_mean:.4f}, p = {g_sg_p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1bf682-4690-4fc5-80d1-73b95e441bdf",
   "metadata": {},
   "source": [
    "ΔBLEU = -0.1091:\n",
    "The BLEU score for gesture-only output is 0.1091 lower on average than for speech+gesture output. \n",
    "p = 1.0000 means that in all bootstrap samples, gesture performed worse than (or equal to) speech+gesture, never better. Therefore the BLEU difference is highly statistically significant, and gesture-only underperforms compared to speech+gesture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0667fb24-759e-4063-a120-3b451c4dc5cf",
   "metadata": {},
   "source": [
    "## METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "090e2c39-a0ad-4e07-9b81-13f6337bdf5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference: so put put a block on the back block good\n",
      "scenario: speech\n",
      "candidate: put the back block.\n",
      "0.395\n",
      "----------------------------------------\n",
      "reference: so put put a block on the back block good\n",
      "scenario: speech\n",
      "candidate: put the back block.\n",
      "0.395\n",
      "----------------------------------------\n",
      "reference: so put put a block on the back block good\n",
      "scenario: speech\n",
      "candidate: put the back block.\n",
      "0.395\n",
      "----------------------------------------\n",
      "reference: so put put a block on the back block good\n",
      "scenario: gesture\n",
      "candidate: look at the location in front of you.\n",
      "0.051\n",
      "----------------------------------------\n",
      "reference: so put put a block on the back block good\n",
      "scenario: gesture\n",
      "candidate: look at the location in front of you.\n",
      "0.051\n",
      "----------------------------------------\n",
      "reference: so put put a block on the back block good\n",
      "scenario: gesture\n",
      "candidate: look over there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: so put put a block on the back block good\n",
      "scenario: speech_gesture\n",
      "candidate: put the block in front of you.\n",
      "0.153\n",
      "----------------------------------------\n",
      "reference: so put put a block on the back block good\n",
      "scenario: speech_gesture\n",
      "candidate: put the block in front of you.\n",
      "0.153\n",
      "----------------------------------------\n",
      "reference: so put put a block on the back block good\n",
      "scenario: speech_gesture\n",
      "candidate: put the block in front of you.\n",
      "0.153\n",
      "----------------------------------------\n",
      "reference: put two blocks\n",
      "scenario: speech\n",
      "candidate: put two blocks.\n",
      "0.950\n",
      "----------------------------------------\n",
      "reference: put two blocks\n",
      "scenario: speech\n",
      "candidate: put two blocks.\n",
      "0.950\n",
      "----------------------------------------\n",
      "reference: put two blocks\n",
      "scenario: speech\n",
      "candidate: put two blocks.\n",
      "0.950\n",
      "----------------------------------------\n",
      "reference: put two blocks\n",
      "scenario: gesture\n",
      "candidate: put the block in the location, then put another block there.\n",
      "0.250\n",
      "----------------------------------------\n",
      "reference: put two blocks\n",
      "scenario: gesture\n",
      "candidate: put the block in that location.\n",
      "0.294\n",
      "----------------------------------------\n",
      "reference: put two blocks\n",
      "scenario: gesture\n",
      "candidate: put the block in that location.\n",
      "0.294\n",
      "----------------------------------------\n",
      "reference: put two blocks\n",
      "scenario: speech_gesture\n",
      "candidate: put the two blocks down.\n",
      "0.774\n",
      "----------------------------------------\n",
      "reference: put two blocks\n",
      "scenario: speech_gesture\n",
      "candidate: put the two blocks down.\n",
      "0.774\n",
      "----------------------------------------\n",
      "reference: put two blocks\n",
      "scenario: speech_gesture\n",
      "candidate: put two blocks down, left.\n",
      "0.866\n",
      "----------------------------------------\n",
      "reference: um\n",
      "scenario: speech\n",
      "candidate: um\n",
      "0.500\n",
      "----------------------------------------\n",
      "reference: um\n",
      "scenario: speech\n",
      "candidate: um\n",
      "0.500\n",
      "----------------------------------------\n",
      "reference: um\n",
      "scenario: speech\n",
      "candidate: um\n",
      "0.500\n",
      "----------------------------------------\n",
      "reference: um\n",
      "scenario: gesture\n",
      "candidate: put the block down.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: um\n",
      "scenario: gesture\n",
      "candidate: put the block down.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: um\n",
      "scenario: gesture\n",
      "candidate: put the block down.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: um\n",
      "scenario: speech_gesture\n",
      "candidate: you put the block in this location, and then you put the other block in that location.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: um\n",
      "scenario: speech_gesture\n",
      "candidate: you put the block and then you're going to put another one over here.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: um\n",
      "scenario: speech_gesture\n",
      "candidate: you put the block, and then you will have a second block.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: and then put one on the top\n",
      "scenario: speech\n",
      "candidate: you put one on top then.\n",
      "0.637\n",
      "----------------------------------------\n",
      "reference: and then put one on the top\n",
      "scenario: speech\n",
      "candidate: you put one on top then.\n",
      "0.637\n",
      "----------------------------------------\n",
      "reference: and then put one on the top\n",
      "scenario: speech\n",
      "candidate: you put one on top then.\n",
      "0.637\n",
      "----------------------------------------\n",
      "reference: and then put one on the top\n",
      "scenario: gesture\n",
      "candidate: point to the location.\n",
      "0.074\n",
      "----------------------------------------\n",
      "reference: and then put one on the top\n",
      "scenario: gesture\n",
      "candidate: point to the location.\n",
      "0.074\n",
      "----------------------------------------\n",
      "reference: and then put one on the top\n",
      "scenario: gesture\n",
      "candidate: point to the location.\n",
      "0.074\n",
      "----------------------------------------\n",
      "reference: and then put one on the top\n",
      "scenario: speech_gesture\n",
      "candidate: put one on top.\n",
      "0.551\n",
      "----------------------------------------\n",
      "reference: and then put one on the top\n",
      "scenario: speech_gesture\n",
      "candidate: put one on top\n",
      "0.560\n",
      "----------------------------------------\n",
      "reference: and then put one on the top\n",
      "scenario: speech_gesture\n",
      "candidate: put one on top.\n",
      "0.551\n",
      "----------------------------------------\n",
      "reference: no that doesn't look like it’s going to work\n",
      "scenario: speech\n",
      "candidate: no, that looks like work.\n",
      "0.323\n",
      "----------------------------------------\n",
      "reference: no that doesn't look like it’s going to work\n",
      "scenario: speech\n",
      "candidate: no, look that work.\n",
      "0.175\n",
      "----------------------------------------\n",
      "reference: no that doesn't look like it’s going to work\n",
      "scenario: speech\n",
      "candidate: no, that looks good.\n",
      "0.132\n",
      "----------------------------------------\n",
      "reference: no that doesn't look like it’s going to work\n",
      "scenario: gesture\n",
      "candidate: i'm grabbing two blocks.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: no that doesn't look like it’s going to work\n",
      "scenario: gesture\n",
      "candidate: i'm going to grab two blocks and close them.\n",
      "0.158\n",
      "----------------------------------------\n",
      "reference: no that doesn't look like it’s going to work\n",
      "scenario: gesture\n",
      "candidate: i'm grabbing two blocks.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: no that doesn't look like it’s going to work\n",
      "scenario: speech_gesture\n",
      "candidate: no, look at that work.\n",
      "0.174\n",
      "----------------------------------------\n",
      "reference: no that doesn't look like it’s going to work\n",
      "scenario: speech_gesture\n",
      "candidate: no, i'm looking at that work.\n",
      "0.171\n",
      "----------------------------------------\n",
      "reference: no that doesn't look like it’s going to work\n",
      "scenario: speech_gesture\n",
      "candidate: no, look at that work.\n",
      "0.174\n",
      "----------------------------------------\n",
      "reference: yes\n",
      "scenario: speech\n",
      "candidate: yes\n",
      "0.500\n",
      "----------------------------------------\n",
      "reference: yes\n",
      "scenario: speech\n",
      "candidate: yes.\n",
      "0.455\n",
      "----------------------------------------\n",
      "reference: yes\n",
      "scenario: speech\n",
      "candidate: yes.\n",
      "0.455\n",
      "----------------------------------------\n",
      "reference: yes\n",
      "scenario: gesture\n",
      "candidate: look up there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yes\n",
      "scenario: gesture\n",
      "candidate: look up there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yes\n",
      "scenario: gesture\n",
      "candidate: look at that.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yes\n",
      "scenario: speech_gesture\n",
      "candidate: point to the location.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yes\n",
      "scenario: speech_gesture\n",
      "candidate: look up.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yes\n",
      "scenario: speech_gesture\n",
      "candidate: point to the location.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: so jiggle the go\n",
      "scenario: speech\n",
      "candidate: jiggle!\n",
      "0.132\n",
      "----------------------------------------\n",
      "reference: so jiggle the go\n",
      "scenario: speech\n",
      "candidate: jiggle!\n",
      "0.132\n",
      "----------------------------------------\n",
      "reference: so jiggle the go\n",
      "scenario: speech\n",
      "candidate: jiggle!\n",
      "0.132\n",
      "----------------------------------------\n",
      "reference: so jiggle the go\n",
      "scenario: gesture\n",
      "candidate: point to the block, then count them.\n",
      "0.222\n",
      "----------------------------------------\n",
      "reference: so jiggle the go\n",
      "scenario: gesture\n",
      "candidate: point to the block, count one.\n",
      "0.114\n",
      "----------------------------------------\n",
      "reference: so jiggle the go\n",
      "scenario: gesture\n",
      "candidate: point to the block in front of you, then count them.\n",
      "0.204\n",
      "----------------------------------------\n",
      "reference: so jiggle the go\n",
      "scenario: speech_gesture\n",
      "candidate: you jiggle the block in front of you, then count how many blocks are to your left and right.\n",
      "0.448\n",
      "----------------------------------------\n",
      "reference: so jiggle the go\n",
      "scenario: speech_gesture\n",
      "candidate: count the blocks in front of you.\n",
      "0.114\n",
      "----------------------------------------\n",
      "reference: so jiggle the go\n",
      "scenario: speech_gesture\n",
      "candidate: count the blocks.\n",
      "0.125\n",
      "----------------------------------------\n",
      "reference: good enough\n",
      "scenario: speech\n",
      "candidate: it is good enough.\n",
      "0.815\n",
      "----------------------------------------\n",
      "reference: good enough\n",
      "scenario: speech\n",
      "candidate: it is good enough.\n",
      "0.815\n",
      "----------------------------------------\n",
      "reference: good enough\n",
      "scenario: speech\n",
      "candidate: it is good enough.\n",
      "0.815\n",
      "----------------------------------------\n",
      "reference: good enough\n",
      "scenario: gesture\n",
      "candidate: you're okay.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: good enough\n",
      "scenario: gesture\n",
      "candidate: it's okay.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: good enough\n",
      "scenario: gesture\n",
      "candidate: it's okay.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: good enough\n",
      "scenario: speech_gesture\n",
      "candidate: that's okay.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: good enough\n",
      "scenario: speech_gesture\n",
      "candidate: that's good enough.\n",
      "0.815\n",
      "----------------------------------------\n",
      "reference: good enough\n",
      "scenario: speech_gesture\n",
      "candidate: that's good enough.\n",
      "0.815\n",
      "----------------------------------------\n",
      "reference: and then jiggle the two in front of them\n",
      "scenario: speech\n",
      "candidate: you should jiggle them in the front then.\n",
      "0.333\n",
      "----------------------------------------\n",
      "reference: and then jiggle the two in front of them\n",
      "scenario: speech\n",
      "candidate: you should jiggle them in front of you then.\n",
      "0.562\n",
      "----------------------------------------\n",
      "reference: and then jiggle the two in front of them\n",
      "scenario: speech\n",
      "candidate: you should jiggle them in front of the others then.\n",
      "0.622\n",
      "----------------------------------------\n",
      "reference: and then jiggle the two in front of them\n",
      "scenario: gesture\n",
      "candidate: point to the block.\n",
      "0.058\n",
      "----------------------------------------\n",
      "reference: and then jiggle the two in front of them\n",
      "scenario: gesture\n",
      "candidate: point down to the block.\n",
      "0.057\n",
      "----------------------------------------\n",
      "reference: and then jiggle the two in front of them\n",
      "scenario: gesture\n",
      "candidate: point to the block on the floor.\n",
      "0.056\n",
      "----------------------------------------\n",
      "reference: and then jiggle the two in front of them\n",
      "scenario: speech_gesture\n",
      "candidate: you shake them, then you move down.\n",
      "0.111\n",
      "----------------------------------------\n",
      "reference: and then jiggle the two in front of them\n",
      "scenario: speech_gesture\n",
      "candidate: you shake them, then you slide them forward.\n",
      "0.110\n",
      "----------------------------------------\n",
      "reference: and then jiggle the two in front of them\n",
      "scenario: speech_gesture\n",
      "candidate: you're shaking them, then you slide forward and point to them.\n",
      "0.158\n",
      "----------------------------------------\n",
      "reference: take another block put it next to it\n",
      "scenario: speech\n",
      "candidate: take another block and put it next to the one.\n",
      "0.765\n",
      "----------------------------------------\n",
      "reference: take another block put it next to it\n",
      "scenario: speech\n",
      "candidate: take another block and put it next to the one.\n",
      "0.765\n",
      "----------------------------------------\n",
      "reference: take another block put it next to it\n",
      "scenario: speech\n",
      "candidate: take another block and put it next to it.\n",
      "0.968\n",
      "----------------------------------------\n",
      "reference: take another block put it next to it\n",
      "scenario: gesture\n",
      "candidate: point to the location in front of you, then put it down.\n",
      "0.174\n",
      "----------------------------------------\n",
      "reference: take another block put it next to it\n",
      "scenario: gesture\n",
      "candidate: point to the location, then put something there.\n",
      "0.122\n",
      "----------------------------------------\n",
      "reference: take another block put it next to it\n",
      "scenario: gesture\n",
      "candidate: point to the location and put it there, then spread your arms apart.\n",
      "0.172\n",
      "----------------------------------------\n",
      "reference: take another block put it next to it\n",
      "scenario: speech_gesture\n",
      "candidate: take another block and put it next to it.\n",
      "0.968\n",
      "----------------------------------------\n",
      "reference: take another block put it next to it\n",
      "scenario: speech_gesture\n",
      "candidate: take another block and put it next to it.\n",
      "0.968\n",
      "----------------------------------------\n",
      "reference: take another block put it next to it\n",
      "scenario: speech_gesture\n",
      "candidate: take another block and put it next to the other one.\n",
      "0.756\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: speech\n",
      "candidate: okay\n",
      "0.500\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: speech\n",
      "candidate: okay\n",
      "0.500\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: speech\n",
      "candidate: okay\n",
      "0.500\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: gesture\n",
      "candidate: point to the location in front of you.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: gesture\n",
      "candidate: point to the location.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: gesture\n",
      "candidate: point to the location.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: speech_gesture\n",
      "candidate: i'm putting it over there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: speech_gesture\n",
      "candidate: you're putting it over there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: speech_gesture\n",
      "candidate: you're putting it here.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: one block on top of each of those two\n",
      "scenario: speech\n",
      "candidate: there is one block on top of each other two blocks.\n",
      "0.682\n",
      "----------------------------------------\n",
      "reference: one block on top of each of those two\n",
      "scenario: speech\n",
      "candidate: there is one block on top of each other two blocks.\n",
      "0.682\n",
      "----------------------------------------\n",
      "reference: one block on top of each of those two\n",
      "scenario: speech\n",
      "candidate: there is one block on top of each of the two blocks that.\n",
      "0.836\n",
      "----------------------------------------\n",
      "reference: one block on top of each of those two\n",
      "scenario: gesture\n",
      "candidate: put it over there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: one block on top of each of those two\n",
      "scenario: gesture\n",
      "candidate: put it on the location.\n",
      "0.057\n",
      "----------------------------------------\n",
      "reference: one block on top of each of those two\n",
      "scenario: gesture\n",
      "candidate: put the block on the left.\n",
      "0.213\n",
      "----------------------------------------\n",
      "reference: one block on top of each of those two\n",
      "scenario: speech_gesture\n",
      "candidate: put that block on top of each other.\n",
      "0.496\n",
      "----------------------------------------\n",
      "reference: one block on top of each of those two\n",
      "scenario: speech_gesture\n",
      "candidate: put the block on top of each other.\n",
      "0.496\n",
      "----------------------------------------\n",
      "reference: one block on top of each of those two\n",
      "scenario: speech_gesture\n",
      "candidate: put that on top of each other.\n",
      "0.355\n",
      "----------------------------------------\n",
      "reference: perfect grab\n",
      "scenario: speech\n",
      "candidate: it's perfect.\n",
      "0.227\n",
      "----------------------------------------\n",
      "reference: perfect grab\n",
      "scenario: speech\n",
      "candidate: it's perfect.\n",
      "0.227\n",
      "----------------------------------------\n",
      "reference: perfect grab\n",
      "scenario: speech\n",
      "candidate: it's perfect.\n",
      "0.227\n",
      "----------------------------------------\n",
      "reference: perfect grab\n",
      "scenario: gesture\n",
      "candidate: it's okay.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: perfect grab\n",
      "scenario: gesture\n",
      "candidate: it's okay.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: perfect grab\n",
      "scenario: gesture\n",
      "candidate: it's okay.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: perfect grab\n",
      "scenario: speech_gesture\n",
      "candidate: it is okay.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: perfect grab\n",
      "scenario: speech_gesture\n",
      "candidate: it's okay.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: perfect grab\n",
      "scenario: speech_gesture\n",
      "candidate: it is okay.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "scenario: speech\n",
      "candidate: you take hold of one thing and then push it forward slightly to put it on the diagonal.\n",
      "0.514\n",
      "----------------------------------------\n",
      "reference: and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "scenario: speech\n",
      "candidate: you take hold of one thing, then push it forward slightly on the diagonal.\n",
      "0.398\n",
      "----------------------------------------\n",
      "reference: and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "scenario: speech\n",
      "candidate: you take hold of one thing, and then push it forward slightly on the diagonal.\n",
      "0.421\n",
      "----------------------------------------\n",
      "reference: and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "scenario: gesture\n",
      "candidate: i'm going to slide this forward, touch it, and then hold still.\n",
      "0.249\n",
      "----------------------------------------\n",
      "reference: and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "scenario: gesture\n",
      "candidate: i'm going to show you something, and then i'll close it and open it again.\n",
      "0.317\n",
      "----------------------------------------\n",
      "reference: and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "scenario: gesture\n",
      "candidate: i'm going to take this and put it in my pocket.\n",
      "0.242\n",
      "----------------------------------------\n",
      "reference: and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "scenario: speech_gesture\n",
      "candidate: you take hold of it and push it forward slightly on the diagonal.\n",
      "0.447\n",
      "----------------------------------------\n",
      "reference: and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "scenario: speech_gesture\n",
      "candidate: you take hold of it and push it forward slightly on the diagonal.\n",
      "0.447\n",
      "----------------------------------------\n",
      "reference: and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "scenario: speech_gesture\n",
      "candidate: you take hold of it and push it forward slightly diagonally.\n",
      "0.303\n",
      "----------------------------------------\n",
      "reference: only two of them\n",
      "scenario: speech\n",
      "candidate: they are the only ones.\n",
      "0.119\n",
      "----------------------------------------\n",
      "reference: only two of them\n",
      "scenario: speech\n",
      "candidate: they are the only ones.\n",
      "0.119\n",
      "----------------------------------------\n",
      "reference: only two of them\n",
      "scenario: speech\n",
      "candidate: they are the only ones.\n",
      "0.119\n",
      "----------------------------------------\n",
      "reference: only two of them\n",
      "scenario: gesture\n",
      "candidate: i don't understand.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: only two of them\n",
      "scenario: gesture\n",
      "candidate: let's go\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: only two of them\n",
      "scenario: gesture\n",
      "candidate: let's go\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: only two of them\n",
      "scenario: speech_gesture\n",
      "candidate: they are only two.\n",
      "0.457\n",
      "----------------------------------------\n",
      "reference: only two of them\n",
      "scenario: speech_gesture\n",
      "candidate: they are only two.\n",
      "0.457\n",
      "----------------------------------------\n",
      "reference: only two of them\n",
      "scenario: speech_gesture\n",
      "candidate: they are only two.\n",
      "0.457\n",
      "----------------------------------------\n",
      "reference: place it on the two that are diagonal and\n",
      "scenario: speech\n",
      "candidate: you place it on the diagonal.\n",
      "0.550\n",
      "----------------------------------------\n",
      "reference: place it on the two that are diagonal and\n",
      "scenario: speech\n",
      "candidate: you place it on the diagonal.\n",
      "0.550\n",
      "----------------------------------------\n",
      "reference: place it on the two that are diagonal and\n",
      "scenario: speech\n",
      "candidate: you place it on the diagonal.\n",
      "0.550\n",
      "----------------------------------------\n",
      "reference: place it on the two that are diagonal and\n",
      "scenario: gesture\n",
      "candidate: point to the left, then down.\n",
      "0.112\n",
      "----------------------------------------\n",
      "reference: place it on the two that are diagonal and\n",
      "scenario: gesture\n",
      "candidate: point to the left, then point down.\n",
      "0.111\n",
      "----------------------------------------\n",
      "reference: place it on the two that are diagonal and\n",
      "scenario: gesture\n",
      "candidate: point to the left, then point down.\n",
      "0.111\n",
      "----------------------------------------\n",
      "reference: place it on the two that are diagonal and\n",
      "scenario: speech_gesture\n",
      "candidate: point it down there.\n",
      "0.218\n",
      "----------------------------------------\n",
      "reference: place it on the two that are diagonal and\n",
      "scenario: speech_gesture\n",
      "candidate: point it down there.\n",
      "0.218\n",
      "----------------------------------------\n",
      "reference: place it on the two that are diagonal and\n",
      "scenario: speech_gesture\n",
      "candidate: point it down there.\n",
      "0.218\n",
      "----------------------------------------\n",
      "reference: flip those two\n",
      "scenario: speech\n",
      "candidate: you flip that.\n",
      "0.161\n",
      "----------------------------------------\n",
      "reference: flip those two\n",
      "scenario: speech\n",
      "candidate: flip that.\n",
      "0.167\n",
      "----------------------------------------\n",
      "reference: flip those two\n",
      "scenario: speech\n",
      "candidate: flip that.\n",
      "0.167\n",
      "----------------------------------------\n",
      "reference: flip those two\n",
      "scenario: gesture\n",
      "candidate: move them this way, like you had it before.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: flip those two\n",
      "scenario: gesture\n",
      "candidate: move the object back, no.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: flip those two\n",
      "scenario: gesture\n",
      "candidate: move your hands back, no.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: flip those two\n",
      "scenario: speech_gesture\n",
      "candidate: flip that over.\n",
      "0.161\n",
      "----------------------------------------\n",
      "reference: flip those two\n",
      "scenario: speech_gesture\n",
      "candidate: flip that over.\n",
      "0.161\n",
      "----------------------------------------\n",
      "reference: flip those two\n",
      "scenario: speech_gesture\n",
      "candidate: flip that over.\n",
      "0.161\n",
      "----------------------------------------\n",
      "reference: keep going a little bit more\n",
      "scenario: speech\n",
      "candidate: you keep going a little more.\n",
      "0.793\n",
      "----------------------------------------\n",
      "reference: keep going a little bit more\n",
      "scenario: speech\n",
      "candidate: you keep going a little more.\n",
      "0.793\n",
      "----------------------------------------\n",
      "reference: keep going a little bit more\n",
      "scenario: speech\n",
      "candidate: you keep going a bit more.\n",
      "0.793\n",
      "----------------------------------------\n",
      "reference: keep going a little bit more\n",
      "scenario: gesture\n",
      "candidate: they're going to be all connected.\n",
      "0.081\n",
      "----------------------------------------\n",
      "reference: keep going a little bit more\n",
      "scenario: gesture\n",
      "candidate: they're going to rotate.\n",
      "0.083\n",
      "----------------------------------------\n",
      "reference: keep going a little bit more\n",
      "scenario: gesture\n",
      "candidate: they are going to be all connected.\n",
      "0.081\n",
      "----------------------------------------\n",
      "reference: keep going a little bit more\n",
      "scenario: speech_gesture\n",
      "candidate: go more slowly.\n",
      "0.172\n",
      "----------------------------------------\n",
      "reference: keep going a little bit more\n",
      "scenario: speech_gesture\n",
      "candidate: you go more slowly.\n",
      "0.169\n",
      "----------------------------------------\n",
      "reference: keep going a little bit more\n",
      "scenario: speech_gesture\n",
      "candidate: you go more slowly.\n",
      "0.169\n",
      "----------------------------------------\n",
      "reference: just like that but closer together\n",
      "scenario: speech\n",
      "candidate: you should just resemble that, having them close together more.\n",
      "0.227\n",
      "----------------------------------------\n",
      "reference: just like that but closer together\n",
      "scenario: speech\n",
      "candidate: you just put that on, though you have to close it together more.\n",
      "0.217\n",
      "----------------------------------------\n",
      "reference: just like that but closer together\n",
      "scenario: speech\n",
      "candidate: you should just resemble that, but you're having it close together more.\n",
      "0.290\n",
      "----------------------------------------\n",
      "reference: just like that but closer together\n",
      "scenario: gesture\n",
      "candidate: move back and then move forward into the gap on the left.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: just like that but closer together\n",
      "scenario: gesture\n",
      "candidate: move back and then point forward.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: just like that but closer together\n",
      "scenario: gesture\n",
      "candidate: move your hands back into a fist, then move them to the left and make a gap in front of you.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: just like that but closer together\n",
      "scenario: speech_gesture\n",
      "candidate: put that just like this.\n",
      "0.426\n",
      "----------------------------------------\n",
      "reference: just like that but closer together\n",
      "scenario: speech_gesture\n",
      "candidate: put that just like you have it closer together.\n",
      "0.697\n",
      "----------------------------------------\n",
      "reference: just like that but closer together\n",
      "scenario: speech_gesture\n",
      "candidate: put that just like you have it closed together more.\n",
      "0.486\n",
      "----------------------------------------\n",
      "reference: doesn't matter\n",
      "scenario: speech\n",
      "candidate: it matters.\n",
      "0.167\n",
      "----------------------------------------\n",
      "reference: doesn't matter\n",
      "scenario: speech\n",
      "candidate: it matters.\n",
      "0.167\n",
      "----------------------------------------\n",
      "reference: doesn't matter\n",
      "scenario: speech\n",
      "candidate: it matters.\n",
      "0.167\n",
      "----------------------------------------\n",
      "reference: doesn't matter\n",
      "scenario: gesture\n",
      "candidate: look at that.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: doesn't matter\n",
      "scenario: gesture\n",
      "candidate: look at that.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: doesn't matter\n",
      "scenario: gesture\n",
      "candidate: look over there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: doesn't matter\n",
      "scenario: speech_gesture\n",
      "candidate: look down.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: doesn't matter\n",
      "scenario: speech_gesture\n",
      "candidate: point to it.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: doesn't matter\n",
      "scenario: speech_gesture\n",
      "candidate: point to it.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: move those together a little bit closer and then put that on top yay\n",
      "scenario: speech\n",
      "candidate: you move those together to have them close a bit more, and put that on the top.\n",
      "0.615\n",
      "----------------------------------------\n",
      "reference: move those together a little bit closer and then put that on top yay\n",
      "scenario: speech\n",
      "candidate: you move those together, close a bit more, and put that on the top.\n",
      "0.624\n",
      "----------------------------------------\n",
      "reference: move those together a little bit closer and then put that on top yay\n",
      "scenario: speech\n",
      "candidate: you move those together, close a bit more, and put that on top.\n",
      "0.660\n",
      "----------------------------------------\n",
      "reference: move those together a little bit closer and then put that on top yay\n",
      "scenario: gesture\n",
      "candidate: put the object together in front of you.\n",
      "0.074\n",
      "----------------------------------------\n",
      "reference: move those together a little bit closer and then put that on top yay\n",
      "scenario: gesture\n",
      "candidate: put them together in front of you.\n",
      "0.075\n",
      "----------------------------------------\n",
      "reference: move those together a little bit closer and then put that on top yay\n",
      "scenario: gesture\n",
      "candidate: put the object together in front of you.\n",
      "0.074\n",
      "----------------------------------------\n",
      "reference: move those together a little bit closer and then put that on top yay\n",
      "scenario: speech_gesture\n",
      "candidate: you move those together, close more a bit little and put that on top.\n",
      "0.712\n",
      "----------------------------------------\n",
      "reference: move those together a little bit closer and then put that on top yay\n",
      "scenario: speech_gesture\n",
      "candidate: move those close together and put that on top.\n",
      "0.551\n",
      "----------------------------------------\n",
      "reference: move those together a little bit closer and then put that on top yay\n",
      "scenario: speech_gesture\n",
      "candidate: move those things closer together and put that on top.\n",
      "0.601\n",
      "----------------------------------------\n",
      "reference: put them together\n",
      "scenario: speech\n",
      "candidate: put them together.\n",
      "0.950\n",
      "----------------------------------------\n",
      "reference: put them together\n",
      "scenario: speech\n",
      "candidate: put them together.\n",
      "0.950\n",
      "----------------------------------------\n",
      "reference: put them together\n",
      "scenario: speech\n",
      "candidate: put them together.\n",
      "0.950\n",
      "----------------------------------------\n",
      "reference: put them together\n",
      "scenario: gesture\n",
      "candidate: push together\n",
      "0.172\n",
      "----------------------------------------\n",
      "reference: put them together\n",
      "scenario: gesture\n",
      "candidate: push together.\n",
      "0.167\n",
      "----------------------------------------\n",
      "reference: put them together\n",
      "scenario: gesture\n",
      "candidate: push together\n",
      "0.172\n",
      "----------------------------------------\n",
      "reference: put them together\n",
      "scenario: speech_gesture\n",
      "candidate: put them together.\n",
      "0.950\n",
      "----------------------------------------\n",
      "reference: put them together\n",
      "scenario: speech_gesture\n",
      "candidate: put them together.\n",
      "0.950\n",
      "----------------------------------------\n",
      "reference: put them together\n",
      "scenario: speech_gesture\n",
      "candidate: put them together.\n",
      "0.950\n",
      "----------------------------------------\n",
      "reference: two more blocks up\n",
      "scenario: speech\n",
      "candidate: there are two more blocks.\n",
      "0.701\n",
      "----------------------------------------\n",
      "reference: two more blocks up\n",
      "scenario: speech\n",
      "candidate: there are two more blocks.\n",
      "0.701\n",
      "----------------------------------------\n",
      "reference: two more blocks up\n",
      "scenario: speech\n",
      "candidate: there are two more blocks.\n",
      "0.701\n",
      "----------------------------------------\n",
      "reference: two more blocks up\n",
      "scenario: gesture\n",
      "candidate: the block is over there, and it's two.\n",
      "0.213\n",
      "----------------------------------------\n",
      "reference: two more blocks up\n",
      "scenario: gesture\n",
      "candidate: point to the block, then show two.\n",
      "0.222\n",
      "----------------------------------------\n",
      "reference: two more blocks up\n",
      "scenario: gesture\n",
      "candidate: point to the block, then show two.\n",
      "0.222\n",
      "----------------------------------------\n",
      "reference: two more blocks up\n",
      "scenario: speech_gesture\n",
      "candidate: you're pointing to two blocks over there.\n",
      "0.222\n",
      "----------------------------------------\n",
      "reference: two more blocks up\n",
      "scenario: speech_gesture\n",
      "candidate: point to the two blocks, then move back.\n",
      "0.217\n",
      "----------------------------------------\n",
      "reference: two more blocks up\n",
      "scenario: speech_gesture\n",
      "candidate: look at the two blocks.\n",
      "0.238\n",
      "----------------------------------------\n",
      "reference: yep\n",
      "scenario: speech\n",
      "candidate: yes.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yep\n",
      "scenario: speech\n",
      "candidate: yes.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yep\n",
      "scenario: speech\n",
      "candidate: yes\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yep\n",
      "scenario: gesture\n",
      "candidate: i agree.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yep\n",
      "scenario: gesture\n",
      "candidate: i agree.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yep\n",
      "scenario: gesture\n",
      "candidate: i agree.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yep\n",
      "scenario: speech_gesture\n",
      "candidate: yes.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yep\n",
      "scenario: speech_gesture\n",
      "candidate: yes.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yep\n",
      "scenario: speech_gesture\n",
      "candidate: yes.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: go near yeah\n",
      "scenario: speech\n",
      "candidate: go near.\n",
      "0.625\n",
      "----------------------------------------\n",
      "reference: go near yeah\n",
      "scenario: speech\n",
      "candidate: go near.\n",
      "0.625\n",
      "----------------------------------------\n",
      "reference: go near yeah\n",
      "scenario: speech\n",
      "candidate: go near.\n",
      "0.625\n",
      "----------------------------------------\n",
      "reference: go near yeah\n",
      "scenario: gesture\n",
      "candidate: that's correct.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: go near yeah\n",
      "scenario: gesture\n",
      "candidate: i agree.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: go near yeah\n",
      "scenario: gesture\n",
      "candidate: i agree.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: go near yeah\n",
      "scenario: speech_gesture\n",
      "candidate: let's go near it.\n",
      "0.568\n",
      "----------------------------------------\n",
      "reference: go near yeah\n",
      "scenario: speech_gesture\n",
      "candidate: let's go near.\n",
      "0.586\n",
      "----------------------------------------\n",
      "reference: go near yeah\n",
      "scenario: speech_gesture\n",
      "candidate: let's go near it.\n",
      "0.568\n",
      "----------------------------------------\n",
      "reference: and uh one block uh ahead of it\n",
      "scenario: speech\n",
      "candidate: you have one block ahead of it.\n",
      "0.605\n",
      "----------------------------------------\n",
      "reference: and uh one block uh ahead of it\n",
      "scenario: speech\n",
      "candidate: there is a block ahead of it and one block.\n",
      "0.678\n",
      "----------------------------------------\n",
      "reference: and uh one block uh ahead of it\n",
      "scenario: speech\n",
      "candidate: there is one block ahead of it, and a block.\n",
      "0.608\n",
      "----------------------------------------\n",
      "reference: and uh one block uh ahead of it\n",
      "scenario: gesture\n",
      "candidate: come here.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: and uh one block uh ahead of it\n",
      "scenario: gesture\n",
      "candidate: come here.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: and uh one block uh ahead of it\n",
      "scenario: gesture\n",
      "candidate: come here.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: and uh one block uh ahead of it\n",
      "scenario: speech_gesture\n",
      "candidate: come ahead.\n",
      "0.067\n",
      "----------------------------------------\n",
      "reference: and uh one block uh ahead of it\n",
      "scenario: speech_gesture\n",
      "candidate: bring it back here.\n",
      "0.065\n",
      "----------------------------------------\n",
      "reference: and uh one block uh ahead of it\n",
      "scenario: speech_gesture\n",
      "candidate: bring it back.\n",
      "0.066\n",
      "----------------------------------------\n",
      "reference: put one block wherever you want\n",
      "scenario: speech\n",
      "candidate: put the block wherever you want.\n",
      "0.793\n",
      "----------------------------------------\n",
      "reference: put one block wherever you want\n",
      "scenario: speech\n",
      "candidate: put the block wherever you want.\n",
      "0.793\n",
      "----------------------------------------\n",
      "reference: put one block wherever you want\n",
      "scenario: speech\n",
      "candidate: put the block wherever you want.\n",
      "0.793\n",
      "----------------------------------------\n",
      "reference: put one block wherever you want\n",
      "scenario: gesture\n",
      "candidate: pick up the block.\n",
      "0.085\n",
      "----------------------------------------\n",
      "reference: put one block wherever you want\n",
      "scenario: gesture\n",
      "candidate: put the blocks in the gap.\n",
      "0.164\n",
      "----------------------------------------\n",
      "reference: put one block wherever you want\n",
      "scenario: gesture\n",
      "candidate: put the block in.\n",
      "0.169\n",
      "----------------------------------------\n",
      "reference: put one block wherever you want\n",
      "scenario: speech_gesture\n",
      "candidate: put it wherever you want.\n",
      "0.625\n",
      "----------------------------------------\n",
      "reference: put one block wherever you want\n",
      "scenario: speech_gesture\n",
      "candidate: put it wherever you want.\n",
      "0.625\n",
      "----------------------------------------\n",
      "reference: put one block wherever you want\n",
      "scenario: speech_gesture\n",
      "candidate: put it wherever you want.\n",
      "0.625\n",
      "----------------------------------------\n",
      "reference: the first block you put it the one nearest and the right side of it\n",
      "scenario: speech\n",
      "candidate: you put the first block on the right side and it is most near you.\n",
      "0.549\n",
      "----------------------------------------\n",
      "reference: the first block you put it the one nearest and the right side of it\n",
      "scenario: speech\n",
      "candidate: you put the first block near most, and you have the right side of it.\n",
      "0.665\n",
      "----------------------------------------\n",
      "reference: the first block you put it the one nearest and the right side of it\n",
      "scenario: speech\n",
      "candidate: you put the first block near most on your right side, and you have a most degree.\n",
      "0.410\n",
      "----------------------------------------\n",
      "reference: the first block you put it the one nearest and the right side of it\n",
      "scenario: gesture\n",
      "candidate: put it to the right.\n",
      "0.224\n",
      "----------------------------------------\n",
      "reference: the first block you put it the one nearest and the right side of it\n",
      "scenario: gesture\n",
      "candidate: put it to the right.\n",
      "0.224\n",
      "----------------------------------------\n",
      "reference: the first block you put it the one nearest and the right side of it\n",
      "scenario: gesture\n",
      "candidate: put it on the right.\n",
      "0.224\n",
      "----------------------------------------\n",
      "reference: the first block you put it the one nearest and the right side of it\n",
      "scenario: speech_gesture\n",
      "candidate: you have a block near you on the right side.\n",
      "0.305\n",
      "----------------------------------------\n",
      "reference: the first block you put it the one nearest and the right side of it\n",
      "scenario: speech_gesture\n",
      "candidate: you have one block near you on the right side.\n",
      "0.350\n",
      "----------------------------------------\n",
      "reference: the first block you put it the one nearest and the right side of it\n",
      "scenario: speech_gesture\n",
      "candidate: you have a block on the right side near most.\n",
      "0.305\n",
      "----------------------------------------\n",
      "reference: we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "scenario: speech\n",
      "candidate: we have two blocks apart from each other.\n",
      "0.412\n",
      "----------------------------------------\n",
      "reference: we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "scenario: speech\n",
      "candidate: we have two blocks apart from each other.\n",
      "0.412\n",
      "----------------------------------------\n",
      "reference: we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "scenario: speech\n",
      "candidate: we have two blocks apart from each other.\n",
      "0.412\n",
      "----------------------------------------\n",
      "reference: we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "scenario: gesture\n",
      "candidate: put the block in space.\n",
      "0.054\n",
      "----------------------------------------\n",
      "reference: we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "scenario: gesture\n",
      "candidate: put the block in space.\n",
      "0.054\n",
      "----------------------------------------\n",
      "reference: we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "scenario: gesture\n",
      "candidate: put the block in space.\n",
      "0.054\n",
      "----------------------------------------\n",
      "reference: we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "scenario: speech_gesture\n",
      "candidate: we have two blocks apart, and i'm putting one in the space, and you put the other block.\n",
      "0.313\n",
      "----------------------------------------\n",
      "reference: we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "scenario: speech_gesture\n",
      "candidate: we have two blocks apart, and i'm putting one block into the other.\n",
      "0.292\n",
      "----------------------------------------\n",
      "reference: we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "scenario: speech_gesture\n",
      "candidate: we have two blocks apart, and we put one in the space and the other on top of it.\n",
      "0.285\n",
      "----------------------------------------\n",
      "reference: but that should be on top on top of the of the other blocks yeah\n",
      "scenario: speech\n",
      "candidate: that should be located on the top of another block.\n",
      "0.432\n",
      "----------------------------------------\n",
      "reference: but that should be on top on top of the of the other blocks yeah\n",
      "scenario: speech\n",
      "candidate: it is recommended that it be located on the other block.\n",
      "0.348\n",
      "----------------------------------------\n",
      "reference: but that should be on top on top of the of the other blocks yeah\n",
      "scenario: speech\n",
      "candidate: it's recommended that you be located on the other block.\n",
      "0.348\n",
      "----------------------------------------\n",
      "reference: but that should be on top on top of the of the other blocks yeah\n",
      "scenario: gesture\n",
      "candidate: no, go back to the top.\n",
      "0.070\n",
      "----------------------------------------\n",
      "reference: but that should be on top on top of the of the other blocks yeah\n",
      "scenario: gesture\n",
      "candidate: no, point to the top and move back.\n",
      "0.069\n",
      "----------------------------------------\n",
      "reference: but that should be on top on top of the of the other blocks yeah\n",
      "scenario: gesture\n",
      "candidate: no, point to the top and then move back.\n",
      "0.068\n",
      "----------------------------------------\n",
      "reference: but that should be on top on top of the of the other blocks yeah\n",
      "scenario: speech_gesture\n",
      "candidate: don't recommend that on the top of the other block.\n",
      "0.478\n",
      "----------------------------------------\n",
      "reference: but that should be on top on top of the of the other blocks yeah\n",
      "scenario: speech_gesture\n",
      "candidate: don't go to the top, but rather be located on something else that is not the other block.\n",
      "0.441\n",
      "----------------------------------------\n",
      "reference: but that should be on top on top of the of the other blocks yeah\n",
      "scenario: speech_gesture\n",
      "candidate: don't go to the top, but rather be located on the other side of the block.\n",
      "0.379\n",
      "----------------------------------------\n",
      "reference: can you just open it open it a little bit uh\n",
      "scenario: speech\n",
      "candidate: just open it a bit.\n",
      "0.425\n",
      "----------------------------------------\n",
      "reference: can you just open it open it a little bit uh\n",
      "scenario: speech\n",
      "candidate: just open it a bit.\n",
      "0.425\n",
      "----------------------------------------\n",
      "reference: can you just open it open it a little bit uh\n",
      "scenario: speech\n",
      "candidate: just open it a bit.\n",
      "0.425\n",
      "----------------------------------------\n",
      "reference: can you just open it open it a little bit uh\n",
      "scenario: gesture\n",
      "candidate: i'm separating myself from you.\n",
      "0.047\n",
      "----------------------------------------\n",
      "reference: can you just open it open it a little bit uh\n",
      "scenario: gesture\n",
      "candidate: i'm going to move it away.\n",
      "0.047\n",
      "----------------------------------------\n",
      "reference: can you just open it open it a little bit uh\n",
      "scenario: gesture\n",
      "candidate: i am separating myself from you.\n",
      "0.047\n",
      "----------------------------------------\n",
      "reference: can you just open it open it a little bit uh\n",
      "scenario: speech_gesture\n",
      "candidate: just open it a little.\n",
      "0.461\n",
      "----------------------------------------\n",
      "reference: can you just open it open it a little bit uh\n",
      "scenario: speech_gesture\n",
      "candidate: just open it a little.\n",
      "0.461\n",
      "----------------------------------------\n",
      "reference: can you just open it open it a little bit uh\n",
      "scenario: speech_gesture\n",
      "candidate: just open it a bit.\n",
      "0.425\n",
      "----------------------------------------\n",
      "reference: (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "scenario: speech\n",
      "candidate: it doesn't recommend the fall.\n",
      "0.070\n",
      "----------------------------------------\n",
      "reference: (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "scenario: speech\n",
      "candidate: it doesn't recommend that you fall.\n",
      "0.070\n",
      "----------------------------------------\n",
      "reference: (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "scenario: speech\n",
      "candidate: it doesn't recommend that you fall.\n",
      "0.070\n",
      "----------------------------------------\n",
      "reference: (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "scenario: gesture\n",
      "candidate: he is standing in front of the block.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "scenario: gesture\n",
      "candidate: the block is on the left.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "scenario: gesture\n",
      "candidate: the block is on the left.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "scenario: speech_gesture\n",
      "candidate: it's not recommended to fall.\n",
      "0.070\n",
      "----------------------------------------\n",
      "reference: (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "scenario: speech_gesture\n",
      "candidate: it's not recommended to fall.\n",
      "0.070\n",
      "----------------------------------------\n",
      "reference: (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "scenario: speech_gesture\n",
      "candidate: it's not recommended to fall.\n",
      "0.070\n",
      "----------------------------------------\n",
      "reference: then the next row is just three on top of that in the middle of those gaps\n",
      "scenario: speech\n",
      "candidate: the next row will be three at the middle of the top gap.\n",
      "0.412\n",
      "----------------------------------------\n",
      "reference: then the next row is just three on top of that in the middle of those gaps\n",
      "scenario: speech\n",
      "candidate: the next row will be three on top of the middle gap.\n",
      "0.565\n",
      "----------------------------------------\n",
      "reference: then the next row is just three on top of that in the middle of those gaps\n",
      "scenario: speech\n",
      "candidate: the next row will be three on top of the middle gap.\n",
      "0.565\n",
      "----------------------------------------\n",
      "reference: then the next row is just three on top of that in the middle of those gaps\n",
      "scenario: gesture\n",
      "candidate: move the block up.\n",
      "0.032\n",
      "----------------------------------------\n",
      "reference: then the next row is just three on top of that in the middle of those gaps\n",
      "scenario: gesture\n",
      "candidate: move the block up.\n",
      "0.032\n",
      "----------------------------------------\n",
      "reference: then the next row is just three on top of that in the middle of those gaps\n",
      "scenario: gesture\n",
      "candidate: move the block up.\n",
      "0.032\n",
      "----------------------------------------\n",
      "reference: then the next row is just three on top of that in the middle of those gaps\n",
      "scenario: speech_gesture\n",
      "candidate: the next row is at the top of the middle gap.\n",
      "0.465\n",
      "----------------------------------------\n",
      "reference: then the next row is just three on top of that in the middle of those gaps\n",
      "scenario: speech_gesture\n",
      "candidate: the next row is going to be at the top of the middle gap.\n",
      "0.456\n",
      "----------------------------------------\n",
      "reference: then the next row is just three on top of that in the middle of those gaps\n",
      "scenario: speech_gesture\n",
      "candidate: the next row is three blocks top middle.\n",
      "0.353\n",
      "----------------------------------------\n",
      "reference: kind of splayed yeah\n",
      "scenario: speech\n",
      "candidate: they are kind of scattered.\n",
      "0.446\n",
      "----------------------------------------\n",
      "reference: kind of splayed yeah\n",
      "scenario: speech\n",
      "candidate: they are kind of a splay.\n",
      "0.594\n",
      "----------------------------------------\n",
      "reference: kind of splayed yeah\n",
      "scenario: speech\n",
      "candidate: they are kind of spreading out.\n",
      "0.436\n",
      "----------------------------------------\n",
      "reference: kind of splayed yeah\n",
      "scenario: gesture\n",
      "candidate: stand apart and then bring your hands together in a fist.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: kind of splayed yeah\n",
      "scenario: gesture\n",
      "candidate: start with your arms apart and then get down on the ground.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: kind of splayed yeah\n",
      "scenario: gesture\n",
      "candidate: start with your arms apart and then move them into a gap.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: kind of splayed yeah\n",
      "scenario: speech_gesture\n",
      "candidate: they're kind of splayed.\n",
      "0.701\n",
      "----------------------------------------\n",
      "reference: kind of splayed yeah\n",
      "scenario: speech_gesture\n",
      "candidate: they're kind of spread out.\n",
      "0.436\n",
      "----------------------------------------\n",
      "reference: kind of splayed yeah\n",
      "scenario: speech_gesture\n",
      "candidate: they are splayed.\n",
      "0.125\n",
      "----------------------------------------\n",
      "reference: come evenly there\n",
      "scenario: speech\n",
      "candidate: you cover there.\n",
      "0.161\n",
      "----------------------------------------\n",
      "reference: come evenly there\n",
      "scenario: speech\n",
      "candidate: you are covering something there.\n",
      "0.152\n",
      "----------------------------------------\n",
      "reference: come evenly there\n",
      "scenario: speech\n",
      "candidate: you cover there.\n",
      "0.161\n",
      "----------------------------------------\n",
      "reference: come evenly there\n",
      "scenario: gesture\n",
      "candidate: move down.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: come evenly there\n",
      "scenario: gesture\n",
      "candidate: move down.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: come evenly there\n",
      "scenario: gesture\n",
      "candidate: move down.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: come evenly there\n",
      "scenario: speech_gesture\n",
      "candidate: you're moving down to cover there.\n",
      "0.143\n",
      "----------------------------------------\n",
      "reference: come evenly there\n",
      "scenario: speech_gesture\n",
      "candidate: you're covering something down there.\n",
      "0.147\n",
      "----------------------------------------\n",
      "reference: come evenly there\n",
      "scenario: speech_gesture\n",
      "candidate: you are covering something there.\n",
      "0.152\n",
      "----------------------------------------\n",
      "reference: like an angle\n",
      "scenario: speech\n",
      "candidate: it resembles an angle.\n",
      "0.586\n",
      "----------------------------------------\n",
      "reference: like an angle\n",
      "scenario: speech\n",
      "candidate: it resembles an angle.\n",
      "0.586\n",
      "----------------------------------------\n",
      "reference: like an angle\n",
      "scenario: speech\n",
      "candidate: it resembles an angle.\n",
      "0.586\n",
      "----------------------------------------\n",
      "reference: like an angle\n",
      "scenario: gesture\n",
      "candidate: look up and down.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: like an angle\n",
      "scenario: gesture\n",
      "candidate: raise and lower\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: like an angle\n",
      "scenario: gesture\n",
      "candidate: raise and lower\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: like an angle\n",
      "scenario: speech_gesture\n",
      "candidate: move your arms up and down.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: like an angle\n",
      "scenario: speech_gesture\n",
      "candidate: move your arms up and down.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: like an angle\n",
      "scenario: speech_gesture\n",
      "candidate: move your arms up and down.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: and it's going to be like a fan or sound wave going out\n",
      "scenario: speech\n",
      "candidate: it's like a fan or a wave of sound going out.\n",
      "0.596\n",
      "----------------------------------------\n",
      "reference: and it's going to be like a fan or sound wave going out\n",
      "scenario: speech\n",
      "candidate: it's like a fan or a wave of sound going out.\n",
      "0.596\n",
      "----------------------------------------\n",
      "reference: and it's going to be like a fan or sound wave going out\n",
      "scenario: speech\n",
      "candidate: it's like a fan or a wave that goes out.\n",
      "0.457\n",
      "----------------------------------------\n",
      "reference: and it's going to be like a fan or sound wave going out\n",
      "scenario: gesture\n",
      "candidate: make a curve with your hand, then move it apart and bring it back down.\n",
      "0.140\n",
      "----------------------------------------\n",
      "reference: and it's going to be like a fan or sound wave going out\n",
      "scenario: gesture\n",
      "candidate: close the gap, but not too close.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: and it's going to be like a fan or sound wave going out\n",
      "scenario: gesture\n",
      "candidate: close your hands and then move them apart.\n",
      "0.074\n",
      "----------------------------------------\n",
      "reference: and it's going to be like a fan or sound wave going out\n",
      "scenario: speech_gesture\n",
      "candidate: it goes out like a fan or a wave.\n",
      "0.353\n",
      "----------------------------------------\n",
      "reference: and it's going to be like a fan or sound wave going out\n",
      "scenario: speech_gesture\n",
      "candidate: it's like a fan or a wave that goes out.\n",
      "0.457\n",
      "----------------------------------------\n",
      "reference: and it's going to be like a fan or sound wave going out\n",
      "scenario: speech_gesture\n",
      "candidate: it goes out like a fan or a wave.\n",
      "0.353\n",
      "----------------------------------------\n",
      "reference: i need four base again\n",
      "scenario: speech\n",
      "candidate: i need to base it again.\n",
      "0.607\n",
      "----------------------------------------\n",
      "reference: i need four base again\n",
      "scenario: speech\n",
      "candidate: i need the base again.\n",
      "0.735\n",
      "----------------------------------------\n",
      "reference: i need four base again\n",
      "scenario: speech\n",
      "candidate: i need to base it again on four.\n",
      "0.689\n",
      "----------------------------------------\n",
      "reference: i need four base again\n",
      "scenario: gesture\n",
      "candidate: the speaker is holding up four fingers in front of them.\n",
      "0.088\n",
      "----------------------------------------\n",
      "reference: i need four base again\n",
      "scenario: gesture\n",
      "candidate: the speaker is holding up four fingers in front of them.\n",
      "0.088\n",
      "----------------------------------------\n",
      "reference: i need four base again\n",
      "scenario: gesture\n",
      "candidate: the speaker is holding four in their right hand and shaking it in front of them.\n",
      "0.081\n",
      "----------------------------------------\n",
      "reference: i need four base again\n",
      "scenario: speech_gesture\n",
      "candidate: i need four bases again.\n",
      "0.976\n",
      "----------------------------------------\n",
      "reference: i need four base again\n",
      "scenario: speech_gesture\n",
      "candidate: i need four again.\n",
      "0.750\n",
      "----------------------------------------\n",
      "reference: i need four base again\n",
      "scenario: speech_gesture\n",
      "candidate: i need four again.\n",
      "0.750\n",
      "----------------------------------------\n",
      "reference: the next one is three on top of those\n",
      "scenario: speech\n",
      "candidate: there are three on top of that one next.\n",
      "0.618\n",
      "----------------------------------------\n",
      "reference: the next one is three on top of those\n",
      "scenario: speech\n",
      "candidate: there are three on top of that one next.\n",
      "0.618\n",
      "----------------------------------------\n",
      "reference: the next one is three on top of those\n",
      "scenario: speech\n",
      "candidate: there are three on top of that one.\n",
      "0.538\n",
      "----------------------------------------\n",
      "reference: the next one is three on top of those\n",
      "scenario: gesture\n",
      "candidate: move it up to four and then down to three.\n",
      "0.054\n",
      "----------------------------------------\n",
      "reference: the next one is three on top of those\n",
      "scenario: gesture\n",
      "candidate: move it to the third position and then bring it back down.\n",
      "0.053\n",
      "----------------------------------------\n",
      "reference: the next one is three on top of those\n",
      "scenario: gesture\n",
      "candidate: move the actor up to four and then bring them down to three.\n",
      "0.105\n",
      "----------------------------------------\n",
      "reference: the next one is three on top of those\n",
      "scenario: speech_gesture\n",
      "candidate: you're pointing to the next one.\n",
      "0.331\n",
      "----------------------------------------\n",
      "reference: the next one is three on top of those\n",
      "scenario: speech_gesture\n",
      "candidate: there are three on top of that.\n",
      "0.446\n",
      "----------------------------------------\n",
      "reference: the next one is three on top of those\n",
      "scenario: speech_gesture\n",
      "candidate: there are three on top of that one.\n",
      "0.538\n",
      "----------------------------------------\n",
      "reference: then you're going to put one right next to it and one right next to that\n",
      "scenario: speech\n",
      "candidate: put the block next to it, and put one block.\n",
      "0.258\n",
      "----------------------------------------\n",
      "reference: then you're going to put one right next to it and one right next to that\n",
      "scenario: speech\n",
      "candidate: put the block next to it, and put one block.\n",
      "0.258\n",
      "----------------------------------------\n",
      "reference: then you're going to put one right next to it and one right next to that\n",
      "scenario: speech\n",
      "candidate: put the block next to it, and put one block.\n",
      "0.258\n",
      "----------------------------------------\n",
      "reference: then you're going to put one right next to it and one right next to that\n",
      "scenario: gesture\n",
      "candidate: look over there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: then you're going to put one right next to it and one right next to that\n",
      "scenario: gesture\n",
      "candidate: look over there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: then you're going to put one right next to it and one right next to that\n",
      "scenario: gesture\n",
      "candidate: look at that.\n",
      "0.032\n",
      "----------------------------------------\n",
      "reference: then you're going to put one right next to it and one right next to that\n",
      "scenario: speech_gesture\n",
      "candidate: put one block next to it, and put one block next to it.\n",
      "0.410\n",
      "----------------------------------------\n",
      "reference: then you're going to put one right next to it and one right next to that\n",
      "scenario: speech_gesture\n",
      "candidate: put the block next to it and put one more.\n",
      "0.312\n",
      "----------------------------------------\n",
      "reference: then you're going to put one right next to it and one right next to that\n",
      "scenario: speech_gesture\n",
      "candidate: put it next to one block, and put one block next to it.\n",
      "0.410\n",
      "----------------------------------------\n",
      "reference: you're gonna have one block\n",
      "scenario: speech\n",
      "candidate: block one.\n",
      "0.152\n",
      "----------------------------------------\n",
      "reference: you're gonna have one block\n",
      "scenario: speech\n",
      "candidate: block one.\n",
      "0.152\n",
      "----------------------------------------\n",
      "reference: you're gonna have one block\n",
      "scenario: speech\n",
      "candidate: block it!\n",
      "0.076\n",
      "----------------------------------------\n",
      "reference: you're gonna have one block\n",
      "scenario: gesture\n",
      "candidate: look over there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: you're gonna have one block\n",
      "scenario: gesture\n",
      "candidate: look over there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: you're gonna have one block\n",
      "scenario: gesture\n",
      "candidate: look at that over there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: you're gonna have one block\n",
      "scenario: speech_gesture\n",
      "candidate: you have a block.\n",
      "0.221\n",
      "----------------------------------------\n",
      "reference: you're gonna have one block\n",
      "scenario: speech_gesture\n",
      "candidate: you have one block.\n",
      "0.551\n",
      "----------------------------------------\n",
      "reference: you're gonna have one block\n",
      "scenario: speech_gesture\n",
      "candidate: you have a block.\n",
      "0.221\n",
      "----------------------------------------\n",
      "reference: there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "scenario: speech\n",
      "candidate: there is one hang on the edge at height one.\n",
      "0.329\n",
      "----------------------------------------\n",
      "reference: there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "scenario: speech\n",
      "candidate: there is one hang on the edge at height three.\n",
      "0.255\n",
      "----------------------------------------\n",
      "reference: there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "scenario: speech\n",
      "candidate: there is one hang on the edge at height three.\n",
      "0.255\n",
      "----------------------------------------\n",
      "reference: there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "scenario: gesture\n",
      "candidate: move the block to the left and then shake it.\n",
      "0.072\n",
      "----------------------------------------\n",
      "reference: there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "scenario: gesture\n",
      "candidate: put it on the left side.\n",
      "0.049\n",
      "----------------------------------------\n",
      "reference: there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "scenario: gesture\n",
      "candidate: put the block on top of it.\n",
      "0.073\n",
      "----------------------------------------\n",
      "reference: there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "scenario: speech_gesture\n",
      "candidate: move the left object to the edge of the third one.\n",
      "0.143\n",
      "----------------------------------------\n",
      "reference: there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "scenario: speech_gesture\n",
      "candidate: move the hang on the edge of the height three to the left, then shake it and move it down to the right.\n",
      "0.157\n",
      "----------------------------------------\n",
      "reference: there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "scenario: speech_gesture\n",
      "candidate: move the object to the left, then shake it and rotate it down on the right.\n",
      "0.093\n",
      "----------------------------------------\n",
      "reference: yeah right\n",
      "scenario: speech\n",
      "candidate: yeah\n",
      "0.263\n",
      "----------------------------------------\n",
      "reference: yeah right\n",
      "scenario: speech\n",
      "candidate: yeah\n",
      "0.263\n",
      "----------------------------------------\n",
      "reference: yeah right\n",
      "scenario: speech\n",
      "candidate: yeah\n",
      "0.263\n",
      "----------------------------------------\n",
      "reference: yeah right\n",
      "scenario: gesture\n",
      "candidate: look at the location below.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yeah right\n",
      "scenario: gesture\n",
      "candidate: look at that.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yeah right\n",
      "scenario: gesture\n",
      "candidate: look over there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yeah right\n",
      "scenario: speech_gesture\n",
      "candidate: look at that.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yeah right\n",
      "scenario: speech_gesture\n",
      "candidate: look at the actor.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: yeah right\n",
      "scenario: speech_gesture\n",
      "candidate: you are pointing to the actor.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: the final one is just pretty much exactly on top of it\n",
      "scenario: speech\n",
      "candidate: it was just then that one, pretty much exactly on top of it, was located.\n",
      "0.701\n",
      "----------------------------------------\n",
      "reference: the final one is just pretty much exactly on top of it\n",
      "scenario: speech\n",
      "candidate: it was just then, pretty much exactly on top of it.\n",
      "0.656\n",
      "----------------------------------------\n",
      "reference: the final one is just pretty much exactly on top of it\n",
      "scenario: speech\n",
      "candidate: it was just then on top of it, pretty much exactly.\n",
      "0.644\n",
      "----------------------------------------\n",
      "reference: the final one is just pretty much exactly on top of it\n",
      "scenario: gesture\n",
      "candidate: put the top on.\n",
      "0.133\n",
      "----------------------------------------\n",
      "reference: the final one is just pretty much exactly on top of it\n",
      "scenario: gesture\n",
      "candidate: put the top on.\n",
      "0.133\n",
      "----------------------------------------\n",
      "reference: the final one is just pretty much exactly on top of it\n",
      "scenario: gesture\n",
      "candidate: put the top on.\n",
      "0.133\n",
      "----------------------------------------\n",
      "reference: the final one is just pretty much exactly on top of it\n",
      "scenario: speech_gesture\n",
      "candidate: put it on top.\n",
      "0.226\n",
      "----------------------------------------\n",
      "reference: the final one is just pretty much exactly on top of it\n",
      "scenario: speech_gesture\n",
      "candidate: put it on top.\n",
      "0.226\n",
      "----------------------------------------\n",
      "reference: the final one is just pretty much exactly on top of it\n",
      "scenario: speech_gesture\n",
      "candidate: put it on top, then just one exactly pretty much on the top of it.\n",
      "0.663\n",
      "----------------------------------------\n",
      "reference: pushed off like the same direction\n",
      "scenario: speech\n",
      "candidate: push it off in the same direction.\n",
      "0.719\n",
      "----------------------------------------\n",
      "reference: pushed off like the same direction\n",
      "scenario: speech\n",
      "candidate: push it off in the same direction.\n",
      "0.719\n",
      "----------------------------------------\n",
      "reference: pushed off like the same direction\n",
      "scenario: speech\n",
      "candidate: push it off in the same direction.\n",
      "0.719\n",
      "----------------------------------------\n",
      "reference: pushed off like the same direction\n",
      "scenario: gesture\n",
      "candidate: put it on the left.\n",
      "0.083\n",
      "----------------------------------------\n",
      "reference: pushed off like the same direction\n",
      "scenario: gesture\n",
      "candidate: put it on the left.\n",
      "0.083\n",
      "----------------------------------------\n",
      "reference: pushed off like the same direction\n",
      "scenario: gesture\n",
      "candidate: put it on the left.\n",
      "0.083\n",
      "----------------------------------------\n",
      "reference: pushed off like the same direction\n",
      "scenario: speech_gesture\n",
      "candidate: push it off to the left.\n",
      "0.246\n",
      "----------------------------------------\n",
      "reference: pushed off like the same direction\n",
      "scenario: speech_gesture\n",
      "candidate: push it off to the left.\n",
      "0.246\n",
      "----------------------------------------\n",
      "reference: pushed off like the same direction\n",
      "scenario: speech_gesture\n",
      "candidate: push it off to the left.\n",
      "0.246\n",
      "----------------------------------------\n",
      "reference: a block space and on a third block\n",
      "scenario: speech\n",
      "candidate: then there was a block that resembled space, and the third block.\n",
      "0.496\n",
      "----------------------------------------\n",
      "reference: a block space and on a third block\n",
      "scenario: speech\n",
      "candidate: and then there was a block that resembled space, and the third one.\n",
      "0.287\n",
      "----------------------------------------\n",
      "reference: a block space and on a third block\n",
      "scenario: speech\n",
      "candidate: and then there was a block that resembled space, followed by the third block.\n",
      "0.485\n",
      "----------------------------------------\n",
      "reference: a block space and on a third block\n",
      "scenario: gesture\n",
      "candidate: you are indicating something in the location.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: a block space and on a third block\n",
      "scenario: gesture\n",
      "candidate: look over there, it's a block in the location.\n",
      "0.119\n",
      "----------------------------------------\n",
      "reference: a block space and on a third block\n",
      "scenario: gesture\n",
      "candidate: look at the location.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: a block space and on a third block\n",
      "scenario: speech_gesture\n",
      "candidate: and then, the space resembles a block at third position.\n",
      "0.298\n",
      "----------------------------------------\n",
      "reference: a block space and on a third block\n",
      "scenario: speech_gesture\n",
      "candidate: the space is like a block, but then there's another one.\n",
      "0.174\n",
      "----------------------------------------\n",
      "reference: a block space and on a third block\n",
      "scenario: speech_gesture\n",
      "candidate: the space is like a block, and then there was another one after that.\n",
      "0.227\n",
      "----------------------------------------\n",
      "reference: then on like the same line you're going to have a space\n",
      "scenario: speech\n",
      "candidate: you had space then.\n",
      "0.164\n",
      "----------------------------------------\n",
      "reference: then on like the same line you're going to have a space\n",
      "scenario: speech\n",
      "candidate: you had space then.\n",
      "0.164\n",
      "----------------------------------------\n",
      "reference: then on like the same line you're going to have a space\n",
      "scenario: speech\n",
      "candidate: you had space then.\n",
      "0.164\n",
      "----------------------------------------\n",
      "reference: then on like the same line you're going to have a space\n",
      "scenario: gesture\n",
      "candidate: move your head down, then move it to the left.\n",
      "0.155\n",
      "----------------------------------------\n",
      "reference: then on like the same line you're going to have a space\n",
      "scenario: gesture\n",
      "candidate: move your hand to the left and up.\n",
      "0.119\n",
      "----------------------------------------\n",
      "reference: then on like the same line you're going to have a space\n",
      "scenario: gesture\n",
      "candidate: move your head down to the left, then move it up.\n",
      "0.154\n",
      "----------------------------------------\n",
      "reference: then on like the same line you're going to have a space\n",
      "scenario: speech_gesture\n",
      "candidate: you have this space over here.\n",
      "0.121\n",
      "----------------------------------------\n",
      "reference: then on like the same line you're going to have a space\n",
      "scenario: speech_gesture\n",
      "candidate: you have the line right here.\n",
      "0.161\n",
      "----------------------------------------\n",
      "reference: then on like the same line you're going to have a space\n",
      "scenario: speech_gesture\n",
      "candidate: you were on the line, then you moved into space.\n",
      "0.271\n",
      "----------------------------------------\n",
      "reference: over the space in between the blocks so it’ll be on\n",
      "scenario: speech\n",
      "candidate: it resembles a block over space between blocks.\n",
      "0.198\n",
      "----------------------------------------\n",
      "reference: over the space in between the blocks so it’ll be on\n",
      "scenario: speech\n",
      "candidate: it resembles something that is over space, between blocks.\n",
      "0.234\n",
      "----------------------------------------\n",
      "reference: over the space in between the blocks so it’ll be on\n",
      "scenario: speech\n",
      "candidate: it resembles something that is over space between blocks, and it should be located at the top.\n",
      "0.257\n",
      "----------------------------------------\n",
      "reference: over the space in between the blocks so it’ll be on\n",
      "scenario: gesture\n",
      "candidate: that's correct.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: over the space in between the blocks so it’ll be on\n",
      "scenario: gesture\n",
      "candidate: that's correct.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: over the space in between the blocks so it’ll be on\n",
      "scenario: gesture\n",
      "candidate: that's correct.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: over the space in between the blocks so it’ll be on\n",
      "scenario: speech_gesture\n",
      "candidate: it's between the blocks.\n",
      "0.305\n",
      "----------------------------------------\n",
      "reference: over the space in between the blocks so it’ll be on\n",
      "scenario: speech_gesture\n",
      "candidate: it's over there, yes.\n",
      "0.081\n",
      "----------------------------------------\n",
      "reference: over the space in between the blocks so it’ll be on\n",
      "scenario: speech_gesture\n",
      "candidate: it's located between the blocks, and it resembles something that is over there.\n",
      "0.384\n",
      "----------------------------------------\n",
      "reference: what one less than\n",
      "scenario: speech\n",
      "candidate: there is one that is less than that.\n",
      "0.568\n",
      "----------------------------------------\n",
      "reference: what one less than\n",
      "scenario: speech\n",
      "candidate: there is one that is less than that.\n",
      "0.568\n",
      "----------------------------------------\n",
      "reference: what one less than\n",
      "scenario: speech\n",
      "candidate: there is one that is less than that.\n",
      "0.568\n",
      "----------------------------------------\n",
      "reference: what one less than\n",
      "scenario: gesture\n",
      "candidate: move the block in front of you, then move it to the left.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: what one less than\n",
      "scenario: gesture\n",
      "candidate: move the block in front of you to the left and point it down.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: what one less than\n",
      "scenario: gesture\n",
      "candidate: move the block in front of you, then move it to your left.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: what one less than\n",
      "scenario: speech_gesture\n",
      "candidate: point to the block that is less than that.\n",
      "0.408\n",
      "----------------------------------------\n",
      "reference: what one less than\n",
      "scenario: speech_gesture\n",
      "candidate: point to the block in front of you, then move left and point there, shake your head and move down right.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: what one less than\n",
      "scenario: speech_gesture\n",
      "candidate: point to the block in front of you and move it less than that.\n",
      "0.368\n",
      "----------------------------------------\n",
      "reference: the other direction it's the same except for there are five\n",
      "scenario: speech\n",
      "candidate: it's the same, but it includes five others.\n",
      "0.430\n",
      "----------------------------------------\n",
      "reference: the other direction it's the same except for there are five\n",
      "scenario: speech\n",
      "candidate: it's the same, but it includes five others.\n",
      "0.430\n",
      "----------------------------------------\n",
      "reference: the other direction it's the same except for there are five\n",
      "scenario: speech\n",
      "candidate: it's the same as five others.\n",
      "0.485\n",
      "----------------------------------------\n",
      "reference: the other direction it's the same except for there are five\n",
      "scenario: gesture\n",
      "candidate: you're moving your arms diagonally.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: the other direction it's the same except for there are five\n",
      "scenario: gesture\n",
      "candidate: you're pointing to the left and then you're pointing forward, but you're shaking your head.\n",
      "0.078\n",
      "----------------------------------------\n",
      "reference: the other direction it's the same except for there are five\n",
      "scenario: gesture\n",
      "candidate: you're going to move the object diagonally.\n",
      "0.043\n",
      "----------------------------------------\n",
      "reference: the other direction it's the same except for there are five\n",
      "scenario: speech_gesture\n",
      "candidate: move the object to the left and then turn it diagonally.\n",
      "0.125\n",
      "----------------------------------------\n",
      "reference: the other direction it's the same except for there are five\n",
      "scenario: speech_gesture\n",
      "candidate: turn them to the left.\n",
      "0.044\n",
      "----------------------------------------\n",
      "reference: the other direction it's the same except for there are five\n",
      "scenario: speech_gesture\n",
      "candidate: turn the thing on the left side over.\n",
      "0.085\n",
      "----------------------------------------\n",
      "reference: then down down one\n",
      "scenario: speech\n",
      "candidate: you go down then.\n",
      "0.244\n",
      "----------------------------------------\n",
      "reference: then down down one\n",
      "scenario: speech\n",
      "candidate: you go down then.\n",
      "0.244\n",
      "----------------------------------------\n",
      "reference: then down down one\n",
      "scenario: speech\n",
      "candidate: you go down then.\n",
      "0.244\n",
      "----------------------------------------\n",
      "reference: then down down one\n",
      "scenario: gesture\n",
      "candidate: point to the block in front of you and then move it down.\n",
      "0.200\n",
      "----------------------------------------\n",
      "reference: then down down one\n",
      "scenario: gesture\n",
      "candidate: point to the block in front of you and then move it down.\n",
      "0.200\n",
      "----------------------------------------\n",
      "reference: then down down one\n",
      "scenario: gesture\n",
      "candidate: point to the block in front of you, then move it down.\n",
      "0.200\n",
      "----------------------------------------\n",
      "reference: then down down one\n",
      "scenario: speech_gesture\n",
      "candidate: move down, then move the block down.\n",
      "0.333\n",
      "----------------------------------------\n",
      "reference: then down down one\n",
      "scenario: speech_gesture\n",
      "candidate: move down and pick up the block, then move it down.\n",
      "0.306\n",
      "----------------------------------------\n",
      "reference: then down down one\n",
      "scenario: speech_gesture\n",
      "candidate: move down, then move the block down.\n",
      "0.333\n",
      "----------------------------------------\n",
      "reference: put them coming diagonal\n",
      "scenario: speech\n",
      "candidate: come and put them in a diagonal manner.\n",
      "0.701\n",
      "----------------------------------------\n",
      "reference: put them coming diagonal\n",
      "scenario: speech\n",
      "candidate: come diagonally and put them.\n",
      "0.893\n",
      "----------------------------------------\n",
      "reference: put them coming diagonal\n",
      "scenario: speech\n",
      "candidate: come over and put them on the diagonal.\n",
      "0.701\n",
      "----------------------------------------\n",
      "reference: put them coming diagonal\n",
      "scenario: gesture\n",
      "candidate: move your hand up and touch it to the right.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: put them coming diagonal\n",
      "scenario: gesture\n",
      "candidate: move your hand up and touch the diagonal.\n",
      "0.111\n",
      "----------------------------------------\n",
      "reference: put them coming diagonal\n",
      "scenario: gesture\n",
      "candidate: move the object diagonally and touch it with your left hand.\n",
      "0.104\n",
      "----------------------------------------\n",
      "reference: put them coming diagonal\n",
      "scenario: speech_gesture\n",
      "candidate: you put them on top of each other.\n",
      "0.417\n",
      "----------------------------------------\n",
      "reference: put them coming diagonal\n",
      "scenario: speech_gesture\n",
      "candidate: put them on you, coming from the diagonal.\n",
      "0.686\n",
      "----------------------------------------\n",
      "reference: put them coming diagonal\n",
      "scenario: speech_gesture\n",
      "candidate: put them down on the diagonal.\n",
      "0.594\n",
      "----------------------------------------\n",
      "reference: no closest\n",
      "scenario: speech\n",
      "candidate: no\n",
      "0.263\n",
      "----------------------------------------\n",
      "reference: no closest\n",
      "scenario: speech\n",
      "candidate: no\n",
      "0.263\n",
      "----------------------------------------\n",
      "reference: no closest\n",
      "scenario: speech\n",
      "candidate: no.\n",
      "0.250\n",
      "----------------------------------------\n",
      "reference: no closest\n",
      "scenario: gesture\n",
      "candidate: they are closing in on each other.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: no closest\n",
      "scenario: gesture\n",
      "candidate: close the door.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: no closest\n",
      "scenario: gesture\n",
      "candidate: close it.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: no closest\n",
      "scenario: speech_gesture\n",
      "candidate: no\n",
      "0.263\n",
      "----------------------------------------\n",
      "reference: no closest\n",
      "scenario: speech_gesture\n",
      "candidate: close it.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: no closest\n",
      "scenario: speech_gesture\n",
      "candidate: close it.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: and the one on the very end\n",
      "scenario: speech\n",
      "candidate: and one is on the very end.\n",
      "0.792\n",
      "----------------------------------------\n",
      "reference: and the one on the very end\n",
      "scenario: speech\n",
      "candidate: it is very on the end of one.\n",
      "0.517\n",
      "----------------------------------------\n",
      "reference: and the one on the very end\n",
      "scenario: speech\n",
      "candidate: it is very on one end.\n",
      "0.286\n",
      "----------------------------------------\n",
      "reference: and the one on the very end\n",
      "scenario: gesture\n",
      "candidate: they are standing still, pointing forward and holding hands.\n",
      "0.068\n",
      "----------------------------------------\n",
      "reference: and the one on the very end\n",
      "scenario: gesture\n",
      "candidate: they are standing still, pointing to the location on the left.\n",
      "0.336\n",
      "----------------------------------------\n",
      "reference: and the one on the very end\n",
      "scenario: gesture\n",
      "candidate: they are standing still and pointing to the location.\n",
      "0.137\n",
      "----------------------------------------\n",
      "reference: and the one on the very end\n",
      "scenario: speech_gesture\n",
      "candidate: point to the very end on one.\n",
      "0.628\n",
      "----------------------------------------\n",
      "reference: and the one on the very end\n",
      "scenario: speech_gesture\n",
      "candidate: one end is very close.\n",
      "0.217\n",
      "----------------------------------------\n",
      "reference: and the one on the very end\n",
      "scenario: speech_gesture\n",
      "candidate: one end is very close.\n",
      "0.217\n",
      "----------------------------------------\n",
      "reference: and then on the other side the two closest to the middle get stacked\n",
      "scenario: speech\n",
      "candidate: you get two stacks, one on each side, and they're most close to the middle.\n",
      "0.475\n",
      "----------------------------------------\n",
      "reference: and then on the other side the two closest to the middle get stacked\n",
      "scenario: speech\n",
      "candidate: you get a stack of two things, one on each side of the other, and they are close to the middle, most.\n",
      "0.526\n",
      "----------------------------------------\n",
      "reference: and then on the other side the two closest to the middle get stacked\n",
      "scenario: speech\n",
      "candidate: you get two stacks, one on each side, with the middle stack being most close but not touching.\n",
      "0.326\n",
      "----------------------------------------\n",
      "reference: and then on the other side the two closest to the middle get stacked\n",
      "scenario: gesture\n",
      "candidate: i want you to take two blocks.\n",
      "0.112\n",
      "----------------------------------------\n",
      "reference: and then on the other side the two closest to the middle get stacked\n",
      "scenario: gesture\n",
      "candidate: take two\n",
      "0.078\n",
      "----------------------------------------\n",
      "reference: and then on the other side the two closest to the middle get stacked\n",
      "scenario: gesture\n",
      "candidate: take two.\n",
      "0.078\n",
      "----------------------------------------\n",
      "reference: and then on the other side the two closest to the middle get stacked\n",
      "scenario: speech_gesture\n",
      "candidate: get two on the other side, close most\n",
      "0.316\n",
      "----------------------------------------\n",
      "reference: and then on the other side the two closest to the middle get stacked\n",
      "scenario: speech_gesture\n",
      "candidate: get two on the other side, then close most of it in the middle.\n",
      "0.485\n",
      "----------------------------------------\n",
      "reference: and then on the other side the two closest to the middle get stacked\n",
      "scenario: speech_gesture\n",
      "candidate: get two on the other side, close to most.\n",
      "0.350\n",
      "----------------------------------------\n",
      "reference: two in front of you and two at the back\n",
      "scenario: speech\n",
      "candidate: you are in front of you and at the back.\n",
      "0.786\n",
      "----------------------------------------\n",
      "reference: two in front of you and two at the back\n",
      "scenario: speech\n",
      "candidate: you are in front of you and at the back.\n",
      "0.786\n",
      "----------------------------------------\n",
      "reference: two in front of you and two at the back\n",
      "scenario: speech\n",
      "candidate: you are in front of you and at the back.\n",
      "0.786\n",
      "----------------------------------------\n",
      "reference: two in front of you and two at the back\n",
      "scenario: gesture\n",
      "candidate: look at the front of it.\n",
      "0.387\n",
      "----------------------------------------\n",
      "reference: two in front of you and two at the back\n",
      "scenario: gesture\n",
      "candidate: look at the front of it.\n",
      "0.387\n",
      "----------------------------------------\n",
      "reference: two in front of you and two at the back\n",
      "scenario: gesture\n",
      "candidate: look at the front and then turn around to look at the back.\n",
      "0.429\n",
      "----------------------------------------\n",
      "reference: two in front of you and two at the back\n",
      "scenario: speech_gesture\n",
      "candidate: you're facing the front and at the back.\n",
      "0.511\n",
      "----------------------------------------\n",
      "reference: two in front of you and two at the back\n",
      "scenario: speech_gesture\n",
      "candidate: move to the front, and then go back to you.\n",
      "0.245\n",
      "----------------------------------------\n",
      "reference: two in front of you and two at the back\n",
      "scenario: speech_gesture\n",
      "candidate: move forward and back to you.\n",
      "0.155\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: speech\n",
      "candidate: okay\n",
      "0.500\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: speech\n",
      "candidate: okay\n",
      "0.500\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: speech\n",
      "candidate: okay\n",
      "0.500\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: gesture\n",
      "candidate: stop the row.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: gesture\n",
      "candidate: stop the row.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: gesture\n",
      "candidate: stop the row.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: speech_gesture\n",
      "candidate: that's okay.\n",
      "0.385\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: speech_gesture\n",
      "candidate: row okay.\n",
      "0.417\n",
      "----------------------------------------\n",
      "reference: okay\n",
      "scenario: speech_gesture\n",
      "candidate: row okay.\n",
      "0.417\n",
      "----------------------------------------\n",
      "reference: i don’t think can be touching\n",
      "scenario: speech\n",
      "candidate: i think it is possible to touch.\n",
      "0.250\n",
      "----------------------------------------\n",
      "reference: i don’t think can be touching\n",
      "scenario: speech\n",
      "candidate: i think it is possible to touch.\n",
      "0.250\n",
      "----------------------------------------\n",
      "reference: i don’t think can be touching\n",
      "scenario: speech\n",
      "candidate: i think it is possible to touch.\n",
      "0.250\n",
      "----------------------------------------\n",
      "reference: i don’t think can be touching\n",
      "scenario: gesture\n",
      "candidate: i'm holding you on top of me.\n",
      "0.062\n",
      "----------------------------------------\n",
      "reference: i don’t think can be touching\n",
      "scenario: gesture\n",
      "candidate: i'm giving you a high-five.\n",
      "0.063\n",
      "----------------------------------------\n",
      "reference: i don’t think can be touching\n",
      "scenario: gesture\n",
      "candidate: i'm giving you the thumbs up.\n",
      "0.062\n",
      "----------------------------------------\n",
      "reference: i don’t think can be touching\n",
      "scenario: speech_gesture\n",
      "candidate: i think it's possible to put two on top of the one.\n",
      "0.116\n",
      "----------------------------------------\n",
      "reference: i don’t think can be touching\n",
      "scenario: speech_gesture\n",
      "candidate: you're thinking it's possible to put two on top of each other.\n",
      "0.057\n",
      "----------------------------------------\n",
      "reference: i don’t think can be touching\n",
      "scenario: speech_gesture\n",
      "candidate: you can put two blocks on top of the other.\n",
      "0.060\n",
      "----------------------------------------\n",
      "reference: there is three blocks for the bottom of the smile\n",
      "scenario: speech\n",
      "candidate: you have three blocks for the bottom of your smile.\n",
      "0.628\n",
      "----------------------------------------\n",
      "reference: there is three blocks for the bottom of the smile\n",
      "scenario: speech\n",
      "candidate: there are three blocks at the bottom of a smile.\n",
      "0.567\n",
      "----------------------------------------\n",
      "reference: there is three blocks for the bottom of the smile\n",
      "scenario: speech\n",
      "candidate: you have three bottoms of a smile.\n",
      "0.322\n",
      "----------------------------------------\n",
      "reference: there is three blocks for the bottom of the smile\n",
      "scenario: gesture\n",
      "candidate: put the row in and put it down.\n",
      "0.051\n",
      "----------------------------------------\n",
      "reference: there is three blocks for the bottom of the smile\n",
      "scenario: gesture\n",
      "candidate: put the row away.\n",
      "0.053\n",
      "----------------------------------------\n",
      "reference: there is three blocks for the bottom of the smile\n",
      "scenario: gesture\n",
      "candidate: put the row in.\n",
      "0.053\n",
      "----------------------------------------\n",
      "reference: there is three blocks for the bottom of the smile\n",
      "scenario: speech_gesture\n",
      "candidate: and you put three blocks at the bottom of your smile.\n",
      "0.501\n",
      "----------------------------------------\n",
      "reference: there is three blocks for the bottom of the smile\n",
      "scenario: speech_gesture\n",
      "candidate: and you put three blocks at the bottom of your smile.\n",
      "0.501\n",
      "----------------------------------------\n",
      "reference: there is three blocks for the bottom of the smile\n",
      "scenario: speech_gesture\n",
      "candidate: and put the row in front of you on the bottom, smile.\n",
      "0.240\n",
      "----------------------------------------\n",
      "reference: there is two blocks for the eyes\n",
      "scenario: speech\n",
      "candidate: the block is for your eye.\n",
      "0.357\n",
      "----------------------------------------\n",
      "reference: there is two blocks for the eyes\n",
      "scenario: speech\n",
      "candidate: there are two blocks for the eye.\n",
      "0.829\n",
      "----------------------------------------\n",
      "reference: there is two blocks for the eyes\n",
      "scenario: speech\n",
      "candidate: there are two blocks for the eye.\n",
      "0.829\n",
      "----------------------------------------\n",
      "reference: there is two blocks for the eyes\n",
      "scenario: gesture\n",
      "candidate: put it in the gap on the left.\n",
      "0.069\n",
      "----------------------------------------\n",
      "reference: there is two blocks for the eyes\n",
      "scenario: gesture\n",
      "candidate: put it in the gap on the left.\n",
      "0.069\n",
      "----------------------------------------\n",
      "reference: there is two blocks for the eyes\n",
      "scenario: gesture\n",
      "candidate: put it in the gap.\n",
      "0.072\n",
      "----------------------------------------\n",
      "reference: there is two blocks for the eyes\n",
      "scenario: speech_gesture\n",
      "candidate: they put the claw into the gap, and then they point with their hands.\n",
      "0.063\n",
      "----------------------------------------\n",
      "reference: there is two blocks for the eyes\n",
      "scenario: speech_gesture\n",
      "candidate: put the actor in two points.\n",
      "0.143\n",
      "----------------------------------------\n",
      "reference: there is two blocks for the eyes\n",
      "scenario: speech_gesture\n",
      "candidate: put the first one in the gap and then put the second one in the point.\n",
      "0.062\n",
      "----------------------------------------\n",
      "reference: and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "scenario: speech\n",
      "candidate: then i have the purpose to make a smile off of block 3, which is wider than block 2.\n",
      "0.459\n",
      "----------------------------------------\n",
      "reference: and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "scenario: speech\n",
      "candidate: then, i will make a smile off of three blocks, wide and more.\n",
      "0.284\n",
      "----------------------------------------\n",
      "reference: and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "scenario: speech\n",
      "candidate: then, i will make a smile off three blocks by making two wide blocks.\n",
      "0.374\n",
      "----------------------------------------\n",
      "reference: and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "scenario: gesture\n",
      "candidate: look at the row below.\n",
      "0.031\n",
      "----------------------------------------\n",
      "reference: and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "scenario: gesture\n",
      "candidate: look at the row over there.\n",
      "0.062\n",
      "----------------------------------------\n",
      "reference: and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "scenario: gesture\n",
      "candidate: look at the row above.\n",
      "0.031\n",
      "----------------------------------------\n",
      "reference: and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "scenario: speech_gesture\n",
      "candidate: then we have three blocks to make a smile with two wide blocks more off.\n",
      "0.454\n",
      "----------------------------------------\n",
      "reference: and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "scenario: speech_gesture\n",
      "candidate: then i have three blocks to make a smile with two wide blocks.\n",
      "0.421\n",
      "----------------------------------------\n",
      "reference: and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "scenario: speech_gesture\n",
      "candidate: then we have three to make a smile, off the blocks.\n",
      "0.380\n",
      "----------------------------------------\n",
      "reference: push them up a little bit\n",
      "scenario: speech\n",
      "candidate: push them up a little bit.\n",
      "0.981\n",
      "----------------------------------------\n",
      "reference: push them up a little bit\n",
      "scenario: speech\n",
      "candidate: push them up a little bit.\n",
      "0.981\n",
      "----------------------------------------\n",
      "reference: push them up a little bit\n",
      "scenario: speech\n",
      "candidate: push them up a little bit.\n",
      "0.981\n",
      "----------------------------------------\n",
      "reference: push them up a little bit\n",
      "scenario: gesture\n",
      "candidate: the actor moves down, then pushes forward, and finally moves back up with their hands in a claw shape.\n",
      "0.197\n",
      "----------------------------------------\n",
      "reference: push them up a little bit\n",
      "scenario: gesture\n",
      "candidate: you're pushing something down and then pulling it back up.\n",
      "0.152\n",
      "----------------------------------------\n",
      "reference: push them up a little bit\n",
      "scenario: gesture\n",
      "candidate: you move down, then push forward, then move up and pull back.\n",
      "0.145\n",
      "----------------------------------------\n",
      "reference: push them up a little bit\n",
      "scenario: speech_gesture\n",
      "candidate: push them up a bit.\n",
      "0.807\n",
      "----------------------------------------\n",
      "reference: push them up a little bit\n",
      "scenario: speech_gesture\n",
      "candidate: push them up a bit.\n",
      "0.807\n",
      "----------------------------------------\n",
      "reference: push them up a little bit\n",
      "scenario: speech_gesture\n",
      "candidate: push them up a bit.\n",
      "0.807\n",
      "----------------------------------------\n",
      "reference: and in on the one far on three divots farthest from you\n",
      "scenario: speech\n",
      "candidate: you have the most far degrees.\n",
      "0.130\n",
      "----------------------------------------\n",
      "reference: and in on the one far on three divots farthest from you\n",
      "scenario: speech\n",
      "candidate: you have had the most far degrees.\n",
      "0.129\n",
      "----------------------------------------\n",
      "reference: and in on the one far on three divots farthest from you\n",
      "scenario: speech\n",
      "candidate: you have had the most far degrees.\n",
      "0.129\n",
      "----------------------------------------\n",
      "reference: and in on the one far on three divots farthest from you\n",
      "scenario: gesture\n",
      "candidate: come down here and shake hands, then go back up.\n",
      "0.042\n",
      "----------------------------------------\n",
      "reference: and in on the one far on three divots farthest from you\n",
      "scenario: gesture\n",
      "candidate: come down here and grab it from far away.\n",
      "0.127\n",
      "----------------------------------------\n",
      "reference: and in on the one far on three divots farthest from you\n",
      "scenario: gesture\n",
      "candidate: come down, and then go up.\n",
      "0.043\n",
      "----------------------------------------\n",
      "reference: and in on the one far on three divots farthest from you\n",
      "scenario: speech_gesture\n",
      "candidate: you have three divots that are far from you.\n",
      "0.378\n",
      "----------------------------------------\n",
      "reference: and in on the one far on three divots farthest from you\n",
      "scenario: speech_gesture\n",
      "candidate: you are going to have three divots of the farthest degree.\n",
      "0.310\n",
      "----------------------------------------\n",
      "reference: and in on the one far on three divots farthest from you\n",
      "scenario: speech_gesture\n",
      "candidate: you have three divots, the farthest one being most.\n",
      "0.358\n",
      "----------------------------------------\n",
      "reference: and then you got two towers like that on the sides\n",
      "scenario: speech\n",
      "candidate: you get two towers on the sides.\n",
      "0.526\n",
      "----------------------------------------\n",
      "reference: and then you got two towers like that on the sides\n",
      "scenario: speech\n",
      "candidate: you get two towers on the sides.\n",
      "0.526\n",
      "----------------------------------------\n",
      "reference: and then you got two towers like that on the sides\n",
      "scenario: speech\n",
      "candidate: you get two towers on the sides.\n",
      "0.526\n",
      "----------------------------------------\n",
      "reference: and then you got two towers like that on the sides\n",
      "scenario: gesture\n",
      "candidate: put your hand on the left side.\n",
      "0.239\n",
      "----------------------------------------\n",
      "reference: and then you got two towers like that on the sides\n",
      "scenario: gesture\n",
      "candidate: look at the left side.\n",
      "0.095\n",
      "----------------------------------------\n",
      "reference: and then you got two towers like that on the sides\n",
      "scenario: gesture\n",
      "candidate: look over there.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: and then you got two towers like that on the sides\n",
      "scenario: speech_gesture\n",
      "candidate: get the two towers on both sides.\n",
      "0.348\n",
      "----------------------------------------\n",
      "reference: and then you got two towers like that on the sides\n",
      "scenario: speech_gesture\n",
      "candidate: get two towers on the sides.\n",
      "0.457\n",
      "----------------------------------------\n",
      "reference: and then you got two towers like that on the sides\n",
      "scenario: speech_gesture\n",
      "candidate: get the two towers on both sides.\n",
      "0.348\n",
      "----------------------------------------\n",
      "reference: and then you do that same process all the way up\n",
      "scenario: speech\n",
      "candidate: you do everything the same way up.\n",
      "0.478\n",
      "----------------------------------------\n",
      "reference: and then you do that same process all the way up\n",
      "scenario: speech\n",
      "candidate: you do everything the same way up.\n",
      "0.478\n",
      "----------------------------------------\n",
      "reference: and then you do that same process all the way up\n",
      "scenario: speech\n",
      "candidate: you do everything the same way up.\n",
      "0.478\n",
      "----------------------------------------\n",
      "reference: and then you do that same process all the way up\n",
      "scenario: gesture\n",
      "candidate: point to the left.\n",
      "0.048\n",
      "----------------------------------------\n",
      "reference: and then you do that same process all the way up\n",
      "scenario: gesture\n",
      "candidate: point to the left.\n",
      "0.048\n",
      "----------------------------------------\n",
      "reference: and then you do that same process all the way up\n",
      "scenario: gesture\n",
      "candidate: point to the left.\n",
      "0.048\n",
      "----------------------------------------\n",
      "reference: and then you do that same process all the way up\n",
      "scenario: speech_gesture\n",
      "candidate: you rotate something up and then do the same process all over again.\n",
      "0.678\n",
      "----------------------------------------\n",
      "reference: and then you do that same process all the way up\n",
      "scenario: speech_gesture\n",
      "candidate: you're doing the same process up.\n",
      "0.398\n",
      "----------------------------------------\n",
      "reference: and then you do that same process all the way up\n",
      "scenario: speech_gesture\n",
      "candidate: you rotate it up, and you rotate it up.\n",
      "0.136\n",
      "----------------------------------------\n",
      "reference: no on top yeah\n",
      "scenario: speech\n",
      "candidate: you must top.\n",
      "0.125\n",
      "----------------------------------------\n",
      "reference: no on top yeah\n",
      "scenario: speech\n",
      "candidate: you must top.\n",
      "0.125\n",
      "----------------------------------------\n",
      "reference: no on top yeah\n",
      "scenario: speech\n",
      "candidate: you top it.\n",
      "0.125\n",
      "----------------------------------------\n",
      "reference: no on top yeah\n",
      "scenario: gesture\n",
      "candidate: look at the tower\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: no on top yeah\n",
      "scenario: gesture\n",
      "candidate: look at the tower\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: no on top yeah\n",
      "scenario: gesture\n",
      "candidate: look at the tower\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: no on top yeah\n",
      "scenario: speech_gesture\n",
      "candidate: turn the tower around.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: no on top yeah\n",
      "scenario: speech_gesture\n",
      "candidate: turn the tower around.\n",
      "0.000\n",
      "----------------------------------------\n",
      "reference: no on top yeah\n",
      "scenario: speech_gesture\n",
      "candidate: turn the tower around.\n",
      "0.000\n",
      "----------------------------------------\n",
      "Average METEOR score: 0.2855\n"
     ]
    }
   ],
   "source": [
    "## Calculate METEOR score for all sentences\n",
    "sent_count = 0\n",
    "total_score = 0\n",
    "for item in ref_and_transl:\n",
    "    candidate = (item['translation']).strip()\n",
    "    reference = (item['reference']).strip()\n",
    "    print(f\"reference: {reference}\\nscenario: {item['scenario']}\\ncandidate: {candidate}\")\n",
    "\n",
    "    score = meteor_score([word_tokenize(reference)], word_tokenize(candidate))\n",
    "    print(f\"{score:.3f}\")\n",
    "    sent_count+=1\n",
    "    total_score+=score\n",
    "    print(40*\"-\")\n",
    "print(f\"Average METEOR score: {(total_score/sent_count):.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "c8fe7815-e45c-44f0-a4ca-846849ae5199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average METEOR score speech scenario: 0.4671\n"
     ]
    }
   ],
   "source": [
    "## Calculate METEOR score for all speech condition sentences\n",
    "speech_sent_count = 0\n",
    "speech_total_score = 0\n",
    "\n",
    "sp_meteor_ref, sp_meteor_cand = [], []\n",
    "for item in ref_and_transl:\n",
    "    if item['scenario'] == \"speech\":\n",
    "        candidate = (item['translation']).strip()\n",
    "        reference = (item['reference']).strip()\n",
    "\n",
    "        sp_meteor_ref.append(word_tokenize(reference))\n",
    "        sp_meteor_cand.append(word_tokenize(candidate))\n",
    "\n",
    "        score = meteor_score([word_tokenize(reference)], word_tokenize(candidate))\n",
    "        speech_sent_count+=1\n",
    "        speech_total_score+=score\n",
    "print(f\"Average METEOR score speech scenario: {(speech_total_score/speech_sent_count):.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "c4b169cf-20f5-49b0-ad98-937ad735ad74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average METEOR score gesture scenario: 0.0715\n"
     ]
    }
   ],
   "source": [
    "## Calculate METEOR score for all gesture condition sentences\n",
    "gesture_sent_count = 0\n",
    "gesture_total_score = 0\n",
    "\n",
    "gest_meteor_cand = []\n",
    "for item in ref_and_transl:\n",
    "    if item['scenario'] == \"gesture\":\n",
    "        candidate = (item['translation']).strip()\n",
    "        reference = (item['reference']).strip()\n",
    "\n",
    "        gest_meteor_cand.append(word_tokenize(candidate))\n",
    "\n",
    "        score = meteor_score([word_tokenize(reference)], word_tokenize(candidate))\n",
    "        gesture_sent_count+=1\n",
    "        gesture_total_score+=score\n",
    "print(f\"Average METEOR score gesture scenario: {(gesture_total_score/gesture_sent_count):.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "cc210d1b-60e4-429a-b895-9a2425f286aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average METEOR score speech+gesture scenario: 0.3180\n"
     ]
    }
   ],
   "source": [
    "## Calculate METEOR score for all speech+gesture condition sentences\n",
    "speech_gesture_sent_count = 0\n",
    "speech_gesture_total_score = 0\n",
    "\n",
    "sp_gest_meteor_cand = []\n",
    "for item in ref_and_transl:\n",
    "    if item['scenario'] == \"speech_gesture\":\n",
    "        candidate = (item['translation']).strip()\n",
    "        reference = (item['reference']).strip()\n",
    "\n",
    "        sp_gest_meteor_cand.append(word_tokenize(candidate))\n",
    "\n",
    "        score = meteor_score([word_tokenize(reference)], word_tokenize(candidate))\n",
    "        speech_gesture_sent_count+=1\n",
    "        speech_gesture_total_score+=score\n",
    "print(f\"Average METEOR score speech+gesture scenario: {(speech_gesture_total_score/speech_gesture_sent_count):.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72592bb9-ae3e-4412-b725-7ff3f57961dc",
   "metadata": {},
   "source": [
    "## Paired Bootstrap Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "168dbe62-f981-4117-a6e7-4e840a5e8eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_test_meteor(refs, sys1, sys2, num_samples=1000, seed=42):\n",
    "    \"\"\"\n",
    "    It tests how much better one system is than another (on average) and whether\n",
    "    that difference is significant\n",
    "    Args:\n",
    "        refs: list of references that you're checking against\n",
    "        sys1: list of tokenized candidates from first output\n",
    "        sys2: list of tokenized candidates from second output\n",
    "        num_samples: number of bootstrap resamples\n",
    "        seed: seed\n",
    "    Returns:\n",
    "        np.mean(diffs): average difference between system 1 and system 2 across all bootstrap samples\n",
    "        p_value: calculated p_value\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    diffs = []\n",
    "\n",
    "    n = len(sys1)\n",
    "    for _ in range(num_samples):\n",
    "        indices = [random.randint(0, n - 1) for _ in range(n)]  ## Generate n random indices 1000 times, with replacement\n",
    "        sample_refs = [refs[i] for i in indices]\n",
    "        sample_sys1 = [sys1[i] for i in indices]\n",
    "        sample_sys2 = [sys2[i] for i in indices]\n",
    "\n",
    "        meteor1 = np.mean([\n",
    "            meteor_score([sample_refs[i]], sample_sys1[i])\n",
    "            for i in range(n)\n",
    "        ]) \n",
    "\n",
    "        meteor2 = np.mean([\n",
    "            meteor_score([sample_refs[i]], sample_sys2[i])\n",
    "            for i in range(n)\n",
    "        ])\n",
    "\n",
    "        diffs.append(meteor1 - meteor2)\n",
    "\n",
    "    diffs = np.array(diffs)                     ## If diff>0 sys1 performed better, if diff<0 sys2 performed better\n",
    "    p_value = np.mean(diffs <= 0)               ## Calculate the proportion of bootstrap samples where sys1 was not better than sys2\n",
    "    return np.mean(diffs), p_value              ## Average observed BLEU difference between the systems, estimated significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "3db43267-e00c-4778-8ddb-0401a4abbdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech vs Gesture: ΔMETEOR = 0.3954, p = 0.0000\n"
     ]
    }
   ],
   "source": [
    "## Speech compared to gesture\n",
    "sg_mean_meteor, sg_p_meteor = bootstrap_test_meteor(sp_meteor_ref, sp_meteor_cand, gest_meteor_cand)\n",
    "print(f\"Speech vs Gesture: ΔMETEOR = {sg_mean_meteor:.4f}, p = {sg_p_meteor:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "6c5ee0fe-7578-48ba-baaf-a8967c300437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech vs Speech+Gesture: ΔMETEOR = 0.1492, p = 0.0000\n"
     ]
    }
   ],
   "source": [
    "## Speech compared to speech+gesture\n",
    "ssg_mean_meteor, ssg_p_meteor = bootstrap_test_meteor(sp_meteor_ref, sp_meteor_cand, sp_gest_meteor_cand)\n",
    "print(f\"Speech vs Speech+Gesture: ΔMETEOR = {ssg_mean_meteor:.4f}, p = {ssg_p_meteor:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "caa661ef-3709-473e-931c-0efa7531f034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesture vs Speech+Gesture: ΔMETEOR = -0.2461, p = 1.0000\n"
     ]
    }
   ],
   "source": [
    "## Gesture compared to speech+gesture\n",
    "## All references are the same so I reuse sp_meteor_ref\n",
    "gsg_mean_meteor, gsg_p_meteor = bootstrap_test_meteor(sp_meteor_ref, gest_meteor_cand, sp_gest_meteor_cand)\n",
    "print(f\"Gesture vs Speech+Gesture: ΔMETEOR = {gsg_mean_meteor:.4f}, p = {gsg_p_meteor:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188bd554-5026-4053-b59f-c670b4830055",
   "metadata": {},
   "source": [
    "## BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "a81f51ed-e88a-405d-967a-6172c0b3f236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['so put put a block on the back block good', 'so put put a block on the back block good', 'so put put a block on the back block good', 'so put put a block on the back block good', 'so put put a block on the back block good', 'so put put a block on the back block good', 'so put put a block on the back block good', 'so put put a block on the back block good', 'so put put a block on the back block good', 'put two blocks', 'put two blocks', 'put two blocks', 'put two blocks', 'put two blocks', 'put two blocks', 'put two blocks', 'put two blocks', 'put two blocks', 'um', 'um', 'um', 'um', 'um', 'um', 'um', 'um', 'um', 'and then put one on the top', 'and then put one on the top', 'and then put one on the top', 'and then put one on the top', 'and then put one on the top', 'and then put one on the top', 'and then put one on the top', 'and then put one on the top', 'and then put one on the top', \"no that doesn't look like it’s going to work\", \"no that doesn't look like it’s going to work\", \"no that doesn't look like it’s going to work\", \"no that doesn't look like it’s going to work\", \"no that doesn't look like it’s going to work\", \"no that doesn't look like it’s going to work\", \"no that doesn't look like it’s going to work\", \"no that doesn't look like it’s going to work\", \"no that doesn't look like it’s going to work\", 'yes', 'yes', 'yes', 'yes', 'yes']\n",
      "----------------------------\n",
      "['put the back block.', 'put the back block.', 'put the back block.', 'look at the location in front of you.', 'look at the location in front of you.', 'look over there.', 'put the block in front of you.', 'put the block in front of you.', 'put the block in front of you.', 'put two blocks.', 'put two blocks.', 'put two blocks.', 'put the block in the location, then put another block there.', 'put the block in that location.', 'put the block in that location.', 'put the two blocks down.', 'put the two blocks down.', 'put two blocks down, left.', 'um', 'um', 'um', 'put the block down.', 'put the block down.', 'put the block down.', 'you put the block in this location, and then you put the other block in that location.', \"you put the block and then you're going to put another one over here.\", 'you put the block, and then you will have a second block.', 'you put one on top then.', 'you put one on top then.', 'you put one on top then.', 'point to the location.', 'point to the location.', 'point to the location.', 'put one on top.', 'put one on top', 'put one on top.', 'no, that looks like work.', 'no, look that work.', 'no, that looks good.', \"i'm grabbing two blocks.\", \"i'm going to grab two blocks and close them.\", \"i'm grabbing two blocks.\", 'no, look at that work.', \"no, i'm looking at that work.\", 'no, look at that work.', 'yes', 'yes.', 'yes.', 'look up there.', 'look up there.']\n"
     ]
    }
   ],
   "source": [
    "## All sentences\n",
    "ref_and_transl_bert = []\n",
    "references = []\n",
    "candidates = []\n",
    "for item in results:\n",
    "    #print(item['sentence'], item['scenario'])\n",
    "    for key in [\"llama_1\", \"llama_2\", \"llama_3\"]:\n",
    "        #print(item[key])\n",
    "        try:\n",
    "            matches = re.findall(r'\"sentence\"\\s*:\\s*\"([^\"]+)\"', item[key])\n",
    "            for match in matches:\n",
    "                #print(match)\n",
    "                ref_and_transl_bert.append({\n",
    "                    \"reference\": item[\"sentence\"],\n",
    "                    \"scenario\": item['scenario'],\n",
    "                    \"translation\": match.lower()\n",
    "                })\n",
    "                references.append(item[\"sentence\"])\n",
    "                candidates.append(match.lower())\n",
    "                \n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"Failed to parse {key} {item[key]}\\nbecause: {e}.\")\n",
    "\n",
    "print(references[0:50])\n",
    "print(\"----------------------------\")\n",
    "print(candidates[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "5cdcaf46-2d76-404c-97fb-8596fbc34689",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1 = score(candidates, references, lang=\"en\", model_type=\"bert-base-uncased\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "27ca3211-7744-4e40-a9d2-63480378dcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanne\\anaconda3\\Lib\\site-packages\\bert_score\\score.py:316: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  fig.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_example(candidates[45], references[45], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "43885748-a32b-4613-ac1b-fd01b3896d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 score: 0.5382\n",
      "Average precision: 0.5371\n",
      "Average recall: 0.5455\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average F1 score: {f1.mean():.4f}\")\n",
    "print(f\"Average precision: {precision.mean():.4f}\")\n",
    "print(f\"Average recall: {recall.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "d1b73c2c-fe5e-4dfa-b2f0-443a07c48281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "Reference : so put put a block on the back block good\n",
      "Prediction: put the back block.\n",
      "BERTScore F1: 0.7119\n",
      "BERTScore precision: 0.7418\n",
      "BERTScore recall: 0.6844\n",
      "Example 2\n",
      "Reference : so put put a block on the back block good\n",
      "Prediction: put the back block.\n",
      "BERTScore F1: 0.7119\n",
      "BERTScore precision: 0.7418\n",
      "BERTScore recall: 0.6844\n",
      "Example 3\n",
      "Reference : so put put a block on the back block good\n",
      "Prediction: put the back block.\n",
      "BERTScore F1: 0.7119\n",
      "BERTScore precision: 0.7418\n",
      "BERTScore recall: 0.6844\n",
      "Example 4\n",
      "Reference : so put put a block on the back block good\n",
      "Prediction: look at the location in front of you.\n",
      "BERTScore F1: 0.4456\n",
      "BERTScore precision: 0.4315\n",
      "BERTScore recall: 0.4607\n",
      "Example 5\n",
      "Reference : so put put a block on the back block good\n",
      "Prediction: look at the location in front of you.\n",
      "BERTScore F1: 0.4456\n",
      "BERTScore precision: 0.4315\n",
      "BERTScore recall: 0.4607\n",
      "Example 6\n",
      "Reference : so put put a block on the back block good\n",
      "Prediction: look over there.\n",
      "BERTScore F1: 0.4180\n",
      "BERTScore precision: 0.4516\n",
      "BERTScore recall: 0.3890\n",
      "Example 7\n",
      "Reference : so put put a block on the back block good\n",
      "Prediction: put the block in front of you.\n",
      "BERTScore F1: 0.5696\n",
      "BERTScore precision: 0.5349\n",
      "BERTScore recall: 0.6091\n",
      "Example 8\n",
      "Reference : so put put a block on the back block good\n",
      "Prediction: put the block in front of you.\n",
      "BERTScore F1: 0.5696\n",
      "BERTScore precision: 0.5349\n",
      "BERTScore recall: 0.6091\n",
      "Example 9\n",
      "Reference : so put put a block on the back block good\n",
      "Prediction: put the block in front of you.\n",
      "BERTScore F1: 0.5696\n",
      "BERTScore precision: 0.5349\n",
      "BERTScore recall: 0.6091\n",
      "Example 10\n",
      "Reference : put two blocks\n",
      "Prediction: put two blocks.\n",
      "BERTScore F1: 0.9006\n",
      "BERTScore precision: 0.8708\n",
      "BERTScore recall: 0.9324\n",
      "Example 11\n",
      "Reference : put two blocks\n",
      "Prediction: put two blocks.\n",
      "BERTScore F1: 0.9006\n",
      "BERTScore precision: 0.8708\n",
      "BERTScore recall: 0.9324\n",
      "Example 12\n",
      "Reference : put two blocks\n",
      "Prediction: put two blocks.\n",
      "BERTScore F1: 0.9006\n",
      "BERTScore precision: 0.8708\n",
      "BERTScore recall: 0.9324\n",
      "Example 13\n",
      "Reference : put two blocks\n",
      "Prediction: put the block in the location, then put another block there.\n",
      "BERTScore F1: 0.5765\n",
      "BERTScore precision: 0.5168\n",
      "BERTScore recall: 0.6516\n",
      "Example 14\n",
      "Reference : put two blocks\n",
      "Prediction: put the block in that location.\n",
      "BERTScore F1: 0.5679\n",
      "BERTScore precision: 0.5191\n",
      "BERTScore recall: 0.6267\n",
      "Example 15\n",
      "Reference : put two blocks\n",
      "Prediction: put the block in that location.\n",
      "BERTScore F1: 0.5679\n",
      "BERTScore precision: 0.5191\n",
      "BERTScore recall: 0.6267\n",
      "Example 16\n",
      "Reference : put two blocks\n",
      "Prediction: put the two blocks down.\n",
      "BERTScore F1: 0.6915\n",
      "BERTScore precision: 0.6461\n",
      "BERTScore recall: 0.7437\n",
      "Example 17\n",
      "Reference : put two blocks\n",
      "Prediction: put the two blocks down.\n",
      "BERTScore F1: 0.6915\n",
      "BERTScore precision: 0.6461\n",
      "BERTScore recall: 0.7437\n",
      "Example 18\n",
      "Reference : put two blocks\n",
      "Prediction: put two blocks down, left.\n",
      "BERTScore F1: 0.6679\n",
      "BERTScore precision: 0.5919\n",
      "BERTScore recall: 0.7663\n",
      "Example 19\n",
      "Reference : um\n",
      "Prediction: um\n",
      "BERTScore F1: 1.0000\n",
      "BERTScore precision: 1.0000\n",
      "BERTScore recall: 1.0000\n",
      "Example 20\n",
      "Reference : um\n",
      "Prediction: um\n",
      "BERTScore F1: 1.0000\n",
      "BERTScore precision: 1.0000\n",
      "BERTScore recall: 1.0000\n",
      "Example 21\n",
      "Reference : um\n",
      "Prediction: um\n",
      "BERTScore F1: 1.0000\n",
      "BERTScore precision: 1.0000\n",
      "BERTScore recall: 1.0000\n",
      "Example 22\n",
      "Reference : um\n",
      "Prediction: put the block down.\n",
      "BERTScore F1: 0.3321\n",
      "BERTScore precision: 0.2885\n",
      "BERTScore recall: 0.3914\n",
      "Example 23\n",
      "Reference : um\n",
      "Prediction: put the block down.\n",
      "BERTScore F1: 0.3321\n",
      "BERTScore precision: 0.2885\n",
      "BERTScore recall: 0.3914\n",
      "Example 24\n",
      "Reference : um\n",
      "Prediction: put the block down.\n",
      "BERTScore F1: 0.3321\n",
      "BERTScore precision: 0.2885\n",
      "BERTScore recall: 0.3914\n",
      "Example 25\n",
      "Reference : um\n",
      "Prediction: you put the block in this location, and then you put the other block in that location.\n",
      "BERTScore F1: 0.3218\n",
      "BERTScore precision: 0.2917\n",
      "BERTScore recall: 0.3587\n",
      "Example 26\n",
      "Reference : um\n",
      "Prediction: you put the block and then you're going to put another one over here.\n",
      "BERTScore F1: 0.3049\n",
      "BERTScore precision: 0.2677\n",
      "BERTScore recall: 0.3541\n",
      "Example 27\n",
      "Reference : um\n",
      "Prediction: you put the block, and then you will have a second block.\n",
      "BERTScore F1: 0.3076\n",
      "BERTScore precision: 0.2842\n",
      "BERTScore recall: 0.3351\n",
      "Example 28\n",
      "Reference : and then put one on the top\n",
      "Prediction: you put one on top then.\n",
      "BERTScore F1: 0.7217\n",
      "BERTScore precision: 0.7043\n",
      "BERTScore recall: 0.7399\n",
      "Example 29\n",
      "Reference : and then put one on the top\n",
      "Prediction: you put one on top then.\n",
      "BERTScore F1: 0.7217\n",
      "BERTScore precision: 0.7043\n",
      "BERTScore recall: 0.7399\n",
      "Example 30\n",
      "Reference : and then put one on the top\n",
      "Prediction: you put one on top then.\n",
      "BERTScore F1: 0.7217\n",
      "BERTScore precision: 0.7043\n",
      "BERTScore recall: 0.7399\n",
      "Example 31\n",
      "Reference : and then put one on the top\n",
      "Prediction: point to the location.\n",
      "BERTScore F1: 0.4549\n",
      "BERTScore precision: 0.4577\n",
      "BERTScore recall: 0.4522\n",
      "Example 32\n",
      "Reference : and then put one on the top\n",
      "Prediction: point to the location.\n",
      "BERTScore F1: 0.4549\n",
      "BERTScore precision: 0.4577\n",
      "BERTScore recall: 0.4522\n",
      "Example 33\n",
      "Reference : and then put one on the top\n",
      "Prediction: point to the location.\n",
      "BERTScore F1: 0.4549\n",
      "BERTScore precision: 0.4577\n",
      "BERTScore recall: 0.4522\n",
      "Example 34\n",
      "Reference : and then put one on the top\n",
      "Prediction: put one on top.\n",
      "BERTScore F1: 0.7648\n",
      "BERTScore precision: 0.7890\n",
      "BERTScore recall: 0.7421\n",
      "Example 35\n",
      "Reference : and then put one on the top\n",
      "Prediction: put one on top\n",
      "BERTScore F1: 0.8115\n",
      "BERTScore precision: 0.8877\n",
      "BERTScore recall: 0.7474\n",
      "Example 36\n",
      "Reference : and then put one on the top\n",
      "Prediction: put one on top.\n",
      "BERTScore F1: 0.7648\n",
      "BERTScore precision: 0.7890\n",
      "BERTScore recall: 0.7421\n",
      "Example 37\n",
      "Reference : no that doesn't look like it’s going to work\n",
      "Prediction: no, that looks like work.\n",
      "BERTScore F1: 0.5318\n",
      "BERTScore precision: 0.5748\n",
      "BERTScore recall: 0.4949\n",
      "Example 38\n",
      "Reference : no that doesn't look like it’s going to work\n",
      "Prediction: no, look that work.\n",
      "BERTScore F1: 0.4298\n",
      "BERTScore precision: 0.5074\n",
      "BERTScore recall: 0.3728\n",
      "Example 39\n",
      "Reference : no that doesn't look like it’s going to work\n",
      "Prediction: no, that looks good.\n",
      "BERTScore F1: 0.5105\n",
      "BERTScore precision: 0.5638\n",
      "BERTScore recall: 0.4665\n",
      "Example 40\n",
      "Reference : no that doesn't look like it’s going to work\n",
      "Prediction: i'm grabbing two blocks.\n",
      "BERTScore F1: 0.3919\n",
      "BERTScore precision: 0.4234\n",
      "BERTScore recall: 0.3647\n",
      "Example 41\n",
      "Reference : no that doesn't look like it’s going to work\n",
      "Prediction: i'm going to grab two blocks and close them.\n",
      "BERTScore F1: 0.4202\n",
      "BERTScore precision: 0.4174\n",
      "BERTScore recall: 0.4230\n",
      "Example 42\n",
      "Reference : no that doesn't look like it’s going to work\n",
      "Prediction: i'm grabbing two blocks.\n",
      "BERTScore F1: 0.3919\n",
      "BERTScore precision: 0.4234\n",
      "BERTScore recall: 0.3647\n",
      "Example 43\n",
      "Reference : no that doesn't look like it’s going to work\n",
      "Prediction: no, look at that work.\n",
      "BERTScore F1: 0.3709\n",
      "BERTScore precision: 0.4170\n",
      "BERTScore recall: 0.3340\n",
      "Example 44\n",
      "Reference : no that doesn't look like it’s going to work\n",
      "Prediction: no, i'm looking at that work.\n",
      "BERTScore F1: 0.4816\n",
      "BERTScore precision: 0.5043\n",
      "BERTScore recall: 0.4609\n",
      "Example 45\n",
      "Reference : no that doesn't look like it’s going to work\n",
      "Prediction: no, look at that work.\n",
      "BERTScore F1: 0.3709\n",
      "BERTScore precision: 0.4170\n",
      "BERTScore recall: 0.3340\n",
      "Example 46\n",
      "Reference : yes\n",
      "Prediction: yes\n",
      "BERTScore F1: 1.0000\n",
      "BERTScore precision: 1.0000\n",
      "BERTScore recall: 1.0000\n",
      "Example 47\n",
      "Reference : yes\n",
      "Prediction: yes.\n",
      "BERTScore F1: 0.7358\n",
      "BERTScore precision: 0.6900\n",
      "BERTScore recall: 0.7881\n",
      "Example 48\n",
      "Reference : yes\n",
      "Prediction: yes.\n",
      "BERTScore F1: 0.7358\n",
      "BERTScore precision: 0.6900\n",
      "BERTScore recall: 0.7881\n",
      "Example 49\n",
      "Reference : yes\n",
      "Prediction: look up there.\n",
      "BERTScore F1: 0.3706\n",
      "BERTScore precision: 0.3254\n",
      "BERTScore recall: 0.4303\n",
      "Example 50\n",
      "Reference : yes\n",
      "Prediction: look up there.\n",
      "BERTScore F1: 0.3706\n",
      "BERTScore precision: 0.3254\n",
      "BERTScore recall: 0.4303\n",
      "Example 51\n",
      "Reference : yes\n",
      "Prediction: look at that.\n",
      "BERTScore F1: 0.3393\n",
      "BERTScore precision: 0.2834\n",
      "BERTScore recall: 0.4226\n",
      "Example 52\n",
      "Reference : yes\n",
      "Prediction: point to the location.\n",
      "BERTScore F1: 0.3513\n",
      "BERTScore precision: 0.3295\n",
      "BERTScore recall: 0.3762\n",
      "Example 53\n",
      "Reference : yes\n",
      "Prediction: look up.\n",
      "BERTScore F1: 0.3892\n",
      "BERTScore precision: 0.3519\n",
      "BERTScore recall: 0.4354\n",
      "Example 54\n",
      "Reference : yes\n",
      "Prediction: point to the location.\n",
      "BERTScore F1: 0.3513\n",
      "BERTScore precision: 0.3295\n",
      "BERTScore recall: 0.3762\n",
      "Example 55\n",
      "Reference : so jiggle the go\n",
      "Prediction: jiggle!\n",
      "BERTScore F1: 0.6222\n",
      "BERTScore precision: 0.6881\n",
      "BERTScore recall: 0.5677\n",
      "Example 56\n",
      "Reference : so jiggle the go\n",
      "Prediction: jiggle!\n",
      "BERTScore F1: 0.6222\n",
      "BERTScore precision: 0.6881\n",
      "BERTScore recall: 0.5677\n",
      "Example 57\n",
      "Reference : so jiggle the go\n",
      "Prediction: jiggle!\n",
      "BERTScore F1: 0.6222\n",
      "BERTScore precision: 0.6881\n",
      "BERTScore recall: 0.5677\n",
      "Example 58\n",
      "Reference : so jiggle the go\n",
      "Prediction: point to the block, then count them.\n",
      "BERTScore F1: 0.4448\n",
      "BERTScore precision: 0.4413\n",
      "BERTScore recall: 0.4482\n",
      "Example 59\n",
      "Reference : so jiggle the go\n",
      "Prediction: point to the block, count one.\n",
      "BERTScore F1: 0.4740\n",
      "BERTScore precision: 0.4685\n",
      "BERTScore recall: 0.4796\n",
      "Example 60\n",
      "Reference : so jiggle the go\n",
      "Prediction: point to the block in front of you, then count them.\n",
      "BERTScore F1: 0.3975\n",
      "BERTScore precision: 0.3713\n",
      "BERTScore recall: 0.4277\n",
      "Example 61\n",
      "Reference : so jiggle the go\n",
      "Prediction: you jiggle the block in front of you, then count how many blocks are to your left and right.\n",
      "BERTScore F1: 0.4680\n",
      "BERTScore precision: 0.3842\n",
      "BERTScore recall: 0.5988\n",
      "Example 62\n",
      "Reference : so jiggle the go\n",
      "Prediction: count the blocks in front of you.\n",
      "BERTScore F1: 0.3981\n",
      "BERTScore precision: 0.3691\n",
      "BERTScore recall: 0.4320\n",
      "Example 63\n",
      "Reference : so jiggle the go\n",
      "Prediction: count the blocks.\n",
      "BERTScore F1: 0.5054\n",
      "BERTScore precision: 0.5241\n",
      "BERTScore recall: 0.4879\n",
      "Example 64\n",
      "Reference : good enough\n",
      "Prediction: it is good enough.\n",
      "BERTScore F1: 0.6136\n",
      "BERTScore precision: 0.5294\n",
      "BERTScore recall: 0.7298\n",
      "Example 65\n",
      "Reference : good enough\n",
      "Prediction: it is good enough.\n",
      "BERTScore F1: 0.6136\n",
      "BERTScore precision: 0.5294\n",
      "BERTScore recall: 0.7298\n",
      "Example 66\n",
      "Reference : good enough\n",
      "Prediction: it is good enough.\n",
      "BERTScore F1: 0.6136\n",
      "BERTScore precision: 0.5294\n",
      "BERTScore recall: 0.7298\n",
      "Example 67\n",
      "Reference : good enough\n",
      "Prediction: you're okay.\n",
      "BERTScore F1: 0.3522\n",
      "BERTScore precision: 0.3203\n",
      "BERTScore recall: 0.3911\n",
      "Example 68\n",
      "Reference : good enough\n",
      "Prediction: it's okay.\n",
      "BERTScore F1: 0.3387\n",
      "BERTScore precision: 0.2990\n",
      "BERTScore recall: 0.3907\n",
      "Example 69\n",
      "Reference : good enough\n",
      "Prediction: it's okay.\n",
      "BERTScore F1: 0.3387\n",
      "BERTScore precision: 0.2990\n",
      "BERTScore recall: 0.3907\n",
      "Example 70\n",
      "Reference : good enough\n",
      "Prediction: that's okay.\n",
      "BERTScore F1: 0.3755\n",
      "BERTScore precision: 0.3520\n",
      "BERTScore recall: 0.4024\n",
      "Example 71\n",
      "Reference : good enough\n",
      "Prediction: that's good enough.\n",
      "BERTScore F1: 0.5736\n",
      "BERTScore precision: 0.4908\n",
      "BERTScore recall: 0.6901\n",
      "Example 72\n",
      "Reference : good enough\n",
      "Prediction: that's good enough.\n",
      "BERTScore F1: 0.5736\n",
      "BERTScore precision: 0.4908\n",
      "BERTScore recall: 0.6901\n",
      "Example 73\n",
      "Reference : and then jiggle the two in front of them\n",
      "Prediction: you should jiggle them in the front then.\n",
      "BERTScore F1: 0.5374\n",
      "BERTScore precision: 0.5370\n",
      "BERTScore recall: 0.5379\n",
      "Example 74\n",
      "Reference : and then jiggle the two in front of them\n",
      "Prediction: you should jiggle them in front of you then.\n",
      "BERTScore F1: 0.6162\n",
      "BERTScore precision: 0.5956\n",
      "BERTScore recall: 0.6383\n",
      "Example 75\n",
      "Reference : and then jiggle the two in front of them\n",
      "Prediction: you should jiggle them in front of the others then.\n",
      "BERTScore F1: 0.5774\n",
      "BERTScore precision: 0.5547\n",
      "BERTScore recall: 0.6020\n",
      "Example 76\n",
      "Reference : and then jiggle the two in front of them\n",
      "Prediction: point to the block.\n",
      "BERTScore F1: 0.4564\n",
      "BERTScore precision: 0.4916\n",
      "BERTScore recall: 0.4259\n",
      "Example 77\n",
      "Reference : and then jiggle the two in front of them\n",
      "Prediction: point down to the block.\n",
      "BERTScore F1: 0.4245\n",
      "BERTScore precision: 0.4426\n",
      "BERTScore recall: 0.4078\n",
      "Example 78\n",
      "Reference : and then jiggle the two in front of them\n",
      "Prediction: point to the block on the floor.\n",
      "BERTScore F1: 0.4331\n",
      "BERTScore precision: 0.4473\n",
      "BERTScore recall: 0.4198\n",
      "Example 79\n",
      "Reference : and then jiggle the two in front of them\n",
      "Prediction: you shake them, then you move down.\n",
      "BERTScore F1: 0.4703\n",
      "BERTScore precision: 0.4982\n",
      "BERTScore recall: 0.4454\n",
      "Example 80\n",
      "Reference : and then jiggle the two in front of them\n",
      "Prediction: you shake them, then you slide them forward.\n",
      "BERTScore F1: 0.4998\n",
      "BERTScore precision: 0.5324\n",
      "BERTScore recall: 0.4710\n",
      "Example 81\n",
      "Reference : and then jiggle the two in front of them\n",
      "Prediction: you're shaking them, then you slide forward and point to them.\n",
      "BERTScore F1: 0.4564\n",
      "BERTScore precision: 0.4534\n",
      "BERTScore recall: 0.4595\n",
      "Example 82\n",
      "Reference : take another block put it next to it\n",
      "Prediction: take another block and put it next to the one.\n",
      "BERTScore F1: 0.7816\n",
      "BERTScore precision: 0.7507\n",
      "BERTScore recall: 0.8151\n",
      "Example 83\n",
      "Reference : take another block put it next to it\n",
      "Prediction: take another block and put it next to the one.\n",
      "BERTScore F1: 0.7816\n",
      "BERTScore precision: 0.7507\n",
      "BERTScore recall: 0.8151\n",
      "Example 84\n",
      "Reference : take another block put it next to it\n",
      "Prediction: take another block and put it next to it.\n",
      "BERTScore F1: 0.8436\n",
      "BERTScore precision: 0.8179\n",
      "BERTScore recall: 0.8711\n",
      "Example 85\n",
      "Reference : take another block put it next to it\n",
      "Prediction: point to the location in front of you, then put it down.\n",
      "BERTScore F1: 0.5075\n",
      "BERTScore precision: 0.4818\n",
      "BERTScore recall: 0.5361\n",
      "Example 86\n",
      "Reference : take another block put it next to it\n",
      "Prediction: point to the location, then put something there.\n",
      "BERTScore F1: 0.5086\n",
      "BERTScore precision: 0.5049\n",
      "BERTScore recall: 0.5125\n",
      "Example 87\n",
      "Reference : take another block put it next to it\n",
      "Prediction: point to the location and put it there, then spread your arms apart.\n",
      "BERTScore F1: 0.5060\n",
      "BERTScore precision: 0.4756\n",
      "BERTScore recall: 0.5405\n",
      "Example 88\n",
      "Reference : take another block put it next to it\n",
      "Prediction: take another block and put it next to it.\n",
      "BERTScore F1: 0.8436\n",
      "BERTScore precision: 0.8179\n",
      "BERTScore recall: 0.8711\n",
      "Example 89\n",
      "Reference : take another block put it next to it\n",
      "Prediction: take another block and put it next to it.\n",
      "BERTScore F1: 0.8436\n",
      "BERTScore precision: 0.8179\n",
      "BERTScore recall: 0.8711\n",
      "Example 90\n",
      "Reference : take another block put it next to it\n",
      "Prediction: take another block and put it next to the other one.\n",
      "BERTScore F1: 0.7701\n",
      "BERTScore precision: 0.7347\n",
      "BERTScore recall: 0.8091\n",
      "Example 91\n",
      "Reference : okay\n",
      "Prediction: okay\n",
      "BERTScore F1: 1.0000\n",
      "BERTScore precision: 1.0000\n",
      "BERTScore recall: 1.0000\n",
      "Example 92\n",
      "Reference : okay\n",
      "Prediction: okay\n",
      "BERTScore F1: 1.0000\n",
      "BERTScore precision: 1.0000\n",
      "BERTScore recall: 1.0000\n",
      "Example 93\n",
      "Reference : okay\n",
      "Prediction: okay\n",
      "BERTScore F1: 1.0000\n",
      "BERTScore precision: 1.0000\n",
      "BERTScore recall: 1.0000\n",
      "Example 94\n",
      "Reference : okay\n",
      "Prediction: point to the location in front of you.\n",
      "BERTScore F1: 0.3044\n",
      "BERTScore precision: 0.2419\n",
      "BERTScore recall: 0.4104\n",
      "Example 95\n",
      "Reference : okay\n",
      "Prediction: point to the location.\n",
      "BERTScore F1: 0.3463\n",
      "BERTScore precision: 0.3067\n",
      "BERTScore recall: 0.3975\n",
      "Example 96\n",
      "Reference : okay\n",
      "Prediction: point to the location.\n",
      "BERTScore F1: 0.3463\n",
      "BERTScore precision: 0.3067\n",
      "BERTScore recall: 0.3975\n",
      "Example 97\n",
      "Reference : okay\n",
      "Prediction: i'm putting it over there.\n",
      "BERTScore F1: 0.3110\n",
      "BERTScore precision: 0.2426\n",
      "BERTScore recall: 0.4332\n",
      "Example 98\n",
      "Reference : okay\n",
      "Prediction: you're putting it over there.\n",
      "BERTScore F1: 0.3169\n",
      "BERTScore precision: 0.2431\n",
      "BERTScore recall: 0.4549\n",
      "Example 99\n",
      "Reference : okay\n",
      "Prediction: you're putting it here.\n",
      "BERTScore F1: 0.3387\n",
      "BERTScore precision: 0.2680\n",
      "BERTScore recall: 0.4603\n",
      "Example 100\n",
      "Reference : one block on top of each of those two\n",
      "Prediction: there is one block on top of each other two blocks.\n",
      "BERTScore F1: 0.6628\n",
      "BERTScore precision: 0.6508\n",
      "BERTScore recall: 0.6752\n",
      "Example 101\n",
      "Reference : one block on top of each of those two\n",
      "Prediction: there is one block on top of each other two blocks.\n",
      "BERTScore F1: 0.6628\n",
      "BERTScore precision: 0.6508\n",
      "BERTScore recall: 0.6752\n",
      "Example 102\n",
      "Reference : one block on top of each of those two\n",
      "Prediction: there is one block on top of each of the two blocks that.\n",
      "BERTScore F1: 0.7388\n",
      "BERTScore precision: 0.6958\n",
      "BERTScore recall: 0.7875\n",
      "Example 103\n",
      "Reference : one block on top of each of those two\n",
      "Prediction: put it over there.\n",
      "BERTScore F1: 0.3628\n",
      "BERTScore precision: 0.3975\n",
      "BERTScore recall: 0.3337\n",
      "Example 104\n",
      "Reference : one block on top of each of those two\n",
      "Prediction: put it on the location.\n",
      "BERTScore F1: 0.3900\n",
      "BERTScore precision: 0.4322\n",
      "BERTScore recall: 0.3553\n",
      "Example 105\n",
      "Reference : one block on top of each of those two\n",
      "Prediction: put the block on the left.\n",
      "BERTScore F1: 0.5030\n",
      "BERTScore precision: 0.5422\n",
      "BERTScore recall: 0.4691\n",
      "Example 106\n",
      "Reference : one block on top of each of those two\n",
      "Prediction: put that block on top of each other.\n",
      "BERTScore F1: 0.5897\n",
      "BERTScore precision: 0.5921\n",
      "BERTScore recall: 0.5872\n",
      "Example 107\n",
      "Reference : one block on top of each of those two\n",
      "Prediction: put the block on top of each other.\n",
      "BERTScore F1: 0.5740\n",
      "BERTScore precision: 0.5884\n",
      "BERTScore recall: 0.5603\n",
      "Example 108\n",
      "Reference : one block on top of each of those two\n",
      "Prediction: put that on top of each other.\n",
      "BERTScore F1: 0.5302\n",
      "BERTScore precision: 0.5425\n",
      "BERTScore recall: 0.5185\n",
      "Example 109\n",
      "Reference : perfect grab\n",
      "Prediction: it's perfect.\n",
      "BERTScore F1: 0.6244\n",
      "BERTScore precision: 0.5428\n",
      "BERTScore recall: 0.7350\n",
      "Example 110\n",
      "Reference : perfect grab\n",
      "Prediction: it's perfect.\n",
      "BERTScore F1: 0.6244\n",
      "BERTScore precision: 0.5428\n",
      "BERTScore recall: 0.7350\n",
      "Example 111\n",
      "Reference : perfect grab\n",
      "Prediction: it's perfect.\n",
      "BERTScore F1: 0.6244\n",
      "BERTScore precision: 0.5428\n",
      "BERTScore recall: 0.7350\n",
      "Example 112\n",
      "Reference : perfect grab\n",
      "Prediction: it's okay.\n",
      "BERTScore F1: 0.4233\n",
      "BERTScore precision: 0.3613\n",
      "BERTScore recall: 0.5110\n",
      "Example 113\n",
      "Reference : perfect grab\n",
      "Prediction: it's okay.\n",
      "BERTScore F1: 0.4233\n",
      "BERTScore precision: 0.3613\n",
      "BERTScore recall: 0.5110\n",
      "Example 114\n",
      "Reference : perfect grab\n",
      "Prediction: it's okay.\n",
      "BERTScore F1: 0.4233\n",
      "BERTScore precision: 0.3613\n",
      "BERTScore recall: 0.5110\n",
      "Example 115\n",
      "Reference : perfect grab\n",
      "Prediction: it is okay.\n",
      "BERTScore F1: 0.4797\n",
      "BERTScore precision: 0.4264\n",
      "BERTScore recall: 0.5482\n",
      "Example 116\n",
      "Reference : perfect grab\n",
      "Prediction: it's okay.\n",
      "BERTScore F1: 0.4233\n",
      "BERTScore precision: 0.3613\n",
      "BERTScore recall: 0.5110\n",
      "Example 117\n",
      "Reference : perfect grab\n",
      "Prediction: it is okay.\n",
      "BERTScore F1: 0.4797\n",
      "BERTScore precision: 0.4264\n",
      "BERTScore recall: 0.5482\n",
      "Example 118\n",
      "Reference : and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "Prediction: you take hold of one thing and then push it forward slightly to put it on the diagonal.\n",
      "BERTScore F1: 0.6988\n",
      "BERTScore precision: 0.7238\n",
      "BERTScore recall: 0.6755\n",
      "Example 119\n",
      "Reference : and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "Prediction: you take hold of one thing, then push it forward slightly on the diagonal.\n",
      "BERTScore F1: 0.6531\n",
      "BERTScore precision: 0.6787\n",
      "BERTScore recall: 0.6294\n",
      "Example 120\n",
      "Reference : and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "Prediction: you take hold of one thing, and then push it forward slightly on the diagonal.\n",
      "BERTScore F1: 0.6606\n",
      "BERTScore precision: 0.6817\n",
      "BERTScore recall: 0.6409\n",
      "Example 121\n",
      "Reference : and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "Prediction: i'm going to slide this forward, touch it, and then hold still.\n",
      "BERTScore F1: 0.5483\n",
      "BERTScore precision: 0.5539\n",
      "BERTScore recall: 0.5428\n",
      "Example 122\n",
      "Reference : and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "Prediction: i'm going to show you something, and then i'll close it and open it again.\n",
      "BERTScore F1: 0.5147\n",
      "BERTScore precision: 0.5184\n",
      "BERTScore recall: 0.5111\n",
      "Example 123\n",
      "Reference : and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "Prediction: i'm going to take this and put it in my pocket.\n",
      "BERTScore F1: 0.4986\n",
      "BERTScore precision: 0.5206\n",
      "BERTScore recall: 0.4783\n",
      "Example 124\n",
      "Reference : and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "Prediction: you take hold of it and push it forward slightly on the diagonal.\n",
      "BERTScore F1: 0.6832\n",
      "BERTScore precision: 0.7349\n",
      "BERTScore recall: 0.6383\n",
      "Example 125\n",
      "Reference : and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "Prediction: you take hold of it and push it forward slightly on the diagonal.\n",
      "BERTScore F1: 0.6832\n",
      "BERTScore precision: 0.7349\n",
      "BERTScore recall: 0.6383\n",
      "Example 126\n",
      "Reference : and then you’re going to take one of them and push it slightly forward so it's on the diagonal\n",
      "Prediction: you take hold of it and push it forward slightly diagonally.\n",
      "BERTScore F1: 0.6585\n",
      "BERTScore precision: 0.7172\n",
      "BERTScore recall: 0.6087\n",
      "Example 127\n",
      "Reference : only two of them\n",
      "Prediction: they are the only ones.\n",
      "BERTScore F1: 0.4646\n",
      "BERTScore precision: 0.4657\n",
      "BERTScore recall: 0.4635\n",
      "Example 128\n",
      "Reference : only two of them\n",
      "Prediction: they are the only ones.\n",
      "BERTScore F1: 0.4646\n",
      "BERTScore precision: 0.4657\n",
      "BERTScore recall: 0.4635\n",
      "Example 129\n",
      "Reference : only two of them\n",
      "Prediction: they are the only ones.\n",
      "BERTScore F1: 0.4646\n",
      "BERTScore precision: 0.4657\n",
      "BERTScore recall: 0.4635\n",
      "Example 130\n",
      "Reference : only two of them\n",
      "Prediction: i don't understand.\n",
      "BERTScore F1: 0.3063\n",
      "BERTScore precision: 0.3010\n",
      "BERTScore recall: 0.3119\n",
      "Example 131\n",
      "Reference : only two of them\n",
      "Prediction: let's go\n",
      "BERTScore F1: 0.2382\n",
      "BERTScore precision: 0.2225\n",
      "BERTScore recall: 0.2563\n",
      "Example 132\n",
      "Reference : only two of them\n",
      "Prediction: let's go\n",
      "BERTScore F1: 0.2382\n",
      "BERTScore precision: 0.2225\n",
      "BERTScore recall: 0.2563\n",
      "Example 133\n",
      "Reference : only two of them\n",
      "Prediction: they are only two.\n",
      "BERTScore F1: 0.6225\n",
      "BERTScore precision: 0.6166\n",
      "BERTScore recall: 0.6284\n",
      "Example 134\n",
      "Reference : only two of them\n",
      "Prediction: they are only two.\n",
      "BERTScore F1: 0.6225\n",
      "BERTScore precision: 0.6166\n",
      "BERTScore recall: 0.6284\n",
      "Example 135\n",
      "Reference : only two of them\n",
      "Prediction: they are only two.\n",
      "BERTScore F1: 0.6225\n",
      "BERTScore precision: 0.6166\n",
      "BERTScore recall: 0.6284\n",
      "Example 136\n",
      "Reference : place it on the two that are diagonal and\n",
      "Prediction: you place it on the diagonal.\n",
      "BERTScore F1: 0.7215\n",
      "BERTScore precision: 0.7592\n",
      "BERTScore recall: 0.6874\n",
      "Example 137\n",
      "Reference : place it on the two that are diagonal and\n",
      "Prediction: you place it on the diagonal.\n",
      "BERTScore F1: 0.7215\n",
      "BERTScore precision: 0.7592\n",
      "BERTScore recall: 0.6874\n",
      "Example 138\n",
      "Reference : place it on the two that are diagonal and\n",
      "Prediction: you place it on the diagonal.\n",
      "BERTScore F1: 0.7215\n",
      "BERTScore precision: 0.7592\n",
      "BERTScore recall: 0.6874\n",
      "Example 139\n",
      "Reference : place it on the two that are diagonal and\n",
      "Prediction: point to the left, then down.\n",
      "BERTScore F1: 0.4762\n",
      "BERTScore precision: 0.4768\n",
      "BERTScore recall: 0.4756\n",
      "Example 140\n",
      "Reference : place it on the two that are diagonal and\n",
      "Prediction: point to the left, then point down.\n",
      "BERTScore F1: 0.5072\n",
      "BERTScore precision: 0.5200\n",
      "BERTScore recall: 0.4950\n",
      "Example 141\n",
      "Reference : place it on the two that are diagonal and\n",
      "Prediction: point to the left, then point down.\n",
      "BERTScore F1: 0.5072\n",
      "BERTScore precision: 0.5200\n",
      "BERTScore recall: 0.4950\n",
      "Example 142\n",
      "Reference : place it on the two that are diagonal and\n",
      "Prediction: point it down there.\n",
      "BERTScore F1: 0.5670\n",
      "BERTScore precision: 0.6463\n",
      "BERTScore recall: 0.5051\n",
      "Example 143\n",
      "Reference : place it on the two that are diagonal and\n",
      "Prediction: point it down there.\n",
      "BERTScore F1: 0.5670\n",
      "BERTScore precision: 0.6463\n",
      "BERTScore recall: 0.5051\n",
      "Example 144\n",
      "Reference : place it on the two that are diagonal and\n",
      "Prediction: point it down there.\n",
      "BERTScore F1: 0.5670\n",
      "BERTScore precision: 0.6463\n",
      "BERTScore recall: 0.5051\n",
      "Example 145\n",
      "Reference : flip those two\n",
      "Prediction: you flip that.\n",
      "BERTScore F1: 0.5557\n",
      "BERTScore precision: 0.5361\n",
      "BERTScore recall: 0.5768\n",
      "Example 146\n",
      "Reference : flip those two\n",
      "Prediction: flip that.\n",
      "BERTScore F1: 0.6742\n",
      "BERTScore precision: 0.6856\n",
      "BERTScore recall: 0.6633\n",
      "Example 147\n",
      "Reference : flip those two\n",
      "Prediction: flip that.\n",
      "BERTScore F1: 0.6742\n",
      "BERTScore precision: 0.6856\n",
      "BERTScore recall: 0.6633\n",
      "Example 148\n",
      "Reference : flip those two\n",
      "Prediction: move them this way, like you had it before.\n",
      "BERTScore F1: 0.3732\n",
      "BERTScore precision: 0.3055\n",
      "BERTScore recall: 0.4793\n",
      "Example 149\n",
      "Reference : flip those two\n",
      "Prediction: move the object back, no.\n",
      "BERTScore F1: 0.4168\n",
      "BERTScore precision: 0.3790\n",
      "BERTScore recall: 0.4630\n",
      "Example 150\n",
      "Reference : flip those two\n",
      "Prediction: move your hands back, no.\n",
      "BERTScore F1: 0.4039\n",
      "BERTScore precision: 0.3731\n",
      "BERTScore recall: 0.4403\n",
      "Example 151\n",
      "Reference : flip those two\n",
      "Prediction: flip that over.\n",
      "BERTScore F1: 0.6569\n",
      "BERTScore precision: 0.6356\n",
      "BERTScore recall: 0.6797\n",
      "Example 152\n",
      "Reference : flip those two\n",
      "Prediction: flip that over.\n",
      "BERTScore F1: 0.6569\n",
      "BERTScore precision: 0.6356\n",
      "BERTScore recall: 0.6797\n",
      "Example 153\n",
      "Reference : flip those two\n",
      "Prediction: flip that over.\n",
      "BERTScore F1: 0.6569\n",
      "BERTScore precision: 0.6356\n",
      "BERTScore recall: 0.6797\n",
      "Example 154\n",
      "Reference : keep going a little bit more\n",
      "Prediction: you keep going a little more.\n",
      "BERTScore F1: 0.7890\n",
      "BERTScore precision: 0.7609\n",
      "BERTScore recall: 0.8192\n",
      "Example 155\n",
      "Reference : keep going a little bit more\n",
      "Prediction: you keep going a little more.\n",
      "BERTScore F1: 0.7890\n",
      "BERTScore precision: 0.7609\n",
      "BERTScore recall: 0.8192\n",
      "Example 156\n",
      "Reference : keep going a little bit more\n",
      "Prediction: you keep going a bit more.\n",
      "BERTScore F1: 0.7861\n",
      "BERTScore precision: 0.7652\n",
      "BERTScore recall: 0.8081\n",
      "Example 157\n",
      "Reference : keep going a little bit more\n",
      "Prediction: they're going to be all connected.\n",
      "BERTScore F1: 0.3004\n",
      "BERTScore precision: 0.3001\n",
      "BERTScore recall: 0.3008\n",
      "Example 158\n",
      "Reference : keep going a little bit more\n",
      "Prediction: they're going to rotate.\n",
      "BERTScore F1: 0.3430\n",
      "BERTScore precision: 0.3712\n",
      "BERTScore recall: 0.3187\n",
      "Example 159\n",
      "Reference : keep going a little bit more\n",
      "Prediction: they are going to be all connected.\n",
      "BERTScore F1: 0.3064\n",
      "BERTScore precision: 0.3139\n",
      "BERTScore recall: 0.2992\n",
      "Example 160\n",
      "Reference : keep going a little bit more\n",
      "Prediction: go more slowly.\n",
      "BERTScore F1: 0.5737\n",
      "BERTScore precision: 0.6011\n",
      "BERTScore recall: 0.5486\n",
      "Example 161\n",
      "Reference : keep going a little bit more\n",
      "Prediction: you go more slowly.\n",
      "BERTScore F1: 0.4967\n",
      "BERTScore precision: 0.5316\n",
      "BERTScore recall: 0.4661\n",
      "Example 162\n",
      "Reference : keep going a little bit more\n",
      "Prediction: you go more slowly.\n",
      "BERTScore F1: 0.4967\n",
      "BERTScore precision: 0.5316\n",
      "BERTScore recall: 0.4661\n",
      "Example 163\n",
      "Reference : just like that but closer together\n",
      "Prediction: you should just resemble that, having them close together more.\n",
      "BERTScore F1: 0.4845\n",
      "BERTScore precision: 0.4453\n",
      "BERTScore recall: 0.5312\n",
      "Example 164\n",
      "Reference : just like that but closer together\n",
      "Prediction: you just put that on, though you have to close it together more.\n",
      "BERTScore F1: 0.4328\n",
      "BERTScore precision: 0.3934\n",
      "BERTScore recall: 0.4809\n",
      "Example 165\n",
      "Reference : just like that but closer together\n",
      "Prediction: you should just resemble that, but you're having it close together more.\n",
      "BERTScore F1: 0.4941\n",
      "BERTScore precision: 0.4282\n",
      "BERTScore recall: 0.5840\n",
      "Example 166\n",
      "Reference : just like that but closer together\n",
      "Prediction: move back and then move forward into the gap on the left.\n",
      "BERTScore F1: 0.3736\n",
      "BERTScore precision: 0.3670\n",
      "BERTScore recall: 0.3804\n",
      "Example 167\n",
      "Reference : just like that but closer together\n",
      "Prediction: move back and then point forward.\n",
      "BERTScore F1: 0.3767\n",
      "BERTScore precision: 0.3834\n",
      "BERTScore recall: 0.3702\n",
      "Example 168\n",
      "Reference : just like that but closer together\n",
      "Prediction: move your hands back into a fist, then move them to the left and make a gap in front of you.\n",
      "BERTScore F1: 0.3101\n",
      "BERTScore precision: 0.2875\n",
      "BERTScore recall: 0.3365\n",
      "Example 169\n",
      "Reference : just like that but closer together\n",
      "Prediction: put that just like this.\n",
      "BERTScore F1: 0.4604\n",
      "BERTScore precision: 0.4939\n",
      "BERTScore recall: 0.4311\n",
      "Example 170\n",
      "Reference : just like that but closer together\n",
      "Prediction: put that just like you have it closer together.\n",
      "BERTScore F1: 0.5296\n",
      "BERTScore precision: 0.4948\n",
      "BERTScore recall: 0.5698\n",
      "Example 171\n",
      "Reference : just like that but closer together\n",
      "Prediction: put that just like you have it closed together more.\n",
      "BERTScore F1: 0.4847\n",
      "BERTScore precision: 0.4633\n",
      "BERTScore recall: 0.5082\n",
      "Example 172\n",
      "Reference : doesn't matter\n",
      "Prediction: it matters.\n",
      "BERTScore F1: 0.5283\n",
      "BERTScore precision: 0.5436\n",
      "BERTScore recall: 0.5139\n",
      "Example 173\n",
      "Reference : doesn't matter\n",
      "Prediction: it matters.\n",
      "BERTScore F1: 0.5283\n",
      "BERTScore precision: 0.5436\n",
      "BERTScore recall: 0.5139\n",
      "Example 174\n",
      "Reference : doesn't matter\n",
      "Prediction: it matters.\n",
      "BERTScore F1: 0.5283\n",
      "BERTScore precision: 0.5436\n",
      "BERTScore recall: 0.5139\n",
      "Example 175\n",
      "Reference : doesn't matter\n",
      "Prediction: look at that.\n",
      "BERTScore F1: 0.2711\n",
      "BERTScore precision: 0.2629\n",
      "BERTScore recall: 0.2799\n",
      "Example 176\n",
      "Reference : doesn't matter\n",
      "Prediction: look at that.\n",
      "BERTScore F1: 0.2711\n",
      "BERTScore precision: 0.2629\n",
      "BERTScore recall: 0.2799\n",
      "Example 177\n",
      "Reference : doesn't matter\n",
      "Prediction: look over there.\n",
      "BERTScore F1: 0.2656\n",
      "BERTScore precision: 0.2640\n",
      "BERTScore recall: 0.2672\n",
      "Example 178\n",
      "Reference : doesn't matter\n",
      "Prediction: look down.\n",
      "BERTScore F1: 0.2668\n",
      "BERTScore precision: 0.2718\n",
      "BERTScore recall: 0.2620\n",
      "Example 179\n",
      "Reference : doesn't matter\n",
      "Prediction: point to it.\n",
      "BERTScore F1: 0.2599\n",
      "BERTScore precision: 0.2574\n",
      "BERTScore recall: 0.2624\n",
      "Example 180\n",
      "Reference : doesn't matter\n",
      "Prediction: point to it.\n",
      "BERTScore F1: 0.2599\n",
      "BERTScore precision: 0.2574\n",
      "BERTScore recall: 0.2624\n",
      "Example 181\n",
      "Reference : move those together a little bit closer and then put that on top yay\n",
      "Prediction: you move those together to have them close a bit more, and put that on the top.\n",
      "BERTScore F1: 0.7327\n",
      "BERTScore precision: 0.7176\n",
      "BERTScore recall: 0.7484\n",
      "Example 182\n",
      "Reference : move those together a little bit closer and then put that on top yay\n",
      "Prediction: you move those together, close a bit more, and put that on the top.\n",
      "BERTScore F1: 0.7405\n",
      "BERTScore precision: 0.7244\n",
      "BERTScore recall: 0.7572\n",
      "Example 183\n",
      "Reference : move those together a little bit closer and then put that on top yay\n",
      "Prediction: you move those together, close a bit more, and put that on top.\n",
      "BERTScore F1: 0.7583\n",
      "BERTScore precision: 0.7443\n",
      "BERTScore recall: 0.7727\n",
      "Example 184\n",
      "Reference : move those together a little bit closer and then put that on top yay\n",
      "Prediction: put the object together in front of you.\n",
      "BERTScore F1: 0.4897\n",
      "BERTScore precision: 0.4977\n",
      "BERTScore recall: 0.4820\n",
      "Example 185\n",
      "Reference : move those together a little bit closer and then put that on top yay\n",
      "Prediction: put them together in front of you.\n",
      "BERTScore F1: 0.5163\n",
      "BERTScore precision: 0.5385\n",
      "BERTScore recall: 0.4959\n",
      "Example 186\n",
      "Reference : move those together a little bit closer and then put that on top yay\n",
      "Prediction: put the object together in front of you.\n",
      "BERTScore F1: 0.4897\n",
      "BERTScore precision: 0.4977\n",
      "BERTScore recall: 0.4820\n",
      "Example 187\n",
      "Reference : move those together a little bit closer and then put that on top yay\n",
      "Prediction: you move those together, close more a bit little and put that on top.\n",
      "BERTScore F1: 0.7680\n",
      "BERTScore precision: 0.7619\n",
      "BERTScore recall: 0.7743\n",
      "Example 188\n",
      "Reference : move those together a little bit closer and then put that on top yay\n",
      "Prediction: move those close together and put that on top.\n",
      "BERTScore F1: 0.7402\n",
      "BERTScore precision: 0.8147\n",
      "BERTScore recall: 0.6782\n",
      "Example 189\n",
      "Reference : move those together a little bit closer and then put that on top yay\n",
      "Prediction: move those things closer together and put that on top.\n",
      "BERTScore F1: 0.7096\n",
      "BERTScore precision: 0.7674\n",
      "BERTScore recall: 0.6598\n",
      "Example 190\n",
      "Reference : put them together\n",
      "Prediction: put them together.\n",
      "BERTScore F1: 0.9101\n",
      "BERTScore precision: 0.8811\n",
      "BERTScore recall: 0.9410\n",
      "Example 191\n",
      "Reference : put them together\n",
      "Prediction: put them together.\n",
      "BERTScore F1: 0.9101\n",
      "BERTScore precision: 0.8811\n",
      "BERTScore recall: 0.9410\n",
      "Example 192\n",
      "Reference : put them together\n",
      "Prediction: put them together.\n",
      "BERTScore F1: 0.9101\n",
      "BERTScore precision: 0.8811\n",
      "BERTScore recall: 0.9410\n",
      "Example 193\n",
      "Reference : put them together\n",
      "Prediction: push together\n",
      "BERTScore F1: 0.5544\n",
      "BERTScore precision: 0.5873\n",
      "BERTScore recall: 0.5250\n",
      "Example 194\n",
      "Reference : put them together\n",
      "Prediction: push together.\n",
      "BERTScore F1: 0.5380\n",
      "BERTScore precision: 0.5689\n",
      "BERTScore recall: 0.5103\n",
      "Example 195\n",
      "Reference : put them together\n",
      "Prediction: push together\n",
      "BERTScore F1: 0.5544\n",
      "BERTScore precision: 0.5873\n",
      "BERTScore recall: 0.5250\n",
      "Example 196\n",
      "Reference : put them together\n",
      "Prediction: put them together.\n",
      "BERTScore F1: 0.9101\n",
      "BERTScore precision: 0.8811\n",
      "BERTScore recall: 0.9410\n",
      "Example 197\n",
      "Reference : put them together\n",
      "Prediction: put them together.\n",
      "BERTScore F1: 0.9101\n",
      "BERTScore precision: 0.8811\n",
      "BERTScore recall: 0.9410\n",
      "Example 198\n",
      "Reference : put them together\n",
      "Prediction: put them together.\n",
      "BERTScore F1: 0.9101\n",
      "BERTScore precision: 0.8811\n",
      "BERTScore recall: 0.9410\n",
      "Example 199\n",
      "Reference : two more blocks up\n",
      "Prediction: there are two more blocks.\n",
      "BERTScore F1: 0.6343\n",
      "BERTScore precision: 0.5840\n",
      "BERTScore recall: 0.6941\n",
      "Example 200\n",
      "Reference : two more blocks up\n",
      "Prediction: there are two more blocks.\n",
      "BERTScore F1: 0.6343\n",
      "BERTScore precision: 0.5840\n",
      "BERTScore recall: 0.6941\n",
      "Example 201\n",
      "Reference : two more blocks up\n",
      "Prediction: there are two more blocks.\n",
      "BERTScore F1: 0.6343\n",
      "BERTScore precision: 0.5840\n",
      "BERTScore recall: 0.6941\n",
      "Example 202\n",
      "Reference : two more blocks up\n",
      "Prediction: the block is over there, and it's two.\n",
      "BERTScore F1: 0.4315\n",
      "BERTScore precision: 0.3781\n",
      "BERTScore recall: 0.5025\n",
      "Example 203\n",
      "Reference : two more blocks up\n",
      "Prediction: point to the block, then show two.\n",
      "BERTScore F1: 0.4237\n",
      "BERTScore precision: 0.3991\n",
      "BERTScore recall: 0.4516\n",
      "Example 204\n",
      "Reference : two more blocks up\n",
      "Prediction: point to the block, then show two.\n",
      "BERTScore F1: 0.4237\n",
      "BERTScore precision: 0.3991\n",
      "BERTScore recall: 0.4516\n",
      "Example 205\n",
      "Reference : two more blocks up\n",
      "Prediction: you're pointing to two blocks over there.\n",
      "BERTScore F1: 0.5009\n",
      "BERTScore precision: 0.4248\n",
      "BERTScore recall: 0.6104\n",
      "Example 206\n",
      "Reference : two more blocks up\n",
      "Prediction: point to the two blocks, then move back.\n",
      "BERTScore F1: 0.4664\n",
      "BERTScore precision: 0.4254\n",
      "BERTScore recall: 0.5161\n",
      "Example 207\n",
      "Reference : two more blocks up\n",
      "Prediction: look at the two blocks.\n",
      "BERTScore F1: 0.5285\n",
      "BERTScore precision: 0.5065\n",
      "BERTScore recall: 0.5525\n",
      "Example 208\n",
      "Reference : yep\n",
      "Prediction: yes.\n",
      "BERTScore F1: 0.5818\n",
      "BERTScore precision: 0.5777\n",
      "BERTScore recall: 0.5860\n",
      "Example 209\n",
      "Reference : yep\n",
      "Prediction: yes.\n",
      "BERTScore F1: 0.5818\n",
      "BERTScore precision: 0.5777\n",
      "BERTScore recall: 0.5860\n",
      "Example 210\n",
      "Reference : yep\n",
      "Prediction: yes\n",
      "BERTScore F1: 0.7692\n",
      "BERTScore precision: 0.7692\n",
      "BERTScore recall: 0.7692\n",
      "Example 211\n",
      "Reference : yep\n",
      "Prediction: i agree.\n",
      "BERTScore F1: 0.4258\n",
      "BERTScore precision: 0.3645\n",
      "BERTScore recall: 0.5118\n",
      "Example 212\n",
      "Reference : yep\n",
      "Prediction: i agree.\n",
      "BERTScore F1: 0.4258\n",
      "BERTScore precision: 0.3645\n",
      "BERTScore recall: 0.5118\n",
      "Example 213\n",
      "Reference : yep\n",
      "Prediction: i agree.\n",
      "BERTScore F1: 0.4258\n",
      "BERTScore precision: 0.3645\n",
      "BERTScore recall: 0.5118\n",
      "Example 214\n",
      "Reference : yep\n",
      "Prediction: yes.\n",
      "BERTScore F1: 0.5818\n",
      "BERTScore precision: 0.5777\n",
      "BERTScore recall: 0.5860\n",
      "Example 215\n",
      "Reference : yep\n",
      "Prediction: yes.\n",
      "BERTScore F1: 0.5818\n",
      "BERTScore precision: 0.5777\n",
      "BERTScore recall: 0.5860\n",
      "Example 216\n",
      "Reference : yep\n",
      "Prediction: yes.\n",
      "BERTScore F1: 0.5818\n",
      "BERTScore precision: 0.5777\n",
      "BERTScore recall: 0.5860\n",
      "Example 217\n",
      "Reference : go near yeah\n",
      "Prediction: go near.\n",
      "BERTScore F1: 0.7171\n",
      "BERTScore precision: 0.7171\n",
      "BERTScore recall: 0.7171\n",
      "Example 218\n",
      "Reference : go near yeah\n",
      "Prediction: go near.\n",
      "BERTScore F1: 0.7171\n",
      "BERTScore precision: 0.7171\n",
      "BERTScore recall: 0.7171\n",
      "Example 219\n",
      "Reference : go near yeah\n",
      "Prediction: go near.\n",
      "BERTScore F1: 0.7171\n",
      "BERTScore precision: 0.7171\n",
      "BERTScore recall: 0.7171\n",
      "Example 220\n",
      "Reference : go near yeah\n",
      "Prediction: that's correct.\n",
      "BERTScore F1: 0.3496\n",
      "BERTScore precision: 0.3312\n",
      "BERTScore recall: 0.3703\n",
      "Example 221\n",
      "Reference : go near yeah\n",
      "Prediction: i agree.\n",
      "BERTScore F1: 0.3874\n",
      "BERTScore precision: 0.3829\n",
      "BERTScore recall: 0.3920\n",
      "Example 222\n",
      "Reference : go near yeah\n",
      "Prediction: i agree.\n",
      "BERTScore F1: 0.3874\n",
      "BERTScore precision: 0.3829\n",
      "BERTScore recall: 0.3920\n",
      "Example 223\n",
      "Reference : go near yeah\n",
      "Prediction: let's go near it.\n",
      "BERTScore F1: 0.4330\n",
      "BERTScore precision: 0.3751\n",
      "BERTScore recall: 0.5121\n",
      "Example 224\n",
      "Reference : go near yeah\n",
      "Prediction: let's go near.\n",
      "BERTScore F1: 0.5259\n",
      "BERTScore precision: 0.4594\n",
      "BERTScore recall: 0.6151\n",
      "Example 225\n",
      "Reference : go near yeah\n",
      "Prediction: let's go near it.\n",
      "BERTScore F1: 0.4330\n",
      "BERTScore precision: 0.3751\n",
      "BERTScore recall: 0.5121\n",
      "Example 226\n",
      "Reference : and uh one block uh ahead of it\n",
      "Prediction: you have one block ahead of it.\n",
      "BERTScore F1: 0.6165\n",
      "BERTScore precision: 0.6501\n",
      "BERTScore recall: 0.5863\n",
      "Example 227\n",
      "Reference : and uh one block uh ahead of it\n",
      "Prediction: there is a block ahead of it and one block.\n",
      "BERTScore F1: 0.6344\n",
      "BERTScore precision: 0.6657\n",
      "BERTScore recall: 0.6058\n",
      "Example 228\n",
      "Reference : and uh one block uh ahead of it\n",
      "Prediction: there is one block ahead of it, and a block.\n",
      "BERTScore F1: 0.6301\n",
      "BERTScore precision: 0.6365\n",
      "BERTScore recall: 0.6239\n",
      "Example 229\n",
      "Reference : and uh one block uh ahead of it\n",
      "Prediction: come here.\n",
      "BERTScore F1: 0.3091\n",
      "BERTScore precision: 0.3476\n",
      "BERTScore recall: 0.2783\n",
      "Example 230\n",
      "Reference : and uh one block uh ahead of it\n",
      "Prediction: come here.\n",
      "BERTScore F1: 0.3091\n",
      "BERTScore precision: 0.3476\n",
      "BERTScore recall: 0.2783\n",
      "Example 231\n",
      "Reference : and uh one block uh ahead of it\n",
      "Prediction: come here.\n",
      "BERTScore F1: 0.3091\n",
      "BERTScore precision: 0.3476\n",
      "BERTScore recall: 0.2783\n",
      "Example 232\n",
      "Reference : and uh one block uh ahead of it\n",
      "Prediction: come ahead.\n",
      "BERTScore F1: 0.3521\n",
      "BERTScore precision: 0.3991\n",
      "BERTScore recall: 0.3151\n",
      "Example 233\n",
      "Reference : and uh one block uh ahead of it\n",
      "Prediction: bring it back here.\n",
      "BERTScore F1: 0.3037\n",
      "BERTScore precision: 0.3391\n",
      "BERTScore recall: 0.2749\n",
      "Example 234\n",
      "Reference : and uh one block uh ahead of it\n",
      "Prediction: bring it back.\n",
      "BERTScore F1: 0.3103\n",
      "BERTScore precision: 0.3535\n",
      "BERTScore recall: 0.2766\n",
      "Example 235\n",
      "Reference : put one block wherever you want\n",
      "Prediction: put the block wherever you want.\n",
      "BERTScore F1: 0.8288\n",
      "BERTScore precision: 0.8093\n",
      "BERTScore recall: 0.8492\n",
      "Example 236\n",
      "Reference : put one block wherever you want\n",
      "Prediction: put the block wherever you want.\n",
      "BERTScore F1: 0.8288\n",
      "BERTScore precision: 0.8093\n",
      "BERTScore recall: 0.8492\n",
      "Example 237\n",
      "Reference : put one block wherever you want\n",
      "Prediction: put the block wherever you want.\n",
      "BERTScore F1: 0.8288\n",
      "BERTScore precision: 0.8093\n",
      "BERTScore recall: 0.8492\n",
      "Example 238\n",
      "Reference : put one block wherever you want\n",
      "Prediction: pick up the block.\n",
      "BERTScore F1: 0.4786\n",
      "BERTScore precision: 0.5236\n",
      "BERTScore recall: 0.4408\n",
      "Example 239\n",
      "Reference : put one block wherever you want\n",
      "Prediction: put the blocks in the gap.\n",
      "BERTScore F1: 0.4977\n",
      "BERTScore precision: 0.5303\n",
      "BERTScore recall: 0.4688\n",
      "Example 240\n",
      "Reference : put one block wherever you want\n",
      "Prediction: put the block in.\n",
      "BERTScore F1: 0.5328\n",
      "BERTScore precision: 0.5849\n",
      "BERTScore recall: 0.4892\n",
      "Example 241\n",
      "Reference : put one block wherever you want\n",
      "Prediction: put it wherever you want.\n",
      "BERTScore F1: 0.7655\n",
      "BERTScore precision: 0.7792\n",
      "BERTScore recall: 0.7523\n",
      "Example 242\n",
      "Reference : put one block wherever you want\n",
      "Prediction: put it wherever you want.\n",
      "BERTScore F1: 0.7655\n",
      "BERTScore precision: 0.7792\n",
      "BERTScore recall: 0.7523\n",
      "Example 243\n",
      "Reference : put one block wherever you want\n",
      "Prediction: put it wherever you want.\n",
      "BERTScore F1: 0.7655\n",
      "BERTScore precision: 0.7792\n",
      "BERTScore recall: 0.7523\n",
      "Example 244\n",
      "Reference : the first block you put it the one nearest and the right side of it\n",
      "Prediction: you put the first block on the right side and it is most near you.\n",
      "BERTScore F1: 0.6825\n",
      "BERTScore precision: 0.6773\n",
      "BERTScore recall: 0.6878\n",
      "Example 245\n",
      "Reference : the first block you put it the one nearest and the right side of it\n",
      "Prediction: you put the first block near most, and you have the right side of it.\n",
      "BERTScore F1: 0.6894\n",
      "BERTScore precision: 0.6705\n",
      "BERTScore recall: 0.7093\n",
      "Example 246\n",
      "Reference : the first block you put it the one nearest and the right side of it\n",
      "Prediction: you put the first block near most on your right side, and you have a most degree.\n",
      "BERTScore F1: 0.6124\n",
      "BERTScore precision: 0.5878\n",
      "BERTScore recall: 0.6390\n",
      "Example 247\n",
      "Reference : the first block you put it the one nearest and the right side of it\n",
      "Prediction: put it to the right.\n",
      "BERTScore F1: 0.5349\n",
      "BERTScore precision: 0.5970\n",
      "BERTScore recall: 0.4845\n",
      "Example 248\n",
      "Reference : the first block you put it the one nearest and the right side of it\n",
      "Prediction: put it to the right.\n",
      "BERTScore F1: 0.5349\n",
      "BERTScore precision: 0.5970\n",
      "BERTScore recall: 0.4845\n",
      "Example 249\n",
      "Reference : the first block you put it the one nearest and the right side of it\n",
      "Prediction: put it on the right.\n",
      "BERTScore F1: 0.5634\n",
      "BERTScore precision: 0.6284\n",
      "BERTScore recall: 0.5106\n",
      "Example 250\n",
      "Reference : the first block you put it the one nearest and the right side of it\n",
      "Prediction: you have a block near you on the right side.\n",
      "BERTScore F1: 0.5995\n",
      "BERTScore precision: 0.6283\n",
      "BERTScore recall: 0.5733\n",
      "Example 251\n",
      "Reference : the first block you put it the one nearest and the right side of it\n",
      "Prediction: you have one block near you on the right side.\n",
      "BERTScore F1: 0.6094\n",
      "BERTScore precision: 0.6321\n",
      "BERTScore recall: 0.5882\n",
      "Example 252\n",
      "Reference : the first block you put it the one nearest and the right side of it\n",
      "Prediction: you have a block on the right side near most.\n",
      "BERTScore F1: 0.6129\n",
      "BERTScore precision: 0.6329\n",
      "BERTScore recall: 0.5942\n",
      "Example 253\n",
      "Reference : we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "Prediction: we have two blocks apart from each other.\n",
      "BERTScore F1: 0.6744\n",
      "BERTScore precision: 0.8071\n",
      "BERTScore recall: 0.5792\n",
      "Example 254\n",
      "Reference : we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "Prediction: we have two blocks apart from each other.\n",
      "BERTScore F1: 0.6744\n",
      "BERTScore precision: 0.8071\n",
      "BERTScore recall: 0.5792\n",
      "Example 255\n",
      "Reference : we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "Prediction: we have two blocks apart from each other.\n",
      "BERTScore F1: 0.6744\n",
      "BERTScore precision: 0.8071\n",
      "BERTScore recall: 0.5792\n",
      "Example 256\n",
      "Reference : we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "Prediction: put the block in space.\n",
      "BERTScore F1: 0.4710\n",
      "BERTScore precision: 0.5399\n",
      "BERTScore recall: 0.4177\n",
      "Example 257\n",
      "Reference : we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "Prediction: put the block in space.\n",
      "BERTScore F1: 0.4710\n",
      "BERTScore precision: 0.5399\n",
      "BERTScore recall: 0.4177\n",
      "Example 258\n",
      "Reference : we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "Prediction: put the block in space.\n",
      "BERTScore F1: 0.4710\n",
      "BERTScore precision: 0.5399\n",
      "BERTScore recall: 0.4177\n",
      "Example 259\n",
      "Reference : we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "Prediction: we have two blocks apart, and i'm putting one in the space, and you put the other block.\n",
      "BERTScore F1: 0.5581\n",
      "BERTScore precision: 0.5364\n",
      "BERTScore recall: 0.5816\n",
      "Example 260\n",
      "Reference : we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "Prediction: we have two blocks apart, and i'm putting one block into the other.\n",
      "BERTScore F1: 0.5458\n",
      "BERTScore precision: 0.5528\n",
      "BERTScore recall: 0.5389\n",
      "Example 261\n",
      "Reference : we’ll have two blocks ah like apart from each other yeah a block space a block space yeah\n",
      "Prediction: we have two blocks apart, and we put one in the space and the other on top of it.\n",
      "BERTScore F1: 0.5423\n",
      "BERTScore precision: 0.5320\n",
      "BERTScore recall: 0.5530\n",
      "Example 262\n",
      "Reference : but that should be on top on top of the of the other blocks yeah\n",
      "Prediction: that should be located on the top of another block.\n",
      "BERTScore F1: 0.7069\n",
      "BERTScore precision: 0.7388\n",
      "BERTScore recall: 0.6776\n",
      "Example 263\n",
      "Reference : but that should be on top on top of the of the other blocks yeah\n",
      "Prediction: it is recommended that it be located on the other block.\n",
      "BERTScore F1: 0.5449\n",
      "BERTScore precision: 0.5506\n",
      "BERTScore recall: 0.5393\n",
      "Example 264\n",
      "Reference : but that should be on top on top of the of the other blocks yeah\n",
      "Prediction: it's recommended that you be located on the other block.\n",
      "BERTScore F1: 0.5011\n",
      "BERTScore precision: 0.4881\n",
      "BERTScore recall: 0.5149\n",
      "Example 265\n",
      "Reference : but that should be on top on top of the of the other blocks yeah\n",
      "Prediction: no, go back to the top.\n",
      "BERTScore F1: 0.4459\n",
      "BERTScore precision: 0.4627\n",
      "BERTScore recall: 0.4302\n",
      "Example 266\n",
      "Reference : but that should be on top on top of the of the other blocks yeah\n",
      "Prediction: no, point to the top and move back.\n",
      "BERTScore F1: 0.4614\n",
      "BERTScore precision: 0.4589\n",
      "BERTScore recall: 0.4640\n",
      "Example 267\n",
      "Reference : but that should be on top on top of the of the other blocks yeah\n",
      "Prediction: no, point to the top and then move back.\n",
      "BERTScore F1: 0.4569\n",
      "BERTScore precision: 0.4468\n",
      "BERTScore recall: 0.4676\n",
      "Example 268\n",
      "Reference : but that should be on top on top of the of the other blocks yeah\n",
      "Prediction: don't recommend that on the top of the other block.\n",
      "BERTScore F1: 0.6290\n",
      "BERTScore precision: 0.6094\n",
      "BERTScore recall: 0.6499\n",
      "Example 269\n",
      "Reference : but that should be on top on top of the of the other blocks yeah\n",
      "Prediction: don't go to the top, but rather be located on something else that is not the other block.\n",
      "BERTScore F1: 0.5236\n",
      "BERTScore precision: 0.4966\n",
      "BERTScore recall: 0.5537\n",
      "Example 270\n",
      "Reference : but that should be on top on top of the of the other blocks yeah\n",
      "Prediction: don't go to the top, but rather be located on the other side of the block.\n",
      "BERTScore F1: 0.5258\n",
      "BERTScore precision: 0.5016\n",
      "BERTScore recall: 0.5524\n",
      "Example 271\n",
      "Reference : can you just open it open it a little bit uh\n",
      "Prediction: just open it a bit.\n",
      "BERTScore F1: 0.7707\n",
      "BERTScore precision: 0.8070\n",
      "BERTScore recall: 0.7374\n",
      "Example 272\n",
      "Reference : can you just open it open it a little bit uh\n",
      "Prediction: just open it a bit.\n",
      "BERTScore F1: 0.7707\n",
      "BERTScore precision: 0.8070\n",
      "BERTScore recall: 0.7374\n",
      "Example 273\n",
      "Reference : can you just open it open it a little bit uh\n",
      "Prediction: just open it a bit.\n",
      "BERTScore F1: 0.7707\n",
      "BERTScore precision: 0.8070\n",
      "BERTScore recall: 0.7374\n",
      "Example 274\n",
      "Reference : can you just open it open it a little bit uh\n",
      "Prediction: i'm separating myself from you.\n",
      "BERTScore F1: 0.3195\n",
      "BERTScore precision: 0.3456\n",
      "BERTScore recall: 0.2971\n",
      "Example 275\n",
      "Reference : can you just open it open it a little bit uh\n",
      "Prediction: i'm going to move it away.\n",
      "BERTScore F1: 0.4288\n",
      "BERTScore precision: 0.4154\n",
      "BERTScore recall: 0.4431\n",
      "Example 276\n",
      "Reference : can you just open it open it a little bit uh\n",
      "Prediction: i am separating myself from you.\n",
      "BERTScore F1: 0.3264\n",
      "BERTScore precision: 0.3570\n",
      "BERTScore recall: 0.3007\n",
      "Example 277\n",
      "Reference : can you just open it open it a little bit uh\n",
      "Prediction: just open it a little.\n",
      "BERTScore F1: 0.7685\n",
      "BERTScore precision: 0.7973\n",
      "BERTScore recall: 0.7417\n",
      "Example 278\n",
      "Reference : can you just open it open it a little bit uh\n",
      "Prediction: just open it a little.\n",
      "BERTScore F1: 0.7685\n",
      "BERTScore precision: 0.7973\n",
      "BERTScore recall: 0.7417\n",
      "Example 279\n",
      "Reference : can you just open it open it a little bit uh\n",
      "Prediction: just open it a bit.\n",
      "BERTScore F1: 0.7707\n",
      "BERTScore precision: 0.8070\n",
      "BERTScore recall: 0.7374\n",
      "Example 280\n",
      "Reference : (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "Prediction: it doesn't recommend the fall.\n",
      "BERTScore F1: 0.4576\n",
      "BERTScore precision: 0.4827\n",
      "BERTScore recall: 0.4351\n",
      "Example 281\n",
      "Reference : (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "Prediction: it doesn't recommend that you fall.\n",
      "BERTScore F1: 0.4500\n",
      "BERTScore precision: 0.4607\n",
      "BERTScore recall: 0.4398\n",
      "Example 282\n",
      "Reference : (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "Prediction: it doesn't recommend that you fall.\n",
      "BERTScore F1: 0.4500\n",
      "BERTScore precision: 0.4607\n",
      "BERTScore recall: 0.4398\n",
      "Example 283\n",
      "Reference : (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "Prediction: he is standing in front of the block.\n",
      "BERTScore F1: 0.3097\n",
      "BERTScore precision: 0.3373\n",
      "BERTScore recall: 0.2863\n",
      "Example 284\n",
      "Reference : (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "Prediction: the block is on the left.\n",
      "BERTScore F1: 0.3410\n",
      "BERTScore precision: 0.3788\n",
      "BERTScore recall: 0.3101\n",
      "Example 285\n",
      "Reference : (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "Prediction: the block is on the left.\n",
      "BERTScore F1: 0.3410\n",
      "BERTScore precision: 0.3788\n",
      "BERTScore recall: 0.3101\n",
      "Example 286\n",
      "Reference : (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "Prediction: it's not recommended to fall.\n",
      "BERTScore F1: 0.4720\n",
      "BERTScore precision: 0.4979\n",
      "BERTScore recall: 0.4487\n",
      "Example 287\n",
      "Reference : (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "Prediction: it's not recommended to fall.\n",
      "BERTScore F1: 0.4720\n",
      "BERTScore precision: 0.4979\n",
      "BERTScore recall: 0.4487\n",
      "Example 288\n",
      "Reference : (unknown) yeah it shouldn’t fall it shouldn’t fall and\n",
      "Prediction: it's not recommended to fall.\n",
      "BERTScore F1: 0.4720\n",
      "BERTScore precision: 0.4979\n",
      "BERTScore recall: 0.4487\n",
      "Example 289\n",
      "Reference : then the next row is just three on top of that in the middle of those gaps\n",
      "Prediction: the next row will be three at the middle of the top gap.\n",
      "BERTScore F1: 0.7368\n",
      "BERTScore precision: 0.7498\n",
      "BERTScore recall: 0.7241\n",
      "Example 290\n",
      "Reference : then the next row is just three on top of that in the middle of those gaps\n",
      "Prediction: the next row will be three on top of the middle gap.\n",
      "BERTScore F1: 0.7544\n",
      "BERTScore precision: 0.7654\n",
      "BERTScore recall: 0.7437\n",
      "Example 291\n",
      "Reference : then the next row is just three on top of that in the middle of those gaps\n",
      "Prediction: the next row will be three on top of the middle gap.\n",
      "BERTScore F1: 0.7544\n",
      "BERTScore precision: 0.7654\n",
      "BERTScore recall: 0.7437\n",
      "Example 292\n",
      "Reference : then the next row is just three on top of that in the middle of those gaps\n",
      "Prediction: move the block up.\n",
      "BERTScore F1: 0.4406\n",
      "BERTScore precision: 0.4603\n",
      "BERTScore recall: 0.4225\n",
      "Example 293\n",
      "Reference : then the next row is just three on top of that in the middle of those gaps\n",
      "Prediction: move the block up.\n",
      "BERTScore F1: 0.4406\n",
      "BERTScore precision: 0.4603\n",
      "BERTScore recall: 0.4225\n",
      "Example 294\n",
      "Reference : then the next row is just three on top of that in the middle of those gaps\n",
      "Prediction: move the block up.\n",
      "BERTScore F1: 0.4406\n",
      "BERTScore precision: 0.4603\n",
      "BERTScore recall: 0.4225\n",
      "Example 295\n",
      "Reference : then the next row is just three on top of that in the middle of those gaps\n",
      "Prediction: the next row is at the top of the middle gap.\n",
      "BERTScore F1: 0.7150\n",
      "BERTScore precision: 0.7454\n",
      "BERTScore recall: 0.6870\n",
      "Example 296\n",
      "Reference : then the next row is just three on top of that in the middle of those gaps\n",
      "Prediction: the next row is going to be at the top of the middle gap.\n",
      "BERTScore F1: 0.6817\n",
      "BERTScore precision: 0.6907\n",
      "BERTScore recall: 0.6729\n",
      "Example 297\n",
      "Reference : then the next row is just three on top of that in the middle of those gaps\n",
      "Prediction: the next row is three blocks top middle.\n",
      "BERTScore F1: 0.6746\n",
      "BERTScore precision: 0.7125\n",
      "BERTScore recall: 0.6406\n",
      "Example 298\n",
      "Reference : kind of splayed yeah\n",
      "Prediction: they are kind of scattered.\n",
      "BERTScore F1: 0.6097\n",
      "BERTScore precision: 0.6209\n",
      "BERTScore recall: 0.5988\n",
      "Example 299\n",
      "Reference : kind of splayed yeah\n",
      "Prediction: they are kind of a splay.\n",
      "BERTScore F1: 0.6600\n",
      "BERTScore precision: 0.6404\n",
      "BERTScore recall: 0.6808\n",
      "Example 300\n",
      "Reference : kind of splayed yeah\n",
      "Prediction: they are kind of spreading out.\n",
      "BERTScore F1: 0.6001\n",
      "BERTScore precision: 0.5905\n",
      "BERTScore recall: 0.6101\n",
      "Example 301\n",
      "Reference : kind of splayed yeah\n",
      "Prediction: stand apart and then bring your hands together in a fist.\n",
      "BERTScore F1: 0.3630\n",
      "BERTScore precision: 0.3562\n",
      "BERTScore recall: 0.3699\n",
      "Example 302\n",
      "Reference : kind of splayed yeah\n",
      "Prediction: start with your arms apart and then get down on the ground.\n",
      "BERTScore F1: 0.3720\n",
      "BERTScore precision: 0.3531\n",
      "BERTScore recall: 0.3930\n",
      "Example 303\n",
      "Reference : kind of splayed yeah\n",
      "Prediction: start with your arms apart and then move them into a gap.\n",
      "BERTScore F1: 0.3979\n",
      "BERTScore precision: 0.3896\n",
      "BERTScore recall: 0.4065\n",
      "Example 304\n",
      "Reference : kind of splayed yeah\n",
      "Prediction: they're kind of splayed.\n",
      "BERTScore F1: 0.7642\n",
      "BERTScore precision: 0.7145\n",
      "BERTScore recall: 0.8213\n",
      "Example 305\n",
      "Reference : kind of splayed yeah\n",
      "Prediction: they're kind of spread out.\n",
      "BERTScore F1: 0.6088\n",
      "BERTScore precision: 0.5902\n",
      "BERTScore recall: 0.6286\n",
      "Example 306\n",
      "Reference : kind of splayed yeah\n",
      "Prediction: they are splayed.\n",
      "BERTScore F1: 0.6476\n",
      "BERTScore precision: 0.6784\n",
      "BERTScore recall: 0.6194\n",
      "Example 307\n",
      "Reference : come evenly there\n",
      "Prediction: you cover there.\n",
      "BERTScore F1: 0.5463\n",
      "BERTScore precision: 0.5401\n",
      "BERTScore recall: 0.5525\n",
      "Example 308\n",
      "Reference : come evenly there\n",
      "Prediction: you are covering something there.\n",
      "BERTScore F1: 0.4446\n",
      "BERTScore precision: 0.4248\n",
      "BERTScore recall: 0.4662\n",
      "Example 309\n",
      "Reference : come evenly there\n",
      "Prediction: you cover there.\n",
      "BERTScore F1: 0.5463\n",
      "BERTScore precision: 0.5401\n",
      "BERTScore recall: 0.5525\n",
      "Example 310\n",
      "Reference : come evenly there\n",
      "Prediction: move down.\n",
      "BERTScore F1: 0.4998\n",
      "BERTScore precision: 0.4958\n",
      "BERTScore recall: 0.5038\n",
      "Example 311\n",
      "Reference : come evenly there\n",
      "Prediction: move down.\n",
      "BERTScore F1: 0.4998\n",
      "BERTScore precision: 0.4958\n",
      "BERTScore recall: 0.5038\n",
      "Example 312\n",
      "Reference : come evenly there\n",
      "Prediction: move down.\n",
      "BERTScore F1: 0.4998\n",
      "BERTScore precision: 0.4958\n",
      "BERTScore recall: 0.5038\n",
      "Example 313\n",
      "Reference : come evenly there\n",
      "Prediction: you're moving down to cover there.\n",
      "BERTScore F1: 0.4520\n",
      "BERTScore precision: 0.4187\n",
      "BERTScore recall: 0.4910\n",
      "Example 314\n",
      "Reference : come evenly there\n",
      "Prediction: you're covering something down there.\n",
      "BERTScore F1: 0.4244\n",
      "BERTScore precision: 0.3895\n",
      "BERTScore recall: 0.4661\n",
      "Example 315\n",
      "Reference : come evenly there\n",
      "Prediction: you are covering something there.\n",
      "BERTScore F1: 0.4446\n",
      "BERTScore precision: 0.4248\n",
      "BERTScore recall: 0.4662\n",
      "Example 316\n",
      "Reference : like an angle\n",
      "Prediction: it resembles an angle.\n",
      "BERTScore F1: 0.6678\n",
      "BERTScore precision: 0.6199\n",
      "BERTScore recall: 0.7238\n",
      "Example 317\n",
      "Reference : like an angle\n",
      "Prediction: it resembles an angle.\n",
      "BERTScore F1: 0.6678\n",
      "BERTScore precision: 0.6199\n",
      "BERTScore recall: 0.7238\n",
      "Example 318\n",
      "Reference : like an angle\n",
      "Prediction: it resembles an angle.\n",
      "BERTScore F1: 0.6678\n",
      "BERTScore precision: 0.6199\n",
      "BERTScore recall: 0.7238\n",
      "Example 319\n",
      "Reference : like an angle\n",
      "Prediction: look up and down.\n",
      "BERTScore F1: 0.3629\n",
      "BERTScore precision: 0.3360\n",
      "BERTScore recall: 0.3945\n",
      "Example 320\n",
      "Reference : like an angle\n",
      "Prediction: raise and lower\n",
      "BERTScore F1: 0.3881\n",
      "BERTScore precision: 0.3900\n",
      "BERTScore recall: 0.3863\n",
      "Example 321\n",
      "Reference : like an angle\n",
      "Prediction: raise and lower\n",
      "BERTScore F1: 0.3881\n",
      "BERTScore precision: 0.3900\n",
      "BERTScore recall: 0.3863\n",
      "Example 322\n",
      "Reference : like an angle\n",
      "Prediction: move your arms up and down.\n",
      "BERTScore F1: 0.3423\n",
      "BERTScore precision: 0.3075\n",
      "BERTScore recall: 0.3861\n",
      "Example 323\n",
      "Reference : like an angle\n",
      "Prediction: move your arms up and down.\n",
      "BERTScore F1: 0.3423\n",
      "BERTScore precision: 0.3075\n",
      "BERTScore recall: 0.3861\n",
      "Example 324\n",
      "Reference : like an angle\n",
      "Prediction: move your arms up and down.\n",
      "BERTScore F1: 0.3423\n",
      "BERTScore precision: 0.3075\n",
      "BERTScore recall: 0.3861\n",
      "Example 325\n",
      "Reference : and it's going to be like a fan or sound wave going out\n",
      "Prediction: it's like a fan or a wave of sound going out.\n",
      "BERTScore F1: 0.7545\n",
      "BERTScore precision: 0.7864\n",
      "BERTScore recall: 0.7251\n",
      "Example 326\n",
      "Reference : and it's going to be like a fan or sound wave going out\n",
      "Prediction: it's like a fan or a wave of sound going out.\n",
      "BERTScore F1: 0.7545\n",
      "BERTScore precision: 0.7864\n",
      "BERTScore recall: 0.7251\n",
      "Example 327\n",
      "Reference : and it's going to be like a fan or sound wave going out\n",
      "Prediction: it's like a fan or a wave that goes out.\n",
      "BERTScore F1: 0.7170\n",
      "BERTScore precision: 0.7547\n",
      "BERTScore recall: 0.6828\n",
      "Example 328\n",
      "Reference : and it's going to be like a fan or sound wave going out\n",
      "Prediction: make a curve with your hand, then move it apart and bring it back down.\n",
      "BERTScore F1: 0.3959\n",
      "BERTScore precision: 0.3973\n",
      "BERTScore recall: 0.3946\n",
      "Example 329\n",
      "Reference : and it's going to be like a fan or sound wave going out\n",
      "Prediction: close the gap, but not too close.\n",
      "BERTScore F1: 0.3414\n",
      "BERTScore precision: 0.3454\n",
      "BERTScore recall: 0.3375\n",
      "Example 330\n",
      "Reference : and it's going to be like a fan or sound wave going out\n",
      "Prediction: close your hands and then move them apart.\n",
      "BERTScore F1: 0.3548\n",
      "BERTScore precision: 0.3555\n",
      "BERTScore recall: 0.3541\n",
      "Example 331\n",
      "Reference : and it's going to be like a fan or sound wave going out\n",
      "Prediction: it goes out like a fan or a wave.\n",
      "BERTScore F1: 0.6681\n",
      "BERTScore precision: 0.7356\n",
      "BERTScore recall: 0.6120\n",
      "Example 332\n",
      "Reference : and it's going to be like a fan or sound wave going out\n",
      "Prediction: it's like a fan or a wave that goes out.\n",
      "BERTScore F1: 0.7170\n",
      "BERTScore precision: 0.7547\n",
      "BERTScore recall: 0.6828\n",
      "Example 333\n",
      "Reference : and it's going to be like a fan or sound wave going out\n",
      "Prediction: it goes out like a fan or a wave.\n",
      "BERTScore F1: 0.6681\n",
      "BERTScore precision: 0.7356\n",
      "BERTScore recall: 0.6120\n",
      "Example 334\n",
      "Reference : i need four base again\n",
      "Prediction: i need to base it again.\n",
      "BERTScore F1: 0.6198\n",
      "BERTScore precision: 0.5953\n",
      "BERTScore recall: 0.6464\n",
      "Example 335\n",
      "Reference : i need four base again\n",
      "Prediction: i need the base again.\n",
      "BERTScore F1: 0.7152\n",
      "BERTScore precision: 0.6944\n",
      "BERTScore recall: 0.7373\n",
      "Example 336\n",
      "Reference : i need four base again\n",
      "Prediction: i need to base it again on four.\n",
      "BERTScore F1: 0.6111\n",
      "BERTScore precision: 0.5661\n",
      "BERTScore recall: 0.6639\n",
      "Example 337\n",
      "Reference : i need four base again\n",
      "Prediction: the speaker is holding up four fingers in front of them.\n",
      "BERTScore F1: 0.3451\n",
      "BERTScore precision: 0.2999\n",
      "BERTScore recall: 0.4063\n",
      "Example 338\n",
      "Reference : i need four base again\n",
      "Prediction: the speaker is holding up four fingers in front of them.\n",
      "BERTScore F1: 0.3451\n",
      "BERTScore precision: 0.2999\n",
      "BERTScore recall: 0.4063\n",
      "Example 339\n",
      "Reference : i need four base again\n",
      "Prediction: the speaker is holding four in their right hand and shaking it in front of them.\n",
      "BERTScore F1: 0.3402\n",
      "BERTScore precision: 0.2888\n",
      "BERTScore recall: 0.4138\n",
      "Example 340\n",
      "Reference : i need four base again\n",
      "Prediction: i need four bases again.\n",
      "BERTScore F1: 0.7949\n",
      "BERTScore precision: 0.7713\n",
      "BERTScore recall: 0.8200\n",
      "Example 341\n",
      "Reference : i need four base again\n",
      "Prediction: i need four again.\n",
      "BERTScore F1: 0.7261\n",
      "BERTScore precision: 0.7473\n",
      "BERTScore recall: 0.7061\n",
      "Example 342\n",
      "Reference : i need four base again\n",
      "Prediction: i need four again.\n",
      "BERTScore F1: 0.7261\n",
      "BERTScore precision: 0.7473\n",
      "BERTScore recall: 0.7061\n",
      "Example 343\n",
      "Reference : the next one is three on top of those\n",
      "Prediction: there are three on top of that one next.\n",
      "BERTScore F1: 0.7475\n",
      "BERTScore precision: 0.7383\n",
      "BERTScore recall: 0.7570\n",
      "Example 344\n",
      "Reference : the next one is three on top of those\n",
      "Prediction: there are three on top of that one next.\n",
      "BERTScore F1: 0.7475\n",
      "BERTScore precision: 0.7383\n",
      "BERTScore recall: 0.7570\n",
      "Example 345\n",
      "Reference : the next one is three on top of those\n",
      "Prediction: there are three on top of that one.\n",
      "BERTScore F1: 0.7266\n",
      "BERTScore precision: 0.7315\n",
      "BERTScore recall: 0.7218\n",
      "Example 346\n",
      "Reference : the next one is three on top of those\n",
      "Prediction: move it up to four and then down to three.\n",
      "BERTScore F1: 0.4756\n",
      "BERTScore precision: 0.4862\n",
      "BERTScore recall: 0.4654\n",
      "Example 347\n",
      "Reference : the next one is three on top of those\n",
      "Prediction: move it to the third position and then bring it back down.\n",
      "BERTScore F1: 0.4431\n",
      "BERTScore precision: 0.4429\n",
      "BERTScore recall: 0.4433\n",
      "Example 348\n",
      "Reference : the next one is three on top of those\n",
      "Prediction: move the actor up to four and then bring them down to three.\n",
      "BERTScore F1: 0.4609\n",
      "BERTScore precision: 0.4667\n",
      "BERTScore recall: 0.4552\n",
      "Example 349\n",
      "Reference : the next one is three on top of those\n",
      "Prediction: you're pointing to the next one.\n",
      "BERTScore F1: 0.5327\n",
      "BERTScore precision: 0.5157\n",
      "BERTScore recall: 0.5507\n",
      "Example 350\n",
      "Reference : the next one is three on top of those\n",
      "Prediction: there are three on top of that.\n",
      "BERTScore F1: 0.7158\n",
      "BERTScore precision: 0.7334\n",
      "BERTScore recall: 0.6989\n",
      "Example 351\n",
      "Reference : the next one is three on top of those\n",
      "Prediction: there are three on top of that one.\n",
      "BERTScore F1: 0.7266\n",
      "BERTScore precision: 0.7315\n",
      "BERTScore recall: 0.7218\n",
      "Example 352\n",
      "Reference : then you're going to put one right next to it and one right next to that\n",
      "Prediction: put the block next to it, and put one block.\n",
      "BERTScore F1: 0.6117\n",
      "BERTScore precision: 0.6407\n",
      "BERTScore recall: 0.5852\n",
      "Example 353\n",
      "Reference : then you're going to put one right next to it and one right next to that\n",
      "Prediction: put the block next to it, and put one block.\n",
      "BERTScore F1: 0.6117\n",
      "BERTScore precision: 0.6407\n",
      "BERTScore recall: 0.5852\n",
      "Example 354\n",
      "Reference : then you're going to put one right next to it and one right next to that\n",
      "Prediction: put the block next to it, and put one block.\n",
      "BERTScore F1: 0.6117\n",
      "BERTScore precision: 0.6407\n",
      "BERTScore recall: 0.5852\n",
      "Example 355\n",
      "Reference : then you're going to put one right next to it and one right next to that\n",
      "Prediction: look over there.\n",
      "BERTScore F1: 0.3816\n",
      "BERTScore precision: 0.4067\n",
      "BERTScore recall: 0.3595\n",
      "Example 356\n",
      "Reference : then you're going to put one right next to it and one right next to that\n",
      "Prediction: look over there.\n",
      "BERTScore F1: 0.3816\n",
      "BERTScore precision: 0.4067\n",
      "BERTScore recall: 0.3595\n",
      "Example 357\n",
      "Reference : then you're going to put one right next to it and one right next to that\n",
      "Prediction: look at that.\n",
      "BERTScore F1: 0.3496\n",
      "BERTScore precision: 0.3852\n",
      "BERTScore recall: 0.3201\n",
      "Example 358\n",
      "Reference : then you're going to put one right next to it and one right next to that\n",
      "Prediction: put one block next to it, and put one block next to it.\n",
      "BERTScore F1: 0.6667\n",
      "BERTScore precision: 0.7160\n",
      "BERTScore recall: 0.6239\n",
      "Example 359\n",
      "Reference : then you're going to put one right next to it and one right next to that\n",
      "Prediction: put the block next to it and put one more.\n",
      "BERTScore F1: 0.6218\n",
      "BERTScore precision: 0.6565\n",
      "BERTScore recall: 0.5905\n",
      "Example 360\n",
      "Reference : then you're going to put one right next to it and one right next to that\n",
      "Prediction: put it next to one block, and put one block next to it.\n",
      "BERTScore F1: 0.6387\n",
      "BERTScore precision: 0.6648\n",
      "BERTScore recall: 0.6145\n",
      "Example 361\n",
      "Reference : you're gonna have one block\n",
      "Prediction: block one.\n",
      "BERTScore F1: 0.4242\n",
      "BERTScore precision: 0.5286\n",
      "BERTScore recall: 0.3543\n",
      "Example 362\n",
      "Reference : you're gonna have one block\n",
      "Prediction: block one.\n",
      "BERTScore F1: 0.4242\n",
      "BERTScore precision: 0.5286\n",
      "BERTScore recall: 0.3543\n",
      "Example 363\n",
      "Reference : you're gonna have one block\n",
      "Prediction: block it!\n",
      "BERTScore F1: 0.3646\n",
      "BERTScore precision: 0.4120\n",
      "BERTScore recall: 0.3270\n",
      "Example 364\n",
      "Reference : you're gonna have one block\n",
      "Prediction: look over there.\n",
      "BERTScore F1: 0.3416\n",
      "BERTScore precision: 0.3657\n",
      "BERTScore recall: 0.3204\n",
      "Example 365\n",
      "Reference : you're gonna have one block\n",
      "Prediction: look over there.\n",
      "BERTScore F1: 0.3416\n",
      "BERTScore precision: 0.3657\n",
      "BERTScore recall: 0.3204\n",
      "Example 366\n",
      "Reference : you're gonna have one block\n",
      "Prediction: look at that over there.\n",
      "BERTScore F1: 0.3351\n",
      "BERTScore precision: 0.3414\n",
      "BERTScore recall: 0.3290\n",
      "Example 367\n",
      "Reference : you're gonna have one block\n",
      "Prediction: you have a block.\n",
      "BERTScore F1: 0.5777\n",
      "BERTScore precision: 0.6368\n",
      "BERTScore recall: 0.5287\n",
      "Example 368\n",
      "Reference : you're gonna have one block\n",
      "Prediction: you have one block.\n",
      "BERTScore F1: 0.6309\n",
      "BERTScore precision: 0.7049\n",
      "BERTScore recall: 0.5710\n",
      "Example 369\n",
      "Reference : you're gonna have one block\n",
      "Prediction: you have a block.\n",
      "BERTScore F1: 0.5777\n",
      "BERTScore precision: 0.6368\n",
      "BERTScore recall: 0.5287\n",
      "Example 370\n",
      "Reference : there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "Prediction: there is one hang on the edge at height one.\n",
      "BERTScore F1: 0.6325\n",
      "BERTScore precision: 0.6999\n",
      "BERTScore recall: 0.5770\n",
      "Example 371\n",
      "Reference : there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "Prediction: there is one hang on the edge at height three.\n",
      "BERTScore F1: 0.6015\n",
      "BERTScore precision: 0.6629\n",
      "BERTScore recall: 0.5505\n",
      "Example 372\n",
      "Reference : there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "Prediction: there is one hang on the edge at height three.\n",
      "BERTScore F1: 0.6015\n",
      "BERTScore precision: 0.6629\n",
      "BERTScore recall: 0.5505\n",
      "Example 373\n",
      "Reference : there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "Prediction: move the block to the left and then shake it.\n",
      "BERTScore F1: 0.3930\n",
      "BERTScore precision: 0.4257\n",
      "BERTScore recall: 0.3649\n",
      "Example 374\n",
      "Reference : there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "Prediction: put it on the left side.\n",
      "BERTScore F1: 0.4405\n",
      "BERTScore precision: 0.4900\n",
      "BERTScore recall: 0.4001\n",
      "Example 375\n",
      "Reference : there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "Prediction: put the block on top of it.\n",
      "BERTScore F1: 0.3990\n",
      "BERTScore precision: 0.4406\n",
      "BERTScore recall: 0.3646\n",
      "Example 376\n",
      "Reference : there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "Prediction: move the left object to the edge of the third one.\n",
      "BERTScore F1: 0.4906\n",
      "BERTScore precision: 0.5525\n",
      "BERTScore recall: 0.4412\n",
      "Example 377\n",
      "Reference : there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "Prediction: move the hang on the edge of the height three to the left, then shake it and move it down to the right.\n",
      "BERTScore F1: 0.4726\n",
      "BERTScore precision: 0.4890\n",
      "BERTScore recall: 0.4573\n",
      "Example 378\n",
      "Reference : there’s gonna be third one that's going to hang over the edge nope on uh height one yeah\n",
      "Prediction: move the object to the left, then shake it and rotate it down on the right.\n",
      "BERTScore F1: 0.3898\n",
      "BERTScore precision: 0.4150\n",
      "BERTScore recall: 0.3675\n",
      "Example 379\n",
      "Reference : yeah right\n",
      "Prediction: yeah\n",
      "BERTScore F1: 0.7704\n",
      "BERTScore precision: 0.7947\n",
      "BERTScore recall: 0.7474\n",
      "Example 380\n",
      "Reference : yeah right\n",
      "Prediction: yeah\n",
      "BERTScore F1: 0.7704\n",
      "BERTScore precision: 0.7947\n",
      "BERTScore recall: 0.7474\n",
      "Example 381\n",
      "Reference : yeah right\n",
      "Prediction: yeah\n",
      "BERTScore F1: 0.7704\n",
      "BERTScore precision: 0.7947\n",
      "BERTScore recall: 0.7474\n",
      "Example 382\n",
      "Reference : yeah right\n",
      "Prediction: look at the location below.\n",
      "BERTScore F1: 0.3291\n",
      "BERTScore precision: 0.3103\n",
      "BERTScore recall: 0.3503\n",
      "Example 383\n",
      "Reference : yeah right\n",
      "Prediction: look at that.\n",
      "BERTScore F1: 0.3375\n",
      "BERTScore precision: 0.2992\n",
      "BERTScore recall: 0.3871\n",
      "Example 384\n",
      "Reference : yeah right\n",
      "Prediction: look over there.\n",
      "BERTScore F1: 0.3413\n",
      "BERTScore precision: 0.3104\n",
      "BERTScore recall: 0.3789\n",
      "Example 385\n",
      "Reference : yeah right\n",
      "Prediction: look at that.\n",
      "BERTScore F1: 0.3375\n",
      "BERTScore precision: 0.2992\n",
      "BERTScore recall: 0.3871\n",
      "Example 386\n",
      "Reference : yeah right\n",
      "Prediction: look at the actor.\n",
      "BERTScore F1: 0.3349\n",
      "BERTScore precision: 0.3055\n",
      "BERTScore recall: 0.3705\n",
      "Example 387\n",
      "Reference : yeah right\n",
      "Prediction: you are pointing to the actor.\n",
      "BERTScore F1: 0.3195\n",
      "BERTScore precision: 0.2815\n",
      "BERTScore recall: 0.3695\n",
      "Example 388\n",
      "Reference : the final one is just pretty much exactly on top of it\n",
      "Prediction: it was just then that one, pretty much exactly on top of it, was located.\n",
      "BERTScore F1: 0.6573\n",
      "BERTScore precision: 0.6018\n",
      "BERTScore recall: 0.7242\n",
      "Example 389\n",
      "Reference : the final one is just pretty much exactly on top of it\n",
      "Prediction: it was just then, pretty much exactly on top of it.\n",
      "BERTScore F1: 0.7125\n",
      "BERTScore precision: 0.6944\n",
      "BERTScore recall: 0.7316\n",
      "Example 390\n",
      "Reference : the final one is just pretty much exactly on top of it\n",
      "Prediction: it was just then on top of it, pretty much exactly.\n",
      "BERTScore F1: 0.6999\n",
      "BERTScore precision: 0.6845\n",
      "BERTScore recall: 0.7160\n",
      "Example 391\n",
      "Reference : the final one is just pretty much exactly on top of it\n",
      "Prediction: put the top on.\n",
      "BERTScore F1: 0.4235\n",
      "BERTScore precision: 0.4578\n",
      "BERTScore recall: 0.3940\n",
      "Example 392\n",
      "Reference : the final one is just pretty much exactly on top of it\n",
      "Prediction: put the top on.\n",
      "BERTScore F1: 0.4235\n",
      "BERTScore precision: 0.4578\n",
      "BERTScore recall: 0.3940\n",
      "Example 393\n",
      "Reference : the final one is just pretty much exactly on top of it\n",
      "Prediction: put the top on.\n",
      "BERTScore F1: 0.4235\n",
      "BERTScore precision: 0.4578\n",
      "BERTScore recall: 0.3940\n",
      "Example 394\n",
      "Reference : the final one is just pretty much exactly on top of it\n",
      "Prediction: put it on top.\n",
      "BERTScore F1: 0.4847\n",
      "BERTScore precision: 0.5428\n",
      "BERTScore recall: 0.4378\n",
      "Example 395\n",
      "Reference : the final one is just pretty much exactly on top of it\n",
      "Prediction: put it on top.\n",
      "BERTScore F1: 0.4847\n",
      "BERTScore precision: 0.5428\n",
      "BERTScore recall: 0.4378\n",
      "Example 396\n",
      "Reference : the final one is just pretty much exactly on top of it\n",
      "Prediction: put it on top, then just one exactly pretty much on the top of it.\n",
      "BERTScore F1: 0.6681\n",
      "BERTScore precision: 0.6520\n",
      "BERTScore recall: 0.6850\n",
      "Example 397\n",
      "Reference : pushed off like the same direction\n",
      "Prediction: push it off in the same direction.\n",
      "BERTScore F1: 0.6773\n",
      "BERTScore precision: 0.6569\n",
      "BERTScore recall: 0.6989\n",
      "Example 398\n",
      "Reference : pushed off like the same direction\n",
      "Prediction: push it off in the same direction.\n",
      "BERTScore F1: 0.6773\n",
      "BERTScore precision: 0.6569\n",
      "BERTScore recall: 0.6989\n",
      "Example 399\n",
      "Reference : pushed off like the same direction\n",
      "Prediction: push it off in the same direction.\n",
      "BERTScore F1: 0.6773\n",
      "BERTScore precision: 0.6569\n",
      "BERTScore recall: 0.6989\n",
      "Example 400\n",
      "Reference : pushed off like the same direction\n",
      "Prediction: put it on the left.\n",
      "BERTScore F1: 0.4266\n",
      "BERTScore precision: 0.4508\n",
      "BERTScore recall: 0.4047\n",
      "Example 401\n",
      "Reference : pushed off like the same direction\n",
      "Prediction: put it on the left.\n",
      "BERTScore F1: 0.4266\n",
      "BERTScore precision: 0.4508\n",
      "BERTScore recall: 0.4047\n",
      "Example 402\n",
      "Reference : pushed off like the same direction\n",
      "Prediction: put it on the left.\n",
      "BERTScore F1: 0.4266\n",
      "BERTScore precision: 0.4508\n",
      "BERTScore recall: 0.4047\n",
      "Example 403\n",
      "Reference : pushed off like the same direction\n",
      "Prediction: push it off to the left.\n",
      "BERTScore F1: 0.4624\n",
      "BERTScore precision: 0.4891\n",
      "BERTScore recall: 0.4384\n",
      "Example 404\n",
      "Reference : pushed off like the same direction\n",
      "Prediction: push it off to the left.\n",
      "BERTScore F1: 0.4624\n",
      "BERTScore precision: 0.4891\n",
      "BERTScore recall: 0.4384\n",
      "Example 405\n",
      "Reference : pushed off like the same direction\n",
      "Prediction: push it off to the left.\n",
      "BERTScore F1: 0.4624\n",
      "BERTScore precision: 0.4891\n",
      "BERTScore recall: 0.4384\n",
      "Example 406\n",
      "Reference : a block space and on a third block\n",
      "Prediction: then there was a block that resembled space, and the third block.\n",
      "BERTScore F1: 0.5790\n",
      "BERTScore precision: 0.5283\n",
      "BERTScore recall: 0.6404\n",
      "Example 407\n",
      "Reference : a block space and on a third block\n",
      "Prediction: and then there was a block that resembled space, and the third one.\n",
      "BERTScore F1: 0.5389\n",
      "BERTScore precision: 0.4883\n",
      "BERTScore recall: 0.6014\n",
      "Example 408\n",
      "Reference : a block space and on a third block\n",
      "Prediction: and then there was a block that resembled space, followed by the third block.\n",
      "BERTScore F1: 0.5569\n",
      "BERTScore precision: 0.4988\n",
      "BERTScore recall: 0.6305\n",
      "Example 409\n",
      "Reference : a block space and on a third block\n",
      "Prediction: you are indicating something in the location.\n",
      "BERTScore F1: 0.3765\n",
      "BERTScore precision: 0.3841\n",
      "BERTScore recall: 0.3692\n",
      "Example 410\n",
      "Reference : a block space and on a third block\n",
      "Prediction: look over there, it's a block in the location.\n",
      "BERTScore F1: 0.4327\n",
      "BERTScore precision: 0.4093\n",
      "BERTScore recall: 0.4590\n",
      "Example 411\n",
      "Reference : a block space and on a third block\n",
      "Prediction: look at the location.\n",
      "BERTScore F1: 0.4162\n",
      "BERTScore precision: 0.4420\n",
      "BERTScore recall: 0.3931\n",
      "Example 412\n",
      "Reference : a block space and on a third block\n",
      "Prediction: and then, the space resembles a block at third position.\n",
      "BERTScore F1: 0.5571\n",
      "BERTScore precision: 0.5376\n",
      "BERTScore recall: 0.5780\n",
      "Example 413\n",
      "Reference : a block space and on a third block\n",
      "Prediction: the space is like a block, but then there's another one.\n",
      "BERTScore F1: 0.4565\n",
      "BERTScore precision: 0.4260\n",
      "BERTScore recall: 0.4917\n",
      "Example 414\n",
      "Reference : a block space and on a third block\n",
      "Prediction: the space is like a block, and then there was another one after that.\n",
      "BERTScore F1: 0.4895\n",
      "BERTScore precision: 0.4563\n",
      "BERTScore recall: 0.5280\n",
      "Example 415\n",
      "Reference : then on like the same line you're going to have a space\n",
      "Prediction: you had space then.\n",
      "BERTScore F1: 0.4806\n",
      "BERTScore precision: 0.5904\n",
      "BERTScore recall: 0.4053\n",
      "Example 416\n",
      "Reference : then on like the same line you're going to have a space\n",
      "Prediction: you had space then.\n",
      "BERTScore F1: 0.4806\n",
      "BERTScore precision: 0.5904\n",
      "BERTScore recall: 0.4053\n",
      "Example 417\n",
      "Reference : then on like the same line you're going to have a space\n",
      "Prediction: you had space then.\n",
      "BERTScore F1: 0.4806\n",
      "BERTScore precision: 0.5904\n",
      "BERTScore recall: 0.4053\n",
      "Example 418\n",
      "Reference : then on like the same line you're going to have a space\n",
      "Prediction: move your head down, then move it to the left.\n",
      "BERTScore F1: 0.3626\n",
      "BERTScore precision: 0.3656\n",
      "BERTScore recall: 0.3595\n",
      "Example 419\n",
      "Reference : then on like the same line you're going to have a space\n",
      "Prediction: move your hand to the left and up.\n",
      "BERTScore F1: 0.3593\n",
      "BERTScore precision: 0.3762\n",
      "BERTScore recall: 0.3438\n",
      "Example 420\n",
      "Reference : then on like the same line you're going to have a space\n",
      "Prediction: move your head down to the left, then move it up.\n",
      "BERTScore F1: 0.3772\n",
      "BERTScore precision: 0.3793\n",
      "BERTScore recall: 0.3751\n",
      "Example 421\n",
      "Reference : then on like the same line you're going to have a space\n",
      "Prediction: you have this space over here.\n",
      "BERTScore F1: 0.4425\n",
      "BERTScore precision: 0.4994\n",
      "BERTScore recall: 0.3973\n",
      "Example 422\n",
      "Reference : then on like the same line you're going to have a space\n",
      "Prediction: you have the line right here.\n",
      "BERTScore F1: 0.4408\n",
      "BERTScore precision: 0.4811\n",
      "BERTScore recall: 0.4068\n",
      "Example 423\n",
      "Reference : then on like the same line you're going to have a space\n",
      "Prediction: you were on the line, then you moved into space.\n",
      "BERTScore F1: 0.4484\n",
      "BERTScore precision: 0.4889\n",
      "BERTScore recall: 0.4141\n",
      "Example 424\n",
      "Reference : over the space in between the blocks so it’ll be on\n",
      "Prediction: it resembles a block over space between blocks.\n",
      "BERTScore F1: 0.5336\n",
      "BERTScore precision: 0.5755\n",
      "BERTScore recall: 0.4975\n",
      "Example 425\n",
      "Reference : over the space in between the blocks so it’ll be on\n",
      "Prediction: it resembles something that is over space, between blocks.\n",
      "BERTScore F1: 0.5283\n",
      "BERTScore precision: 0.5495\n",
      "BERTScore recall: 0.5087\n",
      "Example 426\n",
      "Reference : over the space in between the blocks so it’ll be on\n",
      "Prediction: it resembles something that is over space between blocks, and it should be located at the top.\n",
      "BERTScore F1: 0.5571\n",
      "BERTScore precision: 0.5386\n",
      "BERTScore recall: 0.5768\n",
      "Example 427\n",
      "Reference : over the space in between the blocks so it’ll be on\n",
      "Prediction: that's correct.\n",
      "BERTScore F1: 0.3537\n",
      "BERTScore precision: 0.3714\n",
      "BERTScore recall: 0.3376\n",
      "Example 428\n",
      "Reference : over the space in between the blocks so it’ll be on\n",
      "Prediction: that's correct.\n",
      "BERTScore F1: 0.3537\n",
      "BERTScore precision: 0.3714\n",
      "BERTScore recall: 0.3376\n",
      "Example 429\n",
      "Reference : over the space in between the blocks so it’ll be on\n",
      "Prediction: that's correct.\n",
      "BERTScore F1: 0.3537\n",
      "BERTScore precision: 0.3714\n",
      "BERTScore recall: 0.3376\n",
      "Example 430\n",
      "Reference : over the space in between the blocks so it’ll be on\n",
      "Prediction: it's between the blocks.\n",
      "BERTScore F1: 0.6338\n",
      "BERTScore precision: 0.6858\n",
      "BERTScore recall: 0.5891\n",
      "Example 431\n",
      "Reference : over the space in between the blocks so it’ll be on\n",
      "Prediction: it's over there, yes.\n",
      "BERTScore F1: 0.4849\n",
      "BERTScore precision: 0.4976\n",
      "BERTScore recall: 0.4729\n",
      "Example 432\n",
      "Reference : over the space in between the blocks so it’ll be on\n",
      "Prediction: it's located between the blocks, and it resembles something that is over there.\n",
      "BERTScore F1: 0.5841\n",
      "BERTScore precision: 0.5650\n",
      "BERTScore recall: 0.6045\n",
      "Example 433\n",
      "Reference : what one less than\n",
      "Prediction: there is one that is less than that.\n",
      "BERTScore F1: 0.5615\n",
      "BERTScore precision: 0.5109\n",
      "BERTScore recall: 0.6232\n",
      "Example 434\n",
      "Reference : what one less than\n",
      "Prediction: there is one that is less than that.\n",
      "BERTScore F1: 0.5615\n",
      "BERTScore precision: 0.5109\n",
      "BERTScore recall: 0.6232\n",
      "Example 435\n",
      "Reference : what one less than\n",
      "Prediction: there is one that is less than that.\n",
      "BERTScore F1: 0.5615\n",
      "BERTScore precision: 0.5109\n",
      "BERTScore recall: 0.6232\n",
      "Example 436\n",
      "Reference : what one less than\n",
      "Prediction: move the block in front of you, then move it to the left.\n",
      "BERTScore F1: 0.3576\n",
      "BERTScore precision: 0.3145\n",
      "BERTScore recall: 0.4142\n",
      "Example 437\n",
      "Reference : what one less than\n",
      "Prediction: move the block in front of you to the left and point it down.\n",
      "BERTScore F1: 0.3512\n",
      "BERTScore precision: 0.3057\n",
      "BERTScore recall: 0.4125\n",
      "Example 438\n",
      "Reference : what one less than\n",
      "Prediction: move the block in front of you, then move it to your left.\n",
      "BERTScore F1: 0.3533\n",
      "BERTScore precision: 0.3091\n",
      "BERTScore recall: 0.4121\n",
      "Example 439\n",
      "Reference : what one less than\n",
      "Prediction: point to the block that is less than that.\n",
      "BERTScore F1: 0.4868\n",
      "BERTScore precision: 0.4467\n",
      "BERTScore recall: 0.5348\n",
      "Example 440\n",
      "Reference : what one less than\n",
      "Prediction: point to the block in front of you, then move left and point there, shake your head and move down right.\n",
      "BERTScore F1: 0.3492\n",
      "BERTScore precision: 0.2982\n",
      "BERTScore recall: 0.4213\n",
      "Example 441\n",
      "Reference : what one less than\n",
      "Prediction: point to the block in front of you and move it less than that.\n",
      "BERTScore F1: 0.4421\n",
      "BERTScore precision: 0.3838\n",
      "BERTScore recall: 0.5213\n",
      "Example 442\n",
      "Reference : the other direction it's the same except for there are five\n",
      "Prediction: it's the same, but it includes five others.\n",
      "BERTScore F1: 0.6321\n",
      "BERTScore precision: 0.6522\n",
      "BERTScore recall: 0.6133\n",
      "Example 443\n",
      "Reference : the other direction it's the same except for there are five\n",
      "Prediction: it's the same, but it includes five others.\n",
      "BERTScore F1: 0.6321\n",
      "BERTScore precision: 0.6522\n",
      "BERTScore recall: 0.6133\n",
      "Example 444\n",
      "Reference : the other direction it's the same except for there are five\n",
      "Prediction: it's the same as five others.\n",
      "BERTScore F1: 0.5839\n",
      "BERTScore precision: 0.6386\n",
      "BERTScore recall: 0.5378\n",
      "Example 445\n",
      "Reference : the other direction it's the same except for there are five\n",
      "Prediction: you're moving your arms diagonally.\n",
      "BERTScore F1: 0.3913\n",
      "BERTScore precision: 0.4062\n",
      "BERTScore recall: 0.3774\n",
      "Example 446\n",
      "Reference : the other direction it's the same except for there are five\n",
      "Prediction: you're pointing to the left and then you're pointing forward, but you're shaking your head.\n",
      "BERTScore F1: 0.4323\n",
      "BERTScore precision: 0.4243\n",
      "BERTScore recall: 0.4405\n",
      "Example 447\n",
      "Reference : the other direction it's the same except for there are five\n",
      "Prediction: you're going to move the object diagonally.\n",
      "BERTScore F1: 0.3678\n",
      "BERTScore precision: 0.3755\n",
      "BERTScore recall: 0.3604\n",
      "Example 448\n",
      "Reference : the other direction it's the same except for there are five\n",
      "Prediction: move the object to the left and then turn it diagonally.\n",
      "BERTScore F1: 0.3625\n",
      "BERTScore precision: 0.3723\n",
      "BERTScore recall: 0.3532\n",
      "Example 449\n",
      "Reference : the other direction it's the same except for there are five\n",
      "Prediction: turn them to the left.\n",
      "BERTScore F1: 0.3788\n",
      "BERTScore precision: 0.4140\n",
      "BERTScore recall: 0.3492\n",
      "Example 450\n",
      "Reference : the other direction it's the same except for there are five\n",
      "Prediction: turn the thing on the left side over.\n",
      "BERTScore F1: 0.3805\n",
      "BERTScore precision: 0.4022\n",
      "BERTScore recall: 0.3611\n",
      "Example 451\n",
      "Reference : then down down one\n",
      "Prediction: you go down then.\n",
      "BERTScore F1: 0.4963\n",
      "BERTScore precision: 0.4693\n",
      "BERTScore recall: 0.5266\n",
      "Example 452\n",
      "Reference : then down down one\n",
      "Prediction: you go down then.\n",
      "BERTScore F1: 0.4963\n",
      "BERTScore precision: 0.4693\n",
      "BERTScore recall: 0.5266\n",
      "Example 453\n",
      "Reference : then down down one\n",
      "Prediction: you go down then.\n",
      "BERTScore F1: 0.4963\n",
      "BERTScore precision: 0.4693\n",
      "BERTScore recall: 0.5266\n",
      "Example 454\n",
      "Reference : then down down one\n",
      "Prediction: point to the block in front of you and then move it down.\n",
      "BERTScore F1: 0.4383\n",
      "BERTScore precision: 0.3622\n",
      "BERTScore recall: 0.5547\n",
      "Example 455\n",
      "Reference : then down down one\n",
      "Prediction: point to the block in front of you and then move it down.\n",
      "BERTScore F1: 0.4383\n",
      "BERTScore precision: 0.3622\n",
      "BERTScore recall: 0.5547\n",
      "Example 456\n",
      "Reference : then down down one\n",
      "Prediction: point to the block in front of you, then move it down.\n",
      "BERTScore F1: 0.4406\n",
      "BERTScore precision: 0.3653\n",
      "BERTScore recall: 0.5550\n",
      "Example 457\n",
      "Reference : then down down one\n",
      "Prediction: move down, then move the block down.\n",
      "BERTScore F1: 0.5598\n",
      "BERTScore precision: 0.5098\n",
      "BERTScore recall: 0.6207\n",
      "Example 458\n",
      "Reference : then down down one\n",
      "Prediction: move down and pick up the block, then move it down.\n",
      "BERTScore F1: 0.5108\n",
      "BERTScore precision: 0.4477\n",
      "BERTScore recall: 0.5945\n",
      "Example 459\n",
      "Reference : then down down one\n",
      "Prediction: move down, then move the block down.\n",
      "BERTScore F1: 0.5598\n",
      "BERTScore precision: 0.5098\n",
      "BERTScore recall: 0.6207\n",
      "Example 460\n",
      "Reference : put them coming diagonal\n",
      "Prediction: come and put them in a diagonal manner.\n",
      "BERTScore F1: 0.5464\n",
      "BERTScore precision: 0.4690\n",
      "BERTScore recall: 0.6543\n",
      "Example 461\n",
      "Reference : put them coming diagonal\n",
      "Prediction: come diagonally and put them.\n",
      "BERTScore F1: 0.5933\n",
      "BERTScore precision: 0.5353\n",
      "BERTScore recall: 0.6654\n",
      "Example 462\n",
      "Reference : put them coming diagonal\n",
      "Prediction: come over and put them on the diagonal.\n",
      "BERTScore F1: 0.5409\n",
      "BERTScore precision: 0.4666\n",
      "BERTScore recall: 0.6434\n",
      "Example 463\n",
      "Reference : put them coming diagonal\n",
      "Prediction: move your hand up and touch it to the right.\n",
      "BERTScore F1: 0.4249\n",
      "BERTScore precision: 0.3764\n",
      "BERTScore recall: 0.4876\n",
      "Example 464\n",
      "Reference : put them coming diagonal\n",
      "Prediction: move your hand up and touch the diagonal.\n",
      "BERTScore F1: 0.4503\n",
      "BERTScore precision: 0.4074\n",
      "BERTScore recall: 0.5034\n",
      "Example 465\n",
      "Reference : put them coming diagonal\n",
      "Prediction: move the object diagonally and touch it with your left hand.\n",
      "BERTScore F1: 0.4147\n",
      "BERTScore precision: 0.3574\n",
      "BERTScore recall: 0.4938\n",
      "Example 466\n",
      "Reference : put them coming diagonal\n",
      "Prediction: you put them on top of each other.\n",
      "BERTScore F1: 0.5326\n",
      "BERTScore precision: 0.4510\n",
      "BERTScore recall: 0.6502\n",
      "Example 467\n",
      "Reference : put them coming diagonal\n",
      "Prediction: put them on you, coming from the diagonal.\n",
      "BERTScore F1: 0.5943\n",
      "BERTScore precision: 0.5110\n",
      "BERTScore recall: 0.7099\n",
      "Example 468\n",
      "Reference : put them coming diagonal\n",
      "Prediction: put them down on the diagonal.\n",
      "BERTScore F1: 0.6166\n",
      "BERTScore precision: 0.5521\n",
      "BERTScore recall: 0.6983\n",
      "Example 469\n",
      "Reference : no closest\n",
      "Prediction: no\n",
      "BERTScore F1: 0.6233\n",
      "BERTScore precision: 0.6403\n",
      "BERTScore recall: 0.6071\n",
      "Example 470\n",
      "Reference : no closest\n",
      "Prediction: no\n",
      "BERTScore F1: 0.6233\n",
      "BERTScore precision: 0.6403\n",
      "BERTScore recall: 0.6071\n",
      "Example 471\n",
      "Reference : no closest\n",
      "Prediction: no.\n",
      "BERTScore F1: 0.6812\n",
      "BERTScore precision: 0.6812\n",
      "BERTScore recall: 0.6812\n",
      "Example 472\n",
      "Reference : no closest\n",
      "Prediction: they are closing in on each other.\n",
      "BERTScore F1: 0.3180\n",
      "BERTScore precision: 0.2681\n",
      "BERTScore recall: 0.3908\n",
      "Example 473\n",
      "Reference : no closest\n",
      "Prediction: close the door.\n",
      "BERTScore F1: 0.3735\n",
      "BERTScore precision: 0.3471\n",
      "BERTScore recall: 0.4043\n",
      "Example 474\n",
      "Reference : no closest\n",
      "Prediction: close it.\n",
      "BERTScore F1: 0.3584\n",
      "BERTScore precision: 0.3457\n",
      "BERTScore recall: 0.3721\n",
      "Example 475\n",
      "Reference : no closest\n",
      "Prediction: no\n",
      "BERTScore F1: 0.6233\n",
      "BERTScore precision: 0.6403\n",
      "BERTScore recall: 0.6071\n",
      "Example 476\n",
      "Reference : no closest\n",
      "Prediction: close it.\n",
      "BERTScore F1: 0.3584\n",
      "BERTScore precision: 0.3457\n",
      "BERTScore recall: 0.3721\n",
      "Example 477\n",
      "Reference : no closest\n",
      "Prediction: close it.\n",
      "BERTScore F1: 0.3584\n",
      "BERTScore precision: 0.3457\n",
      "BERTScore recall: 0.3721\n",
      "Example 478\n",
      "Reference : and the one on the very end\n",
      "Prediction: and one is on the very end.\n",
      "BERTScore F1: 0.8009\n",
      "BERTScore precision: 0.7794\n",
      "BERTScore recall: 0.8237\n",
      "Example 479\n",
      "Reference : and the one on the very end\n",
      "Prediction: it is very on the end of one.\n",
      "BERTScore F1: 0.5413\n",
      "BERTScore precision: 0.5291\n",
      "BERTScore recall: 0.5540\n",
      "Example 480\n",
      "Reference : and the one on the very end\n",
      "Prediction: it is very on one end.\n",
      "BERTScore F1: 0.4894\n",
      "BERTScore precision: 0.4771\n",
      "BERTScore recall: 0.5023\n",
      "Example 481\n",
      "Reference : and the one on the very end\n",
      "Prediction: they are standing still, pointing forward and holding hands.\n",
      "BERTScore F1: 0.3004\n",
      "BERTScore precision: 0.3153\n",
      "BERTScore recall: 0.2868\n",
      "Example 482\n",
      "Reference : and the one on the very end\n",
      "Prediction: they are standing still, pointing to the location on the left.\n",
      "BERTScore F1: 0.4555\n",
      "BERTScore precision: 0.4301\n",
      "BERTScore recall: 0.4841\n",
      "Example 483\n",
      "Reference : and the one on the very end\n",
      "Prediction: they are standing still and pointing to the location.\n",
      "BERTScore F1: 0.3749\n",
      "BERTScore precision: 0.3782\n",
      "BERTScore recall: 0.3716\n",
      "Example 484\n",
      "Reference : and the one on the very end\n",
      "Prediction: point to the very end on one.\n",
      "BERTScore F1: 0.6087\n",
      "BERTScore precision: 0.5846\n",
      "BERTScore recall: 0.6349\n",
      "Example 485\n",
      "Reference : and the one on the very end\n",
      "Prediction: one end is very close.\n",
      "BERTScore F1: 0.4778\n",
      "BERTScore precision: 0.4739\n",
      "BERTScore recall: 0.4817\n",
      "Example 486\n",
      "Reference : and the one on the very end\n",
      "Prediction: one end is very close.\n",
      "BERTScore F1: 0.4778\n",
      "BERTScore precision: 0.4739\n",
      "BERTScore recall: 0.4817\n",
      "Example 487\n",
      "Reference : and then on the other side the two closest to the middle get stacked\n",
      "Prediction: you get two stacks, one on each side, and they're most close to the middle.\n",
      "BERTScore F1: 0.5731\n",
      "BERTScore precision: 0.5386\n",
      "BERTScore recall: 0.6123\n",
      "Example 488\n",
      "Reference : and then on the other side the two closest to the middle get stacked\n",
      "Prediction: you get a stack of two things, one on each side of the other, and they are close to the middle, most.\n",
      "BERTScore F1: 0.5694\n",
      "BERTScore precision: 0.5257\n",
      "BERTScore recall: 0.6211\n",
      "Example 489\n",
      "Reference : and then on the other side the two closest to the middle get stacked\n",
      "Prediction: you get two stacks, one on each side, with the middle stack being most close but not touching.\n",
      "BERTScore F1: 0.5310\n",
      "BERTScore precision: 0.4962\n",
      "BERTScore recall: 0.5711\n",
      "Example 490\n",
      "Reference : and then on the other side the two closest to the middle get stacked\n",
      "Prediction: i want you to take two blocks.\n",
      "BERTScore F1: 0.3467\n",
      "BERTScore precision: 0.3531\n",
      "BERTScore recall: 0.3405\n",
      "Example 491\n",
      "Reference : and then on the other side the two closest to the middle get stacked\n",
      "Prediction: take two\n",
      "BERTScore F1: 0.3480\n",
      "BERTScore precision: 0.3910\n",
      "BERTScore recall: 0.3135\n",
      "Example 492\n",
      "Reference : and then on the other side the two closest to the middle get stacked\n",
      "Prediction: take two.\n",
      "BERTScore F1: 0.3864\n",
      "BERTScore precision: 0.4586\n",
      "BERTScore recall: 0.3338\n",
      "Example 493\n",
      "Reference : and then on the other side the two closest to the middle get stacked\n",
      "Prediction: get two on the other side, close most\n",
      "BERTScore F1: 0.6202\n",
      "BERTScore precision: 0.6473\n",
      "BERTScore recall: 0.5953\n",
      "Example 494\n",
      "Reference : and then on the other side the two closest to the middle get stacked\n",
      "Prediction: get two on the other side, then close most of it in the middle.\n",
      "BERTScore F1: 0.6333\n",
      "BERTScore precision: 0.6184\n",
      "BERTScore recall: 0.6490\n",
      "Example 495\n",
      "Reference : and then on the other side the two closest to the middle get stacked\n",
      "Prediction: get two on the other side, close to most.\n",
      "BERTScore F1: 0.6202\n",
      "BERTScore precision: 0.6270\n",
      "BERTScore recall: 0.6136\n",
      "Example 496\n",
      "Reference : two in front of you and two at the back\n",
      "Prediction: you are in front of you and at the back.\n",
      "BERTScore F1: 0.6915\n",
      "BERTScore precision: 0.6884\n",
      "BERTScore recall: 0.6946\n",
      "Example 497\n",
      "Reference : two in front of you and two at the back\n",
      "Prediction: you are in front of you and at the back.\n",
      "BERTScore F1: 0.6915\n",
      "BERTScore precision: 0.6884\n",
      "BERTScore recall: 0.6946\n",
      "Example 498\n",
      "Reference : two in front of you and two at the back\n",
      "Prediction: you are in front of you and at the back.\n",
      "BERTScore F1: 0.6915\n",
      "BERTScore precision: 0.6884\n",
      "BERTScore recall: 0.6946\n",
      "Example 499\n",
      "Reference : two in front of you and two at the back\n",
      "Prediction: look at the front of it.\n",
      "BERTScore F1: 0.4531\n",
      "BERTScore precision: 0.4674\n",
      "BERTScore recall: 0.4398\n",
      "Example 500\n",
      "Reference : two in front of you and two at the back\n",
      "Prediction: look at the front of it.\n",
      "BERTScore F1: 0.4531\n",
      "BERTScore precision: 0.4674\n",
      "BERTScore recall: 0.4398\n",
      "Example 501\n",
      "Reference : two in front of you and two at the back\n",
      "Prediction: look at the front and then turn around to look at the back.\n",
      "BERTScore F1: 0.5076\n",
      "BERTScore precision: 0.5029\n",
      "BERTScore recall: 0.5123\n",
      "Example 502\n",
      "Reference : two in front of you and two at the back\n",
      "Prediction: you're facing the front and at the back.\n",
      "BERTScore F1: 0.5991\n",
      "BERTScore precision: 0.6081\n",
      "BERTScore recall: 0.5903\n",
      "Example 503\n",
      "Reference : two in front of you and two at the back\n",
      "Prediction: move to the front, and then go back to you.\n",
      "BERTScore F1: 0.4938\n",
      "BERTScore precision: 0.4790\n",
      "BERTScore recall: 0.5095\n",
      "Example 504\n",
      "Reference : two in front of you and two at the back\n",
      "Prediction: move forward and back to you.\n",
      "BERTScore F1: 0.4190\n",
      "BERTScore precision: 0.4456\n",
      "BERTScore recall: 0.3953\n",
      "Example 505\n",
      "Reference : okay\n",
      "Prediction: okay\n",
      "BERTScore F1: 1.0000\n",
      "BERTScore precision: 1.0000\n",
      "BERTScore recall: 1.0000\n",
      "Example 506\n",
      "Reference : okay\n",
      "Prediction: okay\n",
      "BERTScore F1: 1.0000\n",
      "BERTScore precision: 1.0000\n",
      "BERTScore recall: 1.0000\n",
      "Example 507\n",
      "Reference : okay\n",
      "Prediction: okay\n",
      "BERTScore F1: 1.0000\n",
      "BERTScore precision: 1.0000\n",
      "BERTScore recall: 1.0000\n",
      "Example 508\n",
      "Reference : okay\n",
      "Prediction: stop the row.\n",
      "BERTScore F1: 0.3872\n",
      "BERTScore precision: 0.3278\n",
      "BERTScore recall: 0.4729\n",
      "Example 509\n",
      "Reference : okay\n",
      "Prediction: stop the row.\n",
      "BERTScore F1: 0.3872\n",
      "BERTScore precision: 0.3278\n",
      "BERTScore recall: 0.4729\n",
      "Example 510\n",
      "Reference : okay\n",
      "Prediction: stop the row.\n",
      "BERTScore F1: 0.3872\n",
      "BERTScore precision: 0.3278\n",
      "BERTScore recall: 0.4729\n",
      "Example 511\n",
      "Reference : okay\n",
      "Prediction: that's okay.\n",
      "BERTScore F1: 0.3964\n",
      "BERTScore precision: 0.3351\n",
      "BERTScore recall: 0.4853\n",
      "Example 512\n",
      "Reference : okay\n",
      "Prediction: row okay.\n",
      "BERTScore F1: 0.5307\n",
      "BERTScore precision: 0.4632\n",
      "BERTScore recall: 0.6212\n",
      "Example 513\n",
      "Reference : okay\n",
      "Prediction: row okay.\n",
      "BERTScore F1: 0.5307\n",
      "BERTScore precision: 0.4632\n",
      "BERTScore recall: 0.6212\n",
      "Example 514\n",
      "Reference : i don’t think can be touching\n",
      "Prediction: i think it is possible to touch.\n",
      "BERTScore F1: 0.5050\n",
      "BERTScore precision: 0.5034\n",
      "BERTScore recall: 0.5066\n",
      "Example 515\n",
      "Reference : i don’t think can be touching\n",
      "Prediction: i think it is possible to touch.\n",
      "BERTScore F1: 0.5050\n",
      "BERTScore precision: 0.5034\n",
      "BERTScore recall: 0.5066\n",
      "Example 516\n",
      "Reference : i don’t think can be touching\n",
      "Prediction: i think it is possible to touch.\n",
      "BERTScore F1: 0.5050\n",
      "BERTScore precision: 0.5034\n",
      "BERTScore recall: 0.5066\n",
      "Example 517\n",
      "Reference : i don’t think can be touching\n",
      "Prediction: i'm holding you on top of me.\n",
      "BERTScore F1: 0.3308\n",
      "BERTScore precision: 0.3122\n",
      "BERTScore recall: 0.3517\n",
      "Example 518\n",
      "Reference : i don’t think can be touching\n",
      "Prediction: i'm giving you a high-five.\n",
      "BERTScore F1: 0.3437\n",
      "BERTScore precision: 0.3321\n",
      "BERTScore recall: 0.3561\n",
      "Example 519\n",
      "Reference : i don’t think can be touching\n",
      "Prediction: i'm giving you the thumbs up.\n",
      "BERTScore F1: 0.3752\n",
      "BERTScore precision: 0.3660\n",
      "BERTScore recall: 0.3850\n",
      "Example 520\n",
      "Reference : i don’t think can be touching\n",
      "Prediction: i think it's possible to put two on top of the one.\n",
      "BERTScore F1: 0.4673\n",
      "BERTScore precision: 0.4176\n",
      "BERTScore recall: 0.5305\n",
      "Example 521\n",
      "Reference : i don’t think can be touching\n",
      "Prediction: you're thinking it's possible to put two on top of each other.\n",
      "BERTScore F1: 0.4055\n",
      "BERTScore precision: 0.3732\n",
      "BERTScore recall: 0.4439\n",
      "Example 522\n",
      "Reference : i don’t think can be touching\n",
      "Prediction: you can put two blocks on top of the other.\n",
      "BERTScore F1: 0.3375\n",
      "BERTScore precision: 0.3319\n",
      "BERTScore recall: 0.3434\n",
      "Example 523\n",
      "Reference : there is three blocks for the bottom of the smile\n",
      "Prediction: you have three blocks for the bottom of your smile.\n",
      "BERTScore F1: 0.7253\n",
      "BERTScore precision: 0.7094\n",
      "BERTScore recall: 0.7419\n",
      "Example 524\n",
      "Reference : there is three blocks for the bottom of the smile\n",
      "Prediction: there are three blocks at the bottom of a smile.\n",
      "BERTScore F1: 0.7377\n",
      "BERTScore precision: 0.7260\n",
      "BERTScore recall: 0.7498\n",
      "Example 525\n",
      "Reference : there is three blocks for the bottom of the smile\n",
      "Prediction: you have three bottoms of a smile.\n",
      "BERTScore F1: 0.4761\n",
      "BERTScore precision: 0.4862\n",
      "BERTScore recall: 0.4663\n",
      "Example 526\n",
      "Reference : there is three blocks for the bottom of the smile\n",
      "Prediction: put the row in and put it down.\n",
      "BERTScore F1: 0.4453\n",
      "BERTScore precision: 0.4308\n",
      "BERTScore recall: 0.4608\n",
      "Example 527\n",
      "Reference : there is three blocks for the bottom of the smile\n",
      "Prediction: put the row away.\n",
      "BERTScore F1: 0.3928\n",
      "BERTScore precision: 0.3934\n",
      "BERTScore recall: 0.3923\n",
      "Example 528\n",
      "Reference : there is three blocks for the bottom of the smile\n",
      "Prediction: put the row in.\n",
      "BERTScore F1: 0.4491\n",
      "BERTScore precision: 0.4502\n",
      "BERTScore recall: 0.4480\n",
      "Example 529\n",
      "Reference : there is three blocks for the bottom of the smile\n",
      "Prediction: and you put three blocks at the bottom of your smile.\n",
      "BERTScore F1: 0.5905\n",
      "BERTScore precision: 0.5727\n",
      "BERTScore recall: 0.6094\n",
      "Example 530\n",
      "Reference : there is three blocks for the bottom of the smile\n",
      "Prediction: and you put three blocks at the bottom of your smile.\n",
      "BERTScore F1: 0.5905\n",
      "BERTScore precision: 0.5727\n",
      "BERTScore recall: 0.6094\n",
      "Example 531\n",
      "Reference : there is three blocks for the bottom of the smile\n",
      "Prediction: and put the row in front of you on the bottom, smile.\n",
      "BERTScore F1: 0.4928\n",
      "BERTScore precision: 0.4676\n",
      "BERTScore recall: 0.5208\n",
      "Example 532\n",
      "Reference : there is two blocks for the eyes\n",
      "Prediction: the block is for your eye.\n",
      "BERTScore F1: 0.6170\n",
      "BERTScore precision: 0.6111\n",
      "BERTScore recall: 0.6230\n",
      "Example 533\n",
      "Reference : there is two blocks for the eyes\n",
      "Prediction: there are two blocks for the eye.\n",
      "BERTScore F1: 0.8206\n",
      "BERTScore precision: 0.8008\n",
      "BERTScore recall: 0.8414\n",
      "Example 534\n",
      "Reference : there is two blocks for the eyes\n",
      "Prediction: there are two blocks for the eye.\n",
      "BERTScore F1: 0.8206\n",
      "BERTScore precision: 0.8008\n",
      "BERTScore recall: 0.8414\n",
      "Example 535\n",
      "Reference : there is two blocks for the eyes\n",
      "Prediction: put it in the gap on the left.\n",
      "BERTScore F1: 0.4303\n",
      "BERTScore precision: 0.4269\n",
      "BERTScore recall: 0.4338\n",
      "Example 536\n",
      "Reference : there is two blocks for the eyes\n",
      "Prediction: put it in the gap on the left.\n",
      "BERTScore F1: 0.4303\n",
      "BERTScore precision: 0.4269\n",
      "BERTScore recall: 0.4338\n",
      "Example 537\n",
      "Reference : there is two blocks for the eyes\n",
      "Prediction: put it in the gap.\n",
      "BERTScore F1: 0.4021\n",
      "BERTScore precision: 0.4094\n",
      "BERTScore recall: 0.3949\n",
      "Example 538\n",
      "Reference : there is two blocks for the eyes\n",
      "Prediction: they put the claw into the gap, and then they point with their hands.\n",
      "BERTScore F1: 0.4121\n",
      "BERTScore precision: 0.3938\n",
      "BERTScore recall: 0.4322\n",
      "Example 539\n",
      "Reference : there is two blocks for the eyes\n",
      "Prediction: put the actor in two points.\n",
      "BERTScore F1: 0.4824\n",
      "BERTScore precision: 0.4813\n",
      "BERTScore recall: 0.4835\n",
      "Example 540\n",
      "Reference : there is two blocks for the eyes\n",
      "Prediction: put the first one in the gap and then put the second one in the point.\n",
      "BERTScore F1: 0.4334\n",
      "BERTScore precision: 0.4253\n",
      "BERTScore recall: 0.4418\n",
      "Example 541\n",
      "Reference : and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "Prediction: then i have the purpose to make a smile off of block 3, which is wider than block 2.\n",
      "BERTScore F1: 0.5697\n",
      "BERTScore precision: 0.5598\n",
      "BERTScore recall: 0.5800\n",
      "Example 542\n",
      "Reference : and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "Prediction: then, i will make a smile off of three blocks, wide and more.\n",
      "BERTScore F1: 0.5971\n",
      "BERTScore precision: 0.5950\n",
      "BERTScore recall: 0.5993\n",
      "Example 543\n",
      "Reference : and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "Prediction: then, i will make a smile off three blocks by making two wide blocks.\n",
      "BERTScore F1: 0.6554\n",
      "BERTScore precision: 0.6730\n",
      "BERTScore recall: 0.6387\n",
      "Example 544\n",
      "Reference : and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "Prediction: look at the row below.\n",
      "BERTScore F1: 0.4064\n",
      "BERTScore precision: 0.4333\n",
      "BERTScore recall: 0.3827\n",
      "Example 545\n",
      "Reference : and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "Prediction: look at the row over there.\n",
      "BERTScore F1: 0.3958\n",
      "BERTScore precision: 0.4127\n",
      "BERTScore recall: 0.3802\n",
      "Example 546\n",
      "Reference : and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "Prediction: look at the row above.\n",
      "BERTScore F1: 0.4138\n",
      "BERTScore precision: 0.4394\n",
      "BERTScore recall: 0.3909\n",
      "Example 547\n",
      "Reference : and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "Prediction: then we have three blocks to make a smile with two wide blocks more off.\n",
      "BERTScore F1: 0.6980\n",
      "BERTScore precision: 0.7121\n",
      "BERTScore recall: 0.6845\n",
      "Example 548\n",
      "Reference : and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "Prediction: then i have three blocks to make a smile with two wide blocks.\n",
      "BERTScore F1: 0.7134\n",
      "BERTScore precision: 0.7496\n",
      "BERTScore recall: 0.6805\n",
      "Example 549\n",
      "Reference : and then um there's three blocks to make the smile off the two wider blocks yeah\n",
      "Prediction: then we have three to make a smile, off the blocks.\n",
      "BERTScore F1: 0.6034\n",
      "BERTScore precision: 0.6291\n",
      "BERTScore recall: 0.5798\n",
      "Example 550\n",
      "Reference : push them up a little bit\n",
      "Prediction: push them up a little bit.\n",
      "BERTScore F1: 0.9364\n",
      "BERTScore precision: 0.9264\n",
      "BERTScore recall: 0.9466\n",
      "Example 551\n",
      "Reference : push them up a little bit\n",
      "Prediction: push them up a little bit.\n",
      "BERTScore F1: 0.9364\n",
      "BERTScore precision: 0.9264\n",
      "BERTScore recall: 0.9466\n",
      "Example 552\n",
      "Reference : push them up a little bit\n",
      "Prediction: push them up a little bit.\n",
      "BERTScore F1: 0.9364\n",
      "BERTScore precision: 0.9264\n",
      "BERTScore recall: 0.9466\n",
      "Example 553\n",
      "Reference : push them up a little bit\n",
      "Prediction: the actor moves down, then pushes forward, and finally moves back up with their hands in a claw shape.\n",
      "BERTScore F1: 0.4364\n",
      "BERTScore precision: 0.4032\n",
      "BERTScore recall: 0.4755\n",
      "Example 554\n",
      "Reference : push them up a little bit\n",
      "Prediction: you're pushing something down and then pulling it back up.\n",
      "BERTScore F1: 0.5036\n",
      "BERTScore precision: 0.4812\n",
      "BERTScore recall: 0.5281\n",
      "Example 555\n",
      "Reference : push them up a little bit\n",
      "Prediction: you move down, then push forward, then move up and pull back.\n",
      "BERTScore F1: 0.4743\n",
      "BERTScore precision: 0.4700\n",
      "BERTScore recall: 0.4786\n",
      "Example 556\n",
      "Reference : push them up a little bit\n",
      "Prediction: push them up a bit.\n",
      "BERTScore F1: 0.9057\n",
      "BERTScore precision: 0.9078\n",
      "BERTScore recall: 0.9036\n",
      "Example 557\n",
      "Reference : push them up a little bit\n",
      "Prediction: push them up a bit.\n",
      "BERTScore F1: 0.9057\n",
      "BERTScore precision: 0.9078\n",
      "BERTScore recall: 0.9036\n",
      "Example 558\n",
      "Reference : push them up a little bit\n",
      "Prediction: push them up a bit.\n",
      "BERTScore F1: 0.9057\n",
      "BERTScore precision: 0.9078\n",
      "BERTScore recall: 0.9036\n",
      "Example 559\n",
      "Reference : and in on the one far on three divots farthest from you\n",
      "Prediction: you have the most far degrees.\n",
      "BERTScore F1: 0.4579\n",
      "BERTScore precision: 0.4944\n",
      "BERTScore recall: 0.4264\n",
      "Example 560\n",
      "Reference : and in on the one far on three divots farthest from you\n",
      "Prediction: you have had the most far degrees.\n",
      "BERTScore F1: 0.4312\n",
      "BERTScore precision: 0.4565\n",
      "BERTScore recall: 0.4085\n",
      "Example 561\n",
      "Reference : and in on the one far on three divots farthest from you\n",
      "Prediction: you have had the most far degrees.\n",
      "BERTScore F1: 0.4312\n",
      "BERTScore precision: 0.4565\n",
      "BERTScore recall: 0.4085\n",
      "Example 562\n",
      "Reference : and in on the one far on three divots farthest from you\n",
      "Prediction: come down here and shake hands, then go back up.\n",
      "BERTScore F1: 0.3383\n",
      "BERTScore precision: 0.3473\n",
      "BERTScore recall: 0.3298\n",
      "Example 563\n",
      "Reference : and in on the one far on three divots farthest from you\n",
      "Prediction: come down here and grab it from far away.\n",
      "BERTScore F1: 0.4035\n",
      "BERTScore precision: 0.4051\n",
      "BERTScore recall: 0.4020\n",
      "Example 564\n",
      "Reference : and in on the one far on three divots farthest from you\n",
      "Prediction: come down, and then go up.\n",
      "BERTScore F1: 0.4074\n",
      "BERTScore precision: 0.4506\n",
      "BERTScore recall: 0.3718\n",
      "Example 565\n",
      "Reference : and in on the one far on three divots farthest from you\n",
      "Prediction: you have three divots that are far from you.\n",
      "BERTScore F1: 0.6118\n",
      "BERTScore precision: 0.6407\n",
      "BERTScore recall: 0.5854\n",
      "Example 566\n",
      "Reference : and in on the one far on three divots farthest from you\n",
      "Prediction: you are going to have three divots of the farthest degree.\n",
      "BERTScore F1: 0.5986\n",
      "BERTScore precision: 0.5933\n",
      "BERTScore recall: 0.6039\n",
      "Example 567\n",
      "Reference : and in on the one far on three divots farthest from you\n",
      "Prediction: you have three divots, the farthest one being most.\n",
      "BERTScore F1: 0.6028\n",
      "BERTScore precision: 0.6109\n",
      "BERTScore recall: 0.5948\n",
      "Example 568\n",
      "Reference : and then you got two towers like that on the sides\n",
      "Prediction: you get two towers on the sides.\n",
      "BERTScore F1: 0.7699\n",
      "BERTScore precision: 0.8292\n",
      "BERTScore recall: 0.7184\n",
      "Example 569\n",
      "Reference : and then you got two towers like that on the sides\n",
      "Prediction: you get two towers on the sides.\n",
      "BERTScore F1: 0.7699\n",
      "BERTScore precision: 0.8292\n",
      "BERTScore recall: 0.7184\n",
      "Example 570\n",
      "Reference : and then you got two towers like that on the sides\n",
      "Prediction: you get two towers on the sides.\n",
      "BERTScore F1: 0.7699\n",
      "BERTScore precision: 0.8292\n",
      "BERTScore recall: 0.7184\n",
      "Example 571\n",
      "Reference : and then you got two towers like that on the sides\n",
      "Prediction: put your hand on the left side.\n",
      "BERTScore F1: 0.4364\n",
      "BERTScore precision: 0.4627\n",
      "BERTScore recall: 0.4128\n",
      "Example 572\n",
      "Reference : and then you got two towers like that on the sides\n",
      "Prediction: look at the left side.\n",
      "BERTScore F1: 0.4482\n",
      "BERTScore precision: 0.4760\n",
      "BERTScore recall: 0.4235\n",
      "Example 573\n",
      "Reference : and then you got two towers like that on the sides\n",
      "Prediction: look over there.\n",
      "BERTScore F1: 0.3540\n",
      "BERTScore precision: 0.3833\n",
      "BERTScore recall: 0.3289\n",
      "Example 574\n",
      "Reference : and then you got two towers like that on the sides\n",
      "Prediction: get the two towers on both sides.\n",
      "BERTScore F1: 0.6141\n",
      "BERTScore precision: 0.6559\n",
      "BERTScore recall: 0.5773\n",
      "Example 575\n",
      "Reference : and then you got two towers like that on the sides\n",
      "Prediction: get two towers on the sides.\n",
      "BERTScore F1: 0.7288\n",
      "BERTScore precision: 0.7955\n",
      "BERTScore recall: 0.6725\n",
      "Example 576\n",
      "Reference : and then you got two towers like that on the sides\n",
      "Prediction: get the two towers on both sides.\n",
      "BERTScore F1: 0.6141\n",
      "BERTScore precision: 0.6559\n",
      "BERTScore recall: 0.5773\n",
      "Example 577\n",
      "Reference : and then you do that same process all the way up\n",
      "Prediction: you do everything the same way up.\n",
      "BERTScore F1: 0.5731\n",
      "BERTScore precision: 0.6104\n",
      "BERTScore recall: 0.5400\n",
      "Example 578\n",
      "Reference : and then you do that same process all the way up\n",
      "Prediction: you do everything the same way up.\n",
      "BERTScore F1: 0.5731\n",
      "BERTScore precision: 0.6104\n",
      "BERTScore recall: 0.5400\n",
      "Example 579\n",
      "Reference : and then you do that same process all the way up\n",
      "Prediction: you do everything the same way up.\n",
      "BERTScore F1: 0.5731\n",
      "BERTScore precision: 0.6104\n",
      "BERTScore recall: 0.5400\n",
      "Example 580\n",
      "Reference : and then you do that same process all the way up\n",
      "Prediction: point to the left.\n",
      "BERTScore F1: 0.3094\n",
      "BERTScore precision: 0.3212\n",
      "BERTScore recall: 0.2983\n",
      "Example 581\n",
      "Reference : and then you do that same process all the way up\n",
      "Prediction: point to the left.\n",
      "BERTScore F1: 0.3094\n",
      "BERTScore precision: 0.3212\n",
      "BERTScore recall: 0.2983\n",
      "Example 582\n",
      "Reference : and then you do that same process all the way up\n",
      "Prediction: point to the left.\n",
      "BERTScore F1: 0.3094\n",
      "BERTScore precision: 0.3212\n",
      "BERTScore recall: 0.2983\n",
      "Example 583\n",
      "Reference : and then you do that same process all the way up\n",
      "Prediction: you rotate something up and then do the same process all over again.\n",
      "BERTScore F1: 0.6913\n",
      "BERTScore precision: 0.6697\n",
      "BERTScore recall: 0.7143\n",
      "Example 584\n",
      "Reference : and then you do that same process all the way up\n",
      "Prediction: you're doing the same process up.\n",
      "BERTScore F1: 0.5985\n",
      "BERTScore precision: 0.6464\n",
      "BERTScore recall: 0.5572\n",
      "Example 585\n",
      "Reference : and then you do that same process all the way up\n",
      "Prediction: you rotate it up, and you rotate it up.\n",
      "BERTScore F1: 0.4978\n",
      "BERTScore precision: 0.5482\n",
      "BERTScore recall: 0.4558\n",
      "Example 586\n",
      "Reference : no on top yeah\n",
      "Prediction: you must top.\n",
      "BERTScore F1: 0.4991\n",
      "BERTScore precision: 0.4991\n",
      "BERTScore recall: 0.4991\n",
      "Example 587\n",
      "Reference : no on top yeah\n",
      "Prediction: you must top.\n",
      "BERTScore F1: 0.4991\n",
      "BERTScore precision: 0.4991\n",
      "BERTScore recall: 0.4991\n",
      "Example 588\n",
      "Reference : no on top yeah\n",
      "Prediction: you top it.\n",
      "BERTScore F1: 0.4587\n",
      "BERTScore precision: 0.4535\n",
      "BERTScore recall: 0.4640\n",
      "Example 589\n",
      "Reference : no on top yeah\n",
      "Prediction: look at the tower\n",
      "BERTScore F1: 0.3805\n",
      "BERTScore precision: 0.3984\n",
      "BERTScore recall: 0.3642\n",
      "Example 590\n",
      "Reference : no on top yeah\n",
      "Prediction: look at the tower\n",
      "BERTScore F1: 0.3805\n",
      "BERTScore precision: 0.3984\n",
      "BERTScore recall: 0.3642\n",
      "Example 591\n",
      "Reference : no on top yeah\n",
      "Prediction: look at the tower\n",
      "BERTScore F1: 0.3805\n",
      "BERTScore precision: 0.3984\n",
      "BERTScore recall: 0.3642\n",
      "Example 592\n",
      "Reference : no on top yeah\n",
      "Prediction: turn the tower around.\n",
      "BERTScore F1: 0.3447\n",
      "BERTScore precision: 0.3309\n",
      "BERTScore recall: 0.3597\n",
      "Example 593\n",
      "Reference : no on top yeah\n",
      "Prediction: turn the tower around.\n",
      "BERTScore F1: 0.3447\n",
      "BERTScore precision: 0.3309\n",
      "BERTScore recall: 0.3597\n",
      "Example 594\n",
      "Reference : no on top yeah\n",
      "Prediction: turn the tower around.\n",
      "BERTScore F1: 0.3447\n",
      "BERTScore precision: 0.3309\n",
      "BERTScore recall: 0.3597\n"
     ]
    }
   ],
   "source": [
    "for i, (p, r, f) in enumerate(zip(precision, recall, f1)):\n",
    "    print(f\"Example {i+1}\")\n",
    "    print(f\"Reference : {references[i]}\")\n",
    "    print(f\"Prediction: {candidates[i]}\")\n",
    "    print(f\"BERTScore F1: {f.item():.4f}\")\n",
    "    print(f\"BERTScore precision: {p.item():.4f}\")\n",
    "    print(f\"BERTScore recall: {r.item():.4f}\")\n",
    "    # if p < 0.30:\n",
    "    #     print(f\"Reference : {references[i]}\")\n",
    "    #     print(f\"Prediction: {candidates[i]}\")\n",
    "    #     print(f\"BERTScore precision: {p.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "51131a6b-3b97-4bb0-b3e0-2c98914bb74a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 score speech: 0.6604\n",
      "Average precision speech: 0.6609\n",
      "Average recall speech: 0.6653\n"
     ]
    }
   ],
   "source": [
    "## All candidates of speech scenario\n",
    "speech_references = []\n",
    "speech_candidates = []\n",
    "for item in ref_and_transl_bert:\n",
    "    # print(item)\n",
    "    if item['scenario'] == \"speech\":\n",
    "        speech_references.append(item['reference'])\n",
    "        speech_candidates.append(item['translation'])\n",
    "\n",
    "speech_precision, speech_recall, speech_f1 = score(speech_candidates, speech_references, lang=\"en\", model_type=\"bert-base-uncased\")\n",
    "print(f\"Average F1 score speech: {speech_f1.mean():.4f}\")\n",
    "print(f\"Average precision speech: {speech_precision.mean():.4f}\")\n",
    "print(f\"Average recall speech: {speech_recall.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "c4cef102-7bea-45e7-977f-f577bda49562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 score gesture: 0.4053\n",
      "Average precision gesture: 0.4035\n",
      "Average recall gesture: 0.4134\n"
     ]
    }
   ],
   "source": [
    "## All candidates of gesture scenario\n",
    "gesture_references = []\n",
    "gesture_candidates = []\n",
    "for item in ref_and_transl_bert:\n",
    "    #print(item)\n",
    "    if item['scenario'] == \"gesture\":\n",
    "        gesture_references.append(item['reference'])\n",
    "        gesture_candidates.append(item['translation'])\n",
    "\n",
    "gesture_precision, gesture_recall, gesture_f1 = score(gesture_candidates, gesture_references, lang=\"en\", model_type=\"bert-base-uncased\")\n",
    "print(f\"Average F1 score gesture: {gesture_f1.mean():.4f}\")\n",
    "print(f\"Average precision gesture: {gesture_precision.mean():.4f}\")\n",
    "print(f\"Average recall gesture: {gesture_recall.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "e0ef9bcd-9e26-432b-8e90-9ab134396461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 score gesture: 0.5488\n",
      "Average precision gesture: 0.5469\n",
      "Average recall gesture: 0.5578\n"
     ]
    }
   ],
   "source": [
    "## All candidates of speech+gesture scenario\n",
    "sp_gest_references = []\n",
    "sp_gest_candidates = []\n",
    "for item in ref_and_transl_bert:\n",
    "    #print(item)\n",
    "    if item['scenario'] == \"speech_gesture\":\n",
    "        sp_gest_references.append(item['reference'])\n",
    "        sp_gest_candidates.append(item['translation'])\n",
    "\n",
    "sp_gest_precision, sp_gest_recall, sp_gest_f1 = score(sp_gest_candidates, sp_gest_references, lang=\"en\", model_type=\"bert-base-uncased\")\n",
    "print(f\"Average F1 score gesture: {sp_gest_f1.mean():.4f}\")\n",
    "print(f\"Average precision gesture: {sp_gest_precision.mean():.4f}\")\n",
    "print(f\"Average recall gesture: {sp_gest_recall.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff97eea-7c5e-4233-9cd3-cc5c47a6c0de",
   "metadata": {},
   "source": [
    "## Paired Bootstrap Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "68abe502-f6b8-4b6c-961c-d9965413a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_test_bertscore(sys1_scores, sys2_scores, num_samples=1000, seed=42):\n",
    "    \"\"\"\n",
    "    It tests how much better one system is than another (on average) and whether\n",
    "    that difference is significant\n",
    "    Args:\n",
    "        refs: list of references that you're checking against\n",
    "        sys1: list of tokenized candidates from first output\n",
    "        sys2: list of tokenized candidates from second output\n",
    "        num_samples: number of bootstrap resamples\n",
    "        seed: seed\n",
    "    Returns:\n",
    "        np.mean(diffs): average difference between system 1 and system 2 across all bootstrap samples\n",
    "        p_value: calculated p_value\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    diffs = []\n",
    "\n",
    "    sys1_scores = np.array(sys1_scores)\n",
    "    sys2_scores = np.array(sys2_scores)\n",
    "\n",
    "    n = len(sys1_scores)\n",
    "    for _ in range(num_samples):\n",
    "        indices = [random.randint(0, n - 1) for _ in range(n)]  ## Generate n random indices 1000 times, with replacement\n",
    "        sample_sys1 = [sys1_scores[i] for i in indices]\n",
    "        sample_sys2 = [sys2_scores[i] for i in indices]\n",
    "\n",
    "        mean1 = np.mean(sample_sys1)\n",
    "        mean2 = np.mean(sample_sys2)\n",
    "\n",
    "        diffs.append(mean1 - mean2)\n",
    "\n",
    "    diffs = np.array(diffs)                     ## If diff>0 sys1 performed better, if diff<0 sys2 performed better\n",
    "    p_value = np.mean(diffs <= 0)               ## Calculate the proportion of bootstrap samples where sys1 was not better than sys2\n",
    "    return np.mean(diffs), p_value              ## Average observed BLEU difference between the systems, estimated significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "332f4151-9202-4676-876a-353b004a6bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech vs Gesture BERTScore Δprecision = 0.2573, p = 0.0000\n",
      "Speech vs Gesture BERTScore Δrecall = 0.2517, p = 0.0000\n",
      "Speech vs Gesture BERTScore f1 = 0.2549, p = 0.0000\n"
     ]
    }
   ],
   "source": [
    "## Speech compared to gesture\n",
    "delta_precision, p_precision = bootstrap_test_bertscore(speech_precision, gesture_precision)\n",
    "delta_recall, p_recall = bootstrap_test_bertscore(speech_recall, gesture_recall)\n",
    "delta_f1, p_f1 = bootstrap_test_bertscore(speech_f1, gesture_f1)\n",
    "\n",
    "print(f\"Speech vs Gesture BERTScore Δprecision = {delta_precision:.4f}, p = {p_precision:.4f}\")\n",
    "print(f\"Speech vs Gesture BERTScore Δrecall = {delta_recall:.4f}, p = {p_recall:.4f}\")\n",
    "print(f\"Speech vs Gesture BERTScore f1 = {delta_f1:.4f}, p = {p_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "83ed1283-7077-4e87-88fe-fe3b8a0ae505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech vs Speech+Gesture BERTScore Δprecision = 0.1142, p = 0.0000\n",
      "Speech vs Speech+Gesture BERTScore Δrecall = 0.1076, p = 0.0000\n",
      "Speech vs Speech+Gesture BERTScore f1 = 0.1117, p = 0.0000\n"
     ]
    }
   ],
   "source": [
    "## Speech compared to speech+gesture\n",
    "delta_precision, p_precision = bootstrap_test_bertscore(speech_precision, sp_gest_precision)\n",
    "delta_recall, p_recall = bootstrap_test_bertscore(speech_recall, sp_gest_recall)\n",
    "delta_f1, p_f1 = bootstrap_test_bertscore(speech_f1, sp_gest_f1)\n",
    "\n",
    "print(f\"Speech vs Speech+Gesture BERTScore Δprecision = {delta_precision:.4f}, p = {p_precision:.4f}\")\n",
    "print(f\"Speech vs Speech+Gesture BERTScore Δrecall = {delta_recall:.4f}, p = {p_recall:.4f}\")\n",
    "print(f\"Speech vs Speech+Gesture BERTScore f1 = {delta_f1:.4f}, p = {p_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "86b20d75-a1fb-43e3-ab29-affe04c5274c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesture vs Speech+Gesture BERTScore Δprecision = -0.1431, p = 1.0000\n",
      "Gesture vs Speech+Gesture BERTScore Δrecall = -0.1440, p = 1.0000\n",
      "Gesture vs Speech+Gesture BERTScore f1 = -0.1433, p = 1.0000\n"
     ]
    }
   ],
   "source": [
    "## Gesture compared to speech+gesture\n",
    "delta_precision, p_precision = bootstrap_test_bertscore(gesture_precision, sp_gest_precision)\n",
    "delta_recall, p_recall = bootstrap_test_bertscore(gesture_recall, sp_gest_recall)\n",
    "delta_f1, p_f1 = bootstrap_test_bertscore(gesture_f1, sp_gest_f1)\n",
    "\n",
    "print(f\"Gesture vs Speech+Gesture BERTScore Δprecision = {delta_precision:.4f}, p = {p_precision:.4f}\")\n",
    "print(f\"Gesture vs Speech+Gesture BERTScore Δrecall = {delta_recall:.4f}, p = {p_recall:.4f}\")\n",
    "print(f\"Gesture vs Speech+Gesture BERTScore f1 = {delta_f1:.4f}, p = {p_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ca122-17c3-4016-8283-f11491729fca",
   "metadata": {},
   "source": [
    "## AMR evaluation using Smatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7fdb499-67c8-4623-a0ac-60866d9c1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = \"test_df.pkl\"\n",
    "example_dataframe = \"example_df.pkl\"\n",
    "test_df = pickle.load(open(test_dataframe, 'rb'))\n",
    "example_df = pickle.load(open(example_dataframe, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e6f64c14-28af-4fb0-851e-e16d6f974ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(p / put-01  :mode imperative  :ARG0 (y / you)  :ARG1 (b / block   :quant 1)  :ARG2 (b2 / block    :mod (b3 / back)))\n",
      "(p / put-01  :mode imperative  :ARG0 (y / you)  :ARG1 (b / block   :quant 1)  :ARG2 (b2 / block    :mod (b3 / back)))\n",
      "(p / put-01  :mode imperative  :ARG0 (y / you)  :ARG1 (b / block   :quant 1)  :ARG2 (b2 / block    :mod (b3 / back)))\n",
      "(p / put-01  :mode imperative  :ARG0 (y / you)  :ARG1 (b / block   :quant 2))\n",
      "(p / put-01  :mode imperative  :ARG0 (y / you)  :ARG1 (b / block   :quant 2))\n",
      "(p / put-01  :mode imperative  :ARG0 (y / you)  :ARG1 (b / block   :quant 2))\n",
      "(u / um  :mode expressive)\n",
      "(u / um  :mode expressive)\n",
      "(u / um  :mode expressive)\n",
      "(a / and  :op2 (p / put-01   :mode imperative   :time (t / then)   :ARG0 (y / you)   :ARG1 (o / one)   :ARG2 (o2 / on    :op1 (t2 / top))))\n",
      "(a / and  :op2 (p / put-01   :mode imperative   :time (t / then)   :ARG0 (y / you)   :ARG1 (o / one)   :ARG2 (o2 / on    :op1 (t2 / top))))\n",
      "(a / and  :op2 (p / put-01   :mode imperative   :time (t / then)   :ARG0 (y / you)   :ARG1 (o / one)   :ARG2 (o2 / on    :op1 (t2 / top))))\n",
      "(m / multi-sentence  :snt1 (n / no)  :snt2 (l / look-02   :ARG0 (t / that)   :ARG1 (w / work-09)   :polarity - ))\n",
      "(m / multi-sentence  :snt1 (n / no)  :snt2 (l / look-02   :ARG0 (t / that)   :ARG1 (w / work-09)   :polarity - ))\n",
      "(m / multi-sentence  :snt1 (n / no)  :snt2 (l / look-02   :ARG0 (t / that)   :ARG1 (w / work-09)   :polarity - ))\n",
      "(y / yes)\n",
      "(y / yes)\n",
      "(y / yes)\n",
      "(j / jiggle-01  :mode imperative  :ARG0 (y / you))\n",
      "(j / jiggle-01  :mode imperative  :ARG0 (y / you))\n",
      "(j / jiggle-01  :mode imperative  :ARG0 (y / you))\n",
      "(e / enough-01  :ARG2 (g / good))\n",
      "(e / enough-01  :ARG2 (g / good))\n",
      "(e / enough-01  :ARG2 (g / good))\n",
      "(a / and  :op1 (j / jiggle-01   :time (t / then)   :mode imperative   :ARG0 (y / you)   :ARG1 (i / implicit-role    :quant 2    :location (f / front     :poss (t2 / them)))))\n",
      "(a / and  :op1 (j / jiggle-01   :time (t / then)   :mode imperative   :ARG0 (y / you)   :ARG1 (i / implicit-role    :quant 2    :location (f / front     :poss (t2 / them)))))\n",
      "(a / and  :op1 (j / jiggle-01   :time (t / then)   :mode imperative   :ARG0 (y / you)   :ARG1 (i / implicit-role    :quant 2    :location (f / front     :poss (t2 / them)))))\n",
      "(a / and   :op1 (t / take-01 :mode imperative          :ARG0 (y / you)          :ARG1 (b / block                  :mod (a2 / another)))   :op2 (p / put-01 :mode imperative          :ARG0 y          :ARG1 b          :ARG2 (n / next-to                  :op1 (i / it))))\n",
      "(a / and   :op1 (t / take-01 :mode imperative          :ARG0 (y / you)          :ARG1 (b / block                  :mod (a2 / another)))   :op2 (p / put-01 :mode imperative          :ARG0 y          :ARG1 b          :ARG2 (n / next-to                  :op1 (i / it))))\n",
      "(a / and   :op1 (t / take-01 :mode imperative          :ARG0 (y / you)          :ARG1 (b / block                  :mod (a2 / another)))   :op2 (p / put-01 :mode imperative          :ARG0 y          :ARG1 b          :ARG2 (n / next-to                  :op1 (i / it))))\n",
      "(o / okay)\n",
      "(o / okay)\n",
      "(o / okay)\n",
      "(b / block   :quant 1   :location (o / on-top-of               :op1 (b2 / block                      :mod (t / that)                      :quant (e / each)                      :quant 2))))\n",
      "(b / block   :quant 1   :location (o / on-top-of               :op1 (b2 / block                      :mod (t / that)                      :quant (e / each)                      :quant 2))))\n",
      "(b / block   :quant 1   :location (o / on-top-of               :op1 (b2 / block                      :mod (t / that)                      :quant (e / each)                      :quant 2))))\n",
      "(p / perfect)\n",
      "(p / perfect)\n",
      "(p / perfect)\n",
      "(a / and   :op2 (a2 / and          :op1 (t / take-hold-24                 :ARG0 (y / you)                 :ARG1 (i / implicit-role                         :quant 1))          :op2 (p / push-01                 :ARG0 y                 :ARG1 (i2 / it)                 :ARG2 (f / forward                         :mod (s / slight))                 :purpose (i3 / it                            :location (o / on                                        :op1 (d / diagonal))))          :time (t2 / then)))\n",
      "(a / and   :op2 (a2 / and          :op1 (t / take-hold-24                 :ARG0 (y / you)                 :ARG1 (i / implicit-role                         :quant 1))          :op2 (p / push-01                 :ARG0 y                 :ARG1 (i2 / it)                 :ARG2 (f / forward                         :mod (s / slight))                 :purpose (i3 / it                            :location (o / on                                        :op1 (d / diagonal))))          :time (t2 / then)))\n",
      "(a / and   :op2 (a2 / and          :op1 (t / take-hold-24                 :ARG0 (y / you)                 :ARG1 (i / implicit-role                         :quant 1))          :op2 (p / push-01                 :ARG0 y                 :ARG1 (i2 / it)                 :ARG2 (f / forward                         :mod (s / slight))                 :purpose (i3 / it                            :location (o / on                                        :op1 (d / diagonal))))          :time (t2 / then)))\n",
      "(i / implicit-role   :quant 2   :ARG1-of (i2 / include-91              :ARG2 (t / they))   :mod (o / only))\n",
      "(i / implicit-role   :quant 2   :ARG1-of (i2 / include-91              :ARG2 (t / they))   :mod (o / only))\n",
      "(i / implicit-role   :quant 2   :ARG1-of (i2 / include-91              :ARG2 (t / they))   :mod (o / only))\n",
      "(p / place-01   :mode imperative   :ARG0 (y / you)   :ARG1 (i / it)   :ARG2 (o / on           :op1 (i2 / implicit-role                  :quant 2                  :mod (d / diagonal))))\n",
      "(p / place-01   :mode imperative   :ARG0 (y / you)   :ARG1 (i / it)   :ARG2 (o / on           :op1 (i2 / implicit-role                  :quant 2                  :mod (d / diagonal))))\n",
      "(p / place-01   :mode imperative   :ARG0 (y / you)   :ARG1 (i / it)   :ARG2 (o / on           :op1 (i2 / implicit-role                  :quant 2                  :mod (d / diagonal))))\n",
      "(f / flip-01   :mode imperative   :ARG0 (y / you)   :ARG1 (i / implicit-role           :quant 2           :mod (t / that)))\n",
      "(f / flip-01   :mode imperative   :ARG0 (y / you)   :ARG1 (i / implicit-role           :quant 2           :mod (t / that)))\n",
      "(f / flip-01   :mode imperative   :ARG0 (y / you)   :ARG1 (i / implicit-role           :quant 2           :mod (t / that)))\n",
      "(k / keep-02   :mode imperative   :ARG0 (y / you)   :ARG2 (g / go-01           :ARG2 (m / more                   :quant (b / bit                            :mod (l / little)))))\n",
      "(k / keep-02   :mode imperative   :ARG0 (y / you)   :ARG2 (g / go-01           :ARG2 (m / more                   :quant (b / bit                            :mod (l / little)))))\n",
      "(k / keep-02   :mode imperative   :ARG0 (y / you)   :ARG2 (g / go-01           :ARG2 (m / more                   :quant (b / bit                            :mod (l / little)))))\n",
      "(p / put-01  :mode imperative   :ARG0 (y / you)   :ARG1-of (r / resemble-01   :ARG2 (t1 / that)    :mod (j / just)    :concession-of (h / have-degree-91    :ARG2 (c / close     :direction (t / together))   :ARG3 (m / more))))\n",
      "(p / put-01  :mode imperative   :ARG0 (y / you)   :ARG1-of (r / resemble-01   :ARG2 (t1 / that)    :mod (j / just)    :concession-of (h / have-degree-91    :ARG2 (c / close     :direction (t / together))   :ARG3 (m / more))))\n",
      "(p / put-01  :mode imperative   :ARG0 (y / you)   :ARG1-of (r / resemble-01   :ARG2 (t1 / that)    :mod (j / just)    :concession-of (h / have-degree-91    :ARG2 (c / close     :direction (t / together))   :ARG3 (m / more))))\n",
      "(m / matter-01    :ARG0 (i / it)    :polarity -))\n",
      "(m / matter-01    :ARG0 (i / it)    :polarity -))\n",
      "(m / matter-01    :ARG0 (i / it)    :polarity -))\n",
      "(a / and  :op1 (m / move   :mode imperative   :ARG0 (y / you)   :ARG1 (t / those)   :direction (t2 / together    :ARG1-of (h / have-degree-91     :ARG2 (c / close)     :ARG3 (m2 / more)     :degree (b / bit      :mod (l / little)))))  :op2 (p / put-01   :mode imperative   :ARG0 y   :ARG1 (t3 / that)   :ARG2 (o / on    :op1 (t4 / top))))\n",
      "(a / and  :op1 (m / move   :mode imperative   :ARG0 (y / you)   :ARG1 (t / those)   :direction (t2 / together    :ARG1-of (h / have-degree-91     :ARG2 (c / close)     :ARG3 (m2 / more)     :degree (b / bit      :mod (l / little)))))  :op2 (p / put-01   :mode imperative   :ARG0 y   :ARG1 (t3 / that)   :ARG2 (o / on    :op1 (t4 / top))))\n",
      "(a / and  :op1 (m / move   :mode imperative   :ARG0 (y / you)   :ARG1 (t / those)   :direction (t2 / together    :ARG1-of (h / have-degree-91     :ARG2 (c / close)     :ARG3 (m2 / more)     :degree (b / bit      :mod (l / little)))))  :op2 (p / put-01   :mode imperative   :ARG0 y   :ARG1 (t3 / that)   :ARG2 (o / on    :op1 (t4 / top))))\n",
      "(p / put-01  :mode imperative  :ARG0 (y / you)  :ARG1 (t / them)   :ARG2 (t2 / together))\n",
      "(p / put-01  :mode imperative  :ARG0 (y / you)  :ARG1 (t / them)   :ARG2 (t2 / together))\n",
      "(p / put-01  :mode imperative  :ARG0 (y / you)  :ARG1 (t / them)   :ARG2 (t2 / together))\n",
      "(b / block  :quant 2  :mod (m / more))\n",
      "(b / block  :quant 2  :mod (m / more))\n",
      "(b / block  :quant 2  :mod (m / more))\n",
      "(y / yep)\n",
      "(y / yep)\n",
      "(y / yep)\n",
      "(g / go-01  :manner (n / near-02))\n",
      "(g / go-01  :manner (n / near-02))\n",
      "(g / go-01  :manner (n / near-02))\n",
      "(a / and   :op2 (b / block          :quant 1          :ARG1-of (a2 / ahead-01                     :ARG2 (i / it))))\n",
      "(a / and   :op2 (b / block          :quant 1          :ARG1-of (a2 / ahead-01                     :ARG2 (i / it))))\n",
      "(a / and   :op2 (b / block          :quant 1          :ARG1-of (a2 / ahead-01                     :ARG2 (i / it))))\n",
      "(p / put-01   :mode imperative   :ARG0 (y / you)   :ARG1 (b / block           :quant 1)   :ARG2 (w / wherever           :ARG1-of (w2 / want-01                      :ARG0 y)))\n",
      "(p / put-01   :mode imperative   :ARG0 (y / you)   :ARG1 (b / block           :quant 1)   :ARG2 (w / wherever           :ARG1-of (w2 / want-01                      :ARG0 y)))\n",
      "(p / put-01   :mode imperative   :ARG0 (y / you)   :ARG1 (b / block           :quant 1)   :ARG2 (w / wherever           :ARG1-of (w2 / want-01                      :ARG0 y)))\n",
      "(a / and   :op1 (b / block          :ord (o / ordinal-entity                 :value 1)          :ARG1-of (p / put-01                     :ARG0 (y / you))          :ARG1-of (h / have-degree-91                     :ARG2 (n / near-02)                     :ARG3 (m / most)))   :op2 (s / side          :ARG1-of (r / right-04)          :poss b))\n",
      "(a / and   :op1 (b / block          :ord (o / ordinal-entity                 :value 1)          :ARG1-of (p / put-01                     :ARG0 (y / you))          :ARG1-of (h / have-degree-91                     :ARG2 (n / near-02)                     :ARG3 (m / most)))   :op2 (s / side          :ARG1-of (r / right-04)          :poss b))\n",
      "(a / and   :op1 (b / block          :ord (o / ordinal-entity                 :value 1)          :ARG1-of (p / put-01                     :ARG0 (y / you))          :ARG1-of (h / have-degree-91                     :ARG2 (n / near-02)                     :ARG3 (m / most)))   :op2 (s / side          :ARG1-of (r / right-04)          :poss b))\n",
      "(h / have-03  :ARG0 (w / we)  :ARG1 (b / block   :quant 2   :mod (a / apart    :op1 (o / other)    :extent (b2 / block     :quant 1))))\n",
      "(h / have-03  :ARG0 (w / we)  :ARG1 (b / block   :quant 2   :mod (a / apart    :op1 (o / other)    :extent (b2 / block     :quant 1))))\n",
      "(h / have-03  :ARG0 (w / we)  :ARG1 (b / block   :quant 2   :mod (a / apart    :op1 (o / other)    :extent (b2 / block     :quant 1))))\n",
      "(c / contrast-01  :ARG2 (r / recommend-01   :ARG1 (b / be-located-at-91    :ARG1 (t / that)    :ARG2 (o / on     :op1 (t2 / top      :poss (b2 / block       :mod (o2 / other)))))))\n",
      "(c / contrast-01  :ARG2 (r / recommend-01   :ARG1 (b / be-located-at-91    :ARG1 (t / that)    :ARG2 (o / on     :op1 (t2 / top      :poss (b2 / block       :mod (o2 / other)))))))\n",
      "(c / contrast-01  :ARG2 (r / recommend-01   :ARG1 (b / be-located-at-91    :ARG1 (t / that)    :ARG2 (o / on     :op1 (t2 / top      :poss (b2 / block       :mod (o2 / other)))))))\n",
      "(o / open-01  :mode imperative  :polite +  :mod (j / just)  :ARG0 (y / you)  :ARG1 (i / it)  :degree (b / bit   :mod (l / little)))\n",
      "(o / open-01  :mode imperative  :polite +  :mod (j / just)  :ARG0 (y / you)  :ARG1 (i / it)  :degree (b / bit   :mod (l / little)))\n",
      "(o / open-01  :mode imperative  :polite +  :mod (j / just)  :ARG0 (y / you)  :ARG1 (i / it)  :degree (b / bit   :mod (l / little)))\n",
      "(c / contrast-01  :ARG2 (r / recommend-01   :polarity -   :ARG1 (f / fall-01    :ARG1 (i / it))))\n",
      "(c / contrast-01  :ARG2 (r / recommend-01   :polarity -   :ARG1 (f / fall-01    :ARG1 (i / it))))\n",
      "(c / contrast-01  :ARG2 (r / recommend-01   :polarity -   :ARG1 (f / fall-01    :ARG1 (i / it))))\n",
      "(b / be-01    :ARG0 (r / row     :mod (n / next))     :ARG1 (t / three       :location (t2 / top         :location (g / gap)         :mod (m / middle))))\n",
      "(b / be-01    :ARG0 (r / row     :mod (n / next))     :ARG1 (t / three       :location (t2 / top         :location (g / gap)         :mod (m / middle))))\n",
      "(b / be-01    :ARG0 (r / row     :mod (n / next))     :ARG1 (t / three       :location (t2 / top         :location (g / gap)         :mod (m / middle))))\n",
      "(s / splay-01    :ARG0 (t / they)   :mod (k / kind-of))\n",
      "(s / splay-01    :ARG0 (t / they)   :mod (k / kind-of))\n",
      "(s / splay-01    :ARG0 (t / they)   :mod (k / kind-of))\n",
      "(c / cover-02  :ARG0 (y / you)  :ARG1 (t / there)  :ARG2 (i / implicit-role))\n",
      "(c / cover-02  :ARG0 (y / you)  :ARG1 (t / there)  :ARG2 (i / implicit-role))\n",
      "(c / cover-02  :ARG0 (y / you)  :ARG1 (t / there)  :ARG2 (i / implicit-role))\n",
      "(r / resemble-01  :ARG1 (i / it)  :ARG2 (a / angle))\n",
      "(r / resemble-01  :ARG1 (i / it)  :ARG2 (a / angle))\n",
      "(r / resemble-01  :ARG1 (i / it)  :ARG2 (a / angle))\n",
      "(a / and   :op2 (l / like-04          :ARG1 (i / it)          :ARG2 (o / or                  :op1 (f / fan)                  :op2 (w / wave                         :mod (s / sound)                         :ARG0-of (g / go-out-17)))))\n",
      "(a / and   :op2 (l / like-04          :ARG1 (i / it)          :ARG2 (o / or                  :op1 (f / fan)                  :op2 (w / wave                         :mod (s / sound)                         :ARG0-of (g / go-out-17)))))\n",
      "(a / and   :op2 (l / like-04          :ARG1 (i / it)          :ARG2 (o / or                  :op1 (f / fan)                  :op2 (w / wave                         :mod (s / sound)                         :ARG0-of (g / go-out-17)))))\n",
      "(n / need-01   :ARG0 (i / i)   :ARG1 (b / base           :quant 4)   :mod (a / again))\n",
      "(n / need-01   :ARG0 (i / i)   :ARG1 (b / base           :quant 4)   :mod (a / again))\n",
      "(n / need-01   :ARG0 (i / i)   :ARG1 (b / base           :quant 4)   :mod (a / again))\n",
      "(i / implicit-role   :quant 3   :location (o / on-top-of               :op1 (t / that))   :domain (o2 / one             :mod (n / next)))\n",
      "(i / implicit-role   :quant 3   :location (o / on-top-of               :op1 (t / that))   :domain (o2 / one             :mod (n / next)))\n",
      "(i / implicit-role   :quant 3   :location (o / on-top-of               :op1 (t / that))   :domain (o2 / one             :mod (n / next)))\n",
      "(a / and  :op1 (p / put-01   :mode imperative   :ARG0 (y / you)   :ARG1 (b / block    :quant 1)   :location (n / next    :ARG1 (i / it)))  :op2 (p2 / put-01    :mode imperative   :ARG0 y   :ARG1 b    :quant 1))\n",
      "(a / and  :op1 (p / put-01   :mode imperative   :ARG0 (y / you)   :ARG1 (b / block    :quant 1)   :location (n / next    :ARG1 (i / it)))  :op2 (p2 / put-01    :mode imperative   :ARG0 y   :ARG1 b    :quant 1))\n",
      "(a / and  :op1 (p / put-01   :mode imperative   :ARG0 (y / you)   :ARG1 (b / block    :quant 1)   :location (n / next    :ARG1 (i / it)))  :op2 (p2 / put-01    :mode imperative   :ARG0 y   :ARG1 b    :quant 1))\n",
      "(h / have-01  :mode imperative  :ARG0 (y / you)  :ARG1 (b / block   :quant 1))\n",
      "(h / have-01  :mode imperative  :ARG0 (y / you)  :ARG1 (b / block   :quant 1))\n",
      "(h / have-01  :mode imperative  :ARG0 (y / you)  :ARG1 (b / block   :quant 1))\n",
      "(b / be-01  :ARG0 (t / there)  :ARG1 (o / one   :ord 3)   :ARG1 (h / hang    :location (e / edge     :location (h2 / height      :ord 1))))\n",
      "(b / be-01  :ARG0 (t / there)  :ARG1 (o / one   :ord 3)   :ARG1 (h / hang    :location (e / edge     :location (h2 / height      :ord 1))))\n",
      "(b / be-01  :ARG0 (t / there)  :ARG1 (o / one   :ord 3)   :ARG1 (h / hang    :location (e / edge     :location (h2 / height      :ord 1))))\n",
      "(y / yeah)\n",
      "(y / yeah)\n",
      "(y / yeah)\n",
      "(b / be-located-at-91  :ARG1 (o / one   :mod (o2 / ordinal-entity    :value -1))  :ARG2 (o3 / on   :op1 (t / top    :op1 (i / it))   :mod (e / exactly    :degree (p / pretty-much)))  :mod (j / just)  :time (t2 / then))\n",
      "(b / be-located-at-91  :ARG1 (o / one   :mod (o2 / ordinal-entity    :value -1))  :ARG2 (o3 / on   :op1 (t / top    :op1 (i / it))   :mod (e / exactly    :degree (p / pretty-much)))  :mod (j / just)  :time (t2 / then))\n",
      "(b / be-located-at-91  :ARG1 (o / one   :mod (o2 / ordinal-entity    :value -1))  :ARG2 (o3 / on   :op1 (t / top    :op1 (i / it))   :mod (e / exactly    :degree (p / pretty-much)))  :mod (j / just)  :time (t2 / then))\n",
      "(s / same-01  :ARG2 (p / push-01   :ARG1 (t / that)   :ARG2 (o / off))  :ARG3 (d / direction))\n",
      "(s / same-01  :ARG2 (p / push-01   :ARG1 (t / that)   :ARG2 (o / off))  :ARG3 (d / direction))\n",
      "(s / same-01  :ARG2 (p / push-01   :ARG1 (t / that)   :ARG2 (o / off))  :ARG3 (d / direction))\n",
      "(i / implicit-predicate-00   :ARG1 (a / and     :op1 (r / resemble-01        :ARG1 (s / space)         :mod (b / block))     :op2 (b2 / block :ord (o / ordinal-entity :value 3))       :time (t / then)))\n",
      "(i / implicit-predicate-00   :ARG1 (a / and     :op1 (r / resemble-01        :ARG1 (s / space)         :mod (b / block))     :op2 (b2 / block :ord (o / ordinal-entity :value 3))       :time (t / then)))\n",
      "(i / implicit-predicate-00   :ARG1 (a / and     :op1 (r / resemble-01        :ARG1 (s / space)         :mod (b / block))     :op2 (b2 / block :ord (o / ordinal-entity :value 3))       :time (t / then)))\n",
      "(h / have-03  :time (t / then)  :location (l / line   :mod (s / same))  :ARG0 (y / you)  :ARG1 (s2 / space))\n",
      "(h / have-03  :time (t / then)  :location (l / line   :mod (s / same))  :ARG0 (y / you)  :ARG1 (s2 / space))\n",
      "(h / have-03  :time (t / then)  :location (l / line   :mod (s / same))  :ARG0 (y / you)  :ARG1 (s2 / space))\n",
      "(r / resemble-01   :ARG1 (o / over    :op1 (s / space     :location (b / between      :op1 (b2 / block))))  :purpose (b3 / be-located-at-91   :ARG1 (i / it)   :ARG2 (o2 / on)))\n",
      "(r / resemble-01   :ARG1 (o / over    :op1 (s / space     :location (b / between      :op1 (b2 / block))))  :purpose (b3 / be-located-at-91   :ARG1 (i / it)   :ARG2 (o2 / on)))\n",
      "(r / resemble-01   :ARG1 (o / over    :op1 (s / space     :location (b / between      :op1 (b2 / block))))  :purpose (b3 / be-located-at-91   :ARG1 (i / it)   :ARG2 (o2 / on)))\n",
      "(i / implicit-predicate  :ARG0 (i2 / implicit-role   :quant 1)  :ARG1 (l / less)  :ARG2 (t / than)  :ARG4 (t2 / that))\n",
      "(i / implicit-predicate  :ARG0 (i2 / implicit-role   :quant 1)  :ARG1 (l / less)  :ARG2 (t / than)  :ARG4 (t2 / that))\n",
      "(i / implicit-predicate  :ARG0 (i2 / implicit-role   :quant 1)  :ARG1 (l / less)  :ARG2 (t / than)  :ARG4 (t2 / that))\n",
      "(s / same-01  :ARG1 (i / implicit-role   :direction (o / other))  :concession (i2 / include   :ARG1 (i3 / implicit-role    :quant 5)))\n",
      "(s / same-01  :ARG1 (i / implicit-role   :direction (o / other))  :concession (i2 / include   :ARG1 (i3 / implicit-role    :quant 5)))\n",
      "(s / same-01  :ARG1 (i / implicit-role   :direction (o / other))  :concession (i2 / include   :ARG1 (i3 / implicit-role    :quant 5)))\n",
      "(i / implicit-predicate-00  :mode imperative  :ARG0 (y / you)  :direction (d / down   :degree 1)  :time (t / then))\n",
      "(i / implicit-predicate-00  :mode imperative  :ARG0 (y / you)  :direction (d / down   :degree 1)  :time (t / then))\n",
      "(i / implicit-predicate-00  :mode imperative  :ARG0 (y / you)  :direction (d / down   :degree 1)  :time (t / then))\n",
      "(p / put-01   :mode imperative   :ARG0 (y / you)   :ARG1 (t / them)   :manner (c / come-33             :ARG2 (d / diagonal)))\n",
      "(p / put-01   :mode imperative   :ARG0 (y / you)   :ARG1 (t / them)   :manner (c / come-33             :ARG2 (d / diagonal)))\n",
      "(p / put-01   :mode imperative   :ARG0 (y / you)   :ARG1 (t / them)   :manner (c / come-33             :ARG2 (d / diagonal)))\n",
      "(n / no)\n",
      "(n / no)\n",
      "(n / no)\n",
      "(a / and   :op2 (o / one          :location (o2 / on                      :op1 (e / end                             :degree (v / very)))))\n",
      "(a / and   :op2 (o / one          :location (o2 / on                      :op1 (e / end                             :degree (v / very)))))\n",
      "(a / and   :op2 (o / one          :location (o2 / on                      :op1 (e / end                             :degree (v / very)))))\n",
      "(a / and   :op2 (g / get-04          :ARG1 (s / stack-01                  :ARG2 (t / two                          :ARG1-of (h / have-degree-91                                     :ARG2 (c / close-10                                             :ARG2 (m / middle))                                     :ARG3 (m2 / most)))                  :location (o / on                              :op1 (s2 / side                                     :mod (o2 / other))))          :time (t2 / then)))\n",
      "(a / and   :op2 (g / get-04          :ARG1 (s / stack-01                  :ARG2 (t / two                          :ARG1-of (h / have-degree-91                                     :ARG2 (c / close-10                                             :ARG2 (m / middle))                                     :ARG3 (m2 / most)))                  :location (o / on                              :op1 (s2 / side                                     :mod (o2 / other))))          :time (t2 / then)))\n",
      "(a / and   :op2 (g / get-04          :ARG1 (s / stack-01                  :ARG2 (t / two                          :ARG1-of (h / have-degree-91                                     :ARG2 (c / close-10                                             :ARG2 (m / middle))                                     :ARG3 (m2 / most)))                  :location (o / on                              :op1 (s2 / side                                     :mod (o2 / other))))          :time (t2 / then)))\n",
      "(a / and   :op1 (i / implicit-role          :quant 2          :location (i2 / in-front-of                      :op1 (y / you)))   :op2 (i3 / implicit-role          :quant 2          :location (a2 / at                      :op1 (b / back))))\n",
      "(a / and   :op1 (i / implicit-role          :quant 2          :location (i2 / in-front-of                      :op1 (y / you)))   :op2 (i3 / implicit-role          :quant 2          :location (a2 / at                      :op1 (b / back))))\n",
      "(a / and   :op1 (i / implicit-role          :quant 2          :location (i2 / in-front-of                      :op1 (y / you)))   :op2 (i3 / implicit-role          :quant 2          :location (a2 / at                      :op1 (b / back))))\n",
      "(o / okay)\n",
      "(o / okay)\n",
      "(o / okay)\n",
      "(t / think-01   :ARG0 (i / i)   :ARG1 (p / possible-01           :ARG1 (t2 / touch-01)           :polarity -))\n",
      "(t / think-01   :ARG0 (i / i)   :ARG1 (p / possible-01           :ARG1 (t2 / touch-01)           :polarity -))\n",
      "(t / think-01   :ARG0 (i / i)   :ARG1 (p / possible-01           :ARG1 (t2 / touch-01)           :polarity -))\n",
      "(b / block  :quant 3  :purpose (b2 / bottom   :poss (s / smile)))\n",
      "(b / block  :quant 3  :purpose (b2 / bottom   :poss (s / smile)))\n",
      "(b / block  :quant 3  :purpose (b2 / bottom   :poss (s / smile)))\n",
      "(b / block  :quant 2  :purpose (e / eye))\n",
      "(b / block  :quant 2  :purpose (e / eye))\n",
      "(b / block  :quant 2  :purpose (e / eye))\n",
      "(h / have-purpose-91  :time (t / then)  :ARG1 (b / block   :quant 3)  :ARG2 (m / make-01   :ARG1 (s / smile    :location (o / off     :op1 (b2 / block      :quant 2      :mod (w / wide       :degree (m2 / more)))))))\n",
      "(h / have-purpose-91  :time (t / then)  :ARG1 (b / block   :quant 3)  :ARG2 (m / make-01   :ARG1 (s / smile    :location (o / off     :op1 (b2 / block      :quant 2      :mod (w / wide       :degree (m2 / more)))))))\n",
      "(h / have-purpose-91  :time (t / then)  :ARG1 (b / block   :quant 3)  :ARG2 (m / make-01   :ARG1 (s / smile    :location (o / off     :op1 (b2 / block      :quant 2      :mod (w / wide       :degree (m2 / more)))))))\n",
      "(p / push-01  :mode imperative  :ARG0 (y / you)  :ARG1 (t / them)  :ARG2 (u / up   :degree (b / bit    :mod (l / little))))\n",
      "(p / push-01  :mode imperative  :ARG0 (y / you)  :ARG1 (t / them)  :ARG2 (u / up   :degree (b / bit    :mod (l / little))))\n",
      "(p / push-01  :mode imperative  :ARG0 (y / you)  :ARG1 (t / them)  :ARG2 (u / up   :degree (b / bit    :mod (l / little))))\n",
      "(i / implicit-predicate-00  :ARG1 (d / divot   :quant 3   :ARG1-of (h / have-degree-91    :ARG2 (f / far     :op1 (y / you))    :ARG3 (m / most))))\n",
      "(i / implicit-predicate-00  :ARG1 (d / divot   :quant 3   :ARG1-of (h / have-degree-91    :ARG2 (f / far     :op1 (y / you))    :ARG3 (m / most))))\n",
      "(i / implicit-predicate-00  :ARG1 (d / divot   :quant 3   :ARG1-of (h / have-degree-91    :ARG2 (f / far     :op1 (y / you))    :ARG3 (m / most))))\n",
      "(g / get-01  :ARG0 (y / you)  :ARG1 (t / tower   :quantity 2   :location (o / on    :op1 (s / sides))))\n",
      "(g / get-01  :ARG0 (y / you)  :ARG1 (t / tower   :quantity 2   :location (o / on    :op1 (s / sides))))\n",
      "(g / get-01  :ARG0 (y / you)  :ARG1 (t / tower   :quantity 2   :location (o / on    :op1 (s / sides))))\n",
      "(d / do-02    :ARG0 (y / you)    :ARG1 (p / process       :mod (s / same))     :mod (a / all)       :manner (u / up)))\n",
      "(d / do-02    :ARG0 (y / you)    :ARG1 (p / process       :mod (s / same))     :mod (a / all)       :manner (u / up)))\n",
      "(d / do-02    :ARG0 (y / you)    :ARG1 (p / process       :mod (s / same))     :mod (a / all)       :manner (u / up)))\n",
      "(i / implicate-predicate-00  :mode imperative  :ARG0 (y / you)  :ARG1 (t / top   :polarity -))\n",
      "(i / implicate-predicate-00  :mode imperative  :ARG0 (y / you)  :ARG1 (t / top   :polarity -))\n",
      "(i / implicate-predicate-00  :mode imperative  :ARG0 (y / you)  :ARG1 (t / top   :polarity -))\n"
     ]
    }
   ],
   "source": [
    "## Extract all gold speech AMRs\n",
    "gold_speech_df = test_df[test_df['prompt_type'] == 'speech']\n",
    "\n",
    "## There are 3 runs for 1 sentence, so each entry needs to be included three times\n",
    "repeat_gold_speech_df = gold_speech_df.loc[gold_speech_df.index.repeat(3)].reset_index(drop=True)\n",
    "\n",
    "gold_speech_amrs = repeat_gold_speech_df['speech_amr'].tolist()\n",
    "for item in gold_speech_amrs:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "abf375d1-7760-46c8-87b4-1def6f4f0496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (f/front) :ARG2 (a/actor))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (f/front) :ARG2 (a/actor))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(s/put-01 :ARG0 (b/block) :location (l/location)) (a/and :op1 (s/put-02 :ARG0 (b2/block) :location (l2/location)))\n",
      "(s/put-01 :ARG0 (i/it) :ARG1 (b/block) :location (l/location))\n",
      "(s/put-01 :ARG0 (i/it) :ARG1 (b/block) :location (d/deixis-GA :ARG0 s :ARG1 (l/location) :ARG2 a2))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block :mod (d/down)) :ARG2 (a/actor))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block :mod (d/down))\n",
      "(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block :mod (d/down)) :ARG2 (a/actor))\n",
      "(d/deixis-01 :mode declarative :ARG0 (y/you) :ARG1 (l/location))\n",
      "(d/deixis-01 :mode declarative :ARG0 (y/you) :ARG1 (l/location))\n",
      "(i/icon-GA :ARG0 (s/signaler) :ARG1 (t/that) :ARG2 (a/actor))\n",
      "(i/icon-GA :ARG0 (s/signaler) :ARG1 (g/grab-01 :ARG1 (b/block :quant 2)) :ARG2 (a/actor))\n",
      "(i/icon-GA :ARG0 (s/signaler) :ARG1 (g/grab-01 :ARG1 (b/block :quant 2)) :ARG2 (a/actor)) (i/icon-GA :ARG0 (s/signaler) :ARG1 (c/close-06) :ARG2 (a/actor))\n",
      "(i/icon-GA :ARG0 (s/signaler) :ARG1 (g/grab-01 :ARG1 (b/block :quant 2)) :ARG2 (a/actor))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (u/up) :ARG2 (t/there))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (u/up) :ARG2 (t/there))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (t/that) :ARG2 (a/actor))\n",
      "(c/count-01 :mode imperative :ARG0 (s/signaler) :ARG1 (a/actor)) (d/deixis-GA :ARG0 s :ARG1 b/block :ARG2 a)\n",
      "(g/gesture-unit :op1 (i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (c/count-01 :ARG2 (a/actor)) :op2 (d/deixis-GA :ARG0 s :ARG1 (b/block) :ARG2 a)))\n",
      "(i/icon-GA :mode imperative :ARG0 (y/you) :ARG1 (j/jiggle-01 :direction (f/front)) :ARG2 (a/actor)) (d/deixis-GA :ARG0 s :ARG1 (b/block) :ARG2 a) (c/count-01 :ARG2 (a/actor) :op2 (d/deixis-GA :ARG0 s :ARG1 (b/block) :ARG2 a))\n",
      "(e/emblem-GA :ARG0 (s/signaler) :ARG1 (o/ok) :ARG2 (a/actor))\n",
      "(e/emblem-GA :ARG0 s :ARG1 o :ARG2 a)\n",
      "(e/emblem-GA :ARG0 s :ARG1 o :ARG2 a)\n",
      "(p/point-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block))\n",
      "(p/point-01 :mode imperative :ARG0 (s/signaler) :ARG1 (d/down) :cause-of (a/deixis-GA :ARG0 s :ARG1 (b/block)))\n",
      "(p/point-01 :mode imperative :ARG0 (y/you) :ARG1 (d/deixis-GA :ARG0 s :ARG1 (b/block) :ARG2 a))\n",
      "(p/put-01 :op1 (d/deixis-GA :ARG0 s :ARG1 l :ARG2 a) :op2 (i/icon-GA :ARG0 s :ARG1 p :ARG2 a))\n",
      "(p/put-01 :op1 (l/location) :op2 (s2/spread-03 :direction (a/apart)))\n",
      "(p/put-01 :op1 (d/deixis-GA :ARG0 s :ARG1 l :ARG2 a) :op2 (s/spread-03 :direction (a/apart)))\n",
      "(d/deixis-GA :ARG0 (y/you) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(g/gesture-unit :op1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) :op2 (i/icon-GA :ARG0 s :ARG1 (p/put-01) :ARG2 a))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (i/it) :ARG2 (o/over-there))\n",
      "(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (i/it) :ARG2 (l/location))\n",
      "(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block) :ARG2 (l/left))\n",
      "(e/emblem-GA :ARG0 (s/signaler) :ARG1 (o/ok) :ARG2 (a/actor))\n",
      "(e/emblem-GA :ARG0 s :ARG1 o :ARG2 a)\n",
      "(o/ok :op1)\n",
      "(i/icon-GA :ARG0 (s/signaler) :ARG1 (s2/slide-01 :direction (f/forward))) (i/icon-GA :ARG0 (s/signaler) :ARG1 (t/touch-01)) (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) (i/icon-GA :ARG0 (s/signaler) :ARG1 (s2/slide-01 :direction (f/forward)) :ARG2 (a/actor))\n",
      "(i/icon-GA :ARG0 (s/signaler) :ARG1 (t/take-01) :ARG2 (o/object)) (p/pickup-01 :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(g/dont-know :mode declarative :ARG0 (i/i) :mod (n/no))\n",
      "(g/go :mode declarative :ARG0 (y/you) :mod (l/let-s))\n",
      "(g/go-01 :mode imperative :ARG0 (y/you) :mod (l/let-s))\n",
      "(i/implicit-predicate-00 :mode imperative :ARG0 (y/you) :ARG1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) :manner (p/point)) (i/implicit-predicate-00 :mode imperative :ARG0 (y/you) :ARG1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) :manner (d/down))\n",
      "(i/implicit-predicate-00 :mode imperative :ARG0 (y/you) :ARG1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) :manner (p/point) :location (l/left)) (i/implicit-predicate-00 :mode imperative :ARG0 (y/you) :ARG1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) :manner (p/point) :location (d/down))\n",
      "(i/implicit-predicate-00 :mode imperative :ARG0 (y/you) :ARG1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) :manner (p/point)) (i/implicit-predicate-00 :mode imperative :ARG0 (y/you) :ARG1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) :manner (p/point))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (t/them) :direction (d/direction :mod (t2/this)) :ARG1-of (l/like-04 :ARG2 (h/have-04 :ARG0 y :ARG1 (i/it) :time (b/before)))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (o/object) :direction (d/direction :mod (b/back))) (e/emblem-GA :ARG0 (s/signaler) :ARG1 (n/no) :ARG2 (a/actor))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (h/hands) :direction (d/direction :mod (b/back))) (e/emblem-GA :ARG0 (s/signaler) :ARG1 (n/no) :ARG2 (a/actor))\n",
      "(c/connect-01 :ARG1 (t/they))\n",
      "(r/rotate-01 :mode declarative :ARG0 (t/they) :ARG1 (s/signaler))\n",
      "(c/connect-01 :ARG1 (t/they))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/back) :time (t/then)) (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (i/into-04 :ARG2 (g/gap :mod (l/left))))\n",
      "(i/icon-GA :ARG0 (s/signaler) :ARG1 (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/back)) (a/and :op2 (p/point-01 :mode imperative :ARG0 (y/you) :ARG1 (f/forward)))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (h/hands :mod (b/back))) (i/icon-GA :ARG0 (s/signaler) :ARG1 (f/fist) :ARG2 (a/actor)) (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (h/hands :mod (l/left))) (c/contrast-01 :ARG1 (g/gap :quant (b/bit) :mod (f/front)))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (o/object) :ARG2 (t/together :location (f/front :poss y)))\n",
      "(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (t/them) :manner (t/together :location (f/front)))\n",
      "(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (o/object) :ARG2 (t/together :location (f/front :poss y)))\n",
      "(i/icon-GA :op1 (p/push-01 :mode imperative :ARG0 (y/you) :ARG1 (t/together) :ARG2 (a/actor)))\n",
      "(i/icon-GA :op1 :mode imperative :ARG0 (y/you) :ARG1 (p/push-01 :ARG2 (t/together)))\n",
      "(i/icon-GA :op1 :ARG0 s :ARG1 p :mode imperative :ARG2 a)\n",
      "(s/is-01 :ARG1 (b/block) :mod (d/deixis-GA :ARG0 (t/there) :ARG1 (a/actor)) :op2 (i/icon-GA :mode expressive :ARG0 s :ARG1 2 :ARG2 a))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (b/block) :ARG2 (a/actor)) (i/icon-GA :mode expressive :ARG0 s :ARG1 2 :ARG2 a)\n",
      "(s/show-02 :ARG0 (s/signaler) :ARG1 (b/block) :mod (t/then) :ARG2 (i/icon-GA :mode expressive :ARG0 s :ARG1 2 :ARG2 a))\n",
      "(e/emblem-GA :ARG0 (s/signaler) :ARG1 (y/yes) :ARG2 (a/actor))\n",
      "(e/emblem-GA :ARG0 (s/signaler) :ARG1 (y/yes) :ARG2 (a/actor))\n",
      "(e/emblem-GA :ARG0 (s/signaler) :ARG1 (y/yes) :ARG2 (a/actor))\n",
      "(y/yes :ARG0 (s/signaler) :ARG1 (t/correct-01 :ARG0 (a/actor)))\n",
      "(e/emblem-GA :ARG0 (s/signaler) :ARG1 (y/yes) :ARG2 (a/actor))\n",
      "(e/emblem-GA :ARG0 (s/signaler) :ARG1 (y/yes) :ARG2 (a/actor))\n",
      "(c/come-01 :mode imperative :ARG0 (y/you) :location (h/here))\n",
      "(c/come-01 :mode imperative :ARG0 (y/you) :location (h/here))\n",
      "(c/come-here :mode imperative :ARG0 (y/you) :ARG1 s)\n",
      "(p/put :mode imperative :ARG0 (y/you) :ARG1 (b/block) :location (g/gap :mod (l/left)))\n",
      "(p/put :mode imperative :ARG0 (y/you) :ARG1 (b/block :quant 2) :location (g/gap :mod (l/left)))\n",
      "(p/put :mode imperative :ARG0 (y/you) :ARG1 (b/block) :location (g/gap :mod (l/left)))\n",
      "(p/put-01 :ARG0 (s/signaler) :ARG1 (t/to-the-right) :ARG2 (a/actor))\n",
      "(p/put-01 :ARG0 (s/signaler) :ARG1 (it) :ARG2 (r/right))\n",
      "(p/put-01 :ARG0 (s/signaler) :ARG1 (t/thing) :ARG2 (l/location))\n",
      "(p/put-01 :mode imperative :polarity + :ARG0 (y/you) :ARG1 (b/block) :ARG2 (s/space))\n",
      "(p/put-01 :ARG0 s :ARG1 b2 :ARG2 s2)\n",
      "(p/put-01 :ARG0 s :ARG1 b :ARG2 s2)\n",
      "(e/enough-01 :ARG2 (n/no)) (d/deixis-GA :mode expressive :ARG0 (s/signaler) :ARG1 (b/backward) :ARG2 (a/actor)) (i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (t/top) :ARG2 (a/actor))\n",
      "(e/emblem-GA :mode expressive :ARG0 (s/signaler) :ARG1 (n/no) :ARG2 (a/actor)) (i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (t/top) :ARG2 (a/actor)) (d/deixis-GA :mode expressive :ARG0 (s/signaler) :ARG1 (b/backward) :ARG2 (a/actor))\n",
      "(e/enough-01 :ARG2 (n/no)) (d/deixis-GA :mode expressive :ARG0 (s/signaler) :ARG1 (t/top) :ARG2 (a/actor)) (i/icon-GA :mode imperative :ARG0 (s/signaler) :ARG1 (m/move-01 :ARG2 (b/backward)))\n",
      "(i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (a/apart) :ARG2 (a2/actor))\n",
      "(i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (m/move-01 :ARG1 (i/it) :ARG3 (a2/actor))\n",
      "(i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (a/apart) :ARG2 (a2/actor))\n",
      "(s/infront-01 :ARG0 (h/he) :location (i2/in :op1 (l/left :mod (f/front))) :ARG2 (b/block))\n",
      "(d/deixis-GA :mode expressive :ARG0 (s/signaler) :ARG1 (l/left) :ARG2 (b/block))\n",
      "(d/deixis-GA :mode expressive :ARG0 (s/signaler) :ARG1 (l/left) :ARG2 (b/block))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block :mod (t/top))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block :mod (u/up)))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block :mod (u/up)))\n",
      "(a/and :op1 (s/stand-apart-01 :mode imperative :ARG0 (y/you) :ARG1 (s/splayed) :time (t3/then)) :op2 (h/have-03 :ARG0 (i/implicit-role :quant 2) :ARG1 (f/fist)))\n",
      "(a/and :op1 (s/start-01 :mode imperative :ARG0 (y/you) :ARG1 (s/splayed)) :op2 (g/get-down-00 :mode imperative :ARG0 y :ARG1 (g/ground)))\n",
      "(a/and :op1 (s/start-01 :mode imperative :ARG0 (y/you) :ARG1 (i/icon-GA :ARG0 (s/signaler) :ARG1 (s2/splayed) :ARG2 (a/actor))) :op2 (m/move-01 :mode imperative :ARG0 y :ARG1 (i/icon-GA :ARG0 s :ARG1 (g/gap) :ARG2 a)))\n",
      "(i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (m/move-01 :ARG2 (c/close-10)) :ARG2 (a/actor))\n",
      "(i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (m/move-01 :ARG2 (c/close-10)) :ARG2 (a/actor))\n",
      "(i/icon-GA :mode expressive :ARG0 (s/signaler) :ARG1 (m/move-01 :ARG2 (c/close-10)) :ARG2 (a/actor))\n",
      "(h/have-91 :ARG0 (a/actor) :ARG1 (l/look))\n",
      "(h/have-91 :ARG1 (a/angle-02 :op1 (r/raise) :op2 (l/lower)))\n",
      "(h/have-02 :ARG0 (y/you) :ARG1 (a3/angle-02 :ARG2 (a2/actor)) :op1 (i/icon-GA :ARG0 s :ARG1 a3 :ARG2 i2) :op2 (i/icon-GA :ARG0 s :ARG1 a3 :ARG2 i2))\n",
      "(m/make-01 :mode imperative :ARG0 (y/you) :ARG1 (c/curve) :direction (r/right) :ARG2 (a/actor)) (s/spread-03 :mode imperative :ARG0 (y/you) :ARG1 (t/them) :direction (a/apart) :quant (b/bit :mod (l/little))) (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (c/curve) :direction (d/down))\n",
      "(c/close-01 :mode imperative :ARG0 (y/you) :ARG1 (g/gap) :direction (i/into :quant (l/little)))\n",
      "(c/close-01 :mode imperative :ARG0 (y/you) :ARG1 (h/hands) :direction (o/opposite)) (m/move :mode imperative :ARG0 (y/you) :ARG1 (h/hands) :direction (a/apart))\n",
      "(i/icon-GA :ARG0 (s/signaler) :ARG1 4 :ARG2 (a/actor))\n",
      "(h/hold-01 :ARG0 (i/implicit-role :quant 4) :ARG1 (f/fingers :mod (u/up)))\n",
      "(h/hold-01 :ARG0 (r/right) :ARG1 (f/four :mod (i/in-front-of))) (s/shake-02 :ARG0 (r/right) :ARG2 (f/four :mod (i/in-front-of)))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 4 :cause-of (i/increase-01 :ARG1 3) :cause-of (d/decrease-01 :ARG1 3))\n",
      "(m/move-01 :ARG1 3 :destination (t/third) :op2 (m2/move-02 :ARG1 3 :mode descending))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 4 :cause-of (r/raise-01 :ARG2 3)) (d/descent-01 :mode imperative :ARG0 (y/you) :ARG1 3)\n",
      "(l/look :op1 (o/over-there :op1 (t/that)))\n",
      "(l/look :op1 (t/there) :op2 (o/over))\n",
      "(l/look-at :op1 (t/that))\n",
      "(d/deixis-GA :ARG0 (y/you) :ARG1 (t/there) :ARG2 (a/actor))\n",
      "(d/deixis-GA :ARG0 (y/you) :ARG1 (o/location) :ARG2 (t/there))\n",
      "(d/deixis-GA :ARG0 (y/you) :ARG1 (t/that) :ARG2 (o/over-there))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block) :ARG2 (l/left)) (s/shake-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block))\n",
      "(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (i/it) :ARG2 (o/on-left-s :op1 (s/side :ARG0-of (h/have :ARG1 (l/left))))\n",
      "(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block) :ARG2 (o/on-top :op1 (i/icon-GA :ARG0 s :ARG1 (r/rotate-01) :ARG2 a)))\n",
      "(d/deixis-GA :ARG0 (y/you) :ARG1 (l/location) :ARG2 (b/below))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(p/put-01 :ARG1 (t/top) :ARG2 (a/actor))\n",
      "(p/put-01 :ARG0 (s/signaler) :ARG1 (t/top) :ARG2 (a/actor))\n",
      "(p/put-01 :ARG0 (s/signaler) :ARG1 (t/top) :ARG2 (a/actor))\n",
      "(g/grab-01 :mode imperative :ARG0 (y/you) :ARG1 (p/place-01 :location (l/left)) :mod (i/icon-GA :ARG0 (s/signaler) :ARG1 (p/put-01) :ARG2 (a/actor)))\n",
      "(g/grab-01 :mode imperative :ARG0 (y/you) :ARG1 (t/it :mod (p/put-01)) :ARG2 (l/left))\n",
      "(g/grab-01 :mode imperative :ARG0 (y/you) :ARG1 (p/put-01 :ARG1 (s/slide :direction (l/left))) :mod ())\n",
      "(i/implicit-predicate-00 :mode declarative :ARG0 (s/signaler) :ARG1 (l/location))\n",
      "(i/implicit-predicate-00 :mode declarative :ARG0 (s/signaler) :ARG1 (l/deixis-GA :ARG0 s :ARG1 (l/location) :ARG2 (a/actor)) :ARG3 (b/block :location (l/location)))\n",
      "(i/implicit-predicate-00 :mode declarative :ARG0 (s/signaler) :ARG1 (l/location))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (h/head) :direction (d/direction :mod (d/down))) (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (h/head) :direction (d/direction :mod (l/left)))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (h/hand) :direction (d/direction :mod (l/left)) :purpose (u/up))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :direction (d/direction :mod (l/left))) (m/move-01 :mode imperative :ARG0 (y/you) :direction (u/up))\n",
      "(y/yes-01 :mode declarative :ARG0 (s/signaler) :ARG1 (l/location))\n",
      "(y/yes-01 :mode declarative :ARG0 (s/signaler) :ARG2 (a/actor))\n",
      "(a/agree-01 :mode declarative :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(a/and :op2 (m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (b/block) :quant (f/front)) :op3 (m/move-02 :mode imperative :ARG0 (y/you) :ARG1 (b/block) :quant (l/left)))\n",
      "(d/deixis-GA :mode imperative :ARG0 (y/you) :ARG1 (b/block) :ARG2 (a/actor)) (i/icon-GA :ARG0 s :ARG1 (m/move-01) :ARG2 a) (i/icon-GA :ARG0 s :ARG1 (p/point-02) :ARG2 a)\n",
      "(a/and :op2 (d/deixis-GA :ARG0 s :ARG1 b :ARG2 a) :op3 (i/icon-GA :ARG0 s :ARG1 m :ARG2 a))\n",
      "(d/diagonal :mode expressive :ARG0 (y/you) :ARG1 (s/signaler) :ARG2 (a/actor))\n",
      "(p/point-01 :mode imperative :ARG0 (y/you) :ARG1-of (l/left) :ARG2-of (f/forward)) (h/head-shake-01 :ARG0 (s/signaler) :ARG1 (a/actor))\n",
      "(p/move-01 :mode imperative :ARG0 (y/you) :ARG2 (o/object) :direction (d/diagonal))\n",
      "(i/icon-GA :ARG0 s :ARG1 (p/point-01 :mode imperative) :ARG2 (b/block) :ARG3 (l/location)) (m/move-01 :direction (f/front)) (d/deixis-GA :ARG0 s :ARG1 (l/location) :ARG2 a) (i/icon-GA :ARG0 s :ARG1 (m/move-01 :direction (d1/down)))\n",
      "(i/icon-GA :ARG0 s :ARG1 (p/point-01 :mode imperative) :ARG2 (b/block) :location (f/front :poss y)) (m/move-01 :direction (d1/down))\n",
      "(i/icon-GA :ARG0 s :ARG1 (p/point-01 :mode imperative) :ARG2 (b/block) :manner (f/front)) (g/gesture-unit :op1 (d/deixis-GA :ARG0 s :ARG1 (l/location) :ARG2 a) :op2 (i/icon-GA :ARG0 s :ARG1 (m/move-01 :direction d1/down) :ARG2 a))\n",
      "(i/icon-GA :op1 (m/move-01 :direction (u/up) :ARG0 (h/hand) :ARG2 (s/signaler)) :op2 (t/touch-01 :mode contact :location (r/right)))\n",
      "(i/icon-GA :op1 (d/deixis-GA :ARG0 s :ARG1 l/location :ARG2 a) :op2 (t/touch-01 :mode imperative :ARG0 y :ARG1 d/diagonal))\n",
      "(i/icon-GA :op1 (d/deixis-GA :ARG0 s :ARG1 l/location :ARG2 a) :op2 (t/touch-01 :mode imperative :ARG0 y :ARG1 o/object :ARG2 l/left))\n",
      "(s/close-10 :ARG1 (t/they) :mod (i/in))\n",
      "(s/close-10 :ARG1 (d/door) :mod (t/towards))\n",
      "(s/close-10 :ARG1 (t/it) :mod (j/just))\n",
      "(e/emblem-GA :ARG0 (s/signaler) :ARG1 2 :ARG2 (a/actor)) (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(e/emblem-GA :mode expressive :ARG0 (s/signaler) :ARG1 2 :ARG2 (a/actor)) (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(e/emblem-GA :ARG0 (s/signaler) :ARG1 2 :ARG2 (a/actor))(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(w/want-01 :ARG0 (i/I) :ARG1 (t/take-01 :ARG0 (y/you) :ARG1 (b/block :quant 2)))\n",
      "(w/take-01 :ARG0 (y/you) :ARG1 (n/number :quant 2))\n",
      "(w/want-01 :ARG0 (y/you) :ARG1 (t/take-01 :ARG0 (s/signaler) :ARG1 (n/number 2)))\n",
      "(l/look-01 :op1 (i/icon-GA :ARG0 (s/signaler) :ARG1 (f/front) :ARG2 (a/actor)))\n",
      "(l/look-01 :op1 (i/icon-GA :ARG0 s :ARG1 f :ARG2 a))\n",
      "(l/look-01 :op1 (f/front) :mod (a/at) :ARG0 (y/you) :ARG1 (t/them) :op2 (r/rotate-02 :mode imperative :ARG0 y :ARG1 a))\n",
      "(s/stoppable-action :mode imperative :ARG0 (y/you) :ARG1 (r/row))\n",
      "(s/stoppable\n",
      "\t:mode imperative\n",
      "\t:ARG0 (y/you)\n",
      "\t:ARG1 (r/row))\n",
      "(p/stop :mode imperative :ARG0 (y/you) :ARG1 (r/row))\n",
      "(h/hold-01 :ARG0 (s/signaler) :ARG1 (a/actor) :ARG2 (o/on-top-of))\n",
      "(t/touch-01 :ARG0 (h/hand) :ARG1 (f/five))\n",
      "(t/touch-01 :ARG0 (s/signaler) :ARG1 (c/corner) :ARG2 (a/actor))\n",
      "(p/put-01 :ARG0 (a2/actor) :ARG1 (r/row) :ARG2 (i/in-01 :ARG0 (s/signaler))) (p2/put-01 :mode imperative :ARG0 s :ARG1 r :ARG2 a2)\n",
      "(p/put-01 :mode imperative :ARG0 (y/you) :ARG1 (r/row) :ARG2 (a/away))\n",
      "(p/put-01 :ARG0 (s/signaler) :ARG1 (r/row) :ARG2 (a/actor))\n",
      "(e/envelope-01 :mode imperative :ARG0 (y/you) :ARG1 (i2/implicit-role) :direction (l/left) :destination (a/at :op1 (g/gap)))\n",
      "(e/enhance-01 :mode declarative :ARG0 (i/icon-GA :ARG0 (s/signaler) :ARG1 (p/put-01 :ARG2 (a2/actor)) :op1 (g/gap :op1 (l/left)))\n",
      "(e/enough-01 :ARG2 (g/gap))\n",
      "(i/icon-GA :ARG0 s :ARG1 r :ARG2 a) (d/deixis-GA :ARG0 s :ARG1 l :ARG2 a)\n",
      "(d/deixis-GA :ARG0 s :ARG1 (l/location) :ARG2 a)\n",
      "(d/deixis-GA :ARG0 s :ARG1 (r/row) :ARG2 a)\n",
      "(s/move-01 :ARG0 (a/actor) :location (l/location)) (p/push-02 :ARG1 (f/forward) :ARG2 (d/down)) (s/move-03 :ARG0 (a/actor) :direction (b/back))\n",
      "(s/push-01 :ARG1 (l/location) :ARG2 (a/actor)) (s/pull-01 :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(s/move-01 :ARG0 (y/you) :location (d/down)) (a/and :op1 (p/push-01 :ARG1 (f/forward) :ARG2 (y/you))) (s/move-02 :ARG0 (y/you) :location (u/up)) (a/and :op1 (p2/pull-01 :ARG1 (b/back) :ARG2 (y/you)))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (l/location)) (a/and :op1 (i/icon-GA :ARG0 s :ARG1 (h/handshake :mod (f/far)) :ARG2 a2)) (g/gesture-unit :op1 (d/deixis-GA :ARG0 s :ARG1 l :ARG2 a2) :op2 (m/move-01 :mode imperative :ARG0 s :ARG1 (u/up)))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (l/location) :ARG2 (a/actor)) (g/gesture-unit :op1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a2/actor)) :op2 (i/icon-GA :ARG0 s :ARG1 (f/far) :ARG2 a2))\n",
      "(m/move-01 :mode imperative :ARG0 (y/you) :ARG1 (l/location)) (a/and :op1 (g/gesture-unit :op1 (d/deixis-GA :ARG0 (s/signaler) :ARG1 (u/up) :ARG2 (a2/actor)) :op2 (i/icon-GA :ARG0 s :ARG1 f :ARG2 a2))\n",
      "(p/put-01 :mode imperative :ARG0 y :ARG1 (h/hand :mod (l/left)) :ARG2 (s/side :mod (l/location)))\n",
      "(d/deixis-GA :mode expressive :ARG0 (y/you) :ARG1 (l/left) :ARG2 (t/side))\n",
      "(d/deixis-GA :mode expressive :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor))\n",
      "(i/icon-GA :ARG0 s :ARG1 (p/point :mod (l/left)) :ARG2 a)\n",
      "(i/icon-GA :ARG0 s :ARG1 (p/point :mod (l/left)) :ARG2 a)\n",
      "(i/icon-GA :ARG0 s :ARG1 (p/point-left) :ARG2 a)\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a/actor)) (i/icon-GA :ARG0 s :ARG1 (t/tower) :ARG2 a2)\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a2/actor)) (i/icon-GA :ARG0 s :ARG1 (t/tower) :ARG2 a2)\n",
      "(d/deixis-GA :ARG0 (s/signaler) :ARG1 (l/location) :ARG2 (a2/actor)) (i/icon-GA :ARG0 s :ARG1 (t/tower) :ARG2 a2)\n"
     ]
    }
   ],
   "source": [
    "## Extract the AMRs generated by Llama for the gesture condition\n",
    "sent_and_amr = []\n",
    "for item in results:   \n",
    "    if item[\"scenario\"] == \"gesture\":\n",
    "        for key in [\"llama_1\", \"llama_2\", \"llama_3\"]:\n",
    "            try:\n",
    "                amr_matches = re.findall(r'\"speech AMR\"\\s*:\\s*\"([^\"]+)\"', item[key])\n",
    "                sent_matches = re.findall(r'\"sentence\"\\s*:\\s*\"([^\"]+)\"', item[key])\n",
    "                for amr_match, sent_match in zip(amr_matches, sent_matches):\n",
    "                    sent_and_amr.append({\n",
    "                        \"reference\": item[\"sentence\"],\n",
    "                        \"speech AMR\": amr_match,\n",
    "                        \"llama_run\": key,\n",
    "                        \"translation\": sent_match.lower()\n",
    "                    })\n",
    "            except (json.JSONDecodeError, TypeError) as e:\n",
    "                print(f\"Failed to parse {key} {item[key]}\\nbecause: {e}.\")\n",
    "\n",
    "llama_amr = []\n",
    "for item in sent_and_amr:\n",
    "    llama_amr.append(item[\"speech AMR\"])\n",
    "\n",
    "for item in llama_amr:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fd5d50bb-4ec4-4812-bba5-881ca28bd54b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Error parsing AMR: list index out of range\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Invalid AMR detected. Skipping...\n",
      "Average precision: 0.275\n",
      "Average recall: 0.242\n",
      "Average f1: 0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  i  in parsing AMR\n",
      "Error in parsing AMR (c/count-01 :mode imperative :ARG0 (s/signaler) :ARG1 (a/actor)) (d/deixis-GA :ARG0 s :ARG1 b/\n",
      "Duplicate node name  a  in parsing AMR\n",
      "Unmatched parenthesis at position 188 in processing (b / block   :quant 1   :location (o / on-top-of               :op1 (b2 / block                      :mod (t / that)                      :quant (e / each)                      :quant 2))))\n",
      "Unmatched parenthesis at position 188 in processing (b / block   :quant 1   :location (o / on-top-of               :op1 (b2 / block                      :mod (t / that)                      :quant (e / each)                      :quant 2))))\n",
      "Unmatched parenthesis at position 188 in processing (b / block   :quant 1   :location (o / on-top-of               :op1 (b2 / block                      :mod (t / that)                      :quant (e / each)                      :quant 2))))\n",
      "Error processing (o/ok :op1) op1\n",
      "Duplicate node name  i  in parsing AMR\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  i  in parsing AMR\n",
      "Duplicate node name  l  in parsing AMR\n",
      "Duplicate node name  i  in parsing AMR\n",
      "Duplicate node name  m  in parsing AMR\n",
      "Duplicate node name  y  in parsing AMR\n",
      "Duplicate node name  m  in parsing AMR\n",
      "Unmatched parenthesis at position 48 in processing (m / matter-01    :ARG0 (i / it)    :polarity -))\n",
      "Unmatched parenthesis at position 48 in processing (m / matter-01    :ARG0 (i / it)    :polarity -))\n",
      "Unmatched parenthesis at position 48 in processing (m / matter-01    :ARG0 (i / it)    :polarity -))\n",
      "Duplicate node name  t  in parsing AMR\n",
      "Error in processing; part len < 2 (i/icon-GA :op1 :\n",
      "Error in processing; part len < 2 (i/icon-GA :op1 :\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  i  in parsing AMR\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  i  in parsing AMR\n",
      "Duplicate node name  y  in parsing AMR\n",
      "Duplicate node name  y  in parsing AMR\n",
      "Duplicate node name  r  in parsing AMR\n",
      "Duplicate node name  y  in parsing AMR\n",
      "Duplicate node name  y  in parsing AMR\n",
      "Duplicate node name  p  in parsing AMR\n",
      "Unmatched parenthesis at position 102 in processing (g/grab-01 :mode imperative :ARG0 (y/you) :ARG1 (p/put-01 :ARG1 (s/slide :direction (l/left))) :mod ())\n",
      "Duplicate node name  l  in parsing AMR\n",
      "Duplicate node name  d  in parsing AMR\n",
      "Duplicate node name  m  in parsing AMR\n",
      "Duplicate node name  a  in parsing AMR\n",
      "Duplicate node name  m  in parsing AMR\n",
      "Duplicate node name  i  in parsing AMR\n",
      "Duplicate node name  l  in parsing AMR\n",
      "Duplicate node name  i  in parsing AMR\n",
      "Error in parsing AMR (i/icon-GA :op1 (d/deixis-GA :ARG0 s :ARG1 l/\n",
      "Error in parsing AMR (i/icon-GA :op1 (d/deixis-GA :ARG0 s :ARG1 l/\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  s  in parsing AMR\n",
      "Duplicate node name  y  in parsing AMR\n",
      "Duplicate node name  m  in parsing AMR\n",
      "Duplicate node name  l  in parsing AMR\n",
      "Duplicate node name  l  in parsing AMR\n",
      "Unmatched parenthesis at position 117 in processing (d / do-02    :ARG0 (y / you)    :ARG1 (p / process       :mod (s / same))     :mod (a / all)       :manner (u / up)))\n",
      "Unmatched parenthesis at position 117 in processing (d / do-02    :ARG0 (y / you)    :ARG1 (p / process       :mod (s / same))     :mod (a / all)       :manner (u / up)))\n",
      "Unmatched parenthesis at position 117 in processing (d / do-02    :ARG0 (y / you)    :ARG1 (p / process       :mod (s / same))     :mod (a / all)       :manner (u / up)))\n"
     ]
    }
   ],
   "source": [
    "## Check gold and predictions are the same length\n",
    "print(len(llama_amr))\n",
    "print(len(gold_speech_amrs))\n",
    "\n",
    "total_matched = 0\n",
    "total_gold = 0\n",
    "total_pred = 0\n",
    "\n",
    "for gold, pred in zip(gold_speech_amrs, llama_amr):\n",
    "    try:\n",
    "        amr_gold = amr.AMR.parse_AMR_line(gold)\n",
    "        amr_pred = amr.AMR.parse_AMR_line(pred)\n",
    "        if amr_gold is None or amr_pred is None:                   ## Many AMRs generated by Llama are invalid, these are skipped\n",
    "            print(\"Invalid AMR detected. Skipping...\")\n",
    "            continue\n",
    "        matched, gold_score, pred_score = smatch.get_amr_match(gold, pred)\n",
    "        \n",
    "        total_matched += matched\n",
    "        total_gold += gold_score\n",
    "        total_pred += pred_score\n",
    "    except Exception as e:                 \n",
    "        print(f\"Error parsing AMR: {e}\")\n",
    "\n",
    "precision = total_matched / total_pred if total_pred > 0 else 0\n",
    "recall = total_matched / total_gold if total_gold > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "print(f\"Average precision: {precision:.3f}\")\n",
    "print(f\"Average recall: {recall:.3f}\")\n",
    "print(f\"Average f1: {f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
