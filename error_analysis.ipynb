{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbaffebb-d73b-4421-a6e9-b244a5d984e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_llama as ulla\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101cb85-6536-47b7-8567-42eaa77961e5",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b788e9c-d396-46fd-bfca-0317733e2050",
   "metadata": {},
   "source": [
    "I put all output sentences in a .txt file, went through all mistakes and classified them either Propbank, polarity, deictic gestures, gesture information, AMR misinterpretation, incoherent or other. First I will count the results, then I will refine the prompt to hopefully improve the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "57f97be9-4c8c-4c6a-b01c-482c4306646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573\n"
     ]
    }
   ],
   "source": [
    "total_sentences = 0\n",
    "with open(\"error_analysis_annotated.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip().lower()\n",
    "        if not line:\n",
    "            continue\n",
    "        total_sentences += 1\n",
    "print(total_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14cefa1d-4480-4cbe-a1c7-8754a07617ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deictic: 46\n",
      "Propbank: 25\n",
      "Polarity: 23\n",
      "Gesture Information: 231\n",
      "AMR Misinterpretation: 176\n",
      "Incoherent: 44\n",
      "Other: 119\n",
      "No mistake: 41\n",
      "Total number of mistakes: 664\n"
     ]
    }
   ],
   "source": [
    "deictic, propbank, polarity, gesture, amr, incoherent, other, no_mistake, total = ulla.count_error_types(\"error_analysis_annotated.txt\")\n",
    "\n",
    "print(f\"Deictic: {deictic}\")\n",
    "print(f\"Propbank: {propbank}\")\n",
    "print(f\"Polarity: {polarity}\")\n",
    "print(f\"Gesture Information: {gesture}\")\n",
    "print(f\"AMR Misinterpretation: {amr}\")\n",
    "print(f\"Incoherent: {incoherent}\")\n",
    "print(f\"Other: {other}\")\n",
    "print(f\"No mistake: {no_mistake}\")\n",
    "print(f\"Total number of mistakes: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0528113-d6e1-4fb2-b4b0-00922802d948",
   "metadata": {},
   "source": [
    "## Prompt refinement\n",
    "Load the results from the Llama run. From these results I picked out 12 sentences to prompt Llama, this time with a refined prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47f5bd20-c360-4846-b934-6dbde5dfebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_llama = 'last_results_llama.pkl'\n",
    "results = pickle.load(open(results_llama, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5486f548-2991-441e-a4f7-a1c8c1356dc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"sentence\": \"It is good enough.\", \"explanation\": \"The speech AMR indicates that the predicate is 'enough' and it has an argument 'good'. This suggests a comparison or evaluation, where something is deemed sufficient or satisfactory. The sentence generated is a common idiomatic expression in English to convey this meaning.\"}]\n",
      "[{\"sentence\": \"It is good enough.\", \"explanation\": \"The speech AMR represents a sentence with the predicate 'enough' in the sense of 'good enough'. The ARG2 slot indicates that the object of the sentence is 'good', which is a complement to the adjective 'enough'. Therefore, the generated sentence is 'It is good enough.'\"}]\n",
      "[{\"sentence\": \"It is good enough.\", \"explanation\": \"The speech AMR indicates that the predicate 'enough' is being used, which means something meets a certain standard. The ARG2 slot specifies the argument for this predicate, which in this case is 'good'. This suggests that the subject (not explicitly mentioned) has reached or surpassed an acceptable level of quality.\"}]\n",
      "[{\"sentence\": \"You're okay.\", \"speech AMR\": \"(e/emblem-GA :ARG0 (s/signaler) :ARG1 (o/ok) :ARG2 (a/actor))\", \"explanation\": \"The gesture label indicates that the arms move up and hands open in front, which is a common emblem for 'okay'. The speech AMR reflects this interpretation.\"}]\n",
      "[{\"sentence\": \"It's okay.\", \"speech AMR\": \"(e/emblem-GA :ARG0 s :ARG1 o :ARG2 a)\", \"explanation\": \"The gesture label indicates that the speaker is signaling 'okay' with their arms and body movements. The speech AMR reflects this, with the emblem-GA relation indicating a symbolic or iconic representation of the concept 'ok'. The ARG0 is the signaler (the speaker), ARG1 is the ok symbol, and ARG2 is the actor (the person being addressed).\"}]\n",
      "[{\"sentence\": \"It's okay.\", \"speech AMR\": \"(e/emblem-GA :ARG0 s :ARG1 o :ARG2 a)\", \"explanation\": \"The gesture label indicates that the arms are moving up and hands are opening, which is typically associated with an 'okay' sign. The speech AMR reflects this interpretation, using the emblem-GA relation to connect the signaler (s) to the ok symbol (o) and the actor (a).\"}]\n",
      "[{\"sentence\": \"That's okay.\", \"explanation\": \"The gesture labels and AMRs indicate that the speaker is signaling approval or agreement. The arms moving up and hands entering an open position in front suggest a positive or affirmative gesture, while the body moving back and arms moving down may indicate a sense of completion or satisfaction. The speech AMR confirms this interpretation with the 'enough' relation and the good argument indicating that everything is satisfactory.\"}]\n",
      "[\n",
      "  {\n",
      "    \"sentence\": \"That's good enough.\",\n",
      "    \"explanation\": \"The gesture labels indicate a series of movements, starting with arms moving up and hands entering an open position in front. The body then moves back, followed by the arms moving down. This sequence suggests a completion or satisfaction, which is reinforced by the emblem-GA indicating 'ok' as the primary action. The speech AMR confirms this interpretation with 'enough-01' as the main concept and 'good' as its argument.\"\n",
      "  }\n",
      "]\n",
      "[{\"sentence\": \"That's good enough.\", \"explanation\": \"The gesture labels indicate that the speaker is moving their arms up and hands into an open position in front of them, then moving back with their body and lowering their arms. This suggests a sense of approval or agreement. The speech AMR indicates that the ARG2 (g/good) is the target of the 'enough' relation, which means that the speaker is indicating that something is satisfactory or acceptable. Therefore, the generated sentence is 'That's good enough.'\"}]\n"
     ]
    }
   ],
   "source": [
    "ref_transl_expl = []\n",
    "for item in results:\n",
    "    for key in [\"llama_1\", \"llama_2\", \"llama_3\"]:\n",
    "        if item['sentence'] == \"good enough\":\n",
    "            print(item[key])\n",
    "        #print(item[key])\n",
    "        try:\n",
    "            sentences = re.findall(r'\"sentence\"\\s*:\\s*\"([^\"]+)\"', item[key])\n",
    "            explanations = re.findall(r'\"explanation\"\\s*:\\s*\"([^\"]+)\"', item[key])\n",
    "            amrs = re.findall(r'\"speech AMR\"\\s*:\\s*\"([^\"]+)\"', item[key])\n",
    "            # print(sentences)\n",
    "            # print(explanations)\n",
    "            for sent, expl, amr in zip(sentences, explanations, amrs):\n",
    "                # if item['sentence'] == \"doesn't matter\":\n",
    "                #     print(sent)\n",
    "                #print(sent)\n",
    "                ref_transl_expl.append({\n",
    "                    \"reference\": item[\"sentence\"],\n",
    "                    \"scenario\": item['scenario'],\n",
    "                    \"llama_run\": key,\n",
    "                    \"translation\": sent.lower(),\n",
    "                    \"explanation\": expl\n",
    "                })\n",
    "                \n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"Failed to parse {key} {item[key]}\\nbecause: {e}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c0e06041-c150-4813-ba2c-cad7fde8c7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    }
   ],
   "source": [
    "print(len(ref_transl_expl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "997dd522-0b87-41aa-b000-a0454db4927f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        file                                           sentence  \\\n",
      "0   p15_gold          so put put a block on the back block good   \n",
      "0   p15_gold          so put put a block on the back block good   \n",
      "0   p15_gold          so put put a block on the back block good   \n",
      "4   p15_gold       no that doesn't look like it’s going to work   \n",
      "4   p15_gold       no that doesn't look like it’s going to work   \n",
      "4   p15_gold       no that doesn't look like it’s going to work   \n",
      "18  p18_gold                 just like that but closer together   \n",
      "18  p18_gold                 just like that but closer together   \n",
      "18  p18_gold                 just like that but closer together   \n",
      "20  p18_gold  move those together a little bit closer and th...   \n",
      "20  p18_gold  move those together a little bit closer and th...   \n",
      "20  p18_gold  move those together a little bit closer and th...   \n",
      "22  p19_gold                                 two more blocks up   \n",
      "22  p19_gold                                 two more blocks up   \n",
      "22  p19_gold                                 two more blocks up   \n",
      "24  p19_gold                                       go near yeah   \n",
      "24  p19_gold                                       go near yeah   \n",
      "24  p19_gold                                       go near yeah   \n",
      "25  p20_gold                    and uh one block uh ahead of it   \n",
      "25  p20_gold                    and uh one block uh ahead of it   \n",
      "25  p20_gold                    and uh one block uh ahead of it   \n",
      "30  p21_gold       can you just open it open it a little bit uh   \n",
      "30  p21_gold       can you just open it open it a little bit uh   \n",
      "30  p21_gold       can you just open it open it a little bit uh   \n",
      "53  p34_gold                        and the one on the very end   \n",
      "53  p34_gold                        and the one on the very end   \n",
      "53  p34_gold                        and the one on the very end   \n",
      "61  p41_gold                          push them up a little bit   \n",
      "61  p41_gold                          push them up a little bit   \n",
      "61  p41_gold                          push them up a little bit   \n",
      "63  p42_gold  and then you got two towers like that on the s...   \n",
      "63  p42_gold  and then you got two towers like that on the s...   \n",
      "63  p42_gold  and then you got two towers like that on the s...   \n",
      "64  p42_gold   and then you do that same process all the way up   \n",
      "64  p42_gold   and then you do that same process all the way up   \n",
      "64  p42_gold   and then you do that same process all the way up   \n",
      "\n",
      "                                           speech_amr  \\\n",
      "0   (p / put-01  :mode imperative  :ARG0 (y / you)...   \n",
      "0                                                None   \n",
      "0   (p / put-01  :mode imperative  :ARG0 (y / you)...   \n",
      "4   (m / multi-sentence  :snt1 (n / no)  :snt2 (l ...   \n",
      "4                                                None   \n",
      "4   (m / multi-sentence  :snt1 (n / no)  :snt2 (l ...   \n",
      "18  (p / put-01  :mode imperative   :ARG0 (y / you...   \n",
      "18                                               None   \n",
      "18  (p / put-01  :mode imperative   :ARG0 (y / you...   \n",
      "20  (a / and  :op1 (m / move   :mode imperative   ...   \n",
      "20                                               None   \n",
      "20  (a / and  :op1 (m / move   :mode imperative   ...   \n",
      "22             (b / block  :quant 2  :mod (m / more))   \n",
      "22                                               None   \n",
      "22             (b / block  :quant 2  :mod (m / more))   \n",
      "24                 (g / go-01  :manner (n / near-02))   \n",
      "24                                               None   \n",
      "24                 (g / go-01  :manner (n / near-02))   \n",
      "25  (a / and   :op2 (b / block          :quant 1  ...   \n",
      "25                                               None   \n",
      "25  (a / and   :op2 (b / block          :quant 1  ...   \n",
      "30  (o / open-01  :mode imperative  :polite +  :mo...   \n",
      "30                                               None   \n",
      "30  (o / open-01  :mode imperative  :polite +  :mo...   \n",
      "53  (a / and   :op2 (o / one          :location (o...   \n",
      "53                                               None   \n",
      "53  (a / and   :op2 (o / one          :location (o...   \n",
      "61  (p / push-01  :mode imperative  :ARG0 (y / you...   \n",
      "61                                               None   \n",
      "61  (p / push-01  :mode imperative  :ARG0 (y / you...   \n",
      "63  (g / get-01  :ARG0 (y / you)  :ARG1 (t / tower...   \n",
      "63                                               None   \n",
      "63  (g / get-01  :ARG0 (y / you)  :ARG1 (t / tower...   \n",
      "64  (d / do-02    :ARG0 (y / you)    :ARG1 (p / pr...   \n",
      "64                                               None   \n",
      "64  (d / do-02    :ARG0 (y / you)    :ARG1 (p / pr...   \n",
      "\n",
      "                                       gesture_labels  \\\n",
      "0                                                None   \n",
      "0   [RA: move, front; RH: point, front;, RA: move,...   \n",
      "0   [RA: move, front; RH: point, front;, RA: move,...   \n",
      "4                                                None   \n",
      "4   [arms: move, down; hands: into claw, down;, bo...   \n",
      "4   [arms: move, down; hands: into claw, down;, bo...   \n",
      "18                                               None   \n",
      "18  [arms: move, down back; hands: into fist, back...   \n",
      "18  [arms: move, down back; hands: into fist, back...   \n",
      "20                                               None   \n",
      "20  [arms: shake, left; hands: facing, closed;, ar...   \n",
      "20  [arms: shake, left; hands: facing, closed;, ar...   \n",
      "22                                               None   \n",
      "22  [RH: into two, up;, RA: move, back; RH: to face;]   \n",
      "22  [RH: into two, up;, RA: move, back; RH: to face;]   \n",
      "24                                               None   \n",
      "24  [arms: together, left; hands: facing, closed;,...   \n",
      "24  [arms: together, left; hands: facing, closed;,...   \n",
      "25                                               None   \n",
      "25  [body: still;, arms: move, up front; hands: in...   \n",
      "25  [body: still;, arms: move, up front; hands: in...   \n",
      "30                                               None   \n",
      "30                 [arms: shake;, arms: apart, left;]   \n",
      "30                 [arms: shake;, arms: apart, left;]   \n",
      "53                                               None   \n",
      "53  [body: still;, RH: into point, front;, RH: rot...   \n",
      "53  [body: still;, RH: into point, front;, RH: rot...   \n",
      "61                                               None   \n",
      "61  [body: move, down; arms: move, front;, body: m...   \n",
      "61  [body: move, down; arms: move, front;, body: m...   \n",
      "63                                               None   \n",
      "63  [arms: move, down, into gap, left; hands: into...   \n",
      "63  [arms: move, down, into gap, left; hands: into...   \n",
      "64                                               None   \n",
      "64  [RH: rotate, into point, left;, RA: rotate, in...   \n",
      "64  [RH: rotate, into point, left;, RA: rotate, in...   \n",
      "\n",
      "                                         gesture_amrs  num_gesture_amrs  \\\n",
      "0                                                None                 1   \n",
      "0   [(d / deixis-GA  :ARG0 (s / signaler)  :ARG1 (...                 1   \n",
      "0   [(d / deixis-GA  :ARG0 (s / signaler)  :ARG1 (...                 1   \n",
      "4                                                None                 2   \n",
      "4   [(i / icon-GA  :ARG0 (s / signaler)  :ARG1 (g ...                 2   \n",
      "4   [(i / icon-GA  :ARG0 (s / signaler)  :ARG1 (g ...                 2   \n",
      "18                                               None                 1   \n",
      "18  [(i / icon-GA  :ARG0 (s / signaler)  :ARG1 (m ...                 1   \n",
      "18  [(i / icon-GA  :ARG0 (s / signaler)  :ARG1 (m ...                 1   \n",
      "20                                               None                 2   \n",
      "20  [(g / gesture-unit  :op1 (d / deixis-GA   :ARG...                 2   \n",
      "20  [(g / gesture-unit  :op1 (d / deixis-GA   :ARG...                 2   \n",
      "22                                               None                 1   \n",
      "22  [(g / gesture-unit  :op1 (d / deixis-GA   :ARG...                 1   \n",
      "22  [(g / gesture-unit  :op1 (d / deixis-GA   :ARG...                 1   \n",
      "24                                               None                 2   \n",
      "24  [(i / icon-GA   :mode expressive  :ARG0 (s / s...                 2   \n",
      "24  [(i / icon-GA   :mode expressive  :ARG0 (s / s...                 2   \n",
      "25                                               None                 1   \n",
      "25  [(i / icon-GA   :ARG0 (s / signaler)   :ARG1 (...                 1   \n",
      "25  [(i / icon-GA   :ARG0 (s / signaler)   :ARG1 (...                 1   \n",
      "30                                               None                 1   \n",
      "30  [(i / icon-GA  :mode expressive  :ARG0 (s / si...                 1   \n",
      "30  [(i / icon-GA  :mode expressive  :ARG0 (s / si...                 1   \n",
      "53                                               None                 2   \n",
      "53  [(e / emblem-GA   :ARG0 (s / signaler)   :ARG1...                 2   \n",
      "53  [(e / emblem-GA   :ARG0 (s / signaler)   :ARG1...                 2   \n",
      "61                                               None                 1   \n",
      "61  [(a / and   :op1 (g / gesture-unit     :op1 (d...                 1   \n",
      "61  [(a / and   :op1 (g / gesture-unit     :op1 (d...                 1   \n",
      "63                                               None                 1   \n",
      "63  [(d / deixis-GA   :mode expressive    :ARG0 (s...                 1   \n",
      "63  [(d / deixis-GA   :mode expressive    :ARG0 (s...                 1   \n",
      "64                                               None                 1   \n",
      "64  [(a / and  :op1 (i / icon-GA   :ARG0 s   :ARG1...                 1   \n",
      "64  [(a / and  :op1 (i / icon-GA   :ARG0 s   :ARG1...                 1   \n",
      "\n",
      "       prompt_type  group_id  \n",
      "0           speech         3  \n",
      "0          gesture         3  \n",
      "0   speech_gesture         3  \n",
      "4           speech         1  \n",
      "4          gesture         1  \n",
      "4   speech_gesture         1  \n",
      "18          speech        19  \n",
      "18         gesture        19  \n",
      "18  speech_gesture        19  \n",
      "20          speech        20  \n",
      "20         gesture        20  \n",
      "20  speech_gesture        20  \n",
      "22          speech        23  \n",
      "22         gesture        23  \n",
      "22  speech_gesture        23  \n",
      "24          speech        21  \n",
      "24         gesture        21  \n",
      "24  speech_gesture        21  \n",
      "25          speech        25  \n",
      "25         gesture        25  \n",
      "25  speech_gesture        25  \n",
      "30          speech        30  \n",
      "30         gesture        30  \n",
      "30  speech_gesture        30  \n",
      "53          speech        51  \n",
      "53         gesture        51  \n",
      "53  speech_gesture        51  \n",
      "61          speech        62  \n",
      "61         gesture        62  \n",
      "61  speech_gesture        62  \n",
      "63          speech        64  \n",
      "63         gesture        64  \n",
      "63  speech_gesture        64  \n",
      "64          speech        63  \n",
      "64         gesture        63  \n",
      "64  speech_gesture        63  \n"
     ]
    }
   ],
   "source": [
    "## Load the test and train set I created\n",
    "example_dataframe = pd.read_pickle(\"example_df.pkl\")\n",
    "test_df = pd.read_pickle('test_df.pkl')\n",
    "\n",
    "## Create smaller dataframe of specific sentence I want to further explore\n",
    "target_sentences = [\n",
    "    \"so put put a block on the back block good\",                 ## speech amr and gesture labels (didnt perform well)\n",
    "    \"no that doesn't look like it’s going to work\",              ## polarity (didnt perform well)\n",
    "    \"and the one on the very end\",                               ## gesture amr isnt great (speech performed well, gesture not) \n",
    "    \"push them up a little bit\",                                 ## gesture amr and labels (speech performed perfect, gesture not)\n",
    "    \"and then you got two towers like that on the sides\",        ## \n",
    "    \"and then you do that same process all the way up\",          ## gesture info is nice however llama doesnt seem to use the amr\n",
    "    \"two more blocks up\",                                        ## gesture amr and labels are representative \n",
    "    \"and uh one block uh ahead of it\",\n",
    "    \"move those together a little bit closer and then put that on top yay\",    ## gesture info\n",
    "    \"just like that but closer together\",                        ## gesture info could be useful, speech and gesture dont perform well\n",
    "    \"go near yeah\",                                              ## gesture info useful, speech performed well\n",
    "    \"can you just open it open it a little bit uh\"               ## gesture info useful, speech performed well\n",
    "]\n",
    "df_subset = test_df[test_df['sentence'].isin(target_sentences)].copy()\n",
    "print(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5974f51-6703-4ca5-88e7-41057c2b69e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okay\n",
      "space two out a little less than a block length\n",
      "four blocks in the front okay\n",
      "it cannot fall down from the ground right\n",
      "five blocks to start\n",
      "now these are a little jiggled\n",
      "you're done\n",
      "put a bit a bit right uh\n",
      "it starts in the top left\n",
      "same direction that that's pushed off yea alright\n",
      "it's gonna be a pyramid from three of the rows of two\n",
      "then they connect to the two wider blocks\n",
      "okay\n",
      "get another one stacked on top\n",
      "move that block uh\n",
      "they’re in other words are not perfectly clear\n",
      "them towards you\n",
      "then you going to have a fourth block\n",
      "just one\n",
      "and go\n",
      "the base is going to have four second one’s going to have three then two on top of that and then one\n",
      "start off with just a block and then put a block on top of\n",
      "stack stack it up no\n",
      "stack three blocks on one side yup\n",
      "like about a third of a block a part so more close in than that\n",
      "four blocks\n",
      "great yep\n",
      "seven blocks in a row\n",
      "and then three more coming off from the other direction touching the corner okay\n",
      "and then the second block goes on top of that\n",
      "starting at row three column three\n",
      "yeah great\n",
      "closest to the middle yeah\n",
      "gonna have another block right next to that block so it’d be over the space of those two bottom blocks\n",
      "and one block on the right side of the first block and move back a bit\n",
      "take one block put it on top of those two in the middle\n",
      "the block you have in your left hand or in your hands goes in between that diagonal shape yep\n",
      "and uh two blocks\n",
      "more great\n",
      "spread them apart a little bit but not as wide as a full block\n",
      "all right put a block down\n",
      "ever so slightly alright\n",
      "then a last block on the crack of those two blocks\n",
      "and then take the two on top\n",
      "this one looks like a (oh sorry) this one looks like a smiley face\n",
      "and there's one touching that block's bottom corner\n",
      "then the gap should be a little less of between him\n",
      "almost like that\n",
      "i want you to tilt all of them so that the one corner is touching\n",
      "it kind of goes down diagonally or so in yours\n",
      "and it's turned at an angle\n",
      "place it such that they are like interleaving\n",
      "ah now uh move it so it's on the front front one and the one you just put it on\n",
      "like they're all stacked right on top of each other\n",
      "yep and then get the last block or another block and put it on top of the one\n",
      "the right were were about correct\n",
      "you have two blocks on top of these\n",
      "on that exactly on that axis so\n",
      "yeah\n",
      "move that about one that tower about one block over\n",
      "that's it\n",
      "think of like a wifi signal where it’s a u shape\n",
      "just like that and then you’re gonna do that one more time in the same direction so it’s kind of like a slanting height three yeah\n",
      "not not too much\n",
      "okay perfect\n",
      "and two blocks like making it smile\n",
      "scoot it over so there's the blocks are flush on one side\n",
      "so like fanned out away from you\n",
      "just turn it turn it vertical okay\n",
      "on the side with three the one closest to the middle put another block on top\n",
      "in the middle\n",
      "and turn it so it's parallel\n",
      "yup\n",
      "then that’s it for your base uh your height you’re every\n",
      "and then there must be one a hard that i'm having time seeing behind\n",
      "place it so it's um sitting in between the two like that\n",
      "okay\n",
      "have two blocks right next to each other\n",
      "three to one but they all gonna be rotated a\n",
      "put a block one block apart behind\n",
      "right there uh\n",
      "like not stacked\n",
      "alright\n",
      "so starting from the top moving to your left down four diagonally a row with the corners\n",
      "move forward a bit\n",
      "both sides\n",
      "alright grab three blocks\n",
      "yea yea and then it\n",
      "take one block and put it on the table\n",
      "alright move one of the blocks off to the side\n",
      "yea and touching corners\n",
      "yea on the side with four on the last one on the inside corner there is another block yeah\n",
      "one block on each side\n",
      "five blocks in a row right in front of them\n",
      "okay and\n",
      "but it's still in berlin\n",
      "please close a little bit the base the base\n",
      "so that’s our new you did not miss from in right blocks space\n",
      "move them this direction like you had it before so they’re touching corners\n",
      "on top of that you're going to between the overlapping the two you're going to have two blocks or the uh middle three\n",
      "so you could squeeze them together a little bit there you go\n",
      "block the goes on top of the block you just placed but not totally centered\n",
      "this one is like three towers next to each other\n",
      "now the ones i just told you to put that were two that last two i told you to put\n",
      "put them to the side of that little section so they line up\n",
      "they gonna be all connecting\n",
      "it's just on the table\n",
      "you see how there are three divots\n",
      "three blocks\n",
      "it will be diagonal like a diamond no no no\n",
      "make a little bit of gap but in line with the back block okay\n",
      "and then grab another block\n",
      "save on the fourth block on the other side\n",
      "that one okay\n",
      "yep\n",
      "looks like like a like jenga\n",
      "maybe just pushed like slightly in the same\n",
      "the third block is it's on top of that block but it's pushed just slightly to the a off of it\n",
      "one on the your le- yeah that one your left side its gonna be just one on top\n",
      "keep them like turn them hor- vertically\n",
      "good\n",
      "two eyes first\n",
      "um i think everything needs to be slightly closer together\n",
      "stick them on the table in a line in front of you\n",
      "get two blocks and put them on the\n",
      "no no\n",
      "close a little bit more not\n",
      "but bothe opposite way like\n",
      "yeah\n",
      "now stick a block on the front one and the one to your left\n",
      "every things on top of that\n",
      "and then put the third one on the fourth one on top of these the middle one\n",
      "we’ll have another block just falling down as if it just for fell down from heaven\n",
      "and then there's two blocks um a little bit like out and then down or up for you\n",
      "and they are just straight\n",
      "the bottom layer starts with four blocks\n",
      "all right then stick\n",
      "and do the exact same thing there\n",
      "behind the two one and\n",
      "and you can you can place them close to each other\n",
      "those too blocks right next each other\n",
      "okay and they’e just kind of jiggled around\n",
      "and one block left of the first block first block and a bit in front of it\n",
      "the three blocks all touch and they’re straight\n",
      "between the block you just placed and the third block on that side it's touching those two corners\n",
      "close even more close but not touching yeah\n",
      "i want you take one block\n",
      "yeah and\n",
      "get two more blocks\n",
      "one right next to it touching\n",
      "get two blocks\n",
      "the blocks are turned like half way on top of each block yeah\n",
      "and a little near you\n",
      "center them on top of where the three blocks meet on it either side\n",
      "they're more laid out in a flower pattern\n",
      "scoot the five over\n",
      "and don't rotate don't don't rotate yeah\n",
      "the first block is like is like like the first tower yeah\n",
      "put a block on like like on the crack of those two blocks\n",
      "grab one more block place\n",
      "that looks good\n",
      "stick it on the other side divot\n",
      "yes\n",
      "now do it on the other side\n",
      "touching corners touching corners\n",
      "yeah\n",
      "one block on top of the both\n",
      "just like you’re building a tower\n",
      "we’re building up a even column i guess so\n",
      "i'm not sure yeah\n",
      "okay this one's somewhat similar to the last one except it's a four four layers\n",
      "don’t do that exactly\n",
      "to\n",
      "and um the middle tower\n",
      "count in with your left hand count to block three and four\n",
      "and one block pick up one block and it is in front of the block you just put it and rotate it forty five degrees\n",
      "so then your next one is going to be up one and it's going to be shifted over half a block to\n",
      "good enough good enough\n",
      "towards to me at the top layer block\n",
      "it stacks like straight up\n",
      "just four\n"
     ]
    }
   ],
   "source": [
    "# Turn example df into a list of dicts\n",
    "examples = []\n",
    "\n",
    "for idx, row in example_dataframe.iterrows():\n",
    "    examples.append({\n",
    "        \"sentence\": row.get(\"sentence\"),\n",
    "        \"speech_amr\": row.get(\"speech_amr\"),\n",
    "        \"gesture_amrs\": row.get(\"gesture_amrs\"),\n",
    "        \"gesture_labels\": row.get(\"gesture_labels\"),\n",
    "        \"num_gesture_amrs\": row.get(\"num_gesture_amrs\"),\n",
    "    })\n",
    "\n",
    "for item in examples:\n",
    "    print(item['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37e0ef95-b810-4eea-8c35-7a6c3e319c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to the server\n",
    "client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"cltl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1163573-72fd-472c-8d31-509259ccdfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 36/36 [1:20:19<00:00, 133.88s/row]\n"
     ]
    }
   ],
   "source": [
    "random.seed(12)\n",
    "\n",
    "## First error analysis run\n",
    "results_ea = []\n",
    "prompts = ulla.generate_prompt_error_anaysis(df_subset, examples)\n",
    "total_prompts = len(prompts)\n",
    "for prompt in tqdm(prompts, total=total_prompts, desc=\"Processing\", unit=\"row\"):\n",
    "    call_llama = ulla.query_LLM_multiple(client, prompt[\"prompt\"], temp=0.3, n=3)\n",
    "    results_ea.append({\n",
    "        \"prompt\": prompt[\"prompt\"],\n",
    "        \"sentence\": prompt[\"meta\"][\"sentence\"],\n",
    "        \"scenario\": prompt[\"meta\"][\"scenario\"],\n",
    "        \"file\": prompt[\"meta\"][\"file\"],\n",
    "        \"llama_1\": call_llama[0],\n",
    "        \"llama_2\": call_llama[1],\n",
    "        \"llama_3\": call_llama[2]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4e2d3a5e-52e7-4041-a9ff-4d09a595346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save results to file each run since I'm restarting the kernel\n",
    "file_ea1 = \"first_ea.pkl\"\n",
    "pickle.dump(results_ea, open(file_ea1, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eeb54fd3-2eb8-44cb-82ba-8453f16dff99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"first_ea.pkl\", \"rb\") as f:\n",
    "    first_ea = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c4ee20b-06f5-4986-949b-62ea344a4ceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reference': 'can you just open it open it a little bit uh', 'scenario': 'speech', 'llama_run': 'llama_1', 'translation': 'just open it a bit, please.', 'explanation': \"I interpreted the speech AMR by identifying the main action 'open-01' and its arguments. The mode is imperative, indicating that the speaker is giving a command, which corresponds to the polite request in the generated sentence. The modifier 'just' was used to convey the idea of doing something slightly or minimally, as indicated by the degree 'bit' with the modifier 'little'. The pronouns 'you' and 'it' were identified from the ARG0 and ARG1 slots, respectively.\"}\n",
      "{'reference': 'can you just open it open it a little bit uh', 'scenario': 'speech', 'llama_run': 'llama_3', 'translation': 'just open it a bit.', 'explanation': \"I interpreted the speech AMR by focusing on the main action 'open-01' and its arguments. The mode is imperative, indicating that the speaker is giving a command, which matches the polite tone. The mod 'j/just' suggests adding a sense of moderation or caution to the action, so I added 'a bit' to convey this nuance. The ARG0 and ARG1 indicate the subject (you) and object (it), respectively.\"}\n",
      "{'reference': 'can you just open it open it a little bit uh', 'scenario': 'gesture', 'llama_run': 'llama_1', 'translation': 'place it so that they are not touching.', 'explanation': 'The gesture labels indicate the arms shaking, which suggests a sense of separation or non-contact. The next label shows the arms moving apart, further emphasizing this idea. Therefore, I interpreted these gestures as indicating that the speaker wants to place an object in such a way that it is not touching something else.'}\n",
      "{'reference': 'can you just open it open it a little bit uh', 'scenario': 'gesture', 'llama_run': 'llama_2', 'translation': 'place it such that they are far from each other.', 'explanation': \"The participant is using gestures to explain how to place an object in a way that two other objects are far from each other. The gesture label 'arms: shake' suggests a sense of separation or distance, which is reinforced by the gesture label 'arms: apart, left'. This indicates that the speaker wants to convey a sense of spatial arrangement where the objects are not close together. Therefore, I generated a sentence that reflects this idea.\"}\n",
      "{'reference': 'can you just open it open it a little bit uh', 'scenario': 'gesture', 'llama_run': 'llama_3', 'translation': 'place it so that they are far apart.', 'explanation': \"I interpreted the gesture information as follows: The participant is explaining how to construct a block structure and uses gestures to convey this information. The first gesture label 'arms: shake' indicates that the participant wants to emphasize or draw attention to something. This is likely related to the placement of blocks in the structure. The second gesture label 'arms: apart, left' suggests that the participant wants to convey a sense of distance or separation between two things. In this context, it's likely that the participant is referring to the blocks being placed far apart from each other. Therefore, I generated the sentence 'Place it so that they are far apart.' and the corresponding speech AMR '(p/place-01 :mode imperative :ARG0 (y/you) :ARG1 (i/it) :cause-of (a/apart))' to reflect this interpretation.\"}\n",
      "{'reference': 'can you just open it open it a little bit uh', 'scenario': 'speech_gesture', 'llama_run': 'llama_1', 'translation': 'open it a bit just apart.', 'explanation': \"To generate the sentence, I combined the speech AMR with the gesture information. The speech AMR indicates that the speaker is using an imperative mode and wants to open something 'a bit' (degree is 'b/bit'). The gesture labels show arms moving apart, which matches the gesture AMR's ARG1 being 'apart'. This suggests that the speaker is trying to convey a physical action of opening something by moving it apart. Therefore, I generated the sentence 'Open it a bit just apart.'\"}\n",
      "{'reference': 'can you just open it open it a little bit uh', 'scenario': 'speech_gesture', 'llama_run': 'llama_2', 'translation': 'open it a bit just apart.', 'explanation': \"I generated the sentence by combining the speech and gesture information. The speech AMR indicates an imperative mode with a polite tone, suggesting that the speaker is giving a command to the listener. The ARG0 (y/you) and ARG1 (i/it) indicate that the speaker is addressing the listener and referring to an object or entity. The degree (b/bit l/little) suggests that the speaker wants the listener to open it only slightly.\\n\\nThe gesture AMR indicates a mode of expressive gestures, which matches with the imperative tone in the speech AMR. The ARG0 (s/signaler) and ARG2 (a/actor) indicate that the speaker is performing the gesture and referring to an entity or object.\\n\\nThe gesture labels provide more specific information about the gestures performed by the speaker. The arms: shake indicates a sudden movement of the arms, which can be interpreted as a way of emphasizing or drawing attention to something. The arms: apart, left suggests a widening or spreading motion, which can be related to the concept of 'apart' in the gesture AMR.\\n\\nCombining these elements, I generated the sentence 'Open it a bit just apart.' This sentence reflects the speaker's intention to have the listener open an object or entity, but only slightly, and in a way that is separate or distinct from other entities.\"}\n",
      "{'reference': 'can you just open it open it a little bit uh', 'scenario': 'speech_gesture', 'llama_run': 'llama_3', 'translation': 'open it a bit, just apart.', 'explanation': \"The gesture labels indicate that the speaker is making expressive gestures with their arms. The first arm movement is described as 'shake', which could imply some kind of emphasis or stress on the action. The second arm movement is 'apart, left', suggesting that the speaker is gesturing to create space or distance between two things. The speech AMR indicates an imperative mode and polite tone, with the speaker addressing the listener directly (y/you). The verb 'open' in the speech AMR matches the gesture AMR's icon class 'icon-GA' which represents a signal or action. Therefore, the sentence generated is 'Open it a bit, just apart.'\"}\n"
     ]
    }
   ],
   "source": [
    "ref_and_transl = []\n",
    "\n",
    "for item in first_ea:\n",
    "    for key in [\"llama_1\", \"llama_2\", \"llama_3\"]:\n",
    "        try:\n",
    "            sentences = re.findall(r'\"sentence\"\\s*:\\s*\"([^\"]+)\"', item[key])\n",
    "            explanations = re.findall(r'\"explanation\"\\s*:\\s*\"([^\"]+)\"', item[key])\n",
    "            for sent, expl in zip(sentences, explanations):\n",
    "                ref_and_transl.append({\n",
    "                    \"reference\": item[\"sentence\"],\n",
    "                    \"scenario\": item['scenario'],\n",
    "                    \"llama_run\": key,\n",
    "                    \"translation\": sent.lower(),\n",
    "                    \"explanation\": expl\n",
    "                })\n",
    "                \n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"Failed to parse {key} {item[key]}\\nbecause: {e}.\")\n",
    "\n",
    "for item in ref_and_transl:\n",
    "    if item['reference'] == \"can you just open it open it a little bit uh\":\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4993cd1-d36f-4d06-9e02-d8d64b7704e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A very specific question!\n",
      "\n",
      "PropBank is a large-scale, linguistically motivated semantic role labeling (SRL) resource that annotates predicate-argument structures for verbs in a sentence. It's a comprehensive dataset used to train and evaluate SRL systems.\n",
      "\n",
      "After checking the documentation and resources related to PropBank, I found that \"look-01\" and \"look-02\" are two different verb sense annotations in PropBank. Specifically:\n",
      "\n",
      "* `look-01` represents the verb sense of looking at or observing something with one's eyes (e.g., \"She looked at the picture.\").\n",
      "* `look-02` represents the verb sense of searching for something, often implying a more active or intentional search (e.g., \"He looked for his keys.\").\n",
      "\n",
      "These two senses are distinguished based on the meaning and context in which the verb is used. The PropBank annotation scheme uses this distinction to capture the nuances of verb meaning and its interactions with other elements in the sentence.\n",
      "\n",
      "Is there anything else I can help you with regarding PropBank or SRL?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Do you know the difference between look-01 and look-02 in Propbank?\"\"\"\n",
    "print(ulla.query_LLM(client, prompt, temp=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c39940e8-3954-4372-938c-4d0979b1a6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In an Abstract Meaning Representation (AMR), the notation `:ARGn` refers to the arguments of a predicate or relation.\n",
      "\n",
      "* `ARG0` is typically the \"doer\" or the subject of the action described by the sentence. In this case, it's the person performing the action.\n",
      "* `ARG1` represents the direct object or the thing affected by the action. Here, it's the specific block (one instance).\n",
      "* `ARG2` represents the indirect object or a secondary participant in the action. In this example, it's another block that is somehow related to the first block.\n",
      "\n",
      "In more detail:\n",
      "\n",
      "* You are performing an action (putting something somewhere)\n",
      "* The direct object of your action is one specific block\n",
      "* The secondary participant involved is another block, which is specified as being \"back\" (implying it's on the back side of something or in a position that's not directly related to the main action)\n",
      "\n",
      "The AMR format allows for more nuance and detail about the relationships between entities in a sentence than traditional dependency parsing or other syntactic representations.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Look at the following Abstract Meaning Representation\n",
    "(p/put-01\n",
    "\t:mode imperative\n",
    "\t:ARG0 (y/you)\n",
    "\t:ARG1 (b/block\n",
    "\t\t:quant 1)\n",
    "\t:ARG2 (b2/block\n",
    "\t\t:mod (b3/back)))\n",
    "Do you know what ARG0, ARG1 and ARG2 indicate?\n",
    "\"\"\"\n",
    "print(ulla.query_LLM(client, prompt, temp=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dda8a177-3f30-4ccb-9a94-028cce7f356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deictic: 5\n",
      "Propbank: 10\n",
      "Polarity: 4\n",
      "Gesture Information: 57\n",
      "AMR Misinterpretation: 39\n",
      "Incoherent: 5\n",
      "Other: 14\n",
      "No mistake: 9\n",
      "Total number of mistakes: 134\n"
     ]
    }
   ],
   "source": [
    "total_sentences = 0\n",
    "with open(\"refined1.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip().lower()\n",
    "        if not line:\n",
    "            continue\n",
    "        total_sentences += 1\n",
    "print(total_sentences)\n",
    "\n",
    "## Count errors in the 12 selected sentences\n",
    "deictic, propbank, polarity, gesture, amr, incoherent, other, no_mistake, total = ulla.count_error_types(\"refined1.txt\")\n",
    "\n",
    "print(f\"Deictic: {deictic}\")\n",
    "print(f\"Propbank: {propbank}\")\n",
    "print(f\"Polarity: {polarity}\")\n",
    "print(f\"Gesture Information: {gesture}\")\n",
    "print(f\"AMR Misinterpretation: {amr}\")\n",
    "print(f\"Incoherent: {incoherent}\")\n",
    "print(f\"Other: {other}\")\n",
    "print(f\"No mistake: {no_mistake}\")\n",
    "print(f\"Total number of mistakes: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d714cd2-62f8-47b3-ad19-9109c96caa52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 36/36 [1:19:46<00:00, 132.96s/row]\n"
     ]
    }
   ],
   "source": [
    "## Second error analysis run --> prompt changed slightly\n",
    "random.seed(12)\n",
    "\n",
    "results_ea2 = []\n",
    "prompts = ulla.generate_prompt_error_anaysis(df_subset, examples)\n",
    "total_prompts = len(prompts)\n",
    "for prompt in tqdm(prompts, total=total_prompts, desc=\"Processing\", unit=\"row\"):\n",
    "    call_llama = ulla.query_LLM_multiple(client, prompt[\"prompt\"], temp=0.3, n=3)\n",
    "    results_ea2.append({\n",
    "        \"prompt\": prompt[\"prompt\"],\n",
    "        \"sentence\": prompt[\"meta\"][\"sentence\"],\n",
    "        \"scenario\": prompt[\"meta\"][\"scenario\"],\n",
    "        \"file\": prompt[\"meta\"][\"file\"],\n",
    "        \"llama_1\": call_llama[0],\n",
    "        \"llama_2\": call_llama[1],\n",
    "        \"llama_3\": call_llama[2]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f7bf97a9-51c2-4023-8f6f-890944b35f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save results to file each run since I'm restarting the kernel\n",
    "file_ea2 = \"second_ea.pkl\"\n",
    "pickle.dump(results_ea2, open(file_ea2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8643026-c3f1-4788-a02f-f632c8b99394",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"second_ea.pkl\", \"rb\") as f:\n",
    "    second_ea = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6800d1d1-b98a-4189-963d-3b68fc04be23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'second_ea' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m ref_and_transl = []\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43msecond_ea\u001b[49m:\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m#print(item['sentence'], item['scenario'])\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mllama_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mllama_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mllama_3\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      6\u001b[39m         \u001b[38;5;66;03m#print(item[key])\u001b[39;00m\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'second_ea' is not defined"
     ]
    }
   ],
   "source": [
    "ref_and_transl = []\n",
    "\n",
    "for item in second_ea:\n",
    "    for key in [\"llama_1\", \"llama_2\", \"llama_3\"]:\n",
    "        try:\n",
    "            sentences = re.findall(r'\"sentence\"\\s*:\\s*\"([^\"]+)\"', item[key])\n",
    "            explanations = re.findall(r'\"explanation\"\\s*:\\s*\"([^\"]+)\"', item[key])\n",
    "            for sent, expl in zip(sentences, explanations):\n",
    "                ref_and_transl.append({\n",
    "                    \"reference\": item[\"sentence\"],\n",
    "                    \"scenario\": item['scenario'],\n",
    "                    \"llama_run\": key,\n",
    "                    \"translation\": sent.lower(),\n",
    "                    \"explanation\": expl\n",
    "                })\n",
    "                \n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"Failed to parse {key} {item[key]}\\nbecause: {e}.\")\n",
    "\n",
    "for item in ref_and_transl:\n",
    "    if item['reference'] == \"doesn't matter\":\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20aa5422-fa97-4252-8b69-ad39bbd773a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deictic: 2\n",
      "Propbank: 11\n",
      "Polarity: 6\n",
      "Gesture Information: 56\n",
      "AMR Misinterpretation: 30\n",
      "Incoherent: 7\n",
      "Other: 19\n",
      "No mistake: 5\n",
      "Total number of mistakes: 131\n"
     ]
    }
   ],
   "source": [
    "## Count errors in the 12 selected sentences\n",
    "deictic, propbank, polarity, gesture, amr, incoherent, other, no_mistake, total = ulla.count_error_types(\"refined2.txt\")\n",
    "\n",
    "print(f\"Deictic: {deictic}\")\n",
    "print(f\"Propbank: {propbank}\")\n",
    "print(f\"Polarity: {polarity}\")\n",
    "print(f\"Gesture Information: {gesture}\")\n",
    "print(f\"AMR Misinterpretation: {amr}\")\n",
    "print(f\"Incoherent: {incoherent}\")\n",
    "print(f\"Other: {other}\")\n",
    "print(f\"No mistake: {no_mistake}\")\n",
    "print(f\"Total number of mistakes: {total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
